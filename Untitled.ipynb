{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "667d174a-5003-4b48-9402-8855e69f85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69b4564f-0213-45bb-8328-3798ac1f1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./mbti_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f221cd8-0edb-4850-b6b7-2b3b3b893feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>I see someone looking for freedom, trying to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>'Wait, what? You're looking for traits of an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'Maybe you could ask people on here to talk ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'I would say so.  I cannot say I have ever bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'This door may be impractical, it's still a co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type                                              posts\n",
       "0   1  INTJ  I see someone looking for freedom, trying to e...\n",
       "1   2  ENTP  'Wait, what? You're looking for traits of an a...\n",
       "2   3  INTP  'Maybe you could ask people on here to talk ab...\n",
       "3   4  INFP  'I would say so.  I cannot say I have ever bee...\n",
       "4   5  INTJ  'This door may be impractical, it's still a co..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d22966e-7e6b-486e-9379-98ae1e4dc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据处理函数\n",
    "def cleanReview(subject):\n",
    "    beau = BeautifulSoup(subject)\n",
    "    newSubject = beau.get_text()\n",
    "    newSubject = newSubject.replace(\"\\\\\", \"\").replace(\"\\'\", \"\").replace('/', '').replace('\"', '').replace(',', '').replace('.', '').replace('?', '').replace('(', '').replace(')', '').replace('|||', '')\n",
    "    newSubject = newSubject.strip().split(\" \")\n",
    "    newSubject = [word.lower() for word in newSubject]\n",
    "    newSubject = \" \".join(newSubject)\n",
    "    \n",
    "    return newSubject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1fcae99e-9738-4c96-949d-a55375347a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df1=pd.DataFrame(train['posts'].str.split('|||').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ec50d6a-af43-471f-8739-81e39e20e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= train['posts'].apply(cleanReview)\n",
    "df=pd.concat([train_x, train['type']], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d26c38a9-171a-4fd0-bb46-54b4680a304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./wordEmbdiing.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8caa2c4-4560-46e1-917e-fdc3b7726813",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 19:59:02,449 : INFO : collecting all words and their counts\n",
      "2021-06-27 19:59:02,451 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-06-27 19:59:04,531 : INFO : PROGRESS: at sentence #10000, processed 7240394 words, keeping 294491 word types\n",
      "2021-06-27 19:59:04,535 : INFO : collected 294491 word types from a corpus of 7242395 raw words and 12001 sentences\n",
      "2021-06-27 19:59:04,536 : INFO : Loading a fresh vocabulary\n",
      "2021-06-27 19:59:04,704 : INFO : effective_min_count=5 retains 31480 unique words (10% of original 294491, drops 263011)\n",
      "2021-06-27 19:59:04,705 : INFO : effective_min_count=5 leaves 6914726 word corpus (95% of original 7242395, drops 327669)\n",
      "2021-06-27 19:59:04,808 : INFO : deleting the raw counts dictionary of 294491 items\n",
      "2021-06-27 19:59:04,817 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2021-06-27 19:59:04,818 : INFO : downsampling leaves estimated 5149775 word corpus (74.5% of prior 6914726)\n",
      "2021-06-27 19:59:04,894 : INFO : estimated required memory for 31480 words and 1000 dimensions: 267580000 bytes\n",
      "2021-06-27 19:59:04,895 : INFO : resetting layer weights\n",
      "2021-06-27 19:59:12,891 : INFO : training model with 3 workers on 31480 vocabulary and 1000 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-06-27 19:59:13,963 : INFO : EPOCH 1 - PROGRESS: at 0.87% examples, 81077 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:15,032 : INFO : EPOCH 1 - PROGRESS: at 1.86% examples, 87186 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:16,056 : INFO : EPOCH 1 - PROGRESS: at 2.78% examples, 90258 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 19:59:17,105 : INFO : EPOCH 1 - PROGRESS: at 3.76% examples, 91716 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:18,144 : INFO : EPOCH 1 - PROGRESS: at 4.77% examples, 92802 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:19,193 : INFO : EPOCH 1 - PROGRESS: at 5.78% examples, 93287 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:20,198 : INFO : EPOCH 1 - PROGRESS: at 6.69% examples, 93358 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:21,243 : INFO : EPOCH 1 - PROGRESS: at 7.64% examples, 93769 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:22,259 : INFO : EPOCH 1 - PROGRESS: at 8.54% examples, 94059 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:23,286 : INFO : EPOCH 1 - PROGRESS: at 9.48% examples, 94525 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:24,384 : INFO : EPOCH 1 - PROGRESS: at 10.45% examples, 94327 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:25,411 : INFO : EPOCH 1 - PROGRESS: at 11.39% examples, 94521 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:26,464 : INFO : EPOCH 1 - PROGRESS: at 12.35% examples, 94535 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:27,495 : INFO : EPOCH 1 - PROGRESS: at 13.32% examples, 94591 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:28,569 : INFO : EPOCH 1 - PROGRESS: at 14.27% examples, 94513 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:29,613 : INFO : EPOCH 1 - PROGRESS: at 15.22% examples, 94562 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:30,651 : INFO : EPOCH 1 - PROGRESS: at 16.17% examples, 94629 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:31,685 : INFO : EPOCH 1 - PROGRESS: at 17.18% examples, 94980 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:32,689 : INFO : EPOCH 1 - PROGRESS: at 18.07% examples, 94912 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:33,747 : INFO : EPOCH 1 - PROGRESS: at 19.06% examples, 94858 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:34,793 : INFO : EPOCH 1 - PROGRESS: at 20.00% examples, 94910 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:35,813 : INFO : EPOCH 1 - PROGRESS: at 20.96% examples, 95006 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:36,871 : INFO : EPOCH 1 - PROGRESS: at 21.99% examples, 95253 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:37,894 : INFO : EPOCH 1 - PROGRESS: at 22.97% examples, 95295 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:38,955 : INFO : EPOCH 1 - PROGRESS: at 23.96% examples, 95249 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 19:59:40,007 : INFO : EPOCH 1 - PROGRESS: at 24.97% examples, 95251 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:41,021 : INFO : EPOCH 1 - PROGRESS: at 25.94% examples, 95303 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:42,079 : INFO : EPOCH 1 - PROGRESS: at 26.92% examples, 95266 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:43,088 : INFO : EPOCH 1 - PROGRESS: at 27.94% examples, 95397 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:44,140 : INFO : EPOCH 1 - PROGRESS: at 28.94% examples, 95417 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:45,181 : INFO : EPOCH 1 - PROGRESS: at 29.89% examples, 95441 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:46,219 : INFO : EPOCH 1 - PROGRESS: at 30.91% examples, 95454 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:47,259 : INFO : EPOCH 1 - PROGRESS: at 31.90% examples, 95480 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:48,309 : INFO : EPOCH 1 - PROGRESS: at 32.83% examples, 95476 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:49,366 : INFO : EPOCH 1 - PROGRESS: at 33.80% examples, 95481 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:50,410 : INFO : EPOCH 1 - PROGRESS: at 34.81% examples, 95517 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:51,416 : INFO : EPOCH 1 - PROGRESS: at 35.76% examples, 95490 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:52,479 : INFO : EPOCH 1 - PROGRESS: at 36.71% examples, 95447 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:53,488 : INFO : EPOCH 1 - PROGRESS: at 37.71% examples, 95542 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:54,492 : INFO : EPOCH 1 - PROGRESS: at 38.72% examples, 95644 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:55,527 : INFO : EPOCH 1 - PROGRESS: at 39.71% examples, 95659 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:56,560 : INFO : EPOCH 1 - PROGRESS: at 40.68% examples, 95677 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:57,573 : INFO : EPOCH 1 - PROGRESS: at 41.65% examples, 95722 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:58,599 : INFO : EPOCH 1 - PROGRESS: at 42.59% examples, 95651 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 19:59:59,612 : INFO : EPOCH 1 - PROGRESS: at 43.55% examples, 95695 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:00,628 : INFO : EPOCH 1 - PROGRESS: at 44.49% examples, 95744 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:01,637 : INFO : EPOCH 1 - PROGRESS: at 45.39% examples, 95674 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:02,662 : INFO : EPOCH 1 - PROGRESS: at 46.29% examples, 95687 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:03,696 : INFO : EPOCH 1 - PROGRESS: at 47.25% examples, 95721 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:04,742 : INFO : EPOCH 1 - PROGRESS: at 48.25% examples, 95748 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:05,831 : INFO : EPOCH 1 - PROGRESS: at 49.20% examples, 95685 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:06,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:00:06,549 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:00:06,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:00:06,712 : INFO : EPOCH - 1 : training on 7242395 raw words (5150774 effective words) took 53.8s, 95707 effective words/s\n",
      "2021-06-27 20:00:07,829 : INFO : EPOCH 2 - PROGRESS: at 0.87% examples, 77686 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:08,905 : INFO : EPOCH 2 - PROGRESS: at 1.86% examples, 85097 words/s, in_qsize 5, out_qsize 1\n",
      "2021-06-27 20:00:09,941 : INFO : EPOCH 2 - PROGRESS: at 2.78% examples, 88491 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:11,048 : INFO : EPOCH 2 - PROGRESS: at 3.76% examples, 89197 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:12,108 : INFO : EPOCH 2 - PROGRESS: at 4.77% examples, 90407 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:13,179 : INFO : EPOCH 2 - PROGRESS: at 5.78% examples, 90955 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:14,215 : INFO : EPOCH 2 - PROGRESS: at 6.76% examples, 91819 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:15,240 : INFO : EPOCH 2 - PROGRESS: at 7.64% examples, 91900 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:16,278 : INFO : EPOCH 2 - PROGRESS: at 8.48% examples, 91514 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:17,357 : INFO : EPOCH 2 - PROGRESS: at 9.42% examples, 91741 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:18,397 : INFO : EPOCH 2 - PROGRESS: at 10.37% examples, 92209 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:19,438 : INFO : EPOCH 2 - PROGRESS: at 11.32% examples, 92477 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:20,459 : INFO : EPOCH 2 - PROGRESS: at 12.28% examples, 92853 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:21,500 : INFO : EPOCH 2 - PROGRESS: at 13.27% examples, 93051 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:22,541 : INFO : EPOCH 2 - PROGRESS: at 14.20% examples, 93205 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:23,564 : INFO : EPOCH 2 - PROGRESS: at 15.15% examples, 93433 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:24,596 : INFO : EPOCH 2 - PROGRESS: at 16.11% examples, 93609 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:25,678 : INFO : EPOCH 2 - PROGRESS: at 17.11% examples, 93770 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:26,718 : INFO : EPOCH 2 - PROGRESS: at 18.07% examples, 93933 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:27,759 : INFO : EPOCH 2 - PROGRESS: at 19.06% examples, 94016 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:28,853 : INFO : EPOCH 2 - PROGRESS: at 20.00% examples, 93900 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:29,885 : INFO : EPOCH 2 - PROGRESS: at 20.96% examples, 94009 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:30,894 : INFO : EPOCH 2 - PROGRESS: at 21.93% examples, 94215 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:31,916 : INFO : EPOCH 2 - PROGRESS: at 22.91% examples, 94284 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:32,945 : INFO : EPOCH 2 - PROGRESS: at 23.86% examples, 94121 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:33,977 : INFO : EPOCH 2 - PROGRESS: at 24.84% examples, 94229 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:35,000 : INFO : EPOCH 2 - PROGRESS: at 25.81% examples, 94315 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:36,015 : INFO : EPOCH 2 - PROGRESS: at 26.78% examples, 94440 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:37,073 : INFO : EPOCH 2 - PROGRESS: at 27.81% examples, 94466 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:38,131 : INFO : EPOCH 2 - PROGRESS: at 28.81% examples, 94479 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:39,166 : INFO : EPOCH 2 - PROGRESS: at 29.76% examples, 94546 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:40,190 : INFO : EPOCH 2 - PROGRESS: at 30.78% examples, 94646 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:41,247 : INFO : EPOCH 2 - PROGRESS: at 31.76% examples, 94644 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:42,295 : INFO : EPOCH 2 - PROGRESS: at 32.70% examples, 94642 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:43,319 : INFO : EPOCH 2 - PROGRESS: at 33.60% examples, 94581 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:44,386 : INFO : EPOCH 2 - PROGRESS: at 34.61% examples, 94584 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:45,427 : INFO : EPOCH 2 - PROGRESS: at 35.61% examples, 94662 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:46,444 : INFO : EPOCH 2 - PROGRESS: at 36.59% examples, 94763 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:47,522 : INFO : EPOCH 2 - PROGRESS: at 37.58% examples, 94709 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:48,541 : INFO : EPOCH 2 - PROGRESS: at 38.58% examples, 94793 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:49,549 : INFO : EPOCH 2 - PROGRESS: at 39.61% examples, 94914 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:50,563 : INFO : EPOCH 2 - PROGRESS: at 40.55% examples, 94978 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:51,601 : INFO : EPOCH 2 - PROGRESS: at 41.52% examples, 94984 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:52,604 : INFO : EPOCH 2 - PROGRESS: at 42.47% examples, 94952 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:53,620 : INFO : EPOCH 2 - PROGRESS: at 43.35% examples, 94861 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:54,630 : INFO : EPOCH 2 - PROGRESS: at 44.30% examples, 94941 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:55,669 : INFO : EPOCH 2 - PROGRESS: at 45.28% examples, 94983 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:56,677 : INFO : EPOCH 2 - PROGRESS: at 46.16% examples, 95027 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:57,704 : INFO : EPOCH 2 - PROGRESS: at 47.12% examples, 95077 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:00:58,710 : INFO : EPOCH 2 - PROGRESS: at 48.05% examples, 95058 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:00:59,776 : INFO : EPOCH 2 - PROGRESS: at 49.02% examples, 95058 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:00,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:01:00,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:01:00,835 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 95144 words/s, in_qsize 0, out_qsize 1\n",
      "2021-06-27 20:01:00,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:01:00,836 : INFO : EPOCH - 2 : training on 7242395 raw words (5149200 effective words) took 54.1s, 95142 effective words/s\n",
      "2021-06-27 20:01:01,903 : INFO : EPOCH 3 - PROGRESS: at 0.87% examples, 81368 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:02,952 : INFO : EPOCH 3 - PROGRESS: at 1.86% examples, 88169 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:03,985 : INFO : EPOCH 3 - PROGRESS: at 2.78% examples, 90673 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:01:05,089 : INFO : EPOCH 3 - PROGRESS: at 3.76% examples, 90782 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:06,132 : INFO : EPOCH 3 - PROGRESS: at 4.77% examples, 91977 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:01:07,175 : INFO : EPOCH 3 - PROGRESS: at 5.78% examples, 92732 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:08,212 : INFO : EPOCH 3 - PROGRESS: at 6.76% examples, 93352 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:09,229 : INFO : EPOCH 3 - PROGRESS: at 7.64% examples, 93347 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:10,245 : INFO : EPOCH 3 - PROGRESS: at 8.48% examples, 93019 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:11,315 : INFO : EPOCH 3 - PROGRESS: at 9.43% examples, 93203 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:12,337 : INFO : EPOCH 3 - PROGRESS: at 10.37% examples, 93701 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:13,397 : INFO : EPOCH 3 - PROGRESS: at 11.32% examples, 93727 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:14,424 : INFO : EPOCH 3 - PROGRESS: at 12.28% examples, 93978 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:15,457 : INFO : EPOCH 3 - PROGRESS: at 13.27% examples, 94165 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:16,509 : INFO : EPOCH 3 - PROGRESS: at 14.20% examples, 94196 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:17,538 : INFO : EPOCH 3 - PROGRESS: at 15.15% examples, 94340 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:18,571 : INFO : EPOCH 3 - PROGRESS: at 16.11% examples, 94452 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:19,603 : INFO : EPOCH 3 - PROGRESS: at 17.05% examples, 94463 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:20,661 : INFO : EPOCH 3 - PROGRESS: at 18.02% examples, 94509 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:21,692 : INFO : EPOCH 3 - PROGRESS: at 19.00% examples, 94606 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:22,703 : INFO : EPOCH 3 - PROGRESS: at 19.93% examples, 94786 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:23,772 : INFO : EPOCH 3 - PROGRESS: at 20.89% examples, 94710 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:01:24,818 : INFO : EPOCH 3 - PROGRESS: at 21.86% examples, 94754 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:25,849 : INFO : EPOCH 3 - PROGRESS: at 22.85% examples, 94786 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:01:26,902 : INFO : EPOCH 3 - PROGRESS: at 23.86% examples, 94764 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:27,924 : INFO : EPOCH 3 - PROGRESS: at 24.84% examples, 94890 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:28,965 : INFO : EPOCH 3 - PROGRESS: at 25.81% examples, 94895 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:29,972 : INFO : EPOCH 3 - PROGRESS: at 26.78% examples, 95025 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:30,977 : INFO : EPOCH 3 - PROGRESS: at 27.81% examples, 95189 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:31,990 : INFO : EPOCH 3 - PROGRESS: at 28.81% examples, 95315 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:33,016 : INFO : EPOCH 3 - PROGRESS: at 29.76% examples, 95391 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:34,026 : INFO : EPOCH 3 - PROGRESS: at 30.78% examples, 95507 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:35,061 : INFO : EPOCH 3 - PROGRESS: at 31.76% examples, 95534 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:36,131 : INFO : EPOCH 3 - PROGRESS: at 32.76% examples, 95643 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:37,157 : INFO : EPOCH 3 - PROGRESS: at 33.73% examples, 95717 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:38,171 : INFO : EPOCH 3 - PROGRESS: at 34.75% examples, 95834 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:39,212 : INFO : EPOCH 3 - PROGRESS: at 35.76% examples, 95889 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:40,245 : INFO : EPOCH 3 - PROGRESS: at 36.71% examples, 95904 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:41,259 : INFO : EPOCH 3 - PROGRESS: at 37.71% examples, 95980 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:42,270 : INFO : EPOCH 3 - PROGRESS: at 38.72% examples, 96054 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:43,278 : INFO : EPOCH 3 - PROGRESS: at 39.71% examples, 96117 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:44,290 : INFO : EPOCH 3 - PROGRESS: at 40.68% examples, 96171 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:45,364 : INFO : EPOCH 3 - PROGRESS: at 41.71% examples, 96220 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:46,432 : INFO : EPOCH 3 - PROGRESS: at 42.72% examples, 96204 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:47,457 : INFO : EPOCH 3 - PROGRESS: at 43.68% examples, 96202 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:48,502 : INFO : EPOCH 3 - PROGRESS: at 44.62% examples, 96196 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:49,566 : INFO : EPOCH 3 - PROGRESS: at 45.57% examples, 96131 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:50,598 : INFO : EPOCH 3 - PROGRESS: at 46.48% examples, 96121 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:01:51,638 : INFO : EPOCH 3 - PROGRESS: at 47.45% examples, 96126 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:52,689 : INFO : EPOCH 3 - PROGRESS: at 48.42% examples, 96137 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:53,719 : INFO : EPOCH 3 - PROGRESS: at 49.41% examples, 96145 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:54,170 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:01:54,175 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:01:54,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:01:54,344 : INFO : EPOCH - 3 : training on 7242395 raw words (5150543 effective words) took 53.5s, 96263 effective words/s\n",
      "2021-06-27 20:01:55,378 : INFO : EPOCH 4 - PROGRESS: at 0.87% examples, 84044 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:56,422 : INFO : EPOCH 4 - PROGRESS: at 1.86% examples, 89901 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:57,456 : INFO : EPOCH 4 - PROGRESS: at 2.78% examples, 91814 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:01:58,498 : INFO : EPOCH 4 - PROGRESS: at 3.69% examples, 91368 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:01:59,563 : INFO : EPOCH 4 - PROGRESS: at 4.70% examples, 92208 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:00,610 : INFO : EPOCH 4 - PROGRESS: at 5.72% examples, 92731 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:01,622 : INFO : EPOCH 4 - PROGRESS: at 6.63% examples, 92872 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:02,680 : INFO : EPOCH 4 - PROGRESS: at 7.58% examples, 93183 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:03,698 : INFO : EPOCH 4 - PROGRESS: at 8.48% examples, 93586 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:04,784 : INFO : EPOCH 4 - PROGRESS: at 9.43% examples, 93575 words/s, in_qsize 5, out_qsize 1\n",
      "2021-06-27 20:02:05,810 : INFO : EPOCH 4 - PROGRESS: at 10.37% examples, 93977 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:06,847 : INFO : EPOCH 4 - PROGRESS: at 11.32% examples, 94133 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:07,871 : INFO : EPOCH 4 - PROGRESS: at 12.28% examples, 94363 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:08,917 : INFO : EPOCH 4 - PROGRESS: at 13.27% examples, 94434 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:09,979 : INFO : EPOCH 4 - PROGRESS: at 14.20% examples, 94366 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:10,999 : INFO : EPOCH 4 - PROGRESS: at 15.15% examples, 94552 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:12,035 : INFO : EPOCH 4 - PROGRESS: at 16.11% examples, 94647 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:13,046 : INFO : EPOCH 4 - PROGRESS: at 17.05% examples, 94750 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:14,112 : INFO : EPOCH 4 - PROGRESS: at 18.02% examples, 94707 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:15,134 : INFO : EPOCH 4 - PROGRESS: at 19.00% examples, 94883 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:16,136 : INFO : EPOCH 4 - PROGRESS: at 19.93% examples, 95089 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:17,173 : INFO : EPOCH 4 - PROGRESS: at 20.89% examples, 95142 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:18,225 : INFO : EPOCH 4 - PROGRESS: at 21.86% examples, 95123 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:19,260 : INFO : EPOCH 4 - PROGRESS: at 22.85% examples, 95126 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:20,298 : INFO : EPOCH 4 - PROGRESS: at 23.85% examples, 95168 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:21,302 : INFO : EPOCH 4 - PROGRESS: at 24.84% examples, 95330 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:22,321 : INFO : EPOCH 4 - PROGRESS: at 25.81% examples, 95375 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:23,397 : INFO : EPOCH 4 - PROGRESS: at 26.78% examples, 95266 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:24,422 : INFO : EPOCH 4 - PROGRESS: at 27.81% examples, 95364 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:25,448 : INFO : EPOCH 4 - PROGRESS: at 28.81% examples, 95440 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:26,480 : INFO : EPOCH 4 - PROGRESS: at 29.76% examples, 95500 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:27,524 : INFO : EPOCH 4 - PROGRESS: at 30.78% examples, 95518 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:28,581 : INFO : EPOCH 4 - PROGRESS: at 31.76% examples, 95487 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:29,591 : INFO : EPOCH 4 - PROGRESS: at 32.70% examples, 95562 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:30,607 : INFO : EPOCH 4 - PROGRESS: at 33.66% examples, 95667 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:31,643 : INFO : EPOCH 4 - PROGRESS: at 34.61% examples, 95544 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:32,683 : INFO : EPOCH 4 - PROGRESS: at 35.61% examples, 95602 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:33,742 : INFO : EPOCH 4 - PROGRESS: at 36.65% examples, 95741 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:34,767 : INFO : EPOCH 4 - PROGRESS: at 37.65% examples, 95801 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:35,768 : INFO : EPOCH 4 - PROGRESS: at 38.58% examples, 95731 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:36,810 : INFO : EPOCH 4 - PROGRESS: at 39.61% examples, 95755 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:37,890 : INFO : EPOCH 4 - PROGRESS: at 40.61% examples, 95811 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:38,914 : INFO : EPOCH 4 - PROGRESS: at 41.60% examples, 95819 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:39,958 : INFO : EPOCH 4 - PROGRESS: at 42.59% examples, 95854 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:41,001 : INFO : EPOCH 4 - PROGRESS: at 43.55% examples, 95824 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:42,025 : INFO : EPOCH 4 - PROGRESS: at 44.49% examples, 95855 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:43,110 : INFO : EPOCH 4 - PROGRESS: at 45.51% examples, 95910 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:44,177 : INFO : EPOCH 4 - PROGRESS: at 46.42% examples, 95837 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:45,219 : INFO : EPOCH 4 - PROGRESS: at 47.38% examples, 95830 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:46,288 : INFO : EPOCH 4 - PROGRESS: at 48.36% examples, 95820 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:47,319 : INFO : EPOCH 4 - PROGRESS: at 49.41% examples, 95962 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:47,767 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:02:47,883 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:02:47,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:02:47,949 : INFO : EPOCH - 4 : training on 7242395 raw words (5149809 effective words) took 53.6s, 96073 effective words/s\n",
      "2021-06-27 20:02:48,972 : INFO : EPOCH 5 - PROGRESS: at 0.87% examples, 84932 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:50,029 : INFO : EPOCH 5 - PROGRESS: at 1.86% examples, 89766 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:51,073 : INFO : EPOCH 5 - PROGRESS: at 2.78% examples, 91443 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:52,109 : INFO : EPOCH 5 - PROGRESS: at 3.69% examples, 91125 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:53,167 : INFO : EPOCH 5 - PROGRESS: at 4.70% examples, 92175 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:54,209 : INFO : EPOCH 5 - PROGRESS: at 5.72% examples, 92727 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:55,271 : INFO : EPOCH 5 - PROGRESS: at 6.69% examples, 93129 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:56,324 : INFO : EPOCH 5 - PROGRESS: at 7.64% examples, 93470 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:57,333 : INFO : EPOCH 5 - PROGRESS: at 8.54% examples, 93888 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:02:58,351 : INFO : EPOCH 5 - PROGRESS: at 9.48% examples, 94436 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:02:59,419 : INFO : EPOCH 5 - PROGRESS: at 10.45% examples, 94501 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:00,437 : INFO : EPOCH 5 - PROGRESS: at 11.39% examples, 94746 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:01,494 : INFO : EPOCH 5 - PROGRESS: at 12.35% examples, 94728 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:02,523 : INFO : EPOCH 5 - PROGRESS: at 13.32% examples, 94870 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:03,568 : INFO : EPOCH 5 - PROGRESS: at 14.27% examples, 94888 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:04,611 : INFO : EPOCH 5 - PROGRESS: at 15.22% examples, 94926 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:05,631 : INFO : EPOCH 5 - PROGRESS: at 16.17% examples, 95060 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:06,670 : INFO : EPOCH 5 - PROGRESS: at 17.18% examples, 95386 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:07,686 : INFO : EPOCH 5 - PROGRESS: at 18.14% examples, 95553 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:08,690 : INFO : EPOCH 5 - PROGRESS: at 19.00% examples, 95103 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:09,691 : INFO : EPOCH 5 - PROGRESS: at 19.93% examples, 95301 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:10,733 : INFO : EPOCH 5 - PROGRESS: at 20.89% examples, 95310 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:11,766 : INFO : EPOCH 5 - PROGRESS: at 21.86% examples, 95372 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:12,805 : INFO : EPOCH 5 - PROGRESS: at 22.85% examples, 95348 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:13,864 : INFO : EPOCH 5 - PROGRESS: at 23.85% examples, 95305 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:14,875 : INFO : EPOCH 5 - PROGRESS: at 24.84% examples, 95436 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:15,948 : INFO : EPOCH 5 - PROGRESS: at 25.87% examples, 95535 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:16,985 : INFO : EPOCH 5 - PROGRESS: at 26.85% examples, 95558 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:18,066 : INFO : EPOCH 5 - PROGRESS: at 27.88% examples, 95472 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:19,119 : INFO : EPOCH 5 - PROGRESS: at 28.87% examples, 95465 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:20,143 : INFO : EPOCH 5 - PROGRESS: at 29.83% examples, 95543 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:21,162 : INFO : EPOCH 5 - PROGRESS: at 30.83% examples, 95615 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:22,230 : INFO : EPOCH 5 - PROGRESS: at 31.83% examples, 95567 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:23,293 : INFO : EPOCH 5 - PROGRESS: at 32.76% examples, 95507 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:24,328 : INFO : EPOCH 5 - PROGRESS: at 33.73% examples, 95559 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:25,367 : INFO : EPOCH 5 - PROGRESS: at 34.75% examples, 95613 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:26,442 : INFO : EPOCH 5 - PROGRESS: at 35.76% examples, 95591 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:27,506 : INFO : EPOCH 5 - PROGRESS: at 36.71% examples, 95542 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:28,530 : INFO : EPOCH 5 - PROGRESS: at 37.71% examples, 95602 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:29,558 : INFO : EPOCH 5 - PROGRESS: at 38.72% examples, 95650 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:30,606 : INFO : EPOCH 5 - PROGRESS: at 39.71% examples, 95638 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:31,646 : INFO : EPOCH 5 - PROGRESS: at 40.68% examples, 95638 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:32,650 : INFO : EPOCH 5 - PROGRESS: at 41.65% examples, 95697 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:33,696 : INFO : EPOCH 5 - PROGRESS: at 42.65% examples, 95735 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:34,785 : INFO : EPOCH 5 - PROGRESS: at 43.68% examples, 95753 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:35,887 : INFO : EPOCH 5 - PROGRESS: at 44.62% examples, 95647 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:36,923 : INFO : EPOCH 5 - PROGRESS: at 45.57% examples, 95648 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:37,934 : INFO : EPOCH 5 - PROGRESS: at 46.48% examples, 95689 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:38,939 : INFO : EPOCH 5 - PROGRESS: at 47.45% examples, 95766 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:39,989 : INFO : EPOCH 5 - PROGRESS: at 48.42% examples, 95789 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:41,032 : INFO : EPOCH 5 - PROGRESS: at 49.41% examples, 95782 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:41,500 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:03:41,516 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:03:41,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:03:41,671 : INFO : EPOCH - 5 : training on 7242395 raw words (5150458 effective words) took 53.7s, 95878 effective words/s\n",
      "2021-06-27 20:03:42,685 : INFO : EPOCH 6 - PROGRESS: at 0.87% examples, 85738 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:43,731 : INFO : EPOCH 6 - PROGRESS: at 1.86% examples, 90669 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:44,764 : INFO : EPOCH 6 - PROGRESS: at 2.78% examples, 92355 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:45,801 : INFO : EPOCH 6 - PROGRESS: at 3.69% examples, 91886 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:03:46,862 : INFO : EPOCH 6 - PROGRESS: at 4.72% examples, 92606 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:47,896 : INFO : EPOCH 6 - PROGRESS: at 5.72% examples, 93363 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:48,937 : INFO : EPOCH 6 - PROGRESS: at 6.69% examples, 93955 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:49,973 : INFO : EPOCH 6 - PROGRESS: at 7.58% examples, 93567 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:50,999 : INFO : EPOCH 6 - PROGRESS: at 8.48% examples, 93835 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:52,044 : INFO : EPOCH 6 - PROGRESS: at 9.43% examples, 94182 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:53,063 : INFO : EPOCH 6 - PROGRESS: at 10.37% examples, 94608 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:54,137 : INFO : EPOCH 6 - PROGRESS: at 11.32% examples, 94451 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:55,143 : INFO : EPOCH 6 - PROGRESS: at 12.28% examples, 94780 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:56,170 : INFO : EPOCH 6 - PROGRESS: at 13.27% examples, 94940 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:57,210 : INFO : EPOCH 6 - PROGRESS: at 14.20% examples, 94969 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:58,227 : INFO : EPOCH 6 - PROGRESS: at 15.15% examples, 95135 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:03:59,255 : INFO : EPOCH 6 - PROGRESS: at 16.11% examples, 95242 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:00,265 : INFO : EPOCH 6 - PROGRESS: at 17.05% examples, 95328 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:01,272 : INFO : EPOCH 6 - PROGRESS: at 17.96% examples, 95216 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:02,297 : INFO : EPOCH 6 - PROGRESS: at 18.87% examples, 95020 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:03,357 : INFO : EPOCH 6 - PROGRESS: at 19.81% examples, 94949 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:04,388 : INFO : EPOCH 6 - PROGRESS: at 20.77% examples, 95002 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:05,392 : INFO : EPOCH 6 - PROGRESS: at 21.74% examples, 95192 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:06,419 : INFO : EPOCH 6 - PROGRESS: at 22.72% examples, 95265 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:07,436 : INFO : EPOCH 6 - PROGRESS: at 23.73% examples, 95354 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:08,446 : INFO : EPOCH 6 - PROGRESS: at 24.71% examples, 95498 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:09,456 : INFO : EPOCH 6 - PROGRESS: at 25.69% examples, 95584 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:10,466 : INFO : EPOCH 6 - PROGRESS: at 26.60% examples, 95457 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:11,473 : INFO : EPOCH 6 - PROGRESS: at 27.53% examples, 95361 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:12,506 : INFO : EPOCH 6 - PROGRESS: at 28.54% examples, 95454 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:13,558 : INFO : EPOCH 6 - PROGRESS: at 29.49% examples, 95417 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:14,597 : INFO : EPOCH 6 - PROGRESS: at 30.49% examples, 95475 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:15,666 : INFO : EPOCH 6 - PROGRESS: at 31.56% examples, 95582 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:16,705 : INFO : EPOCH 6 - PROGRESS: at 32.51% examples, 95591 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:04:17,711 : INFO : EPOCH 6 - PROGRESS: at 33.40% examples, 95541 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:18,719 : INFO : EPOCH 6 - PROGRESS: at 34.36% examples, 95487 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:19,782 : INFO : EPOCH 6 - PROGRESS: at 35.36% examples, 95494 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:20,840 : INFO : EPOCH 6 - PROGRESS: at 36.32% examples, 95467 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:21,908 : INFO : EPOCH 6 - PROGRESS: at 37.30% examples, 95445 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:22,913 : INFO : EPOCH 6 - PROGRESS: at 38.31% examples, 95522 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:23,936 : INFO : EPOCH 6 - PROGRESS: at 39.32% examples, 95595 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:24,958 : INFO : EPOCH 6 - PROGRESS: at 40.30% examples, 95623 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:25,976 : INFO : EPOCH 6 - PROGRESS: at 41.29% examples, 95667 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:27,016 : INFO : EPOCH 6 - PROGRESS: at 42.27% examples, 95662 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:28,018 : INFO : EPOCH 6 - PROGRESS: at 43.21% examples, 95751 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:29,025 : INFO : EPOCH 6 - PROGRESS: at 44.11% examples, 95687 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:30,049 : INFO : EPOCH 6 - PROGRESS: at 45.02% examples, 95583 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:31,091 : INFO : EPOCH 6 - PROGRESS: at 45.93% examples, 95580 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:32,125 : INFO : EPOCH 6 - PROGRESS: at 46.86% examples, 95587 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:04:33,153 : INFO : EPOCH 6 - PROGRESS: at 47.84% examples, 95652 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:34,205 : INFO : EPOCH 6 - PROGRESS: at 48.82% examples, 95656 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:35,257 : INFO : EPOCH 6 - PROGRESS: at 49.80% examples, 95621 words/s, in_qsize 4, out_qsize 0\n",
      "2021-06-27 20:04:35,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:04:35,296 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:04:35,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:04:35,460 : INFO : EPOCH - 6 : training on 7242395 raw words (5150513 effective words) took 53.8s, 95758 effective words/s\n",
      "2021-06-27 20:04:36,488 : INFO : EPOCH 7 - PROGRESS: at 0.87% examples, 84431 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:37,535 : INFO : EPOCH 7 - PROGRESS: at 1.86% examples, 89899 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:38,566 : INFO : EPOCH 7 - PROGRESS: at 2.78% examples, 91842 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:39,655 : INFO : EPOCH 7 - PROGRESS: at 3.76% examples, 92041 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:40,710 : INFO : EPOCH 7 - PROGRESS: at 4.77% examples, 92816 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:41,756 : INFO : EPOCH 7 - PROGRESS: at 5.78% examples, 93346 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:42,792 : INFO : EPOCH 7 - PROGRESS: at 6.76% examples, 93897 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:43,881 : INFO : EPOCH 7 - PROGRESS: at 7.71% examples, 93810 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:44,917 : INFO : EPOCH 7 - PROGRESS: at 8.61% examples, 93940 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:45,972 : INFO : EPOCH 7 - PROGRESS: at 9.54% examples, 94139 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:47,011 : INFO : EPOCH 7 - PROGRESS: at 10.52% examples, 94435 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:04:48,076 : INFO : EPOCH 7 - PROGRESS: at 11.46% examples, 94374 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:04:49,086 : INFO : EPOCH 7 - PROGRESS: at 12.42% examples, 94641 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:50,093 : INFO : EPOCH 7 - PROGRESS: at 13.38% examples, 94888 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:51,103 : INFO : EPOCH 7 - PROGRESS: at 14.34% examples, 95155 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:52,105 : INFO : EPOCH 7 - PROGRESS: at 15.22% examples, 95002 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:04:53,147 : INFO : EPOCH 7 - PROGRESS: at 16.17% examples, 95013 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:54,162 : INFO : EPOCH 7 - PROGRESS: at 17.11% examples, 95084 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:55,185 : INFO : EPOCH 7 - PROGRESS: at 18.07% examples, 95263 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:56,226 : INFO : EPOCH 7 - PROGRESS: at 19.06% examples, 95271 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:57,290 : INFO : EPOCH 7 - PROGRESS: at 20.00% examples, 95226 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:58,326 : INFO : EPOCH 7 - PROGRESS: at 20.96% examples, 95234 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:04:59,336 : INFO : EPOCH 7 - PROGRESS: at 21.93% examples, 95406 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:00,353 : INFO : EPOCH 7 - PROGRESS: at 22.91% examples, 95446 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:01,362 : INFO : EPOCH 7 - PROGRESS: at 23.91% examples, 95572 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:02,405 : INFO : EPOCH 7 - PROGRESS: at 24.91% examples, 95602 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:03,460 : INFO : EPOCH 7 - PROGRESS: at 25.87% examples, 95510 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:04,508 : INFO : EPOCH 7 - PROGRESS: at 26.85% examples, 95505 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:05,593 : INFO : EPOCH 7 - PROGRESS: at 27.88% examples, 95406 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:06,689 : INFO : EPOCH 7 - PROGRESS: at 28.87% examples, 95261 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:07,735 : INFO : EPOCH 7 - PROGRESS: at 29.83% examples, 95276 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:08,771 : INFO : EPOCH 7 - PROGRESS: at 30.83% examples, 95306 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:05:09,828 : INFO : EPOCH 7 - PROGRESS: at 31.83% examples, 95289 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:05:10,896 : INFO : EPOCH 7 - PROGRESS: at 32.76% examples, 95229 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:11,974 : INFO : EPOCH 7 - PROGRESS: at 33.73% examples, 95182 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:13,023 : INFO : EPOCH 7 - PROGRESS: at 34.75% examples, 95222 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:05:14,104 : INFO : EPOCH 7 - PROGRESS: at 35.76% examples, 95191 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:15,151 : INFO : EPOCH 7 - PROGRESS: at 36.71% examples, 95194 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:16,188 : INFO : EPOCH 7 - PROGRESS: at 37.71% examples, 95231 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:17,235 : INFO : EPOCH 7 - PROGRESS: at 38.72% examples, 95245 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:18,275 : INFO : EPOCH 7 - PROGRESS: at 39.71% examples, 95252 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:19,301 : INFO : EPOCH 7 - PROGRESS: at 40.68% examples, 95294 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:20,359 : INFO : EPOCH 7 - PROGRESS: at 41.71% examples, 95396 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:21,421 : INFO : EPOCH 7 - PROGRESS: at 42.72% examples, 95404 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:22,440 : INFO : EPOCH 7 - PROGRESS: at 43.68% examples, 95425 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:23,479 : INFO : EPOCH 7 - PROGRESS: at 44.62% examples, 95453 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:05:24,535 : INFO : EPOCH 7 - PROGRESS: at 45.57% examples, 95422 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:25,580 : INFO : EPOCH 7 - PROGRESS: at 46.48% examples, 95406 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:26,607 : INFO : EPOCH 7 - PROGRESS: at 47.45% examples, 95450 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:27,657 : INFO : EPOCH 7 - PROGRESS: at 48.42% examples, 95479 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:28,688 : INFO : EPOCH 7 - PROGRESS: at 49.41% examples, 95499 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:29,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:05:29,187 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:05:29,320 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:05:29,320 : INFO : EPOCH - 7 : training on 7242395 raw words (5149260 effective words) took 53.9s, 95609 effective words/s\n",
      "2021-06-27 20:05:30,342 : INFO : EPOCH 8 - PROGRESS: at 0.87% examples, 85042 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:31,383 : INFO : EPOCH 8 - PROGRESS: at 1.86% examples, 90491 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:32,411 : INFO : EPOCH 8 - PROGRESS: at 2.78% examples, 92418 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:33,454 : INFO : EPOCH 8 - PROGRESS: at 3.69% examples, 91750 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:34,519 : INFO : EPOCH 8 - PROGRESS: at 4.72% examples, 92414 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:05:35,568 : INFO : EPOCH 8 - PROGRESS: at 5.72% examples, 92912 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:05:36,605 : INFO : EPOCH 8 - PROGRESS: at 6.70% examples, 93588 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:37,635 : INFO : EPOCH 8 - PROGRESS: at 7.64% examples, 94194 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:38,639 : INFO : EPOCH 8 - PROGRESS: at 8.54% examples, 94575 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:39,641 : INFO : EPOCH 8 - PROGRESS: at 9.43% examples, 94587 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:40,669 : INFO : EPOCH 8 - PROGRESS: at 10.37% examples, 94894 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:41,724 : INFO : EPOCH 8 - PROGRESS: at 11.32% examples, 94848 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:42,819 : INFO : EPOCH 8 - PROGRESS: at 12.35% examples, 95030 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:43,845 : INFO : EPOCH 8 - PROGRESS: at 13.32% examples, 95091 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:44,898 : INFO : EPOCH 8 - PROGRESS: at 14.27% examples, 95099 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:45,924 : INFO : EPOCH 8 - PROGRESS: at 15.22% examples, 95231 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:46,949 : INFO : EPOCH 8 - PROGRESS: at 16.17% examples, 95320 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:47,955 : INFO : EPOCH 8 - PROGRESS: at 17.11% examples, 95417 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:49,010 : INFO : EPOCH 8 - PROGRESS: at 18.07% examples, 95420 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:50,067 : INFO : EPOCH 8 - PROGRESS: at 19.06% examples, 95345 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:51,110 : INFO : EPOCH 8 - PROGRESS: at 19.99% examples, 95352 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:52,121 : INFO : EPOCH 8 - PROGRESS: at 20.96% examples, 95514 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:53,147 : INFO : EPOCH 8 - PROGRESS: at 21.93% examples, 95589 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:54,185 : INFO : EPOCH 8 - PROGRESS: at 22.91% examples, 95545 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:55,188 : INFO : EPOCH 8 - PROGRESS: at 23.91% examples, 95692 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:56,216 : INFO : EPOCH 8 - PROGRESS: at 24.91% examples, 95778 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:57,221 : INFO : EPOCH 8 - PROGRESS: at 25.87% examples, 95852 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:58,222 : INFO : EPOCH 8 - PROGRESS: at 26.78% examples, 95753 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:05:59,271 : INFO : EPOCH 8 - PROGRESS: at 27.81% examples, 95756 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:00,300 : INFO : EPOCH 8 - PROGRESS: at 28.81% examples, 95830 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:01,331 : INFO : EPOCH 8 - PROGRESS: at 29.76% examples, 95865 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:02,369 : INFO : EPOCH 8 - PROGRESS: at 30.78% examples, 95887 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:03,414 : INFO : EPOCH 8 - PROGRESS: at 31.76% examples, 95875 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:04,439 : INFO : EPOCH 8 - PROGRESS: at 32.70% examples, 95905 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:05,456 : INFO : EPOCH 8 - PROGRESS: at 33.66% examples, 95999 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:06,488 : INFO : EPOCH 8 - PROGRESS: at 34.61% examples, 95876 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:07,537 : INFO : EPOCH 8 - PROGRESS: at 35.61% examples, 95900 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:08,608 : INFO : EPOCH 8 - PROGRESS: at 36.65% examples, 96003 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:09,637 : INFO : EPOCH 8 - PROGRESS: at 37.65% examples, 96045 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:06:10,674 : INFO : EPOCH 8 - PROGRESS: at 38.66% examples, 96048 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:11,676 : INFO : EPOCH 8 - PROGRESS: at 39.61% examples, 96001 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:12,676 : INFO : EPOCH 8 - PROGRESS: at 40.55% examples, 96063 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:13,688 : INFO : EPOCH 8 - PROGRESS: at 41.52% examples, 96098 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:14,725 : INFO : EPOCH 8 - PROGRESS: at 42.53% examples, 96123 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:15,757 : INFO : EPOCH 8 - PROGRESS: at 43.48% examples, 96120 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:16,815 : INFO : EPOCH 8 - PROGRESS: at 44.43% examples, 96066 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:17,873 : INFO : EPOCH 8 - PROGRESS: at 45.39% examples, 96035 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:06:18,886 : INFO : EPOCH 8 - PROGRESS: at 46.29% examples, 96058 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:19,907 : INFO : EPOCH 8 - PROGRESS: at 47.25% examples, 96108 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:20,967 : INFO : EPOCH 8 - PROGRESS: at 48.25% examples, 96099 words/s, in_qsize 6, out_qsize 0\n",
      "2021-06-27 20:06:22,023 : INFO : EPOCH 8 - PROGRESS: at 49.20% examples, 96089 words/s, in_qsize 5, out_qsize 0\n",
      "2021-06-27 20:06:22,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-27 20:06:22,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-27 20:06:22,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-27 20:06:22,838 : INFO : EPOCH - 8 : training on 7242395 raw words (5149344 effective words) took 53.5s, 96222 effective words/s\n",
      "2021-06-27 20:06:22,839 : INFO : training on a 57939160 raw words (41199901 effective words) took 429.9s, 95826 effective words/s\n",
      "2021-06-27 20:06:22,883 : INFO : storing 31480x1000 projection weights into ./word2Vec.bin\n",
      "2021-06-27 20:06:23,997 : INFO : loading projection weights from word2Vec.bin\n",
      "2021-06-27 20:06:25,206 : INFO : loaded (31480, 1000) matrix from word2Vec.bin\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 设置输出日志\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 直接用gemsim提供的API去读取txt文件，读取文件的API有LineSentence 和 Text8Corpus, PathLineSentences等。\n",
    "sentences = word2vec.LineSentence(\"./wordEmbdiing.txt\")\n",
    "\n",
    "# 训练模型，词向量的长度设置为1000， 迭代次数为8，采用skip-gram模型，模型保存为bin格式\n",
    "model = gensim.models.Word2Vec(sentences, size=1000, sg=1, iter=8)  \n",
    "model.wv.save_word2vec_format(\"./word2Vec\" + \".bin\", binary=True) \n",
    "\n",
    "# 加载bin格式的模型\n",
    "wordVec = gensim.models.KeyedVectors.load_word2vec_format(\"word2Vec.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c5f0e82-a4a7-43f1-9913-5ec8b70e21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from math import sqrt\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56ea4147-6041-48b6-a7be-ad5166e16f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "\n",
    "class TrainingConfig(object):\n",
    "    epoches = 80\n",
    "    evaluateEvery = 100\n",
    "    checkpointEvery = 100\n",
    "    learningRate = 0.001\n",
    "    \n",
    "class ModelConfig(object):\n",
    "    embeddingSize = 1000\n",
    "    \n",
    "    hiddenSizes = [256, 256]  # 单层LSTM结构的神经元个数\n",
    "    \n",
    "    dropoutKeepProb = 0.5\n",
    "    l2RegLambda = 0.0\n",
    "    \n",
    "class Config(object):\n",
    "    sequenceLength = 200  # 取了所有序列长度的均值\n",
    "    batchSize = 64\n",
    "    \n",
    "    dataSource = \"./mbti_train.csv\"\n",
    "    \n",
    "    stopWordSource = \"./english.txt\"\n",
    "    \n",
    "    numClasses = 16  # 二分类设置为1，多分类设置为类别的数目\n",
    "    \n",
    "    rate = 0.9  # 训练集的比例\n",
    "    \n",
    "    training = TrainingConfig()\n",
    "    \n",
    "    model = ModelConfig()\n",
    "\n",
    "    \n",
    "# 实例化配置参数对象\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e433a3f-0063-4118-9f75-52832e577e14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 20:06:29,020 : INFO : loading projection weights from ./word2Vec.bin\n",
      "2021-06-27 20:06:30,205 : INFO : loaded (31480, 1000) matrix from ./word2Vec.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I不存在于词向量中\n",
      "I'm不存在于词向量中\n",
      "don't不存在于词向量中\n",
      "it's不存在于词向量中\n",
      "I've不存在于词向量中\n",
      "The不存在于词向量中\n",
      "It不存在于词向量中\n",
      "But不存在于词向量中\n",
      "If不存在于词向量中\n",
      "It's不存在于词向量中\n",
      "you're不存在于词向量中\n",
      "You不存在于词向量中\n",
      "And不存在于词向量中\n",
      "can't不存在于词向量中\n",
      "it.不存在于词向量中\n",
      "My不存在于词向量中\n",
      "me.不存在于词向量中\n",
      "that's不存在于词向量中\n",
      "didn't不存在于词向量中\n",
      "I'd不存在于词向量中\n",
      "doesn't不存在于词向量中\n",
      "me,不存在于词向量中\n",
      "I'll不存在于词向量中\n",
      "What不存在于词向量中\n",
      "This不存在于词向量中\n",
      "it,不存在于词向量中\n",
      "So不存在于词向量中\n",
      "We不存在于词向量中\n",
      "When不存在于词向量中\n",
      "He不存在于词向量中\n",
      "In不存在于词向量中\n",
      "A不存在于词向量中\n",
      ":)不存在于词向量中\n",
      "isn't不存在于词向量中\n",
      "That不存在于词向量中\n",
      "you.不存在于词向量中\n",
      "They不存在于词向量中\n",
      "For不存在于词向量中\n",
      "As不存在于词向量中\n",
      "he's不存在于词向量中\n",
      "that.不存在于词向量中\n",
      "wouldn't不存在于词向量中\n",
      "Not不存在于词向量中\n",
      "them.不存在于词向量中\n",
      "you,不存在于词向量中\n",
      "There不存在于词向量中\n",
      "there's不存在于词向量中\n",
      "MBTI不存在于词向量中\n",
      "they're不存在于词向量中\n",
      "time.不存在于词向量中\n",
      "haven't不存在于词向量中\n",
      "How不存在于词向量中\n",
      "Just不存在于词向量中\n",
      "She不存在于词向量中\n",
      "too.不存在于词向量中\n",
      "Do不存在于词向量中\n",
      "this.不存在于词向量中\n",
      "wasn't不存在于词向量中\n",
      "That's不存在于词向量中\n",
      "that,不存在于词向量中\n",
      "Fe不存在于词向量中\n",
      "well.不存在于词向量中\n",
      "people.不存在于词向量中\n",
      "aren't不存在于词向量中\n",
      "i'm不存在于词向量中\n",
      "time,不存在于词向量中\n",
      "we're不存在于词向量中\n",
      "Maybe不存在于词向量中\n",
      "people,不存在于词向量中\n",
      "won't不存在于词向量中\n",
      "Fi不存在于词向量中\n",
      "here.不存在于词向量中\n",
      "though.不存在于词向量中\n",
      "life.不存在于词向量中\n",
      "now.不存在于词向量中\n",
      "2.不存在于词向量中\n",
      "To不存在于词向量中\n",
      "Or不存在于词向量中\n",
      "she's不存在于词向量中\n",
      "though,不存在于词向量中\n",
      "One不存在于词向量中\n",
      "No不存在于词向量中\n",
      "Ne不存在于词向量中\n",
      "them,不存在于词向量中\n",
      "(I不存在于词向量中\n",
      "you've不存在于词向量中\n",
      "Your不存在于词向量中\n",
      "However,不存在于词向量中\n",
      "Is不存在于词向量中\n",
      "way.不存在于词向量中\n",
      "Why不存在于词向量中\n",
      "INFPs不存在于词向量中\n",
      "Ni不存在于词向量中\n",
      "this,不存在于词向量中\n",
      "Also,不存在于词向量中\n",
      "People不存在于词向量中\n",
      "know,不存在于词向量中\n",
      "all.不存在于词向量中\n",
      "...不存在于词向量中\n",
      ".不存在于词向量中\n",
      "Then不存在于词向量中\n",
      "INTJs不存在于词向量中\n",
      "well,不存在于词向量中\n",
      "Like不存在于词向量中\n",
      "(and不存在于词向量中\n",
      "do.不存在于词向量中\n",
      "is,不存在于词向量中\n",
      "Don't不存在于词向量中\n",
      "one.不存在于词向量中\n",
      "At不存在于词向量中\n",
      "couldn't不存在于词向量中\n",
      "All不存在于词向量中\n",
      "now,不存在于词向量中\n",
      "out.不存在于词向量中\n",
      "Now不存在于词向量中\n",
      "You're不存在于词向量中\n",
      "thing.不存在于词向量中\n",
      "Thank不存在于词向量中\n",
      "myself.不存在于词向量中\n",
      "INFJs不存在于词向量中\n",
      "Sometimes不存在于词向量中\n",
      ":D不存在于词向量中\n",
      "Even不存在于词向量中\n",
      "Ti不存在于词向量中\n",
      ",不存在于词向量中\n",
      "Some不存在于词向量中\n",
      "life,不存在于词向量中\n",
      "things.不存在于词向量中\n",
      "said,不存在于词向量中\n",
      "Sent不存在于词向量中\n",
      "1.不存在于词向量中\n",
      "Most不存在于词向量中\n",
      "I...|||I不存在于词向量中\n",
      "INTPs不存在于词向量中\n",
      "too,不存在于词向量中\n",
      "yes,不存在于词向量中\n",
      "way,不存在于词向量中\n",
      "here,不存在于词向量中\n",
      "him.不存在于词向量中\n",
      "all,不存在于词向量中\n",
      "type.不存在于词向量中\n",
      "myself,不存在于词向量中\n",
      "Are不存在于词向量中\n",
      "up.不存在于词向量中\n",
      "what's不存在于词向量中\n",
      "Also不存在于词向量中\n",
      "(or不存在于词向量中\n",
      "Te不存在于词向量中\n",
      "etc.不存在于词向量中\n",
      "much.不存在于词向量中\n",
      "'I不存在于词向量中\n",
      "the...|||I不存在于词向量中\n",
      "Thanks不存在于词向量中\n",
      "3.不存在于词向量中\n",
      "person.不存在于词向量中\n",
      "you'll不存在于词向量中\n",
      "you?不存在于词向量中\n",
      "There's不存在于词向量中\n",
      "know.不存在于词向量中\n",
      "to...|||I不存在于词向量中\n",
      "Se不存在于词向量中\n",
      "to.不存在于词向量中\n",
      "there.不存在于词向量中\n",
      "is.不存在于词向量中\n",
      "lol.不存在于词向量中\n",
      "He's不存在于词向量中\n",
      "Because不存在于词向量中\n",
      ":P不存在于词向量中\n",
      "do,不存在于词向量中\n",
      "On不存在于词向量中\n",
      "INFP.不存在于词向量中\n",
      "things,不存在于词向量中\n",
      "say,不存在于词向量中\n",
      "mean,不存在于词向量中\n",
      "one,不存在于词向量中\n",
      "INFP,不存在于词向量中\n",
      "friends,不存在于词向量中\n",
      "Well,不存在于词向量中\n",
      "out,不存在于词向量中\n",
      "ENTPs不存在于词向量中\n",
      "it?不存在于词向量中\n",
      "...|||I不存在于词向量中\n",
      "Si不存在于词向量中\n",
      "not.不存在于词向量中\n",
      "Yes,不存在于词向量中\n",
      "thread.不存在于词向量中\n",
      "ENFPs不存在于词向量中\n",
      "person,不存在于词向量中\n",
      "thing,不存在于词向量中\n",
      "friends.不存在于词向量中\n",
      "Oh不存在于词向量中\n",
      "up,不存在于词向量中\n",
      "and...|||I不存在于词向量中\n",
      "on.不存在于词向量中\n",
      "example,不存在于词向量中\n",
      "INFJ,不存在于词向量中\n",
      "type,不存在于词向量中\n",
      "Its不存在于词向量中\n",
      "with.不存在于词向量中\n",
      "Im不存在于词向量中\n",
      "Have不存在于词向量中\n",
      "years.不存在于词向量中\n",
      "right.不存在于词向量中\n",
      "like,不存在于词向量中\n",
      "Of不存在于词向量中\n",
      "With不存在于词向量中\n",
      "lot.不存在于词向量中\n",
      "Being不存在于词向量中\n",
      "day.不存在于词向量中\n",
      "a...|||I不存在于词向量中\n",
      "After不存在于词向量中\n",
      "people's不存在于词向量中\n",
      "/不存在于词向量中\n",
      "INFJ.不存在于词向量中\n",
      "her.不存在于词向量中\n",
      "others.不存在于词向量中\n",
      "Although不存在于词向量中\n",
      "INTJ.不存在于词向量中\n",
      "work.不存在于词向量中\n",
      "him,不存在于词向量中\n",
      "there,不存在于词向量中\n",
      "yeah,不存在于词向量中\n",
      "God不存在于词向量中\n",
      "Well不存在于词向量中\n",
      "Good不存在于词向量中\n",
      "Though不存在于词向量中\n",
      "so,不存在于词向量中\n",
      "INTP,不存在于词向量中\n",
      "again.不存在于词向量中\n",
      ";)不存在于词向量中\n",
      "INTJ,不存在于词向量中\n",
      "something,不存在于词向量中\n",
      "Type不存在于词向量中\n",
      "ago.不存在于词向量中\n",
      "school,不存在于词向量中\n",
      "thread,不存在于词向量中\n",
      "be.不存在于词向量中\n",
      "INTP.不存在于词向量中\n",
      "Which不存在于词向量中\n",
      "i've不存在于词向量中\n",
      "Especially不存在于词向量中\n",
      "to,不存在于词向量中\n",
      "From不存在于词向量中\n",
      "shouldn't不存在于词向量中\n",
      "of...|||I不存在于词向量中\n",
      "work,不存在于词向量中\n",
      "in.不存在于词向量中\n",
      "An不存在于词向量中\n",
      "?不存在于词向量中\n",
      "school.不存在于词向量中\n",
      "not,不存在于词向量中\n",
      "post.不存在于词向量中\n",
      "true.不存在于词向量中\n",
      "again,不存在于词向量中\n",
      "point.不存在于词向量中\n",
      "good.不存在于词向量中\n",
      "ago,不存在于词向量中\n",
      "world.不存在于词向量中\n",
      "are.不存在于词向量中\n",
      "So,不存在于词向量中\n",
      "interesting.不存在于词向量中\n",
      "iPhone不存在于词向量中\n",
      "They're不存在于词向量中\n",
      "anything.不存在于词向量中\n",
      "day,不存在于词向量中\n",
      "years,不存在于词向量中\n",
      "She's不存在于词向量中\n",
      "friend,不存在于词向量中\n",
      "Can不存在于词向量中\n",
      "4.不存在于词向量中\n",
      "something.不存在于词向量中\n",
      "ENFP.不存在于词向量中\n",
      "English不存在于词向量中\n",
      "much,不存在于词向量中\n",
      "you'd不存在于词向量中\n",
      "(which不存在于词向量中\n",
      "times.不存在于词向量中\n",
      "question.不存在于词向量中\n",
      "about.不存在于词向量中\n",
      "yes.不存在于词向量中\n",
      "friend.不存在于词向量中\n",
      "others,不存在于词向量中\n",
      "ENFP,不存在于词向量中\n",
      "so.不存在于词向量中\n",
      "types.不存在于词向量中\n",
      "relationship.不存在于词向量中\n",
      "who's不存在于词向量中\n",
      "no,不存在于词向量中\n",
      "fact,不存在于词向量中\n",
      "wrong.不存在于词向量中\n",
      "either.不存在于词向量中\n",
      "her,不存在于词向量中\n",
      ":)|||I不存在于词向量中\n",
      "sense.不存在于词向量中\n",
      "Does不存在于词向量中\n",
      "haha.不存在于词向量中\n",
      "right,不存在于词向量中\n",
      "mind.不存在于词向量中\n",
      "better.不存在于词向量中\n",
      "think.不存在于词向量中\n",
      "world,不存在于词向量中\n",
      "Very不存在于词向量中\n",
      "(not不存在于词向量中\n",
      "before,不存在于词向量中\n",
      "While不存在于词向量中\n",
      "SO不存在于词向量中\n",
      "2)不存在于词向量中\n",
      "F不存在于词向量中\n",
      "however,不存在于词向量中\n",
      "1)不存在于词向量中\n",
      "today.不存在于词向量中\n",
      "more.不存在于词向量中\n",
      "Love不存在于词向量中\n",
      "in,不存在于词向量中\n",
      "Here不存在于词向量中\n",
      "course,不存在于词向量中\n",
      "Enneagram不存在于词向量中\n",
      "N不存在于词向量中\n",
      "am.不存在于词向量中\n",
      "We're不存在于词向量中\n",
      "stuff.不存在于词向量中\n",
      "Who不存在于词向量中\n",
      "really,不存在于词向量中\n",
      "Perhaps不存在于词向量中\n",
      "sure.不存在于词向量中\n",
      "Yeah,不存在于词向量中\n",
      "What's不存在于词向量中\n",
      "are,不存在于词向量中\n",
      "Any不存在于词向量中\n",
      "before.不存在于词向量中\n",
      "ENTP.不存在于词向量中\n",
      "Where不存在于词向量中\n",
      "on,不存在于词向量中\n",
      "us.不存在于词向量中\n",
      "times,不存在于词向量中\n",
      "XD不存在于词向量中\n",
      "Would不存在于词向量中\n",
      "off.不存在于词向量中\n",
      "Please不存在于词向量中\n",
      "agree.不存在于词向量中\n",
      "said.不存在于词向量中\n",
      "me?不存在于词向量中\n",
      "post,不存在于词向量中\n",
      "music,不存在于词向量中\n",
      "First不存在于词向量中\n",
      "anything,不存在于词向量中\n",
      "But,不存在于词向量中\n",
      "yourself.不存在于词向量中\n",
      "Anyway,不存在于词向量中\n",
      "These不存在于词向量中\n",
      "else.不存在于词向量中\n",
      "no.不存在于词向量中\n",
      "OP不存在于词向量中\n",
      "Did不存在于词向量中\n",
      "By不存在于词向量中\n",
      "situation.不存在于词向量中\n",
      "J不存在于词向量中\n",
      "types,不存在于词向量中\n",
      "Since不存在于词向量中\n",
      "love.不存在于词向量中\n",
      "T不存在于词向量中\n",
      "good,不存在于词向量中\n",
      "problem.不存在于词向量中\n",
      "lot,不存在于词向量中\n",
      "ENTP,不存在于词向量中\n",
      "experience,不存在于词向量中\n",
      "(in不存在于词向量中\n",
      "really.不存在于词向量中\n",
      "xD不存在于词向量中\n",
      "INFJ's不存在于词向量中\n",
      "alone.不存在于词向量中\n",
      "with,不存在于词向量中\n",
      "Other不存在于词向量中\n",
      "think,不存在于词向量中\n",
      "INFP's不存在于词向量中\n",
      "like.不存在于词向量中\n",
      "say.不存在于词向量中\n",
      "and/or不存在于词向量中\n",
      "right?不存在于词向量中\n",
      "guys,不存在于词向量中\n",
      "love,不存在于词向量中\n",
      "Sorry不存在于词向量中\n",
      "NOT不存在于词向量中\n",
      "back.不存在于词向量中\n",
      "No,不存在于词向量中\n",
      "then,不存在于词向量中\n",
      "Never不存在于词向量中\n",
      "Only不存在于词向量中\n",
      "Here's不存在于词向量中\n",
      "Welcome不存在于词向量中\n",
      "Every不存在于词向量中\n",
      "someone,不存在于词向量中\n",
      "forum.不存在于词向量中\n",
      "More不存在于词向量中\n",
      "5.不存在于词向量中\n",
      "(I'm不存在于词向量中\n",
      "here's不存在于词向量中\n",
      "one's不存在于词向量中\n",
      "down.不存在于词向量中\n",
      "(the不存在于词向量中\n",
      "Everyone不存在于词向量中\n",
      "Me不存在于词向量中\n",
      "mind,不存在于词向量中\n",
      "PerC不存在于词向量中\n",
      ":(不存在于词向量中\n",
      "Personality不存在于词向量中\n",
      "fun.不存在于词向量中\n",
      "that?不存在于词向量中\n",
      "be,不存在于词向量中\n",
      "let's不存在于词向量中\n",
      "Usually不存在于词向量中\n",
      "Those不存在于词向量中\n",
      "weren't不存在于词向量中\n",
      "(不存在于词向量中\n",
      "forum,不存在于词向量中\n",
      "everything.不存在于词向量中\n",
      "sometimes.不存在于词向量中\n",
      "wrong,不存在于词向量中\n",
      "New不存在于词向量中\n",
      "His不存在于词向量中\n",
      "other.不存在于词向量中\n",
      "NF不存在于词向量中\n",
      "Oh,不存在于词向量中\n",
      "question,不存在于词向量中\n",
      "LOVE不存在于词向量中\n",
      "honest,不存在于词向量中\n",
      "Yes不存在于词向量中\n",
      "feelings.不存在于词向量中\n",
      "that...|||I不存在于词向量中\n",
      "case,不存在于词向量中\n",
      "true,不存在于词向量中\n",
      "However不存在于词向量中\n",
      "(as不存在于词向量中\n",
      "point,不存在于词向量中\n",
      "anymore.不存在于词向量中\n",
      "ENFJs不存在于词向量中\n",
      "ISTPs不存在于词向量中\n",
      "man,不存在于词向量中\n",
      "hasn't不存在于词向量中\n",
      "off,不存在于词向量中\n",
      "first,不存在于词向量中\n",
      "ENTJs不存在于词向量中\n",
      "INTJ's不存在于词向量中\n",
      "music.不存在于词向量中\n",
      "functions.不存在于词向量中\n",
      "head.不存在于词向量中\n",
      "year.不存在于词向量中\n",
      "while.不存在于词向量中\n",
      "someone's不存在于词向量中\n",
      "anyway.不存在于词向量中\n",
      "Be不存在于词向量中\n",
      "guys.不存在于词向量中\n",
      "actually.不存在于词向量中\n",
      "my...|||I不存在于词向量中\n",
      "NT不存在于词向量中\n",
      "relationship,不存在于词向量中\n",
      "Once不存在于词向量中\n",
      "place.不存在于词向量中\n",
      "bad.不存在于词向量中\n",
      "enough.不存在于词向量中\n",
      "us,不存在于词向量中\n",
      "Let's不存在于词向量中\n",
      "Probably不存在于词向量中\n",
      "everyone,不存在于词向量中\n",
      "TV不存在于词向量中\n",
      "am,不存在于词向量中\n",
      "TMLT不存在于词向量中\n",
      "then.不存在于词向量中\n",
      "help.不存在于词向量中\n",
      "Let不存在于词向量中\n",
      "is...|||I不存在于词向量中\n",
      "but,不存在于词向量中\n",
      "agree,不存在于词向量中\n",
      "back,不存在于词向量中\n",
      "more,不存在于词向量中\n",
      "this?不存在于词向量中\n",
      "sometimes,不存在于词向量中\n",
      "away.不存在于词向量中\n",
      "yet,不存在于词向量中\n",
      "experience.不存在于词向量中\n",
      "yourself,不存在于词向量中\n",
      "man.不存在于词向量中\n",
      "together.不存在于词向量中\n",
      "idea.不存在于词向量中\n",
      "Both不存在于词向量中\n",
      "type?不存在于词向量中\n",
      "S不存在于词向量中\n",
      "we've不存在于词向量中\n",
      "Nothing不存在于词向量中\n",
      "great.不存在于词向量中\n",
      "Go不存在于词向量中\n",
      "Me:不存在于词向量中\n",
      "P不存在于词向量中\n",
      "Life不存在于词向量中\n",
      "YOU不存在于词向量中\n",
      "down,不存在于词向量中\n",
      "enough,不存在于词向量中\n",
      "around.不存在于词向量中\n",
      "me...不存在于词向量中\n",
      "year,不存在于词向量中\n",
      "reason,不存在于词向量中\n",
      "possible.不存在于词向量中\n",
      "go.不存在于词向量中\n",
      "Someone不存在于词向量中\n",
      "sure,不存在于词向量中\n",
      "American不存在于词向量中\n",
      "about,不存在于词向量中\n",
      "everyone.不存在于词向量中\n",
      "general,不存在于词向量中\n",
      "Something不存在于词向量中\n",
      "awesome.不存在于词向量中\n",
      "in...|||I不存在于词向量中\n",
      "ISTJ.不存在于词向量中\n",
      "Get不存在于词向量中\n",
      "yet.不存在于词向量中\n",
      "i'll不存在于词向量中\n",
      "interesting,不存在于词向量中\n",
      "reason.不存在于词向量中\n",
      "advice.不存在于词向量中\n",
      "Too不存在于词向量中\n",
      "first.不存在于词向量中\n",
      "feel.不存在于词向量中\n",
      "different.不存在于词向量中\n",
      "functions,不存在于词向量中\n",
      "same.不存在于词向量中\n",
      "IQ不存在于词向量中\n",
      "it.|||I不存在于词向量中\n",
      "feelings,不存在于词向量中\n",
      "Everything不存在于词向量中\n",
      "bit.不存在于词向量中\n",
      "guess.不存在于词向量中\n",
      "sense,不存在于词向量中\n",
      "Hope不存在于词向量中\n",
      "INTP's不存在于词向量中\n",
      "(like不存在于词向量中\n",
      "while,不存在于词向量中\n",
      "stuff,不存在于词向量中\n",
      "ISFP.不存在于词向量中\n",
      "Our不存在于词向量中\n",
      "Can't不存在于词向量中\n",
      "don't.不存在于词向量中\n",
      "mean.不存在于词向量中\n",
      "(if不存在于词向量中\n",
      "E不存在于词向量中\n",
      "moment.不存在于词向量中\n",
      "have.不存在于词向量中\n",
      "ISTP.不存在于词向量中\n",
      "opinion,不存在于词向量中\n",
      "guy.不存在于词向量中\n",
      "ENFJ.不存在于词向量中\n",
      "alone,不存在于词向量中\n",
      "THE不存在于词向量中\n",
      "night.不存在于词向量中\n",
      "ENFJ,不存在于词向量中\n",
      "Right不存在于词向量中\n",
      "funny,不存在于词向量中\n",
      "person's不存在于词向量中\n",
      "often.不存在于词向量中\n",
      "someone.不存在于词向量中\n",
      ")不存在于词向量中\n",
      "words.不存在于词向量中\n",
      "general.不存在于词向量中\n",
      "situation,不存在于词向量中\n",
      "ISTJ,不存在于词向量中\n",
      "of.不存在于词向量中\n",
      "fun,不存在于词向量中\n",
      "job,不存在于词向量中\n",
      "hand,不存在于词向量中\n",
      "Introverted不存在于词向量中\n",
      "part.不存在于词向量中\n",
      "Many不存在于词向量中\n",
      "job.不存在于词向量中\n",
      "done.不存在于词向量中\n",
      "ENTJ.不存在于词向量中\n",
      "happy.不存在于词向量中\n",
      "family,不存在于词向量中\n",
      "emotions.不存在于词向量中\n",
      "I,不存在于词向量中\n",
      "moment,不存在于词向量中\n",
      "you...|||I不存在于词向量中\n",
      "days.不存在于词向量中\n",
      "opinion.不存在于词向量中\n",
      "did.不存在于词向量中\n",
      "personality.不存在于词向量中\n",
      "Fe,不存在于词向量中\n",
      "problem,不存在于词向量中\n",
      "sorry,不存在于词向量中\n",
      "words,不存在于词向量中\n",
      "test,不存在于词向量中\n",
      "ISFPs不存在于词向量中\n",
      "ISTP,不存在于词向量中\n",
      "emotions,不存在于词向量中\n",
      "ISTJs不存在于词向量中\n",
      "Feeling不存在于词向量中\n",
      "Still不存在于词向量中\n",
      "vs.不存在于词向量中\n",
      "Yeah不存在于词向量中\n",
      "ISFJ.不存在于词向量中\n",
      "Sounds不存在于词向量中\n",
      "ESFJs不存在于词向量中\n",
      "Things不存在于词向量中\n",
      "Take不存在于词向量中\n",
      "Having不存在于词向量中\n",
      "YouTube不存在于词向量中\n",
      "and,不存在于词向量中\n",
      "else,不存在于词向量中\n",
      "today,不存在于词向量中\n",
      "child,不存在于词向量中\n",
      ":/不存在于词向量中\n",
      "days,不存在于词向量中\n",
      "i'd不存在于词向量中\n",
      "(but不存在于词向量中\n",
      "why.不存在于词向量中\n",
      "IS不存在于词向量中\n",
      "head,不存在于词向量中\n",
      "Last不存在于词向量中\n",
      "Will不存在于词向量中\n",
      "Could不存在于词向量中\n",
      "Fi,不存在于词向量中\n",
      "everything,不存在于词向量中\n",
      "Unless不存在于词向量中\n",
      "function.不存在于词向量中\n",
      "answer.不存在于词向量中\n",
      "bad,不存在于词向量中\n",
      "other,不存在于词向量中\n",
      "Fe.不存在于词向量中\n",
      "Like,不存在于词向量中\n",
      "Christian不存在于词向量中\n",
      "John不存在于词向量中\n",
      "see.不存在于词向量中\n",
      "fine.不存在于词向量中\n",
      "ENTJ,不存在于词向量中\n",
      "cool.不存在于词向量中\n",
      "Was不存在于词向量中\n",
      "it'll不存在于词向量中\n",
      "it...不存在于词向量中\n",
      "Time不存在于词向量中\n",
      "own.不存在于词向量中\n",
      "ISFJ,不存在于词向量中\n",
      "they've不存在于词向量中\n",
      "Facebook不存在于词向量中\n",
      "Try不存在于词向量中\n",
      "them?不存在于词向量中\n",
      "better,不存在于词向量中\n",
      "be...|||I不存在于词向量中\n",
      "mine.不存在于词向量中\n",
      "hadn't不存在于词向量中\n",
      "it'd不存在于词向量中\n",
      "(for不存在于词向量中\n",
      "Big不存在于词向量中\n",
      "see,不存在于词向量中\n",
      "have,不存在于词向量中\n",
      "Now,不存在于词向量中\n",
      "want.不存在于词向量中\n",
      "Either不存在于词向量中\n",
      "for...|||I不存在于词向量中\n",
      "Great不存在于词向量中\n",
      "thinking.不存在于词向量中\n",
      "understand.不存在于词向量中\n",
      "family.不存在于词向量中\n",
      "US不存在于词向量中\n",
      "Pretty不存在于词向量中\n",
      "far.不存在于词向量中\n",
      "night,不存在于词向量中\n",
      "for.不存在于词向量中\n",
      "guy,不存在于词向量中\n",
      "part,不存在于词向量中\n",
      "Christmas不存在于词向量中\n",
      "they'll不存在于词向量中\n",
      "ESTPs不存在于词向量中\n",
      "Thinking不存在于词向量中\n",
      "(at不存在于词向量中\n",
      "feeling.不存在于词向量中\n",
      "it...|||I不存在于词向量中\n",
      "we'll不存在于词向量中\n",
      "Always不存在于词向量中\n",
      "nice.不存在于词向量中\n",
      "months.不存在于词向量中\n",
      "Nice不存在于词向量中\n",
      "hard.不存在于词向量中\n",
      "Before不存在于词向量中\n",
      "nice,不存在于词向量中\n",
      "AND不存在于词向量中\n",
      "ISFP,不存在于词向量中\n",
      "3)不存在于词向量中\n",
      "Personally,不存在于词向量中\n",
      "seriously,不存在于词向量中\n",
      "themselves.不存在于词向量中\n",
      "least,不存在于词向量中\n",
      "from.不存在于词向量中\n",
      "funny.不存在于词向量中\n",
      "long,不存在于词向量中\n",
      "can.不存在于词向量中\n",
      "place,不存在于词向量中\n",
      "relationships.不存在于词向量中\n",
      "Anyone不存在于词向量中\n",
      "everyone's不存在于词向量中\n",
      "Honestly,不存在于词向量中\n",
      "thinking,不存在于词向量中\n",
      "Edit:不存在于词向量中\n",
      "High不存在于词向量中\n",
      "Yes.不存在于词向量中\n",
      "shit.不存在于词向量中\n",
      "questions.不存在于词向量中\n",
      "week.不存在于词向量中\n",
      "ALL不存在于词向量中\n",
      "(a不存在于词向量中\n",
      "college.不存在于词向量中\n",
      "Actually,不存在于词向量中\n",
      "thought.不存在于词向量中\n",
      "why,不存在于词向量中\n",
      "Best不存在于词向量中\n",
      "away,不存在于词向量中\n",
      "Fi.不存在于词向量中\n",
      "idea,不存在于词向量中\n",
      "Her不存在于词向量中\n",
      "(though不存在于词向量中\n",
      "6.不存在于词向量中\n",
      "either,不存在于词向量中\n",
      "relationships,不存在于词向量中\n",
      "You'll不存在于词向量中\n",
      "often,不存在于词向量中\n",
      "ever.不存在于词向量中\n",
      "with...|||I不存在于词向量中\n",
      "Another不存在于词向量中\n",
      "test.不存在于词向量中\n",
      "REALLY不存在于词向量中\n",
      "girl.不存在于词向量中\n",
      "around,不存在于词向量中\n",
      "ones.不存在于词向量中\n",
      "No.不存在于词向量中\n",
      "ENFP's不存在于词向量中\n",
      "weird.不存在于词向量中\n",
      "but...不存在于词向量中\n",
      "Definitely不存在于词向量中\n",
      "best.不存在于词向量中\n",
      "NTs不存在于词向量中\n",
      "Make不存在于词向量中\n",
      "of,不存在于词向量中\n",
      "Two不存在于词向量中\n",
      "ISFJs不存在于词向量中\n",
      "want,不存在于词向量中\n",
      "go,不存在于词向量中\n",
      "book,不存在于词向量中\n",
      "books,不存在于词向量中\n",
      "May不存在于词向量中\n",
      "Look不存在于词向量中\n",
      "thought,不存在于词向量中\n",
      "far,不存在于词向量中\n",
      "games,不存在于词向量中\n",
      "(even不存在于词向量中\n",
      "happy,不存在于词向量中\n",
      "read.不存在于词向量中\n",
      "MBTI,不存在于词向量中\n",
      "ESTP.不存在于词向量中\n",
      "Ne,不存在于词向量中\n",
      "Keep不存在于词向量中\n",
      "ways.不存在于词向量中\n",
      "me.|||I不存在于词向量中\n",
      "Star不存在于词向量中\n",
      "anyway,不存在于词向量中\n",
      "was.不存在于词向量中\n",
      "kid,不存在于词向量中\n",
      "happen.不存在于词向量中\n",
      "thoughts,不存在于词向量中\n",
      "Mostly不存在于词向量中\n",
      "home.不存在于词向量中\n",
      "did,不存在于词向量中\n",
      "what?不存在于词向量中\n",
      "weird,不存在于词向量中\n",
      "Whenever不存在于词向量中\n",
      "life?不存在于词向量中\n",
      "over.不存在于词向量中\n",
      "About不存在于词向量中\n",
      "Their不存在于词向量中\n",
      "reasons.不存在于词向量中\n",
      "past,不存在于词向量中\n",
      "once,不存在于词向量中\n",
      "personally,不存在于词向量中\n",
      "Black不存在于词向量中\n",
      "Seems不存在于词向量中\n",
      "problems.不存在于词向量中\n",
      "college,不存在于词向量中\n",
      "side.不存在于词向量中\n",
      "care.不存在于词向量中\n",
      "(my不存在于词向量中\n",
      "advice,不存在于词向量中\n",
      "or...|||I不存在于词向量中\n",
      "World不存在于词向量中\n",
      "IT不存在于词向量中\n",
      "younger,不存在于词向量中\n",
      "TO不存在于词向量中\n",
      "home,不存在于词向量中\n",
      "face.不存在于词向量中\n",
      "Think不存在于词向量中\n",
      "NFs不存在于词向量中\n",
      "..不存在于词向量中\n",
      "girl,不存在于词向量中\n",
      "friend's不存在于词向量中\n",
      "ESFJ.不存在于词向量中\n",
      "was,不存在于词向量中\n",
      "Ni,不存在于词向量中\n",
      "Am不存在于词向量中\n",
      "response.不存在于词向量中\n",
      "(especially不存在于词向量中\n",
      "bit,不存在于词向量中\n",
      "DO不存在于词向量中\n",
      "once.不存在于词向量中\n",
      "Tell不存在于词向量中\n",
      "also,不存在于词向量中\n",
      "Really不存在于词向量中\n",
      "nothing.不存在于词向量中\n",
      "SJ不存在于词向量中\n",
      "saying,不存在于词向量中\n",
      "ENTP's不存在于词向量中\n",
      "VERY不存在于词向量中\n",
      "have...|||I不存在于词向量中\n",
      "Plus不存在于词向量中\n",
      "done,不存在于词向量中\n",
      "ESFP.不存在于词向量中\n",
      "Sensing不存在于词向量中\n",
      "topic,不存在于词向量中\n",
      "Harry不存在于词向量中\n",
      "great,不存在于词向量中\n",
      "long.不存在于词向量中\n",
      "both.不存在于词向量中\n",
      "ideas,不存在于词向量中\n",
      "reality.不存在于词向量中\n",
      "function,不存在于词向量中\n",
      "X不存在于词向量中\n",
      "change.不存在于词向量中\n",
      "story.不存在于词向量中\n",
      "future.不存在于词向量中\n",
      "'I'm不存在于词向量中\n",
      "(who不存在于词向量中\n",
      "okay.不存在于词向量中\n",
      "anyone.不存在于词向量中\n",
      "end.不存在于词向量中\n",
      "matter.不存在于词向量中\n",
      "issues.不存在于词向量中\n",
      "Except不存在于词向量中\n",
      "I...|||I'm不存在于词向量中\n",
      "yeah.不存在于词向量中\n",
      "course.不存在于词向量中\n",
      "people?不存在于词向量中\n",
      "Actually不存在于词向量中\n",
      "eyes.不存在于词向量中\n",
      "honest.不存在于词向量中\n",
      "conversation.不存在于词向量中\n",
      "read,不存在于词向量中\n",
      "past.不存在于词向量中\n",
      "7.不存在于词向量中\n",
      "games.不存在于词向量中\n",
      "Ne.不存在于词向量中\n",
      "lately.不存在于词向量中\n",
      "are...|||I不存在于词向量中\n",
      "age.不存在于词向量中\n",
      "instance,不存在于词向量中\n",
      "kid.不存在于词向量中\n",
      "Jung不存在于词向量中\n",
      "Stop不存在于词向量中\n",
      "does.不存在于词向量中\n",
      "different,不存在于词向量中\n",
      "relate.不存在于词向量中\n",
      "thoughts.不存在于词向量中\n",
      "book.不存在于词向量中\n",
      "You've不存在于词向量中\n",
      "help,不存在于词向量中\n",
      "INFPs,不存在于词向量中\n",
      "saying.不存在于词向量中\n",
      "ESTJ.不存在于词向量中\n",
      "level.不存在于词向量中\n",
      "actually,不存在于词向量中\n",
      "INFPs.不存在于词向量中\n",
      "case.不存在于词向量中\n",
      "MBTI.不存在于词向量中\n",
      "ideas.不存在于词向量中\n",
      "issue.不存在于词向量中\n",
      "ESFJ,不存在于词向量中\n",
      "Ive不存在于词向量中\n",
      "side,不存在于词向量中\n",
      "later.不存在于词向量中\n",
      "Mr.不存在于词向量中\n",
      "seriously.不存在于词向量中\n",
      "child.不存在于词向量中\n",
      "important.不存在于词向量中\n",
      "movie,不存在于词向量中\n",
      "Death不存在于词向量中\n",
      "possible,不存在于词向量中\n",
      "together,不存在于词向量中\n",
      "not...|||I不存在于词向量中\n",
      "months,不存在于词向量中\n",
      "we'd不存在于词向量中\n",
      "women.不存在于词向量中\n",
      "they'd不存在于词向量中\n",
      "god,不存在于词向量中\n",
      "here?不存在于词向量中\n",
      "(although不存在于词向量中\n",
      "talk,不存在于词向量中\n",
      "Glad不存在于词向量中\n",
      "personality,不存在于词向量中\n",
      "money.不存在于词向量中\n",
      "David不存在于词向量中\n",
      "ESTP,不存在于词向量中\n",
      "Briggs不存在于词向量中\n",
      "Myers不存在于词向量中\n",
      "Japanese不存在于词向量中\n",
      "sleep.不存在于词向量中\n",
      "song.不存在于词向量中\n",
      "game.不存在于词向量中\n",
      "Basically不存在于词向量中\n",
      "feeling,不存在于词向量中\n",
      "heart.不存在于词向量中\n",
      "quiet,不存在于词向量中\n",
      "MY不存在于词向量中\n",
      "this...不存在于词向量中\n",
      "Man不存在于词向量中\n",
      "movie.不存在于词向量中\n",
      "Google不存在于词向量中\n",
      "God,不存在于词向量中\n",
      "talk.不存在于词向量中\n",
      "me...|||I不存在于词向量中\n",
      "Why?不存在于词向量中\n",
      "perspective.不存在于词向量中\n",
      "Same不存在于词向量中\n",
      "situations.不存在于词向量中\n",
      "ESFP,不存在于词向量中\n",
      "Anything不存在于词向量中\n",
      "Dark不存在于词向量中\n",
      "class.不存在于词向量中\n",
      "two.不存在于词向量中\n",
      "fine,不存在于词向量中\n",
      "another.不存在于词向量中\n",
      "old,不存在于词向量中\n",
      "posts.不存在于词向量中\n",
      "class,不存在于词向量中\n",
      "Doesn't不存在于词向量中\n",
      "Little不存在于词向量中\n",
      "Ti,不存在于词向量中\n",
      "other's不存在于词向量中\n",
      "but...|||I不存在于词向量中\n",
      "for,不存在于词向量中\n",
      "do?不存在于词向量中\n",
      "Plus,不存在于词向量中\n",
      "most.不存在于词向量中\n",
      "that...不存在于词向量中\n",
      "week,不存在于词向量中\n",
      "like?不存在于词向量中\n",
      "sex.不存在于词向量中\n",
      "I'm...|||I不存在于词向量中\n",
      "feel,不存在于词向量中\n",
      "shit,不存在于词向量中\n",
      "We've不存在于词向量中\n",
      "hey,不存在于词向量中\n",
      "would've不存在于词向量中\n",
      "writing,不存在于词向量中\n",
      "Social不存在于词向量中\n",
      "through.不存在于词向量中\n",
      "was...|||I不存在于词向量中\n",
      "nature.不存在于词向量中\n",
      "old.不存在于词向量中\n",
      "same,不存在于词向量中\n",
      "ain't不存在于词向量中\n",
      "okay,不存在于词向量中\n",
      "helpful.不存在于词向量中\n",
      "theory.不存在于词向量中\n",
      "LOL不存在于词向量中\n",
      "See不存在于词向量中\n",
      "best,不存在于词向量中\n",
      "Ni.不存在于词向量中\n",
      "will.不存在于词向量中\n",
      "French不存在于词向量中\n",
      "house.不存在于词向量中\n",
      "crazy.不存在于词向量中\n",
      "end,不存在于词向量中\n",
      "conversation,不存在于词向量中\n",
      "posts,不存在于词向量中\n",
      "thanks.不存在于词向量中\n",
      "understand,不存在于词向量中\n",
      "Seriously,不存在于词向量中\n",
      "accurate.不存在于词向量中\n",
      "sorry.不存在于词向量中\n",
      "example.不存在于词向量中\n",
      "INTJs,不存在于词向量中\n",
      "hard,不存在于词向量中\n",
      "topic.不存在于词向量中\n",
      "INTJs.不存在于词向量中\n",
      "he'll不存在于词向量中\n",
      "problems,不存在于词向量中\n",
      "money,不存在于词向量中\n",
      "questions,不存在于词向量中\n",
      "theory,不存在于词向量中\n",
      "doing.不存在于词向量中\n",
      "works.不存在于词向量中\n",
      "Makes不存在于词向量中\n",
      "information.不存在于词向量中\n",
      "Got不存在于词向量中\n",
      "about?不存在于词向量中\n",
      "easily.不存在于词向量中\n",
      "Although,不存在于词向量中\n",
      "Tapatalk|||I不存在于词向量中\n",
      "amazing.不存在于词向量中\n",
      "guess,不存在于词向量中\n",
      "recently,不存在于词向量中\n",
      "anyone,不存在于词向量中\n",
      "anymore,不存在于词向量中\n",
      "can,不存在于词向量中\n",
      "itself.不存在于词向量中\n",
      "exist.不存在于词向量中\n",
      "Music不存在于词向量中\n",
      "Socionics不存在于词向量中\n",
      "attention.不存在于词向量中\n",
      "me)不存在于词向量中\n",
      "INTPs,不存在于词向量中\n",
      "Se,不存在于词向量中\n",
      "on...|||I不存在于词向量中\n",
      "(that不存在于词向量中\n",
      "INFJs.不存在于词向量中\n",
      "Anyways,不存在于词向量中\n",
      "Day不存在于词向量中\n",
      "(because不存在于词向量中\n",
      "nature,不存在于词向量中\n",
      "boring.不存在于词向量中\n",
      ":-)不存在于词向量中\n",
      "INTPs.不存在于词向量中\n",
      "truth.不存在于词向量中\n",
      "reply.不存在于词向量中\n",
      "Come不存在于词向量中\n",
      "stupid.不存在于词向量中\n",
      "EDIT:不存在于词向量中\n",
      "song,不存在于词向量中\n",
      "house,不存在于词向量中\n",
      "Trump不存在于词向量中\n",
      "choice.不存在于词向量中\n",
      "children.不存在于词向量中\n",
      "eyes,不存在于词向量中\n",
      "happens.不存在于词向量中\n",
      "to...|||I'm不存在于词向量中\n",
      "is...不存在于词向量中\n",
      "King不存在于词向量中\n",
      "Without不存在于词向量中\n",
      "Unfortunately,不存在于词向量中\n",
      "(with不存在于词向量中\n",
      "angry,不存在于词向量中\n",
      "lol,不存在于词向量中\n",
      "INFJs,不存在于词向量中\n",
      "a...|||I'm不存在于词向量中\n",
      "an...|||I不存在于词向量中\n",
      "Jesus不存在于词向量中\n",
      "Science不存在于词向量中\n",
      "ESTJs不存在于词向量中\n",
      "ways,不存在于词向量中\n",
      "HATE不存在于词向量中\n",
      "sad.不存在于词向量中\n",
      "change,不存在于词向量中\n",
      "(to不存在于词向量中\n",
      "worry,不存在于词向量中\n",
      "mine,不存在于词向量中\n",
      "beautiful.不存在于词向量中\n",
      "....不存在于词向量中\n",
      "more...|||I不存在于词向量中\n",
      "why?不存在于词向量中\n",
      "note,不存在于词向量中\n",
      "Internet不存在于词向量中\n",
      "age,不存在于词向量中\n",
      "Today不存在于词向量中\n",
      "NO不存在于词向量中\n",
      "kind,不存在于词向量中\n",
      "Kind不存在于词向量中\n",
      "hours.不存在于词向量中\n",
      "you...不存在于词向量中\n",
      "word.不存在于词向量中\n",
      "Sorry,不存在于词向量中\n",
      "Lord不存在于词向量中\n",
      "Happy不存在于词向量中\n",
      "least.不存在于词向量中\n",
      "food,不存在于词向量中\n",
      "the...|||I'm不存在于词向量中\n",
      "very,不存在于词向量中\n",
      "answer,不存在于词向量中\n",
      "ESTJ,不存在于词向量中\n",
      "themselves,不存在于词向量中\n",
      "recently.不存在于词向量中\n",
      "Te,不存在于词向量中\n",
      "welcome.不存在于词向量中\n",
      "list.不存在于词向量中\n",
      "Cognitive不存在于词向量中\n",
      "depression.不存在于词向量中\n",
      "so...不存在于词向量中\n",
      "America不存在于词向量中\n",
      "Going不存在于词向量中\n",
      "just...|||I不存在于词向量中\n",
      "Dad不存在于词向量中\n",
      "Wikipedia,不存在于词向量中\n",
      "Sure,不存在于词向量中\n",
      "Such不存在于词向量中\n",
      "ARE不存在于词向量中\n",
      "annoying.不存在于词向量中\n",
      "process.不存在于词向量中\n",
      "Had不存在于词向量中\n",
      "kids,不存在于词向量中\n",
      "crazy,不存在于词向量中\n",
      "whatever.不存在于词向量中\n",
      "Okay,不存在于词向量中\n",
      "Personally不存在于词向量中\n",
      "now?不存在于词向量中\n",
      "room,不存在于词向量中\n",
      "House不存在于词向量中\n",
      "Lots不存在于词向量中\n",
      "cool,不存在于词向量中\n",
      "sad,不存在于词向量中\n",
      "PerC!不存在于词向量中\n",
      "else's不存在于词向量中\n",
      "about...|||I不存在于词向量中\n",
      "interest.不存在于词向量中\n",
      "own,不存在于词向量中\n",
      "honestly,不存在于词向量中\n",
      "Si,不存在于词向量中\n",
      "Unfortunately不存在于词向量中\n",
      "Obviously不存在于词向量中\n",
      "language,不存在于词向量中\n",
      "room.不存在于词向量中\n",
      "(i.e.不存在于词向量中\n",
      "Whether不存在于词向量中\n",
      "Apparently不存在于词向量中\n",
      "Give不存在于词向量中\n",
      ":).不存在于词向量中\n",
      ":D|||I不存在于词向量中\n",
      "Looking不存在于词向量中\n",
      "sex,不存在于词向量中\n",
      "And,不存在于词向量中\n",
      "personally.不存在于词向量中\n",
      "Lol不存在于词向量中\n",
      "...|||I'm不存在于词向量中\n",
      "kids.不存在于词向量中\n",
      "Hey不存在于词向量中\n",
      "from,不存在于词向量中\n",
      "Find不存在于词向量中\n",
      "SP不存在于词向量中\n",
      "behavior.不存在于词向量中\n",
      "German不存在于词向量中\n",
      "Show不存在于词向量中\n",
      "2,不存在于词向量中\n",
      "also.不存在于词向量中\n",
      "books.不存在于词向量中\n",
      "movies,不存在于词向量中\n",
      "as...|||I不存在于词向量中\n",
      "True不存在于词向量中\n",
      "group.不存在于词向量中\n",
      "smart,不存在于词向量中\n",
      "Se.不存在于词向量中\n",
      "awesome,不存在于词向量中\n",
      "not?不存在于词向量中\n",
      "society.不存在于词向量中\n",
      "Potter不存在于词向量中\n",
      "laugh.不存在于词向量中\n",
      "4,不存在于词向量中\n",
      "Has不存在于词向量中\n",
      "OP,不存在于词向量中\n",
      "sleep,不存在于词向量中\n",
      "PM不存在于词向量中\n",
      "Art不存在于词向量中\n",
      "face,不存在于词向量中\n",
      "soon.不存在于词向量中\n",
      "video.不存在于词向量中\n",
      "ENFPs.不存在于词向量中\n",
      "'The不存在于词向量中\n",
      "Guess不存在于词向量中\n",
      "i.e.不存在于词向量中\n",
      "Thats不存在于词向量中\n",
      "Disney不存在于词向量中\n",
      "he'd不存在于词向量中\n",
      "shy,不存在于词向量中\n",
      "name.不存在于词向量中\n",
      "such.不存在于词向量中\n",
      "thing?不存在于词向量中\n",
      "Feel不存在于词向量中\n",
      "answers.不存在于词向量中\n",
      "month.不存在于词向量中\n",
      "Nobody不存在于词向量中\n",
      "THAT不存在于词向量中\n",
      "try.不存在于词向量中\n",
      "Instead不存在于词向量中\n",
      ":laughing:|||I不存在于词向量中\n",
      "9.不存在于词向量中\n",
      "tests,不存在于词向量中\n",
      "cold,不存在于词向量中\n",
      "ADHD不存在于词向量中\n",
      "points,不存在于词向量中\n",
      "LOT不存在于词向量中\n",
      "Female不存在于词向量中\n",
      "like...|||I不存在于词向量中\n",
      "space.不存在于词向量中\n",
      "results.不存在于词向量中\n",
      "women,不存在于词向量中\n",
      "story,不存在于词向量中\n",
      "Didn't不存在于词向量中\n",
      "THIS不存在于词向量中\n",
      "art.不存在于词向量中\n",
      "Haha,不存在于词向量中\n",
      "Te.不存在于词向量中\n",
      "8.不存在于词向量中\n",
      "mood.不存在于词向量中\n",
      "already.不存在于词向量中\n",
      "Extraverted不存在于词向量中\n",
      "later,不存在于词向量中\n",
      "logic,不存在于词向量中\n",
      "too...不存在于词向量中\n",
      "Back不存在于词向量中\n",
      "truth,不存在于词向量中\n",
      "depressed,不存在于词向量中\n",
      "language.不存在于词向量中\n",
      "Isn't不存在于词向量中\n",
      "at.不存在于词向量中\n",
      "values,不存在于词向量中\n",
      "situations,不存在于词向量中\n",
      "time?不存在于词向量中\n",
      "Sometimes,不存在于词向量中\n",
      "opposite.不存在于词向量中\n",
      "body.不存在于词向量中\n",
      "Earth不存在于词向量中\n",
      "Been不存在于词向量中\n",
      "curious,不存在于词向量中\n",
      ":tongue:|||I不存在于词向量中\n",
      ":P|||I不存在于词向量中\n",
      "so...|||I不存在于词向量中\n",
      "Hey,不存在于词向量中\n",
      "speaking,不存在于词向量中\n",
      "(it不存在于词向量中\n",
      "degree.不存在于词向量中\n",
      "ESFPs不存在于词向量中\n",
      "Ask不存在于词向量中\n",
      "food.不存在于词向量中\n",
      "be?不存在于词向量中\n",
      "little.不存在于词向量中\n",
      "points.不存在于词向量中\n",
      "happened.不存在于词向量中\n",
      "like...不存在于词向量中\n",
      "future,不存在于词向量中\n",
      "George不存在于词向量中\n",
      "system.不存在于词向量中\n",
      "yesterday.不存在于词向量中\n",
      "don't...|||I不存在于词向量中\n",
      "Bad不存在于词向量中\n",
      "questions?不存在于词向量中\n",
      "men.不存在于词向量中\n",
      "mean?不存在于词向量中\n",
      "interested.不存在于词向量中\n",
      "your...|||I不存在于词向量中\n",
      "view.不存在于词向量中\n",
      "I.不存在于词向量中\n",
      "Should不存在于词向量中\n",
      "Part不存在于词向量中\n",
      "PC不存在于词向量中\n",
      "this...|||I不存在于词向量中\n",
      "Whatever不存在于词向量中\n",
      "ok,不存在于词向量中\n",
      "he/she不存在于词向量中\n",
      "Red不存在于词向量中\n",
      "forums,不存在于词向量中\n",
      "above.不存在于词向量中\n",
      "Dr.不存在于词向量中\n",
      "writing.不存在于词向量中\n",
      "don't,不存在于词向量中\n",
      "it)不存在于词向量中\n",
      "level,不存在于词向量中\n",
      "pain.不存在于词向量中\n",
      "(no不存在于词向量中\n",
      "strong,不存在于词向量中\n",
      "Reading不存在于词向量中\n",
      "beautiful,不存在于词向量中\n",
      "hair,不存在于词向量中\n",
      "BUT不存在于词向量中\n",
      "Hopefully不存在于词向量中\n",
      "experiences,不存在于词向量中\n",
      "Blue不存在于词向量中\n",
      "death.不存在于词向量中\n",
      "Ti.不存在于词向量中\n",
      "ones,不存在于词向量中\n",
      "Out不存在于词向量中\n",
      "(The不存在于词向量中\n",
      "over,不存在于词向量中\n",
      "(i不存在于词向量中\n",
      "others'不存在于词向量中\n",
      "Doctor不存在于词向量中\n",
      "exactly.不存在于词向量中\n",
      "Otherwise,不存在于词向量中\n",
      "lately,不存在于词向量中\n",
      "sucks.不存在于词向量中\n",
      "Sherlock不存在于词向量中\n",
      "Dad:不存在于词向量中\n",
      "ME不存在于词向量中\n",
      "Might不存在于词向量中\n",
      "3,不存在于词向量中\n",
      "confused.不存在于词向量中\n",
      "School不存在于词向量中\n",
      "Almost不存在于词向量中\n",
      "similar.不存在于词向量中\n",
      "White不存在于词向量中\n",
      "B不存在于词向量中\n",
      "time...不存在于词向量中\n",
      "Yet不存在于词向量中\n",
      "intelligent,不存在于词向量中\n",
      "Over不存在于词向量中\n",
      "parents,不存在于词向量中\n",
      "online,不存在于词向量中\n",
      "internet.不存在于词向量中\n",
      "responses.不存在于词向量中\n",
      "late,不存在于词向量中\n",
      "out?不存在于词向量中\n",
      "know?不存在于词向量中\n",
      "now...不存在于词向量中\n",
      "reality,不存在于词向量中\n",
      "movies.不存在于词向量中\n",
      "reading,不存在于词向量中\n",
      "=)不存在于词向量中\n",
      "humor.不存在于词向量中\n",
      "easy.不存在于词向量中\n",
      "woman.不存在于词向量中\n",
      "to?不存在于词向量中\n",
      "and...|||I'm不存在于词向量中\n",
      "Funny不存在于词向量中\n",
      "younger.不存在于词向量中\n",
      "most,不存在于词向量中\n",
      "ENFJ's不存在于词向量中\n",
      "children,不存在于词向量中\n",
      "society,不存在于词向量中\n",
      "Basically,不存在于词向量中\n",
      "religion.不存在于词向量中\n",
      "female,不存在于词向量中\n",
      "Much不存在于词向量中\n",
      "mood,不存在于词向量中\n",
      "Getting不存在于词向量中\n",
      "Extroverted不存在于词向量中\n",
      "female.不存在于词向量中\n",
      "here...不存在于词向量中\n",
      "yourself?不存在于词向量中\n",
      "two,不存在于词向量中\n",
      "subject.不存在于词向量中\n",
      "ask,不存在于词向量中\n",
      "she'll不存在于词向量中\n",
      "the...'不存在于词向量中\n",
      "though.|||I不存在于词向量中\n",
      "short,不存在于词向量中\n",
      "die.不存在于词向量中\n",
      "forums.不存在于词向量中\n",
      "information,不存在于词向量中\n",
      "game,不存在于词向量中\n",
      "I...'不存在于词向量中\n",
      "introvert.不存在于词向量中\n",
      "parents.不存在于词向量中\n",
      "name,不存在于词向量中\n",
      "know...不存在于词向量中\n",
      "art,不存在于词向量中\n",
      "Say不存在于词向量中\n",
      "Game不存在于词向量中\n",
      "issues,不存在于词向量中\n",
      "I...|||My不存在于词向量中\n",
      "Haha不存在于词向量中\n",
      "happens,不存在于词向量中\n",
      "hand.不存在于词向量中\n",
      "Male不存在于词向量中\n",
      "Otherwise不存在于词向量中\n",
      "says,不存在于词向量中\n",
      "inside.不存在于词向量中\n",
      "young,不存在于词向量中\n",
      "PerC,不存在于词向量中\n",
      "introvert,不存在于词向量中\n",
      "perspective,不存在于词向量中\n",
      "morning,不存在于词向量中\n",
      "heart,不存在于词向量中\n",
      "(this不存在于词向量中\n",
      "care,不存在于词向量中\n",
      "mom,不存在于词向量中\n",
      "way?不存在于词向量中\n",
      "Still,不存在于词向量中\n",
      "Though,不存在于词向量中\n",
      "INFP?不存在于词向量中\n",
      "mother,不存在于词向量中\n",
      "depression,不存在于词向量中\n",
      "lives.不存在于词向量中\n",
      "South不存在于词向量中\n",
      "Honestly不存在于词向量中\n",
      "characters.不存在于词向量中\n",
      "introverted,不存在于词向量中\n",
      "skills.不存在于词向量中\n",
      "Long不存在于词向量中\n",
      "introverted.不存在于词向量中\n",
      "Fuck不存在于词向量中\n",
      "AM不存在于词向量中\n",
      "response,不存在于词向量中\n",
      "Mine不存在于词向量中\n",
      "sister,不存在于词向量中\n",
      "Read不存在于词向量中\n",
      "Green不存在于词向量中\n",
      "Chinese不存在于词向量中\n",
      "boring,不存在于词向量中\n",
      "God.不存在于词向量中\n",
      "stupid,不存在于词向量中\n",
      "Interesting不存在于词向量中\n",
      "correct.不存在于词向量中\n",
      "reasons,不存在于词向量中\n",
      "NEVER不存在于词向量中\n",
      "Seriously不存在于词向量中\n",
      "intelligence,不存在于词向量中\n",
      "Jane不存在于词向量中\n",
      "at...|||I不存在于词向量中\n",
      "Based不存在于词向量中\n",
      "get.不存在于词向量中\n",
      "dreams,不存在于词向量中\n",
      ";)|||I不存在于词向量中\n",
      "science,不存在于词向量中\n",
      "Human不存在于词向量中\n",
      "woman,不存在于词向量中\n",
      "wow,不存在于词向量中\n",
      "kind.不存在于词向量中\n",
      "illness,不存在于词向量中\n",
      "something?不存在于词向量中\n",
      "Test不存在于词向量中\n",
      "(And不存在于词向量中\n",
      "action.不存在于词向量中\n",
      "Hitler不存在于词向量中\n",
      "think?不存在于词向量中\n",
      "5,不存在于词向量中\n",
      "of...|||I'm不存在于词向量中\n",
      "Jack不存在于词向量中\n",
      "what,不存在于词向量中\n",
      "curious.不存在于词向量中\n",
      "it's...|||I不存在于词向量中\n",
      "show.不存在于词向量中\n",
      "because,不存在于词向量中\n",
      "INTJ?不存在于词向量中\n",
      "hell.不存在于词向量中\n",
      "start.不存在于词向量中\n",
      "easy,不存在于词向量中\n",
      "Name不存在于词向量中\n",
      "self.不存在于词向量中\n",
      "very...|||I不存在于词向量中\n",
      "cry.不存在于词向量中\n",
      "Dead不存在于词向量中\n",
      "energy.不存在于词向量中\n",
      "ENFPs,不存在于词向量中\n",
      "picture.不存在于词向量中\n",
      "1,不存在于词向量中\n",
      "Girl不存在于词向量中\n",
      "late.不存在于词向量中\n",
      "one?不存在于词向量中\n",
      "4)不存在于词向量中\n",
      "doing,不存在于词向量中\n",
      "logic.不存在于词向量中\n",
      "control.不存在于词向量中\n",
      "aside,不存在于词向量中\n",
      "None不存在于词向量中\n",
      "intelligence.不存在于词向量中\n",
      "they...|||I不存在于词向量中\n",
      "ENTPs,不存在于词向量中\n",
      "word,不存在于词向量中\n",
      "values.不存在于词向量中\n",
      "(from不存在于词向量中\n",
      "quickly.不存在于词向量中\n",
      "girls.不存在于词向量中\n",
      "IN不存在于词向量中\n",
      "Intuition不存在于词向量中\n",
      "Trying不存在于词向量中\n",
      "system,不存在于词向量中\n",
      "2.)不存在于词向量中\n",
      "happen,不存在于词向量中\n",
      "another,不存在于词向量中\n",
      "then?不存在于词向量中\n",
      "date.不存在于词向量中\n",
      "During不存在于词向量中\n",
      "hilarious.不存在于词向量中\n",
      "though...不存在于词向量中\n",
      "group,不存在于词向量中\n",
      "Often不存在于词向量中\n",
      "math.不存在于词向量中\n",
      "...'不存在于词向量中\n",
      "huh?不存在于词向量中\n",
      "completely.不存在于词向量中\n",
      "mom's不存在于词向量中\n",
      "smile.不存在于词向量中\n",
      "Then,不存在于词向量中\n",
      "extent.不存在于词向量中\n",
      "nothing,不存在于词向量中\n",
      "depressed.不存在于词向量中\n",
      "style.不存在于词向量中\n",
      "Next不存在于词向量中\n",
      "Psychology不存在于词向量中\n",
      "remember.不存在于词向量中\n",
      "-I不存在于词向量中\n",
      "bed,不存在于词向量中\n",
      "dad's不存在于词向量中\n",
      "less.不存在于词向量中\n",
      "space,不存在于词向量中\n",
      "environment.不存在于词向量中\n",
      "deep,不存在于词向量中\n",
      "picture,不存在于词向量中\n",
      "perfect.不存在于词向量中\n",
      "Bible不存在于词向量中\n",
      "Physical不存在于词向量中\n",
      "angry.不存在于词向量中\n",
      "Judging不存在于词向量中\n",
      "James不存在于词向量中\n",
      "Wow,不存在于词向量中\n",
      "ISTJ's不存在于词向量中\n",
      "dreams.不存在于词向量中\n",
      "people...|||I不存在于词向量中\n",
      "do...|||I不存在于词向量中\n",
      "hair.不存在于词向量中\n",
      "emotional,不存在于词向量中\n",
      "cute.不存在于词向量中\n",
      "bored.不存在于词向量中\n",
      "being.不存在于词向量中\n",
      "OF不存在于词向量中\n",
      "experiences.不存在于词向量中\n",
      "morning.不存在于词向量中\n",
      "Neutral不存在于词向量中\n",
      "both,不存在于词向量中\n",
      "attention,不存在于词向量中\n",
      "mother.不存在于词向量中\n",
      "up?不存在于词向量中\n",
      "English,不存在于词向量中\n",
      "worse.不存在于词向量中\n",
      "well...不存在于词向量中\n",
      ":)|||I'm不存在于词向量中\n",
      "series.不存在于词向量中\n",
      "Spanish不存在于词向量中\n",
      "lol|||I不存在于词向量中\n",
      "suppose.不存在于词向量中\n",
      "is?不存在于词向量中\n",
      "ok.不存在于词向量中\n",
      "I鈥檓不存在于词向量中\n",
      "issue,不存在于词向量中\n",
      "OP.不存在于词向量中\n",
      "male.不存在于词向量中\n",
      "character.不存在于词向量中\n",
      "Age不存在于词向量中\n",
      "tests.不存在于词向量中\n",
      "hurt.不存在于词向量中\n",
      "(:不存在于词向量中\n",
      "view,不存在于词向量中\n",
      "6,不存在于词向量中\n",
      "stress.不存在于词向量中\n",
      "(except不存在于词向量中\n",
      "Thought不存在于词向量中\n",
      "mom.不存在于词向量中\n",
      "etc.)不存在于词向量中\n",
      "internet,不存在于词向量中\n",
      "sx/so不存在于词向量中\n",
      "psychology,不存在于词向量中\n",
      "serious.不存在于词向量中\n",
      "simple.不存在于词向量中\n",
      "SJs不存在于词向量中\n",
      "joke.不存在于词向量中\n",
      "normal.不存在于词向量中\n",
      "sweet,不存在于词向量中\n",
      "company.不存在于词向量中\n",
      "Trust不存在于词向量中\n",
      "Tom不存在于词向量中\n",
      "real.不存在于词向量中\n",
      "First,不存在于词向量中\n",
      "HAVE不存在于词向量中\n",
      "Ok,不存在于词向量中\n",
      "easily,不存在于词向量中\n",
      "history,不存在于词向量中\n",
      "humor,不存在于词向量中\n",
      "weeks.不存在于词向量中\n",
      "INFJ?不存在于词向量中\n",
      "online.不存在于词向量中\n",
      "weeks,不存在于词向量中\n",
      "young.不存在于词向量中\n",
      "fair,不存在于词向量中\n",
      "pain,不存在于词向量中\n",
      "emotion.不存在于词向量中\n",
      "Wars不存在于词向量中\n",
      "Second不存在于词向量中\n",
      "instead.不存在于词向量中\n",
      "Jungian不存在于词向量中\n",
      "Sure不存在于词向量中\n",
      "(maybe不存在于词向量中\n",
      "brother,不存在于词向量中\n",
      "Each不存在于词向量中\n",
      ":happy:|||I不存在于词向量中\n",
      "input.不存在于词向量中\n",
      "(he不存在于词向量中\n",
      "Intuitive不存在于词向量中\n",
      "Emotional不存在于词向量中\n",
      "would.不存在于词向量中\n",
      "met.不存在于词向量中\n",
      "dream.不存在于词向量中\n",
      "little,不存在于词向量中\n",
      "disagree.不存在于词向量中\n",
      "anxiety.不存在于词向量中\n",
      "can...|||I不存在于词向量中\n",
      "outside,不存在于词向量中\n",
      "simple,不存在于词向量中\n",
      "(unless不存在于词向量中\n",
      "(so不存在于词向量中\n",
      "bed.不存在于词向量中\n",
      "car,不存在于词向量中\n",
      "had.不存在于词向量中\n",
      "definitely.不存在于词向量中\n",
      "Looks不存在于词向量中\n",
      "T,不存在于词向量中\n",
      "that.|||I不存在于词向量中\n",
      "Haven't不存在于词向量中\n",
      "please.不存在于词向量中\n",
      "religion,不存在于词向量中\n",
      "though?不存在于词向量中\n",
      "anxiety,不存在于词向量中\n",
      "degree,不存在于词向量中\n",
      "awkward.不存在于词向量中\n",
      "going.不存在于词向量中\n",
      "difference.不存在于词向量中\n",
      "extrovert.不存在于词向量中\n",
      "really...|||I不存在于词向量中\n",
      "T.不存在于词向量中\n",
      "older,不存在于词向量中\n",
      "science.不存在于词向量中\n",
      "ENTPs.不存在于词向量中\n",
      "Types不存在于词向量中\n",
      "math,不存在于词向量中\n",
      "Remember不存在于词向量中\n",
      "(when不存在于词向量中\n",
      "country,不存在于词向量中\n",
      "sensitive,不存在于词向量中\n",
      "forever.不存在于词向量中\n",
      "purpose.不存在于词向量中\n",
      "Free不存在于词向量中\n",
      "Check不存在于词向量中\n",
      "reading.不存在于词向量中\n",
      "show,不存在于词向量中\n",
      "phone.不存在于词向量中\n",
      "site.不存在于词向量中\n",
      "Besides,不存在于词向量中\n",
      "y'all不存在于词向量中\n",
      "understanding.不存在于词向量中\n",
      "party,不存在于词向量中\n",
      "Despite不存在于词向量中\n",
      "male,不存在于词向量中\n",
      "Old不存在于词向量中\n",
      "self,不存在于词向量中\n",
      "Sincerely,不存在于词向量中\n",
      "Enjoy不存在于词向量中\n",
      "perfect,不存在于词向量中\n",
      "'My不存在于词向量中\n",
      "close.不存在于词向量中\n",
      "Currently不存在于词向量中\n",
      "yours.不存在于词向量中\n",
      "partner.不存在于词向量中\n",
      "what...|||I不存在于词向量中\n",
      "such,不存在于词向量中\n",
      "still,不存在于词向量中\n",
      "loud,不存在于词向量中\n",
      "anyone's不存在于词向量中\n",
      "new,不存在于词向量中\n",
      "character,不存在于词向量中\n",
      "interests.不存在于词向量中\n",
      "all?不存在于词向量中\n",
      "interested,不存在于词向量中\n",
      "his/her不存在于词向量中\n",
      "Generally不存在于词向量中\n",
      "Si.不存在于词向量中\n",
      "NT's不存在于词向量中\n",
      "order.不存在于词向量中\n",
      "you.|||I不存在于词向量中\n",
      "mentioned,不存在于词向量中\n",
      "Imagine不存在于词向量中\n",
      "Jung's不存在于词向量中\n",
      "oh,不存在于词向量中\n",
      "attractive.不存在于词向量中\n",
      "Hello不存在于词向量中\n",
      "(you不存在于词向量中\n",
      "Mom不存在于词向量中\n",
      "emotional.不存在于词向量中\n",
      "difficult.不存在于词向量中\n",
      "YOUR不存在于词向量中\n",
      "fact.不存在于词向量中\n",
      "Slytherin不存在于词向量中\n",
      "(it's不存在于词向量中\n",
      "Robert不存在于词向量中\n",
      "Words不存在于词向量中\n",
      "brain.不存在于词向量中\n",
      "matter,不存在于词向量中\n",
      "emotion,不存在于词向量中\n",
      "argument.不存在于词向量中\n",
      "Ok不存在于词向量中\n",
      "a)不存在于词向量中\n",
      "PerC.不存在于词向量中\n",
      "ISFJ's不存在于词向量中\n",
      "above,不存在于词向量中\n",
      "from...|||I不存在于词向量中\n",
      "them...不存在于词向量中\n",
      "behavior,不存在于词向量中\n",
      "Besides不存在于词向量中\n",
      "hurt,不存在于词向量中\n",
      "made.不存在于词向量中\n",
      "Michael不存在于词向量中\n",
      "Ever不存在于词向量中\n",
      "lonely.不存在于词向量中\n",
      "girls,不存在于词向量中\n",
      "Mind不存在于词向量中\n",
      "to...|||My不存在于词向量中\n",
      "Moon不存在于词向量中\n",
      "site,不存在于词向量中\n",
      "the...|||My不存在于词向量中\n",
      "Ix92m不存在于词向量中\n",
      "understanding,不存在于词向量中\n",
      "United不存在于词向量中\n",
      "(just不存在于词向量中\n",
      "Or,不存在于词向量中\n",
      "use.不存在于词向量中\n",
      "lie,不存在于词向量中\n",
      "itself,不存在于词向量中\n",
      "Ravenclaw不存在于词向量中\n",
      "Anyway不存在于词向量中\n",
      "through,不存在于词向量中\n",
      "new.不存在于词向量中\n",
      "(probably不存在于词向量中\n",
      "list,不存在于词向量中\n",
      "Myers-Briggs不存在于词向量中\n",
      "real,不存在于词向量中\n",
      "interest,不存在于词向量中\n",
      "individual.不存在于词向量中\n",
      "bored,不存在于词向量中\n",
      "him?不存在于词向量中\n",
      "curiosity,不存在于词向量中\n",
      "Five不存在于词向量中\n",
      "look,不存在于词向量中\n",
      "does,不存在于词向量中\n",
      "already,不存在于词向量中\n",
      "others?不存在于词向量中\n",
      "amazing,不存在于词向量中\n",
      "Were不存在于词向量中\n",
      "Cause不存在于词向量中\n",
      "video,不存在于词向量中\n",
      "important,不存在于词向量中\n",
      "would...|||I不存在于词向量中\n",
      "Note不存在于词向量中\n",
      "cute,不存在于词向量中\n",
      "look.不存在于词向量中\n",
      "According不存在于词向量中\n",
      "Friday不存在于词向量中\n",
      "KNOW不存在于词向量中\n",
      "think...|||I不存在于词向量中\n",
      ":proud:|||I不存在于词向量中\n",
      "dark,不存在于词向量中\n",
      "ever,不存在于词向量中\n",
      "stories,不存在于词向量中\n",
      "live.不存在于词向量中\n",
      "Super不存在于词向量中\n",
      "otherwise.不存在于词向量中\n",
      "traits.不存在于词向量中\n",
      "ISFP's不存在于词向量中\n",
      "reply,不存在于词向量中\n",
      "Talk不存在于词向量中\n",
      "correct,不存在于词向量中\n",
      "himself.不存在于词向量中\n",
      "British不存在于词向量中\n",
      "knowledge,不存在于词向量中\n",
      "avatar.不存在于词向量中\n",
      "sister.不存在于词向量中\n",
      "will,不存在于词向量中\n",
      "from?不存在于词向量中\n",
      "medications,不存在于词向量中\n",
      "there?不存在于词向量中\n",
      "ISTP's不存在于词向量中\n",
      "dude.不存在于词向量中\n",
      "fast.不存在于词向量中\n",
      "...|||The不存在于词向量中\n",
      "Wish不存在于词向量中\n",
      "Making不存在于词向量中\n",
      "argument,不存在于词向量中\n",
      "happened,不存在于词向量中\n",
      "live,不存在于词向量中\n",
      "crap.不存在于词向量中\n",
      "Eye不存在于词向量中\n",
      "I...|||The不存在于词向量中\n",
      "answers,不存在于词向量中\n",
      "common.不存在于词向量中\n",
      "boyfriend,不存在于词向量中\n",
      "skills,不存在于词向量中\n",
      "I...|||This不存在于词向量中\n",
      "conversations,不存在于词向量中\n",
      "sweet.不存在于词向量中\n",
      "awkward,不存在于词向量中\n",
      "OR不存在于词向量中\n",
      "accurate,不存在于词向量中\n",
      "wait,不存在于词向量中\n",
      "person?不存在于词向量中\n",
      "sharing.不存在于词向量中\n",
      "the...|||The不存在于词向量中\n",
      "admit,不存在于词向量中\n",
      "remember,不存在于词向量中\n",
      "country.不存在于词向量中\n",
      "tomorrow.不存在于词向量中\n",
      "Men不存在于词向量中\n",
      "quiet.不存在于词向量中\n",
      "ENTJ's不存在于词向量中\n",
      "all...|||I不存在于词向量中\n",
      "believe,不存在于词向量中\n",
      "characters,不存在于词向量中\n",
      "9,不存在于词向量中\n",
      "and...'不存在于词向量中\n",
      "too?不存在于词向量中\n",
      "some...|||I不存在于词向量中\n",
      "business.不存在于词向量中\n",
      "ask.不存在于词向量中\n",
      "maybe,不存在于词向量中\n",
      "ADD不存在于词向量中\n",
      "seen.不存在于词向量中\n",
      "their...|||I不存在于词向量中\n",
      "stop.不存在于词向量中\n",
      "friends?不存在于词向量中\n",
      "honesty,不存在于词向量中\n",
      "say?不存在于词向量中\n",
      "Real不存在于词向量中\n",
      "normal,不存在于词向量中\n",
      "honestly.不存在于词向量中\n",
      "evil.不存在于词向量中\n",
      "knowledge.不存在于词向量中\n",
      "state.不存在于词向量中\n",
      "the...|||You不存在于词向量中\n",
      "series,不存在于词向量中\n",
      "Up不存在于词向量中\n",
      "cry,不存在于词向量中\n",
      "her?不存在于词向量中\n",
      "relationship?不存在于词向量中\n",
      "insight.不存在于词向量中\n",
      "Damn不存在于词向量中\n",
      "animals,不存在于词向量中\n",
      "(most不存在于词向量中\n",
      "Japan不存在于词向量中\n",
      "description.不存在于词向量中\n",
      "computer.不存在于词向量中\n",
      "differently.不存在于词向量中\n",
      "Computer不存在于词向量中\n",
      "them.|||I不存在于词向量中\n",
      "actions.不存在于词向量中\n",
      "please,不存在于词向量中\n",
      "men,不存在于词向量中\n",
      "childhood.不存在于词向量中\n",
      "interests,不存在于词向量中\n",
      "phone,不存在于词向量中\n",
      "work?不存在于词向量中\n",
      "works,不存在于词向量中\n",
      "open,不存在于词向量中\n",
      "party.不存在于词向量中\n",
      "yesterday,不存在于词向量中\n",
      "talking.不存在于词向量中\n",
      "death,不存在于词向量中\n",
      "the...|||This不存在于词向量中\n",
      "cold.不存在于词向量中\n",
      "(well,不存在于词向量中\n",
      "thread?不存在于词向量中\n",
      "hours,不存在于词向量中\n",
      "ALWAYS不存在于词向量中\n",
      "sx/sp不存在于词向量中\n",
      "get...|||I不存在于词向量中\n",
      "w/不存在于词向量中\n",
      "etc)不存在于词向量中\n",
      "UK不存在于词向量中\n",
      "IRL不存在于词向量中\n",
      "universe.不存在于词向量中\n",
      "description,不存在于词向量中\n",
      "actions,不存在于词向量中\n",
      "drugs,不存在于词向量中\n",
      "Writing不存在于词向量中\n",
      "serious,不存在于词向量中\n",
      "at,不存在于词向量中\n",
      "many,不存在于词向量中\n",
      "Made不存在于词向量中\n",
      "means,不存在于词向量中\n",
      "god.不存在于词向量中\n",
      "brother.不存在于词向量中\n",
      "so/sx不存在于词向量中\n",
      "statement.不存在于词向量中\n",
      "whatever,不存在于词向量中\n",
      "disorder.不存在于词向量中\n",
      "Until不存在于词向量中\n",
      "if...|||I不存在于词向量中\n",
      "along.不存在于词向量中\n",
      "to...|||This不存在于词向量中\n",
      "Paul不存在于词向量中\n",
      "smile,不存在于词向量中\n",
      "healthy,不存在于词向量中\n",
      "fit.不存在于词向量中\n",
      "soul.不存在于词向量中\n",
      "page.不存在于词向量中\n",
      "Seeing不存在于词向量中\n",
      "Step不存在于词向量中\n",
      "Top不存在于词向量中\n",
      "songs,不存在于词向量中\n",
      "Lately不存在于词向量中\n",
      "time.|||I不存在于词向量中\n",
      "exist,不存在于词向量中\n",
      "Mom:不存在于词向量中\n",
      "are?不存在于词向量中\n",
      "Hard不存在于词向量中\n",
      "Quite不存在于词向量中\n",
      "sp/sx不存在于词向量中\n",
      "obvious.不存在于词向量中\n",
      "Women不存在于词向量中\n",
      "shy.不存在于词向量中\n",
      "somewhere.不存在于词向量中\n",
      "attractive,不存在于词向量中\n",
      "strange,不存在于词向量中\n",
      "Depends不存在于词向量中\n",
      "Watch不存在于词向量中\n",
      "War不存在于词向量中\n",
      "circumstances?不存在于词向量中\n",
      "in?不存在于词向量中\n",
      "animals.不存在于词向量中\n",
      "North不存在于词向量中\n",
      "JUST不存在于词向量中\n",
      "choice,不存在于词向量中\n",
      "Better不存在于词向量中\n",
      "a...|||The不存在于词向量中\n",
      "boy,不存在于词向量中\n",
      "depends.不存在于词向量中\n",
      "she'd不存在于词向量中\n",
      "all...不存在于词向量中\n",
      "replies.不存在于词向量中\n",
      "necessary.不存在于词向量中\n",
      "lie.不存在于词向量中\n",
      "basis.不存在于词向量中\n",
      "needed.不存在于词向量中\n",
      "up...|||I不存在于词向量中\n",
      "boyfriend.不存在于词向量中\n",
      "to...不存在于词向量中\n",
      "details.不存在于词向量中\n",
      "with?不存在于词向量中\n",
      "Haha.不存在于词向量中\n",
      "OCD不存在于词向量中\n",
      "caring,不存在于词向量中\n",
      "(usually不存在于词向量中\n",
      "common,不存在于词向量中\n",
      "b)不存在于词向量中\n",
      "P.不存在于词向量中\n",
      "C不存在于词向量中\n",
      "'You不存在于词向量中\n",
      "Personal不存在于词向量中\n",
      "philosophy,不存在于词向量中\n",
      "LOL.不存在于词向量中\n",
      "University不存在于词向量中\n",
      "dunno,不存在于词向量中\n",
      "(of不存在于词向量中\n",
      "body,不存在于词向量中\n",
      "hell,不存在于词向量中\n",
      "to...'不存在于词向量中\n",
      "Peter不存在于词向量中\n",
      "on?不存在于词向量中\n",
      "believe.不存在于词向量中\n",
      "can't.不存在于词向量中\n",
      "laugh,不存在于词向量中\n",
      "me..不存在于词向量中\n",
      "etc,不存在于词向量中\n",
      "Sex不存在于词向量中\n",
      "Hate不存在于词向量中\n",
      "talking,不存在于词向量中\n",
      "happiness.不存在于词向量中\n",
      "goes.不存在于词向量中\n",
      "Dream不存在于词向量中\n",
      "rules.不存在于词向量中\n",
      "upset,不存在于词向量中\n",
      "lonely,不存在于词向量中\n",
      "being,不存在于词向量中\n",
      "contact.不存在于词向量中\n",
      "other...|||I不存在于词向量中\n",
      "Stephen不存在于词向量中\n",
      "J.不存在于词向量中\n",
      "History不存在于词向量中\n",
      "childhood,不存在于词向量中\n",
      "Ill不存在于词向量中\n",
      "West不存在于词向量中\n",
      "helps.不存在于词向量中\n",
      "Gotta不存在于词向量中\n",
      "clear,不存在于词向量中\n",
      "anyways.不存在于词向量中\n",
      "meaning.不存在于词向量中\n",
      "Self不存在于词向量中\n",
      "really?不存在于词向量中\n",
      "subject,不存在于词向量中\n",
      "love?不存在于词向量中\n",
      "Posted不存在于词向量中\n",
      "ex.不存在于词向量中\n",
      "conflict.不存在于词向量中\n",
      "play.不存在于词向量中\n",
      "means.不存在于词向量中\n",
      "//不存在于词向量中\n",
      "older.不存在于词向量中\n",
      "'cause不存在于词向量中\n",
      "Dear不存在于词向量中\n",
      "(mostly不存在于词向量中\n",
      "Bill不存在于词向量中\n",
      "(on不存在于词向量中\n",
      "I...|||I've不存在于词向量中\n",
      "goes,不存在于词向量中\n",
      "should've不存在于词向量中\n",
      "I...|||You不存在于词向量中\n",
      "area.不存在于词向量中\n",
      "grade,不存在于词向量中\n",
      "tell,不存在于词向量中\n",
      "when...|||I不存在于词向量中\n",
      "close,不存在于词向量中\n",
      "for?不存在于词向量中\n",
      "decisions.不存在于词向量中\n",
      "conversations.不存在于词向量中\n",
      "welcome,不存在于词向量中\n",
      "drugs.不存在于词向量中\n",
      "high,不存在于词向量中\n",
      "comment.不存在于词向量中\n",
      "F.不存在于词向量中\n",
      "Learning不存在于词向量中\n",
      "act.不存在于词向量中\n",
      "control,不存在于词向量中\n",
      "(I've不存在于词向量中\n",
      "rare.不存在于词向量中\n",
      "decision.不存在于词向量中\n",
      "...|||My不存在于词向量中\n",
      "the...|||I've不存在于词向量中\n",
      "sensitive.不存在于词向量中\n",
      "uncomfortable.不存在于词向量中\n",
      "drunk.不存在于词向量中\n",
      "annoying,不存在于词向量中\n",
      "kidding.不存在于词向量中\n",
      "7,不存在于词向量中\n",
      "seen,不存在于词向量中\n",
      "a...'不存在于词向量中\n",
      "joke,不存在于词向量中\n",
      "ENFP?不存在于词向量中\n",
      "voice,不存在于词向量中\n",
      "friendship.不存在于词向量中\n",
      "(Not不存在于词向量中\n",
      "Germany不存在于词向量中\n",
      "water,不存在于词向量中\n",
      "am...|||I不存在于词向量中\n",
      "intuitive,不存在于词向量中\n",
      "Sunday不存在于词向量中\n",
      "The...|||I不存在于词向量中\n",
      "D:不存在于词向量中\n",
      "power,不存在于词向量中\n",
      "could've不存在于词向量中\n",
      "to...|||You不存在于词向量中\n",
      "haha,不存在于词向量中\n",
      "(both不存在于词向量中\n",
      "BS不存在于词向量中\n",
      "5)不存在于词向量中\n",
      "wrong?不存在于词向量中\n",
      "ONE不存在于词向量中\n",
      "dom.不存在于词向量中\n",
      "(also不存在于词向量中\n",
      "Math不存在于词向量中\n",
      "plan.不存在于词向量中\n",
      "public.不存在于词向量中\n",
      "1.)不存在于词向量中\n",
      "tell.不存在于词向量中\n",
      "IF不存在于词向量中\n",
      "introverts.不存在于词向量中\n",
      "Brain不存在于词向量中\n",
      "Canada不存在于词向量中\n",
      "well?不存在于词向量中\n",
      "bullshit.不存在于词向量中\n",
      "Ah,不存在于词向量中\n",
      "Thanks!不存在于词向量中\n",
      "Kinda不存在于词向量中\n",
      "lazy,不存在于词向量中\n",
      "energy,不存在于词向量中\n",
      "everywhere.不存在于词向量中\n",
      "Fantasy不存在于词向量中\n",
      "Perceiving不存在于词向量中\n",
      "friendly,不存在于词向量中\n",
      "environment,不存在于词向量中\n",
      "Way不存在于词向量中\n",
      "NF's不存在于词向量中\n",
      "chance.不存在于词向量中\n",
      "anime,不存在于词向量中\n",
      "value.不存在于词向量中\n",
      "discussion.不存在于词向量中\n",
      "again?不存在于词向量中\n",
      "Lol.不存在于词向量中\n",
      "Brother:不存在于词向量中\n",
      "favorite.不存在于词向量中\n",
      "inside,不存在于词向量中\n",
      "student,不存在于词向量中\n",
      "'This不存在于词向量中\n",
      "II不存在于词向量中\n",
      "fear,不存在于词向量中\n",
      "(they不存在于词向量中\n",
      "partner,不存在于词向量中\n",
      "context.不存在于词向量中\n",
      "power.不存在于词向量中\n",
      "and...|||My不存在于词向量中\n",
      "culture,不存在于词向量中\n",
      "European不存在于词向量中\n",
      "know...|||I不存在于词向量中\n",
      "Catholic不存在于词向量中\n",
      "month,不存在于词向量中\n",
      "going,不存在于词向量中\n",
      "Richard不存在于词向量中\n",
      "empathy.不存在于词向量中\n",
      "OMG不存在于词向量中\n",
      "obvious,不存在于词向量中\n",
      "Really,不存在于词向量中\n",
      "indeed.不存在于词向量中\n",
      "Greek不存在于词向量中\n",
      "Others不存在于词向量中\n",
      "WHAT不存在于词向量中\n",
      "responses,不存在于词向量中\n",
      "(including不存在于词向量中\n",
      "...|||You不存在于词向量中\n",
      "Lady不存在于词向量中\n",
      "Recently不存在于词向量中\n",
      "feel...|||I不存在于词向量中\n",
      "classes.不存在于词向量中\n",
      "Europe不存在于词向量中\n",
      "Sister:不存在于词向量中\n",
      "fear.不存在于词向量中\n",
      "result.不存在于词向量中\n",
      "10.不存在于词向量中\n",
      "coffee,不存在于词向量中\n",
      "lazy.不存在于词向量中\n",
      "It'll不存在于词向量中\n",
      "die,不存在于词向量中\n",
      "songs.不存在于词向量中\n",
      "OK不存在于词向量中\n",
      "Truth不存在于词向量中\n",
      "involved.不存在于词向量中\n",
      "tired.不存在于词向量中\n",
      "ourselves.不存在于词向量中\n",
      "worse,不存在于词向量中\n",
      "Rock不存在于词向量中\n",
      "see...不存在于词向量中\n",
      "creative,不存在于词向量中\n",
      "Need不存在于词向量中\n",
      "Theory不存在于词向量中\n",
      "hear.不存在于词向量中\n",
      "man's不存在于词向量中\n",
      "dating,不存在于词向量中\n",
      "conflict,不存在于词向量中\n",
      "extent,不存在于词向量中\n",
      "possibilities.不存在于词向量中\n",
      "else?不存在于词向量中\n",
      "that...|||I'm不存在于词向量中\n",
      "summer.不存在于词向量中\n",
      "small,不存在于词向量中\n",
      "Neither不存在于词向量中\n",
      "being...|||I不存在于词向量中\n",
      "(an不存在于词向量中\n",
      "Post不存在于词向量中\n",
      "mother's不存在于词向量中\n",
      "Australia不存在于词向量中\n",
      "(we不存在于词向量中\n",
      "minutes.不存在于词向量中\n",
      "too.|||I不存在于词向量中\n",
      "a...|||My不存在于词向量中\n",
      "form.不存在于词向量中\n",
      "alive.不存在于词向量中\n",
      "left.不存在于词向量中\n",
      "tonight.不存在于词向量中\n",
      "Know不存在于词向量中\n",
      "Four不存在于词向量中\n",
      "sports,不存在于词向量中\n",
      "cat.不存在于词向量中\n",
      "need.不存在于词向量中\n",
      "on...不存在于词向量中\n",
      "Use不存在于词向量中\n",
      "DON'T不存在于词向量中\n",
      "Book不存在于词向量中\n",
      "Fire不存在于词向量中\n",
      "appreciated.不存在于词向量中\n",
      "ridiculous.不存在于词向量中\n",
      "smart.不存在于词向量中\n",
      "along,不存在于词向量中\n",
      "respect.不存在于词向量中\n",
      "Home不存在于词向量中\n",
      "it..不存在于词向量中\n",
      "school?不存在于词向量中\n",
      "company,不存在于词向量中\n",
      "just...不存在于词向量中\n",
      "sister's不存在于词向量中\n",
      "We'll不存在于词向量中\n",
      "Captain不存在于词向量中\n",
      "style,不存在于词向量中\n",
      "line.不存在于词向量中\n",
      "by,不存在于词向量中\n",
      "S.不存在于词向量中\n",
      "Used不存在于词向量中\n",
      "mentioned.不存在于词向量中\n",
      "Okay不存在于词向量中\n",
      "open.不存在于词向量中\n",
      "write,不存在于词向量中\n",
      "Asian不存在于词向量中\n",
      "warm,不存在于词向量中\n",
      "happening.不存在于词向量中\n",
      "O不存在于词向量中\n",
      "dad,不存在于词向量中\n",
      "Low不存在于词向量中\n",
      "Walking不存在于词向量中\n",
      "similar,不存在于词向量中\n",
      "somewhere,不存在于词向量中\n",
      "Speaking不存在于词向量中\n",
      "ESFJ's不存在于词向量中\n",
      "had,不存在于词向量中\n",
      "Mother不存在于词向量中\n",
      "Given不存在于词向量中\n",
      "discussion,不存在于词向量中\n",
      "Light不存在于词向量中\n",
      "these,不存在于词向量中\n",
      "INTP?不存在于词向量中\n",
      "eh?不存在于词向量中\n",
      "date,不存在于词向量中\n",
      "my...|||I'm不存在于词向量中\n",
      "Three不存在于词向量中\n",
      "doubt.不存在于词向量中\n",
      "Talking不存在于词向量中\n",
      "so?不存在于词向量中\n",
      "lol)不存在于词向量中\n",
      "opinions,不存在于词向量中\n",
      "tired,不存在于词向量中\n",
      "do...不存在于词向量中\n",
      "selfish,不存在于词向量中\n",
      "Call不存在于词向量中\n",
      "stereotype.不存在于词向量中\n",
      "water.不存在于词向量中\n",
      "evil,不存在于词向量中\n",
      "much?不存在于词向量中\n",
      "girlfriend.不存在于词向量中\n",
      "exactly,不存在于词向量中\n",
      "Fear不存在于词向量中\n",
      "Hi不存在于词向量中\n",
      "get,不存在于词向量中\n",
      "weekend.不存在于词向量中\n",
      "S,不存在于词向量中\n",
      "Put不存在于词向量中\n",
      "rude,不存在于词向量中\n",
      "way...不存在于词向量中\n",
      "Mainly不存在于词向量中\n",
      "outgoing,不存在于词向量中\n",
      "I?不存在于词向量中\n",
      "extrovert,不存在于词向量中\n",
      "Metal不存在于词向量中\n",
      "thread...不存在于词向量中\n",
      "he...|||I不存在于词向量中\n",
      "those.不存在于词向量中\n",
      "dream,不存在于词向量中\n",
      "order,不存在于词向量中\n",
      "Dont不存在于词向量中\n",
      "Italian不存在于词向量中\n",
      "awhile.不存在于词向量中\n",
      "introverts,不存在于词向量中\n",
      "rock,不存在于词向量中\n",
      "Taking不存在于词向量中\n",
      "free.不存在于词向量中\n",
      "anger,不存在于词向量中\n",
      "(all不存在于词向量中\n",
      "(more不存在于词向量中\n",
      "Batman不存在于词向量中\n",
      "clear.不存在于词向量中\n",
      "E,不存在于词向量中\n",
      "calm,不存在于词向量中\n",
      "guy's不存在于词向量中\n",
      "blue,不存在于词向量中\n",
      "opinions.不存在于词向量中\n",
      "one...|||I不存在于词向量中\n",
      "You'd不存在于词向量中\n",
      "Hair不存在于词向量中\n",
      "dude,不存在于词向量中\n",
      "computer,不存在于词向量中\n",
      "...|||This不存在于词向量中\n",
      "Sun不存在于词向量中\n",
      "more?不存在于词向量中\n",
      "moments.不存在于词向量中\n",
      "we...|||I不存在于词向量中\n",
      "communication.不存在于词向量中\n",
      "NEED不存在于词向量中\n",
      "Chris不存在于词向量中\n",
      "classes,不存在于词向量中\n",
      "loud.不存在于词向量中\n",
      "something...|||I不存在于词向量中\n",
      "write.不存在于词向量中\n",
      "types?不存在于词向量中\n",
      "deal.不存在于词向量中\n",
      "however.不存在于词向量中\n",
      "Heart不存在于词向量中\n",
      "YES不存在于词向量中\n",
      "dominant.不存在于词向量中\n",
      "memory.不存在于词向量中\n",
      "Generally,不存在于词向量中\n",
      "user.不存在于词向量中\n",
      "move.不存在于词向量中\n",
      "traits,不存在于词向量中\n",
      "Christian,不存在于词向量中\n",
      "myself...不存在于词向量中\n",
      "and...|||The不存在于词向量中\n",
      "didn't.不存在于词向量中\n",
      "Carl不存在于词向量中\n",
      "details,不存在于词向量中\n",
      "Work不存在于词向量中\n",
      "England不存在于词向量中\n",
      ":(|||I不存在于词向量中\n",
      "CAN不存在于词向量中\n",
      "debate.不存在于词向量中\n",
      "Must不存在于词向量中\n",
      "research,不存在于词向量中\n",
      "helpful,不存在于词向量中\n",
      "Usually,不存在于词向量中\n",
      "social,不存在于词向量中\n",
      "Finding不存在于词向量中\n",
      "line,不存在于词向量中\n",
      "dating.不存在于词向量中\n",
      "again...不存在于词向量中\n",
      "connection.不存在于词向量中\n",
      "useful.不存在于词向量中\n",
      "Person不存在于词向量中\n",
      "Bob不存在于词向量中\n",
      "fast,不存在于词向量中\n",
      "places,不存在于词向量中\n",
      "sp/so不存在于词向量中\n",
      "stereotypes.不存在于词向量中\n",
      "(what不存在于词向量中\n",
      "maybe.不存在于词向量中\n",
      "Again,不存在于词向量中\n",
      "versa.不存在于词向量中\n",
      "been.不存在于词向量中\n",
      "Thanks.不存在于词向量中\n",
      "ass.不存在于词向量中\n",
      "1/2不存在于词向量中\n",
      "Growing不存在于词向量中\n",
      "USA不存在于词向量中\n",
      "manner.不存在于词向量中\n",
      "process,不存在于词向量中\n",
      "met,不存在于词向量中\n",
      "human.不存在于词向量中\n",
      "eat,不存在于词向量中\n",
      "D不存在于词向量中\n",
      "Doing不存在于词向量中\n",
      "Yeah.不存在于词向量中\n",
      "win.不存在于词向量中\n",
      "married,不存在于词向量中\n",
      "one...不存在于词向量中\n",
      "City不存在于词向量中\n",
      "WHY不存在于词向量中\n",
      "the...|||When不存在于词向量中\n",
      "Took不存在于词向量中\n",
      "research.不存在于词向量中\n",
      "(one不存在于词向量中\n",
      "Final不存在于词向量中\n",
      "out...|||I不存在于词向量中\n",
      "comments.不存在于词向量中\n",
      "go?不存在于词向量中\n",
      "Lets不存在于词向量中\n",
      "culture.不存在于词向量中\n",
      "EXACTLY不存在于词向量中\n",
      "now.|||I不存在于词向量中\n",
      "light.不存在于词向量中\n",
      "into.不存在于词向量中\n",
      "WAY不存在于词向量中\n",
      "Breaking不存在于词向量中\n",
      "to...|||The不存在于词向量中\n",
      "stories.不存在于词向量中\n",
      "e.g.不存在于词向量中\n",
      "trust.不存在于词向量中\n",
      "lyrics,不存在于词向量中\n",
      "FB不存在于词向量中\n",
      "posted,不存在于词向量中\n",
      "time)不存在于词向量中\n",
      "Feelers不存在于词向量中\n",
      "speak.不存在于词向量中\n",
      "asking,不存在于词向量中\n",
      "anyways,不存在于词向量中\n",
      "intuition.不存在于词向量中\n",
      "quickly,不存在于词向量中\n",
      "teacher,不存在于词向量中\n",
      "everyday.不存在于词向量中\n",
      "ENTP?不存在于词向量中\n",
      "one)不存在于词向量中\n",
      "rules,不存在于词向量中\n",
      "results,不存在于词向量中\n",
      "Somehow不存在于词向量中\n",
      "Pink不存在于词向量中\n",
      "life.|||I不存在于词向量中\n",
      "Video不存在于词向量中\n",
      "Song不存在于词向量中\n",
      "share.不存在于词向量中\n",
      "Wouldn't不存在于词向量中\n",
      "approach.不存在于词向量中\n",
      "Color:不存在于词向量中\n",
      "Western不存在于词向量中\n",
      "relate,不存在于词向量中\n",
      "logical,不存在于词向量中\n",
      "option.不存在于词向量中\n",
      "term.不存在于词向量中\n",
      "alright.不存在于词向量中\n",
      "8,不存在于词向量中\n",
      "Ah不存在于词向量中\n",
      "project.不存在于词向量中\n",
      "threads.不存在于词向量中\n",
      "match.不存在于词向量中\n",
      "Holy不存在于词向量中\n",
      "afterwards.不存在于词向量中\n",
      "confidence,不存在于词向量中\n",
      "needs.不存在于词向量中\n",
      "strange.不存在于词向量中\n",
      "Friends不存在于词向量中\n",
      "much...|||I不存在于词向量中\n",
      "unfortunately.不存在于词向量中\n",
      "personalities.不存在于词向量中\n",
      "history.不存在于词向量中\n",
      "goals.不存在于词向量中\n",
      "time...|||I不存在于词向量中\n",
      "U.S.不存在于词向量中\n",
      "brain,不存在于词向量中\n",
      "(e.g.不存在于词向量中\n",
      "Totally不存在于词向量中\n",
      "fault.不存在于词向量中\n",
      "these.不存在于词向量中\n",
      "Princess不存在于词向量中\n",
      "Saturday不存在于词向量中\n",
      "insane.不存在于词向量中\n",
      ":)|||Welcome不存在于词向量中\n",
      "second.不存在于词向量中\n",
      "Russian不存在于词向量中\n",
      "trait.不存在于词向量中\n",
      "LIKE不存在于词向量中\n",
      "beliefs.不存在于词向量中\n",
      "the...|||It不存在于词向量中\n",
      "So...不存在于词向量中\n",
      "INTJ:不存在于词向量中\n",
      "drink,不存在于词向量中\n",
      "clothes,不存在于词向量中\n",
      "beginning,不存在于词向量中\n",
      "(she不存在于词向量中\n",
      "much...不存在于词向量中\n",
      "Yep,不存在于词向量中\n",
      "Night不存在于词向量中\n",
      "action,不存在于词向量中\n",
      "cases,不存在于词向量中\n",
      "Start不存在于词向量中\n",
      "V不存在于词向量中\n",
      "use,不存在于词向量中\n",
      "well.|||I不存在于词向量中\n",
      ":wink:|||I不存在于词向量中\n",
      "difficult,不存在于词向量中\n",
      "matters.不存在于词向量中\n",
      "Idk不存在于词向量中\n",
      "doing?不存在于词向量中\n",
      "...|||I've不存在于词向量中\n",
      "Frank不存在于词向量中\n",
      "it).不存在于词向量中\n",
      "Through不存在于词向量中\n",
      "Skype不存在于词向量中\n",
      "terrible.不存在于词向量中\n",
      "were,不存在于词向量中\n",
      "debate,不存在于词向量中\n",
      "Therefore,不存在于词向量中\n",
      "things?不存在于词向量中\n",
      "title,不存在于词向量中\n",
      "big,不存在于词向量中\n",
      "somehow.不存在于词向量中\n",
      "Want不存在于词向量中\n",
      "summer,不存在于词向量中\n",
      "any.不存在于词向量中\n",
      "Power不存在于词向量中\n",
      "Introverts不存在于词向量中\n",
      "that'd不存在于词向量中\n",
      "marriage,不存在于词向量中\n",
      "make.不存在于词向量中\n",
      "public,不存在于词向量中\n",
      "F,不存在于词向量中\n",
      "Id不存在于词向量中\n",
      "and...不存在于词向量中\n",
      "decision,不存在于词向量中\n",
      "BE不存在于词向量中\n",
      "teacher.不存在于词向量中\n",
      "Inferior不存在于词向量中\n",
      "Scott不存在于词向量中\n",
      "Gryffindor不存在于词向量中\n",
      "Religion不存在于词向量中\n",
      "posted.不存在于词向量中\n",
      "speaking.不存在于词向量中\n",
      "fascinating.不存在于词向量中\n",
      "asshole.不存在于词向量中\n",
      "typing.不存在于词向量中\n",
      "tomorrow,不存在于词向量中\n",
      "Holmes不存在于词向量中\n",
      "genius.不存在于词向量中\n",
      "threads,不存在于词向量中\n",
      "meaning,不存在于词向量中\n",
      "Cafe不存在于词向量中\n",
      ";D不存在于词向量中\n",
      "cats.不存在于词向量中\n",
      "learn,不存在于词向量中\n",
      "alright,不存在于词向量中\n",
      "Hell不存在于词向量中\n",
      "Nah,不存在于词向量中\n",
      "specifically,不存在于词向量中\n",
      "dominant,不存在于词向量中\n",
      "Story不存在于词向量中\n",
      "'I've不存在于词向量中\n",
      "intelligent.不存在于词向量中\n",
      "4w5,不存在于词向量中\n",
      "soon,不存在于词向量中\n",
      "Introvert不存在于词向量中\n",
      "Living不存在于词向量中\n",
      "what.不存在于词向量中\n",
      "title.不存在于词向量中\n",
      "Third不存在于词向量中\n",
      "=P不存在于词向量中\n",
      "who...|||I不存在于词向量中\n",
      "empathy,不存在于词向量中\n",
      "L不存在于词向量中\n",
      "world?不存在于词向量中\n",
      "lives,不存在于词向量中\n",
      "SPs不存在于词向量中\n",
      "out...不存在于词向量中\n",
      "some,不存在于词向量中\n",
      "Middle不存在于词向量中\n",
      "Mobile不存在于词向量中\n",
      "guitar,不存在于词向量中\n",
      "philosophy.不存在于词向量中\n",
      "married.不存在于词向量中\n",
      "silly.不存在于词向量中\n",
      "world's不存在于词向量中\n",
      "Park不存在于词向量中\n",
      "wondering,不存在于词向量中\n",
      "or,不存在于词向量中\n",
      "some.不存在于词向量中\n",
      "girlfriend,不存在于词向量中\n",
      "E.不存在于词向量中\n",
      "(by不存在于词向量中\n",
      "places.不存在于词向量中\n",
      "of...不存在于词向量中\n",
      "Possibly不存在于词向量中\n",
      "beliefs,不存在于词向量中\n",
      "Taylor不存在于词向量中\n",
      "Brother不存在于词向量中\n",
      "earlier,不存在于词向量中\n",
      "(don't不存在于词向量中\n",
      "next.不存在于词向量中\n",
      "because...|||I不存在于词向量中\n",
      "have?不存在于词向量中\n",
      "'What不存在于词向量中\n",
      "scary.不存在于词向量中\n",
      "hands.不存在于词向量中\n",
      "here.|||I不存在于词向量中\n",
      "which,不存在于词向量中\n",
      "Age:不存在于词向量中\n",
      "should.不存在于词向量中\n",
      "ENFJs,不存在于词向量中\n",
      "INTP:不存在于词向量中\n",
      "circumstances,不存在于词向量中\n",
      "left,不存在于词向量中\n",
      "gone.不存在于词向量中\n",
      "a...|||This不存在于词向量中\n",
      "thanks,不存在于词向量中\n",
      "need,不存在于词向量中\n",
      "learn.不存在于词向量中\n",
      "outside.不存在于词向量中\n",
      "options.不存在于词向量中\n",
      "extroverted,不存在于词向量中\n",
      "iPad不存在于词向量中\n",
      "always,不存在于词向量中\n",
      "friendship,不存在于词向量中\n",
      "them...|||I不存在于词向量中\n",
      "could,不存在于词向量中\n",
      "expectations.不存在于词向量中\n",
      "imagination.不存在于词向量中\n",
      "SJ's不存在于词向量中\n",
      "confidence.不存在于词向量中\n",
      "no...|||I不存在于词向量中\n",
      "explain.不存在于词向量中\n",
      "stress,不存在于词向量中\n",
      "and...|||You不存在于词向量中\n",
      "father,不存在于词向量中\n",
      "dad.不存在于词向量中\n",
      "life...不存在于词向量中\n",
      "etc...不存在于词向量中\n",
      "terms.不存在于词向量中\n",
      "It'd不存在于词向量中\n",
      "working.不存在于词向量中\n",
      "Ni-Ti不存在于词向量中\n",
      "-...|||I不存在于词向量中\n",
      "Working不存在于词向量中\n",
      "context,不存在于词向量中\n",
      "of...|||The不存在于词向量中\n",
      "theories,不存在于词向量中\n",
      "descriptions,不存在于词向量中\n",
      "Full不存在于词向量中\n",
      "Kill不存在于词向量中\n",
      "Depending不存在于词向量中\n",
      "wall.不存在于词向量中\n",
      "mouth.不存在于词向量中\n",
      "university,不存在于词向量中\n",
      "say...不存在于词向量中\n",
      "as,不存在于词向量中\n",
      "OP's不存在于词向量中\n",
      "day?不存在于词向量中\n",
      "Lost不存在于词向量中\n",
      "confused,不存在于词向量中\n",
      "car.不存在于词向量中\n",
      "term,不存在于词向量中\n",
      "I鈥檝e不存在于词向量中\n",
      "dead.不存在于词向量中\n",
      "wonderful.不存在于词向量中\n",
      "business,不存在于词向量中\n",
      "Donald不存在于词向量中\n",
      "J/P不存在于词向量中\n",
      "N,不存在于词向量中\n",
      "correctly,不存在于词向量中\n",
      "by.不存在于词向量中\n",
      "university.不存在于词向量中\n",
      "Online不存在于词向量中\n",
      "Young不存在于词向量中\n",
      "study,不存在于词向量中\n",
      "today?不存在于词向量中\n",
      "Man,不存在于词向量中\n",
      "tho.不存在于词向量中\n",
      "Quality不存在于词向量中\n",
      "naturally.不存在于词向量中\n",
      "Help不存在于词向量中\n",
      "upset.不存在于词向量中\n",
      "Sensors不存在于词向量中\n",
      "statement,不存在于词向量中\n",
      "writer,不存在于词向量中\n",
      "Rings不存在于词向量中\n",
      "=D不存在于词向量中\n",
      "infp.不存在于词向量中\n",
      "voice.不存在于词向量中\n",
      "a...|||You不存在于词向量中\n",
      "b/c不存在于词向量中\n",
      "Rather不存在于词向量中\n",
      "Live不存在于词向量中\n",
      "strong.不存在于词向量中\n",
      "confident,不存在于词向量中\n",
      "Believe不存在于词向量中\n",
      "Twilight不存在于词向量中\n",
      "alcohol,不存在于词向量中\n",
      "today's不存在于词向量中\n",
      "groups.不存在于词向量中\n",
      "Alice不存在于词向量中\n",
      "so/sp不存在于词向量中\n",
      "twice.不存在于词向量中\n",
      "purpose,不存在于词向量中\n",
      "thing...不存在于词向量中\n",
      "to...|||I've不存在于词向量中\n",
      "avatar,不存在于词向量中\n",
      "marriage.不存在于词向量中\n",
      "start,不存在于词向量中\n",
      "mode.不存在于词向量中\n",
      "Intelligence不存在于词向量中\n",
      "San不存在于词向量中\n",
      "frustrating.不存在于词向量中\n",
      "(sometimes不存在于词向量中\n",
      "ENTJs,不存在于词向量中\n",
      "you)不存在于词向量中\n",
      "Small不存在于词向量中\n",
      "try,不存在于词向量中\n",
      "exists.不存在于词向量中\n",
      "beginning.不存在于词向量中\n",
      "Voice不存在于词向量中\n",
      "INFJ:不存在于词向量中\n",
      "ESTJ's不存在于词向量中\n",
      "universe,不存在于词向量中\n",
      "Youtube不存在于词向量中\n",
      "J,不存在于词向量中\n",
      "religious,不存在于词向量中\n",
      "btw.不存在于词向量中\n",
      "leave.不存在于词向量中\n",
      "descriptions.不存在于词向量中\n",
      "Seriously.不存在于词向量中\n",
      "See,不存在于词向量中\n",
      "INFP:不存在于词向量中\n",
      "shows.不存在于词向量中\n",
      "people...不存在于词向量中\n",
      "Tapatalk不存在于词向量中\n",
      "50/50不存在于词向量中\n",
      "stressed,不存在于词向量中\n",
      "there...不存在于词向量中\n",
      "Thanks,不存在于词向量中\n",
      "Mark不存在于词向量中\n",
      "intuition,不存在于词向量中\n",
      "N's不存在于词向量中\n",
      "HOW不存在于词向量中\n",
      "Awesome不存在于词向量中\n",
      "English.不存在于词向量中\n",
      "politics,不存在于词向量中\n",
      "special.不存在于词向量中\n",
      "Law不存在于词向量中\n",
      "Hmm,不存在于词向量中\n",
      "vibe.不存在于词向量中\n",
      "perfectly.不存在于词向量中\n",
      "career,不存在于词向量中\n",
      "subjective.不存在于词向量中\n",
      "how...|||I不存在于词向量中\n",
      "SF不存在于词向量中\n",
      "a...|||I've不存在于词向量中\n",
      "btw,不存在于词向量中\n",
      "FOR不存在于词向量中\n",
      "enjoy.不存在于词向量中\n",
      "existence.不存在于词向量中\n",
      "artist,不存在于词向量中\n",
      "Nor不存在于词向量中\n",
      "second,不存在于词向量中\n",
      "drawing,不存在于词向量中\n",
      "poetry,不存在于词向量中\n",
      "taste.不存在于词向量中\n",
      "physics,不存在于词向量中\n",
      "anger.不存在于词向量中\n",
      "could.不存在于词向量中\n",
      "anywhere.不存在于词向量中\n",
      "U不存在于词向量中\n",
      "direction.不存在于词向量中\n",
      "3.)不存在于词向量中\n",
      "still.不存在于词向量中\n",
      "Down不存在于词向量中\n",
      "were.不存在于词向量中\n",
      "never...|||I不存在于词向量中\n",
      "I...|||It's不存在于词向量中\n",
      "those,不存在于词向量中\n",
      "city.不存在于词向量中\n",
      "sick.不存在于词向量中\n",
      "psychology.不存在于词向量中\n",
      "meant.不存在于词向量中\n",
      "respect,不存在于词向量中\n",
      "blue.不存在于词向量中\n",
      "Beautiful不存在于词向量中\n",
      "mistakes.不存在于词向量中\n",
      "crap,不存在于词向量中\n",
      "P.S.不存在于词向量中\n",
      "tbh.不存在于词向量中\n",
      "of...|||This不存在于词向量中\n",
      "Ice不存在于词向量中\n",
      "drunk,不存在于词向量中\n",
      "California不存在于词向量中\n",
      "Einstein不存在于词向量中\n",
      "only.不存在于词向量中\n",
      "7w6,不存在于词向量中\n",
      "effort.不存在于词向量中\n",
      "constantly.不存在于词向量中\n",
      "metal,不存在于词向量中\n",
      "preference.不存在于词向量中\n",
      "creepy.不存在于词向量中\n",
      "silly,不存在于词向量中\n",
      "Fun不存在于词向量中\n",
      "sports.不存在于词向量中\n",
      "AP不存在于词向量中\n",
      "horrible.不存在于词向量中\n",
      "extroverted.不存在于词向量中\n",
      "grade.不存在于词向量中\n",
      "mistake.不存在于词向量中\n",
      ">.<不存在于词向量中\n",
      "Miss不存在于词向量中\n",
      "ass,不存在于词向量中\n",
      "support.不存在于词向量中\n",
      "light,不存在于词向量中\n",
      "apart.不存在于词向量中\n",
      "ground.不存在于词向量中\n",
      "infp,不存在于词向量中\n",
      "Christianity不存在于词向量中\n",
      "career.不存在于词向量中\n",
      "General不存在于词向量中\n",
      "videos,不存在于词向量中\n",
      "Steve不存在于词向量中\n",
      "the...|||It's不存在于词向量中\n",
      "awful.不存在于词向量中\n",
      "correctly.不存在于词向量中\n",
      "connection,不存在于词向量中\n",
      "Type:不存在于词向量中\n",
      "mean...不存在于词向量中\n",
      "yours,不存在于词向量中\n",
      "worth,不存在于词向量中\n",
      "social.不存在于词向量中\n",
      "few.不存在于词向量中\n",
      "rather,不存在于词向量中\n",
      "Granted,不存在于词向量中\n",
      "(only不存在于词向量中\n",
      "pictures,不存在于词向量中\n",
      "friend?不存在于词向量中\n",
      "link,不存在于词向量中\n",
      "Couldn't不存在于词向量中\n",
      "possibility.不存在于词向量中\n",
      "would,不存在于词向量中\n",
      "Deep不存在于词向量中\n",
      "(well不存在于词向量中\n",
      "Blood不存在于词向量中\n",
      "husband,不存在于词向量中\n",
      "Everybody不存在于词向量中\n",
      "explanation.不存在于词向量中\n",
      "potential.不存在于词向量中\n",
      "States不存在于词向量中\n",
      "rational,不存在于词向量中\n",
      "Introversion不存在于词向量中\n",
      "Smith不存在于词向量中\n",
      "eat.不存在于词向量中\n",
      ";-)不存在于词向量中\n",
      "Games不存在于词向量中\n",
      "result,不存在于词向量中\n",
      "Hell,不存在于词向量中\n",
      "Rose不存在于词向量中\n",
      "twice,不存在于词向量中\n",
      "Space不存在于词向量中\n",
      "in...|||I'm不存在于词向量中\n",
      "special,不存在于词向量中\n",
      "Using不存在于词向量中\n",
      "Problem不存在于词向量中\n",
      "busy,不存在于词向量中\n",
      "count?不存在于词向量中\n",
      "Knowing不存在于词向量中\n",
      "Gender:不存在于词向量中\n",
      "feels.不存在于词向量中\n",
      "message.不存在于词向量中\n",
      "Evil不存在于词向量中\n",
      "Animal不存在于词向量中\n",
      "Swedish不存在于词向量中\n",
      "Watching不存在于词向量中\n",
      "unfortunately,不存在于词向量中\n",
      "A:不存在于词向量中\n",
      "Johnny不存在于词向量中\n",
      "Around不存在于词向量中\n",
      "changed.不存在于词向量中\n",
      "dog,不存在于词向量中\n",
      "FUCKING不存在于词向量中\n",
      "xD|||I不存在于词向量中\n",
      "earth.不存在于词向量中\n",
      "wait.不存在于词向量中\n",
      "any...|||I不存在于词向量中\n",
      "Pokemon不存在于词向量中\n",
      "Listening不存在于词向量中\n",
      "Pride不存在于词向量中\n",
      "hear,不存在于词向量中\n",
      "<3|||I不存在于词向量中\n",
      "etc.,不存在于词向量中\n",
      "living.不存在于词向量中\n",
      "cats,不存在于词向量中\n",
      "Dragon不存在于词向量中\n",
      "Cool不存在于词向量中\n",
      "life's不存在于词向量中\n",
      "painting,不存在于词向量中\n",
      "College不存在于词向量中\n",
      "Thing不存在于词向量中\n",
      "Family不存在于词向量中\n",
      "Into不存在于词向量中\n",
      "question?不存在于词向量中\n",
      "Americans不存在于词向量中\n",
      "ONLY不存在于词向量中\n",
      "father.不存在于词向量中\n",
      "Yesterday不存在于词向量中\n",
      "anyway?不存在于词向量中\n",
      "Left不存在于词向量中\n",
      "my...'不存在于词向量中\n",
      "watch.不存在于词向量中\n",
      "(since不存在于词向量中\n",
      "Nexus不存在于词向量中\n",
      "ON不存在于词向量中\n",
      "differences.不存在于词向量中\n",
      "dunno.不存在于词向量中\n",
      "Absolutely不存在于词向量中\n",
      "listen.不存在于词向量中\n",
      "...|||What不存在于词向量中\n",
      "city,不存在于词向量中\n",
      "ourselves,不存在于词向量中\n",
      "observation.不存在于词向量中\n",
      "properly.不存在于词向量中\n",
      "teenager,不存在于词向量中\n",
      ":)'不存在于词向量中\n",
      "mostly.不存在于词向量中\n",
      "I've...|||I不存在于词向量中\n",
      "challenge.不存在于词向量中\n",
      "up...不存在于词向量中\n",
      "high.不存在于词向量中\n",
      "France不存在于词向量中\n",
      "concept.不存在于词向量中\n",
      "Soul不存在于词向量中\n",
      "that'll不存在于词向量中\n",
      "(still不存在于词向量中\n",
      "videos.不存在于词向量中\n",
      "You:不存在于词向量中\n",
      "who,不存在于词向量中\n",
      "asking.不存在于词向量中\n",
      "unhealthy.不存在于词向量中\n",
      "independent,不存在于词向量中\n",
      "Anne不存在于词向量中\n",
      "black,不存在于词向量中\n",
      "ANY不存在于词向量中\n",
      "human,不存在于词向量中\n",
      "Thinker不存在于词向量中\n",
      "less,不存在于词向量中\n",
      "page,不存在于词向量中\n",
      "Beauty不存在于词向量中\n",
      "Favorite不存在于词向量中\n",
      "Under不存在于词向量中\n",
      "ESTP's不存在于词向量中\n",
      ":crazy:|||I不存在于词向量中\n",
      "dogs,不存在于词向量中\n",
      "Within不存在于词向量中\n",
      "Girls不存在于词向量中\n",
      "more...不存在于词向量中\n",
      "wow.不存在于词向量中\n",
      "Learn不存在于词向量中\n",
      "Trek不存在于词向量中\n",
      "Father:不存在于词向量中\n",
      "community.不存在于词向量中\n",
      "creative.不存在于词向量中\n",
      "who've不存在于词向量中\n",
      "learning.不存在于词向量中\n",
      "now)不存在于词向量中\n",
      "lol.|||I不存在于词向量中\n",
      "myself.|||I不存在于词向量中\n",
      "Cat不存在于词向量中\n",
      "is...|||I'm不存在于词向量中\n",
      "trust,不存在于词向量中\n",
      "dog.不存在于词向量中\n",
      "too...|||I不存在于词向量中\n",
      "one.|||I不存在于词向量中\n",
      "forever,不存在于词向量中\n",
      "arguments.不存在于词向量中\n",
      "events,不存在于词向量中\n",
      "'the不存在于词向量中\n",
      "disorder,不存在于词向量中\n",
      "Sad不存在于词向量中\n",
      "notice.不存在于词向量中\n",
      "favorites.不存在于词向量中\n",
      "imo.不存在于词向量中\n",
      "awhile,不存在于词向量中\n",
      "Latin不存在于词向量中\n",
      "yet?不存在于词向量中\n",
      "Strange不存在于词向量中\n",
      "goals,不存在于词向量中\n",
      "here)不存在于词向量中\n",
      "Firstly,不存在于词向量中\n",
      "than...|||I不存在于词向量中\n",
      "groups,不存在于词向量中\n",
      "Sx不存在于词向量中\n",
      "WANT不存在于词向量中\n",
      "Really?不存在于词向量中\n",
      "whatsoever.不存在于词向量中\n",
      "Monday不存在于词向量中\n",
      "doubt,不存在于词向量中\n",
      "looks,不存在于词向量中\n",
      "contact,不存在于词向量中\n",
      "Ben不存在于词向量中\n",
      "ENTJs.不存在于词向量中\n",
      "doesn't.不存在于词向量中\n",
      "Summer不存在于词向量中\n",
      "views,不存在于词向量中\n",
      "levels.不存在于词向量中\n",
      "started.不存在于词向量中\n",
      "feedback.不存在于词向量中\n",
      "Between不存在于词向量中\n",
      "Clear不存在于词向量中\n",
      "I麓m不存在于词向量中\n",
      "take.不存在于词向量中\n",
      "state,不存在于词向量中\n",
      "be...不存在于词向量中\n",
      "good...|||I不存在于词向量中\n",
      "Half不存在于词向量中\n",
      "and...|||I've不存在于词向量中\n",
      "entirely.不存在于词向量中\n",
      "made,不存在于词向量中\n",
      "it),不存在于词向量中\n",
      "enneagram.不存在于词向量中\n",
      "Hufflepuff不存在于词向量中\n",
      "Wow.不存在于词向量中\n",
      "kidding,不存在于词向量中\n",
      "way)不存在于词向量中\n",
      "Feels不存在于词向量中\n",
      "selfish.不存在于词向量中\n",
      "intense,不存在于词向量中\n",
      "break.不存在于词向量中\n",
      "easier.不存在于词向量中\n",
      "'If不存在于词向量中\n",
      "friendly.不存在于词向量中\n",
      "working,不存在于词向量中\n",
      "likely.不存在于词向量中\n",
      "Listen不存在于词向量中\n",
      "after.不存在于词向量中\n",
      "Hence不存在于词向量中\n",
      "jokes,不存在于词向量中\n",
      "dom,不存在于词向量中\n",
      "link.不存在于词向量中\n",
      "Grey不存在于词向量中\n",
      "confusing.不存在于词向量中\n",
      "Martin不存在于词向量中\n",
      "Years不存在于词向量中\n",
      "run,不存在于词向量中\n",
      "balance.不存在于词向量中\n",
      "Lol,不存在于词向量中\n",
      "position.不存在于词向量中\n",
      "fan,不存在于词向量中\n",
      "Perfect不存在于词向量中\n",
      "Cold不存在于词向量中\n",
      "heard.不存在于词向量中\n",
      "I...|||It不存在于词向量中\n",
      "area,不存在于词向量中\n",
      "goal.不存在于词向量中\n",
      "earth,不存在于词向量中\n",
      "analysis.不存在于词向量中\n",
      "short.不存在于词向量中\n",
      "organized,不存在于词向量中\n",
      "logical.不存在于词向量中\n",
      "unique.不存在于词向量中\n",
      "related.不存在于词向量中\n",
      "I...|||When不存在于词向量中\n",
      "maybe?不存在于词向量中\n",
      "J's不存在于词向量中\n",
      "individual,不存在于词向量中\n",
      "William不存在于词向量中\n",
      "white,不存在于词向量中\n",
      "hahaha.不存在于词向量中\n",
      "isn't.不存在于词向量中\n",
      "feelings?不存在于词向量中\n",
      "gosh,不存在于词向量中\n",
      "even...|||I不存在于词向量中\n",
      "complex,不存在于词向量中\n",
      "Bang不存在于词向量中\n",
      "her...|||I不存在于词向量中\n",
      "minutes,不存在于词向量中\n",
      "field.不存在于词向量中\n",
      "meet.不存在于词向量中\n",
      "obviously,不存在于词向量中\n",
      "(If不存在于词向量中\n",
      "position,不存在于词向量中\n",
      "they?不存在于词向量中\n",
      "me).不存在于词向量中\n",
      "'It不存在于词向量中\n",
      "Saying不存在于词向量中\n",
      "N.不存在于词向量中\n",
      ":)|||My不存在于词向量中\n",
      "post?不存在于词向量中\n",
      "But...|||I不存在于词向量中\n",
      "color.不存在于词向量中\n",
      "fan.不存在于词向量中\n",
      "'It's不存在于词向量中\n",
      "What?不存在于词向量中\n",
      "Leave不存在于词向量中\n",
      "completely,不存在于词向量中\n",
      "Orange不存在于词向量中\n",
      "Example:不存在于词向量中\n",
      "End不存在于词向量中\n",
      "started,不存在于词向量中\n",
      "Turns不存在于词向量中\n",
      "York不存在于词向量中\n",
      "uncomfortable,不存在于词向量中\n",
      "behaviour.不存在于词向量中\n",
      "meant,不存在于词向量中\n",
      "personalities,不存在于词向量中\n",
      "to...|||If不存在于词向量中\n",
      "strangers.不存在于词向量中\n",
      "Kate不存在于词向量中\n",
      "odd,不存在于词向量中\n",
      "Guys不存在于词向量中\n",
      "Welcome!不存在于词向量中\n",
      "MUCH不存在于词向量中\n",
      "trouble.不存在于词向量中\n",
      "category.不存在于词向量中\n",
      "choices.不存在于词向量中\n",
      "circumstances.不存在于词向量中\n",
      "Thinkers不存在于词向量中\n",
      "only...|||I不存在于词向量中\n",
      "typing,不存在于词向量中\n",
      "sucks,不存在于词向量中\n",
      "make...|||I不存在于词向量中\n",
      "play,不存在于词向量中\n",
      "dumb.不存在于词向量中\n",
      "(after不存在于词向量中\n",
      "Knight不存在于词向量中\n",
      "(In不存在于词向量中\n",
      "by...|||I不存在于词向量中\n",
      "text.不存在于词向量中\n",
      "fight.不存在于词向量中\n",
      "Van不存在于词向量中\n",
      "I'M不存在于词向量中\n",
      "reserved,不存在于词向量中\n",
      "worry.不存在于词向量中\n",
      "store,不存在于词向量中\n",
      "Netflix不存在于词向量中\n",
      "run.不存在于词向量中\n",
      "Nature不存在于词向量中\n",
      "random,不存在于词向量中\n",
      "you...|||I'm不存在于词向量中\n",
      "child?不存在于词向量中\n",
      "that)不存在于词向量中\n",
      "people.|||I不存在于词向量中\n",
      "image.不存在于词向量中\n",
      "right...不存在于词向量中\n",
      "lines.不存在于词向量中\n",
      "(Se)不存在于词向量中\n",
      "NF.不存在于词向量中\n",
      "facts,不存在于词向量中\n",
      "comment,不存在于词向量中\n",
      "memory,不存在于词向量中\n",
      "student.不存在于词向量中\n",
      "Society不存在于词向量中\n",
      "tendencies.不存在于词向量中\n",
      "mess.不存在于词向量中\n",
      "average.不存在于词向量中\n",
      "conclusion.不存在于词向量中\n",
      "sick,不存在于词向量中\n",
      "TOO不存在于词向量中\n",
      "value,不存在于词向量中\n",
      "rare,不存在于词向量中\n",
      "be...|||I'm不存在于词向量中\n",
      "'em不存在于词向量中\n",
      "'When不存在于词向量中\n",
      "asleep.不存在于词向量中\n",
      "plan,不存在于词向量中\n",
      "loop.不存在于词向量中\n",
      "Days不存在于词向量中\n",
      "usually,不存在于词向量中\n",
      "are...不存在于词向量中\n",
      "period.不存在于词向量中\n",
      "Engineering不存在于词向量中\n",
      "tough.不存在于词向量中\n",
      "gay,不存在于词向量中\n",
      "Anna不存在于词向量中\n",
      "detail,不存在于词向量中\n",
      ":D.不存在于词向量中\n",
      "romantic.不存在于词向量中\n",
      "Mars不存在于词向量中\n",
      "major,不存在于词向量中\n",
      "Understanding不存在于词向量中\n",
      "OH不存在于词向量中\n",
      "died.不存在于词向量中\n",
      "passion.不存在于词向量中\n",
      "National不存在于词向量中\n",
      "strangers,不存在于词向量中\n",
      "mate.不存在于词向量中\n",
      "impossible.不存在于词向量中\n",
      "Touch不存在于词向量中\n",
      "OK,不存在于词向量中\n",
      "hate.不存在于词向量中\n",
      "plans,不存在于词向量中\n",
      "minds.不存在于词向量中\n",
      "baby.不存在于词向量中\n",
      "God's不存在于词向量中\n",
      "of?不存在于词向量中\n",
      "A.不存在于词向量中\n",
      "adorable.不存在于词向量中\n",
      "parties,不存在于词向量中\n",
      "coffee.不存在于词向量中\n",
      "dogs.不存在于词向量中\n",
      "hands,不存在于词向量中\n",
      "it.|||I'm不存在于词向量中\n",
      "Jim不存在于词向量中\n",
      "Sam不存在于词向量中\n",
      "respond.不存在于词向量中\n",
      "sir.不存在于词向量中\n",
      "Wait不存在于词向量中\n",
      "ISTJs,不存在于词向量中\n",
      "Roman不存在于词向量中\n",
      "ISTJs.不存在于词向量中\n",
      "fit,不存在于词向量中\n",
      "Hmm...不存在于词向量中\n",
      "soul,不存在于词向量中\n",
      ":O不存在于词向量中\n",
      "film,不存在于词向量中\n",
      "Normally不存在于词向量中\n",
      "definition.不存在于词向量中\n",
      "input,不存在于词向量中\n",
      "20's不存在于词向量中\n",
      "and...|||This不存在于词向量中\n",
      "something...不存在于词向量中\n",
      "Master不存在于词向量中\n",
      "of...|||My不存在于词向量中\n",
      "Upon不存在于词向量中\n",
      "Tim不存在于词向量中\n",
      "record,不存在于词向量中\n",
      "PhD不存在于词向量中\n",
      "hate,不存在于词向量中\n",
      "Yet,不存在于词向量中\n",
      "Irish不存在于词向量中\n",
      "Adam不存在于词向量中\n",
      "P,不存在于词向量中\n",
      "hope.不存在于词向量中\n",
      "drive.不存在于词向量中\n",
      "looks.不存在于词向量中\n",
      "data.不存在于词向量中\n",
      "free,不存在于词向量中\n",
      "Click不存在于词向量中\n",
      "seriousness,不存在于词向量中\n",
      "skin.不存在于词向量中\n",
      "comfortable,不存在于词向量中\n",
      "State不存在于词向量中\n",
      "speak,不存在于词向量中\n",
      "jobs.不存在于词向量中\n",
      "break,不存在于词向量中\n",
      "females.不存在于词向量中\n",
      "(very不存在于词向量中\n",
      "straight,不存在于词向量中\n",
      "idiot.不存在于词向量中\n",
      "touch.不存在于词向量中\n",
      "that..不存在于词向量中\n",
      "then...不存在于词向量中\n",
      "Mother:不存在于词向量中\n",
      "differently,不存在于词向量中\n",
      "Leo不存在于词向量中\n",
      "clean,不存在于词向量中\n",
      "ENTP:不存在于词向量中\n",
      "Short不存在于词向量中\n",
      "point?不存在于词向量中\n",
      "listen,不存在于词向量中\n",
      "personal,不存在于词向量中\n",
      "check.不存在于词向量中\n",
      "things...不存在于词向量中\n",
      "generally,不存在于词向量中\n",
      "^.^不存在于词向量中\n",
      "IT.不存在于词向量中\n",
      "single,不存在于词向量中\n",
      "Wait,不存在于词向量中\n",
      "news,不存在于词向量中\n",
      "Open不存在于词向量中\n",
      "16.不存在于词向量中\n",
      "decisions,不存在于词向量中\n",
      "Thinking)不存在于词向量中\n",
      "Club不存在于词向量中\n",
      "Brown不存在于词向量中\n",
      "mad,不存在于词向量中\n",
      "sound,不存在于词向量中\n",
      "facts.不存在于词向量中\n",
      "badly.不存在于词向量中\n",
      "particular.不存在于词向量中\n",
      "paper.不存在于词向量中\n",
      "emotionally.不存在于词向量中\n",
      "...|||It不存在于词向量中\n",
      "politics.不存在于词向量中\n",
      "terms,不存在于词向量中\n",
      "Sleep不存在于词向量中\n",
      "standards.不存在于词向量中\n",
      "Keirsey不存在于词向量中\n",
      "basically,不存在于词向量中\n",
      "number.不存在于词向量中\n",
      "himself,不存在于词向量中\n",
      "Mr不存在于词向量中\n",
      "insight,不存在于词向量中\n",
      "average,不存在于词向量中\n",
      "says.不存在于词向量中\n",
      "band.不存在于词向量中\n",
      "quote.不存在于词向量中\n",
      "appearance.不存在于词向量中\n",
      "fiction.不存在于词向量中\n",
      "complicated.不存在于词向量中\n",
      "How's不存在于词向量中\n",
      "Christ不存在于词向量中\n",
      "Father不存在于词向量中\n",
      "(that's不存在于词向量中\n",
      "Hot不存在于词向量中\n",
      "of...'不存在于词向量中\n",
      "asked,不存在于词向量中\n",
      "us?不存在于词向量中\n",
      "hope,不存在于词向量中\n",
      "gender,不存在于词向量中\n",
      "French,不存在于词向量中\n",
      "fashion,不存在于词向量中\n",
      "Sister不存在于词向量中\n",
      "Obama不存在于词向量中\n",
      "attitude,不存在于词向量中\n",
      "ENFJ?不存在于词向量中\n",
      "NT,不存在于词向量中\n",
      "atheist.不存在于词向量中\n",
      "things...|||I不存在于词向量中\n",
      "10,不存在于词向量中\n",
      "interactions.不存在于词向量中\n",
      "cat,不存在于词向量中\n",
      "Hmm不存在于词向量中\n",
      "arrogant,不存在于词向量中\n",
      "hilarious,不存在于词向量中\n",
      "IMO不存在于词向量中\n",
      "fashion.不存在于词向量中\n",
      "a...|||It不存在于词向量中\n",
      "Giving不存在于词向量中\n",
      "baby,不存在于词向量中\n",
      "WILL不存在于词向量中\n",
      "Fight不存在于词向量中\n",
      "color,不存在于词向量中\n",
      "Sorry.不存在于词向量中\n",
      "shows,不存在于词向量中\n",
      "Eventually不存在于词向量中\n",
      "depth.不存在于词向量中\n",
      "user,不存在于词向量中\n",
      "Apple不存在于词向量中\n",
      "Books不存在于词向量中\n",
      "April不存在于词向量中\n",
      "iPod不存在于词向量中\n",
      "sarcastic,不存在于词向量中\n",
      "Charlie不存在于词向量中\n",
      "eventually.不存在于词向量中\n",
      "Y不存在于词向量中\n",
      "there...|||I不存在于词向量中\n",
      "Therefore不存在于词向量中\n",
      "motivation,不存在于词向量中\n",
      "how.不存在于词向量中\n",
      "tea.不存在于词向量中\n",
      "disagree,不存在于词向量中\n",
      "tea,不存在于词向量中\n",
      "Albert不存在于词向量中\n",
      "my...|||My不存在于词向量中\n",
      "exists,不存在于词向量中\n",
      "compliment.不存在于词向量中\n",
      "Kurt不存在于词向量中\n",
      "Queen不存在于词向量中\n",
      "early,不存在于词向量中\n",
      "been,不存在于词向量中\n",
      "library,不存在于词向量中\n",
      "ISFPs,不存在于词向量中\n",
      "board.不存在于词向量中\n",
      "Tumblr不存在于词向量中\n",
      "chance,不存在于词向量中\n",
      "Charles不存在于词向量中\n",
      "Fall不存在于词向量中\n",
      "curiosity.不存在于词向量中\n",
      "healthy.不存在于词向量中\n",
      "ahead.不存在于词向量中\n",
      "Simply不存在于词向量中\n",
      "parties.不存在于词向量中\n",
      "friends'不存在于词向量中\n",
      "present,不存在于词向量中\n",
      "Service不存在于词向量中\n",
      "Gifts不存在于词向量中\n",
      "comfortable.不存在于词向量中\n",
      "views.不存在于词向量中\n",
      "type...不存在于词向量中\n",
      "League不存在于词向量中\n",
      "development.不存在于词向量中\n",
      "i...|||I不存在于词向量中\n",
      "ol'不存在于词向量中\n",
      "Mary不存在于词向量中\n",
      "drink.不存在于词向量中\n",
      "alot.不存在于词向量中\n",
      "Sensor不存在于词向量中\n",
      "mature,不存在于词向量中\n",
      "Aren't不存在于词向量中\n",
      "chemistry,不存在于词向量中\n",
      "hugs,不存在于词向量中\n",
      "...I不存在于词向量中\n",
      "ya.不存在于词向量中\n",
      "town.不存在于词向量中\n",
      "Guide不存在于词向量中\n",
      "boy.不存在于词向量中\n",
      "myself?不存在于词向量中\n",
      "Development不存在于词向量中\n",
      "complex.不存在于词向量中\n",
      "please?不存在于词向量中\n",
      "(sorry不存在于词向量中\n",
      "suppose,不存在于词向量中\n",
      "account.不存在于词向量中\n",
      "no?不存在于词向量中\n",
      "Loved不存在于词向量中\n",
      "learning,不存在于词向量中\n",
      "Robin不存在于词向量中\n",
      "hug.不存在于词向量中\n",
      "film.不存在于词向量中\n",
      "worst.不存在于词向量中\n",
      "single.不存在于词向量中\n",
      "wise,不存在于词向量中\n",
      "paper,不存在于词向量中\n",
      "stereotype,不存在于词向量中\n",
      "basis,不存在于词向量中\n",
      "Poor不存在于词向量中\n",
      "whole,不存在于词向量中\n",
      "cynical,不存在于词向量中\n",
      ":)|||This不存在于词向量中\n",
      "present.不存在于词向量中\n",
      "Aside不存在于词向量中\n",
      "ISTPs.不存在于词向量中\n",
      "That,不存在于词向量中\n",
      "Btw,不存在于词向量中\n",
      "major.不存在于词向量中\n",
      "Christians不存在于词向量中\n",
      "definition,不存在于词向量中\n",
      "feeler.不存在于词向量中\n",
      "suck.不存在于词向量中\n",
      "uh,不存在于词向量中\n",
      "nervous,不存在于词向量中\n",
      "since.不存在于词向量中\n",
      "Humans不存在于词向量中\n",
      "yea,不存在于词向量中\n",
      "16,不存在于词向量中\n",
      ":kitteh:|||I不存在于词向量中\n",
      "hugs.不存在于词向量中\n",
      "practice.不存在于词向量中\n",
      "clothes.不存在于词向量中\n",
      "for...|||I'm不存在于词向量中\n",
      "March不存在于词向量中\n",
      "effort,不存在于词向量中\n",
      "enneagram,不存在于词向量中\n",
      "humans.不存在于词向量中\n",
      "Considering不存在于词向量中\n",
      "hot.不存在于词向量中\n",
      "form,不存在于词向量中\n",
      "18.不存在于词向量中\n",
      "had...|||I不存在于词向量中\n",
      "about...不存在于词向量中\n",
      "I...|||If不存在于词向量中\n",
      "dead,不存在于词向量中\n",
      "out.|||I不存在于词向量中\n",
      "children's不存在于词向量中\n",
      "Meaning不存在于词向量中\n",
      "Lee不存在于词向量中\n",
      "people)不存在于词向量中\n",
      "Anyways不存在于词向量中\n",
      "needs,不存在于词向量中\n",
      "peace.不存在于词向量中\n",
      "fiction,不存在于词向量中\n",
      "Wild不存在于词向量中\n",
      "Vocaroo不存在于词向量中\n",
      "Peace不存在于词向量中\n",
      "(My不存在于词向量中\n",
      "also...|||I不存在于词向量中\n",
      "Instead,不存在于词向量中\n",
      "Canadian不存在于词向量中\n",
      "that...'不存在于词向量中\n",
      "possibilities,不存在于词向量中\n",
      "Gemini不存在于词向量中\n",
      "comments,不存在于词向量中\n",
      "factor.不存在于词向量中\n",
      "100%.不存在于词向量中\n",
      "with...|||I'm不存在于词向量中\n",
      "negative,不存在于词向量中\n",
      "all.|||I不存在于词向量中\n",
      "always.不存在于词向量中\n",
      "Paris不存在于词向量中\n",
      "Food不存在于词向量中\n",
      "expected.不存在于词向量中\n",
      "loss.不存在于词向量中\n",
      "Stay不存在于词向量中\n",
      "XD|||I不存在于词向量中\n",
      "account,不存在于词向量中\n",
      "(aka不存在于词向量中\n",
      "called?不存在于词向量中\n",
      "shoes,不存在于词向量中\n",
      "East不存在于词向量中\n",
      "creativity,不存在于词向量中\n",
      "lyrics.不存在于词向量中\n",
      "Thrones不存在于词向量中\n",
      "white.不存在于词向量中\n",
      "pictures.不存在于词向量中\n",
      "This.不存在于词向量中\n",
      "Radiohead不存在于词向量中\n",
      "wife,不存在于词向量中\n",
      "she...|||I不存在于词向量中\n",
      "Relationships不存在于词向量中\n",
      "wonderful,不存在于词向量中\n",
      "BBC不存在于词向量中\n",
      "HUGE不存在于词向量中\n",
      "the...|||What不存在于词向量中\n",
      "pretty,不存在于词向量中\n",
      "loyal,不存在于词向量中\n",
      "Well...不存在于词向量中\n",
      "languages.不存在于词向量中\n",
      "apparently.不存在于词向量中\n",
      "devil's不存在于词向量中\n",
      "girl's不存在于词向量中\n",
      "move,不存在于词向量中\n",
      "They'll不存在于词向量中\n",
      "seems.不存在于词向量中\n",
      "Playing不存在于词向量中\n",
      "Joe不存在于词向量中\n",
      "with...不存在于词向量中\n",
      "involved,不存在于词向量中\n",
      "everyday,不存在于词向量中\n",
      "find.不存在于词向量中\n",
      "Emma不存在于词向量中\n",
      "green,不存在于词向量中\n",
      "indeed,不存在于词向量中\n",
      "examples.不存在于词向量中\n",
      "0.不存在于词向量中\n",
      "even.不存在于词向量中\n",
      "jokes.不存在于词向量中\n",
      "leader.不存在于词向量中\n",
      "(This不存在于词向量中\n",
      "China不存在于词向量中\n",
      "Guy不存在于词向量中\n",
      "Ix92ve不存在于词向量中\n",
      "mind?不存在于词向量中\n",
      "faces.不存在于词向量中\n",
      "has.不存在于词向量中\n",
      "Particularly不存在于词向量中\n",
      "door,不存在于词向量中\n",
      "Money不存在于词向量中\n",
      "a...|||If不存在于词向量中\n",
      "many.不存在于词向量中\n",
      "any,不存在于词向量中\n",
      "this.|||I不存在于词向量中\n",
      "nonsense.不存在于词向量中\n",
      "then...|||I不存在于词向量中\n",
      "how,不存在于词向量中\n",
      "news.不存在于词向量中\n",
      ";P不存在于词向量中\n",
      "Prince不存在于词向量中\n",
      "Aries不存在于词向量中\n",
      "when...不存在于词向量中\n",
      "AT不存在于词向量中\n",
      "patterns.不存在于词向量中\n",
      "question...不存在于词向量中\n",
      "Wow不存在于词向量中\n",
      "positive.不存在于词向量中\n",
      "Country不存在于词向量中\n",
      "do.|||I不存在于词向量中\n",
      "sarcasm.不存在于词向量中\n",
      "black.不存在于词向量中\n",
      "Ron不存在于词向量中\n",
      "EVERYTHING不存在于词向量中\n",
      "BTW,不存在于词向量中\n",
      "type)不存在于词向量中\n",
      "his...|||I不存在于词向量中\n",
      "Psychological不存在于词向量中\n",
      "shoes.不存在于词向量中\n",
      "Legend不存在于词向量中\n",
      "(Ne)不存在于词向量中\n",
      "goal,不存在于词向量中\n",
      ":)|||Thank不存在于词向量中\n",
      "Point不存在于词向量中\n",
      "happiness,不存在于词向量中\n",
      "arguments,不存在于词向量中\n",
      "imagination,不存在于词向量中\n",
      "dance,不存在于词向量中\n",
      "favorite,不存在于词向量中\n",
      "or...|||I'm不存在于词向量中\n",
      "are)不存在于词向量中\n",
      "(I)不存在于词向量中\n",
      "immature.不存在于词向量中\n",
      "alcohol.不存在于词向量中\n",
      "Understand不存在于词向量中\n",
      "direction,不存在于词向量中\n",
      "INFP!不存在于词向量中\n",
      "WE不存在于词向量中\n",
      "Magic不存在于词向量中\n",
      "BTW不存在于词向量中\n",
      "ENFP!不存在于词向量中\n",
      "frequently.不存在于词向量中\n",
      "anxious,不存在于词向量中\n",
      "type's不存在于词向量中\n",
      "interaction.不存在于词向量中\n",
      "ISFP?不存在于词向量中\n",
      "Beatles不存在于词向量中\n",
      "usually.不存在于词向量中\n",
      "Scorpio不存在于词向量中\n",
      "etc).不存在于词向量中\n",
      "most?不存在于词向量中\n",
      "door.不存在于词向量中\n",
      "has...|||I不存在于词向量中\n",
      "before?不存在于词向量中\n",
      "names,不存在于词向量中\n",
      "Valentine's不存在于词向量中\n",
      "flirting.不存在于词向量中\n",
      "sides.不存在于词向量中\n",
      "help?不存在于词向量中\n",
      "ENTJ?不存在于词向量中\n",
      "extroverts,不存在于词向量中\n",
      "Change不存在于词向量中\n",
      "weekend,不存在于词向量中\n",
      "things.|||I不存在于词向量中\n",
      "9w1,不存在于词向量中\n",
      "Moderate不存在于词向量中\n",
      "Question不存在于词向量中\n",
      "TV,不存在于词向量中\n",
      "effect.不存在于词向量中\n",
      "sexy.不存在于词向量中\n",
      "wants.不存在于词向量中\n",
      "text,不存在于词向量中\n",
      "profile.不存在于词向量中\n",
      "Simple不存在于词向量中\n",
      "activities.不存在于词向量中\n",
      "K不存在于词向量中\n",
      "particular,不存在于词向量中\n",
      "club.不存在于词向量中\n",
      "terrible,不存在于词向量中\n",
      "London不存在于词向量中\n",
      "Regardless不存在于词向量中\n",
      "Business不存在于词向量中\n",
      "piano,不存在于词向量中\n",
      "Chaotic不存在于词向量中\n",
      "shot.不存在于词向量中\n",
      "Dreams不存在于词向量中\n",
      ".....不存在于词向量中\n",
      "Moving不存在于词向量中\n",
      "loved.不存在于词向量中\n",
      "Me,不存在于词向量中\n",
      "Facebook.不存在于词向量中\n",
      "Weird不存在于词向量中\n",
      "Yes!不存在于词向量中\n",
      "Closest不存在于词向量中\n",
      "Texas不存在于词向量中\n",
      "partner?不存在于词向量中\n",
      "straight.不存在于词向量中\n",
      "sir,不存在于词向量中\n",
      "Air不存在于词向量中\n",
      "written,不存在于词向量中\n",
      "yeah...不存在于词向量中\n",
      "rude.不存在于词向量中\n",
      "sleeping.不存在于词向量中\n",
      "Different不存在于词向量中\n",
      "sort.不存在于词向量中\n",
      "practice,不存在于词向量中\n",
      "boss,不存在于词向量中\n",
      "posting.不存在于词向量中\n",
      "understood.不存在于词向量中\n",
      "role.不存在于词向量中\n",
      "our...|||I不存在于词向量中\n",
      "born,不存在于词向量中\n",
      "You,不存在于词向量中\n",
      "Snow不存在于词向量中\n",
      "always...|||I不存在于词向量中\n",
      "Friend不存在于词向量中\n",
      "Whats不存在于词向量中\n",
      "taken.不存在于词向量中\n",
      "se,不存在于词向量中\n",
      "La不存在于词向量中\n",
      "Interesting.不存在于词向量中\n",
      "zone.不存在于词向量中\n",
      "reaction.不存在于词向量中\n",
      "development,不存在于词向量中\n",
      "Thomas不存在于词向量中\n",
      "Close不存在于词向量中\n",
      "Random不存在于词向量中\n",
      "exercise.不存在于词向量中\n",
      "WAS不存在于词向量中\n",
      "names.不存在于词向量中\n",
      "negative.不存在于词向量中\n",
      "option,不存在于词向量中\n",
      "Relationship不存在于词向量中\n",
      "boundaries.不存在于词向量中\n",
      "LOT.不存在于词向量中\n",
      "Modern不存在于词向量中\n",
      "WITH不存在于词向量中\n",
      "years...不存在于词向量中\n",
      "focus.不存在于词向量中\n",
      "Surely不存在于词向量中\n",
      "act,不存在于词向量中\n",
      "'A不存在于词向量中\n",
      "last.不存在于词向量中\n",
      "Baby不存在于词向量中\n",
      "ENFJs.不存在于词向量中\n",
      "difference,不存在于词向量中\n",
      "probably.不存在于词向量中\n",
      "manipulative,不存在于词向量中\n",
      "now..不存在于词向量中\n",
      "success.不存在于词向量中\n",
      "Extroverts不存在于词向量中\n",
      "Specifically不存在于词向量中\n",
      "across.不存在于词向量中\n",
      "earlier.不存在于词向量中\n",
      "busy.不存在于词向量中\n",
      "theories.不存在于词向量中\n",
      "think...不存在于词向量中\n",
      "sound.不存在于词向量中\n",
      "education,不存在于词向量中\n",
      "romantic,不存在于词向量中\n",
      "Went不存在于词向量中\n",
      "love...|||I不存在于词向量中\n",
      "subjective,不存在于词向量中\n",
      "jeans,不存在于词向量中\n",
      "the...|||Thank不存在于词向量中\n",
      "wrote,不存在于词向量中\n",
      "Lion不存在于词向量中\n",
      "Neil不存在于词向量中\n",
      "-The不存在于词向量中\n",
      "natural.不存在于词向量中\n",
      "Beyond不存在于词向量中\n",
      "Shadow不存在于词向量中\n",
      "live?不存在于词向量中\n",
      "all)不存在于词向量中\n",
      "...and不存在于词向量中\n",
      "minute.不存在于词向量中\n",
      "leader,不存在于词向量中\n",
      "useless.不存在于词向量中\n",
      "reasoning.不存在于词向量中\n",
      "whole.不存在于词向量中\n",
      "early.不存在于词向量中\n",
      "section.不存在于词向量中\n",
      "way.|||I不存在于词向量中\n",
      "longer.不存在于词向量中\n",
      "deal,不存在于词向量中\n",
      "parts.不存在于词向量中\n",
      "Several不存在于词向量中\n",
      "It's...|||I不存在于词向量中\n",
      "Christian.不存在于词向量中\n",
      "lost.不存在于词向量中\n",
      "Love,不存在于词向量中\n",
      "Fair不存在于词向量中\n",
      "will...|||I不存在于词向量中\n",
      "We'd不存在于词向量中\n",
      "Iron不存在于词向量中\n",
      "Windows不存在于词向量中\n",
      "myself)不存在于词向量中\n",
      "Sort不存在于词向量中\n",
      "general?不存在于词向量中\n",
      "Dog不存在于词向量中\n",
      "sadness,不存在于词向量中\n",
      "Australian不存在于词向量中\n",
      "Location不存在于词向量中\n",
      "test?不存在于词向量中\n",
      "thinker.不存在于词向量中\n",
      "Fi-dom不存在于词向量中\n",
      "never,不存在于词向量中\n",
      "otherwise,不存在于词向量中\n",
      "better?不存在于词向量中\n",
      "though)不存在于词向量中\n",
      "looking.不存在于词向量中\n",
      "peace,不存在于词向量中\n",
      "Jon不存在于词向量中\n",
      "atheist,不存在于词向量中\n",
      "herself,不存在于词向量中\n",
      "Halloween不存在于词向量中\n",
      "gay.不存在于词向量中\n",
      "season.不存在于词向量中\n",
      "parents'不存在于词向量中\n",
      "war.不存在于词向量中\n",
      "friendships.不存在于词向量中\n",
      "Libra不存在于词向量中\n",
      "Functions不存在于词向量中\n",
      "do)不存在于词向量中\n",
      "Obviously,不存在于词向量中\n",
      "it?|||I不存在于词向量中\n",
      "Daniel不存在于词向量中\n",
      "husband.不存在于词向量中\n",
      "band,不存在于词向量中\n",
      "'s不存在于词向量中\n",
      "patient,不存在于词向量中\n",
      "stop,不存在于词向量中\n",
      "Nope.不存在于词向量中\n",
      "WTF不存在于词向量中\n",
      "box.不存在于词向量中\n",
      "adorable,不存在于词向量中\n",
      "trying.不存在于词向量中\n",
      "colors.不存在于词向量中\n",
      ":)|||You不存在于词向量中\n",
      "content.不存在于词向量中\n",
      "EVERY不存在于词向量中\n",
      "humanity.不存在于词向量中\n",
      "relationships?不存在于词向量中\n",
      "air.不存在于词向量中\n",
      "manner,不存在于词向量中\n",
      "Amy不存在于词向量中\n",
      "Found不存在于词向量中\n",
      "T/F不存在于词向量中\n",
      "Spring不存在于词向量中\n",
      "choose,不存在于词向量中\n",
      "helps,不存在于词向量中\n",
      "Highly不存在于词向量中\n",
      "birthday.不存在于词向量中\n",
      "approach,不存在于词向量中\n",
      "Fucking不存在于词向量中\n",
      "into...|||I不存在于词向量中\n",
      "you?|||I不存在于词向量中\n",
      "Likely不存在于词向量中\n",
      "observation,不存在于词向量中\n",
      "someone?不存在于词向量中\n",
      "'i不存在于词向量中\n",
      "Regarding不存在于词向量中\n",
      "Sadly不存在于词向量中\n",
      "Extroversion不存在于词向量中\n",
      "Care不存在于词向量中\n",
      "nervous.不存在于词向量中\n",
      "ISTP:不存在于词向量中\n",
      "interaction,不存在于词向量中\n",
      "forum?不存在于词向量中\n",
      "Naruto不存在于词向量中\n",
      "apologize.不存在于词向量中\n",
      "loving,不存在于词向量中\n",
      "lovely.不存在于词向量中\n",
      "intense.不存在于词向量中\n",
      "GOD不存在于词向量中\n",
      "rock.不存在于词向量中\n",
      "Total不存在于词向量中\n",
      "Good.不存在于词向量中\n",
      "hurts.不存在于词向量中\n",
      "Calvin不存在于词向量中\n",
      "lying,不存在于词向量中\n",
      "behaviour,不存在于词向量中\n",
      "creativity.不存在于词向量中\n",
      "honesty.不存在于词向量中\n",
      ":))不存在于词向量中\n",
      "well..不存在于词向量中\n",
      "Matt不存在于词向量中\n",
      "know)不存在于词向量中\n",
      "come.不存在于词向量中\n",
      "Bruce不存在于词向量中\n",
      "low,不存在于词向量中\n",
      "Church不存在于词向量中\n",
      "(?)不存在于词向量中\n",
      "Santa不存在于词向量中\n",
      "ego.不存在于词向量中\n",
      "Clearly不存在于词向量中\n",
      "Stone不存在于词向量中\n",
      "caring.不存在于词向量中\n",
      "setting.不存在于词向量中\n",
      "affection.不存在于词向量中\n",
      "Simon不存在于词向量中\n",
      "Less不存在于词向量中\n",
      "likely,不存在于词向量中\n",
      "Number不存在于词向量中\n",
      "lines,不存在于词向量中\n",
      "women's不存在于词向量中\n",
      "education.不存在于词向量中\n",
      "of...|||You不存在于词向量中\n",
      "80's不存在于词向量中\n",
      "Typically不存在于词向量中\n",
      "ex,不存在于词向量中\n",
      "users.不存在于词向量中\n",
      "evidence.不存在于词向量中\n",
      "mouth,不存在于词向量中\n",
      "It...|||I不存在于词向量中\n",
      "intuitive.不存在于词向量中\n",
      "username.不存在于词向量中\n",
      "mad.不存在于词向量中\n",
      "opposite,不存在于词向量中\n",
      "polite,不存在于词向量中\n",
      "...|||If不存在于词向量中\n",
      "occasion.不存在于词向量中\n",
      "just,不存在于词向量中\n",
      "ISTJ:不存在于词向量中\n",
      "'what不存在于词向量中\n",
      "weak.不存在于词向量中\n",
      "flow.不存在于词向量中\n",
      "DID不存在于词向量中\n",
      "June不存在于词向量中\n",
      "Indian不存在于词向量中\n",
      "attitude.不存在于词向量中\n",
      "it...|||I'm不存在于词向量中\n",
      "weed.不存在于词向量中\n",
      "luck.不存在于词向量中\n",
      "ISFPs.不存在于词向量中\n",
      "(some不存在于词向量中\n",
      "anything?不存在于词向量中\n",
      "Luckily不存在于词向量中\n",
      "Here,不存在于词向量中\n",
      "pretty.不存在于词向量中\n",
      "dear.不存在于词向量中\n",
      "Angel不存在于词向量中\n",
      "Vampire不存在于词向量中\n",
      "Yay不存在于词向量中\n",
      "Asking不存在于词向量中\n",
      "Eternal不存在于词向量中\n",
      "Season不存在于词向量中\n",
      "TV.不存在于词向量中\n",
      "living,不存在于词向量中\n",
      "exercise,不存在于词向量中\n",
      "Ace不存在于词向量中\n",
      "20.不存在于词向量中\n",
      "think)不存在于词向量中\n",
      "rest.不存在于词向量中\n",
      "understood,不存在于词向量中\n",
      "support,不存在于词向量中\n",
      "Future不存在于词向量中\n",
      "...|||Yes,不存在于词向量中\n",
      "anime.不存在于词向量中\n",
      "wonder,不存在于词向量中\n",
      "image,不存在于词向量中\n",
      "5w4,不存在于词向量中\n",
      "unique,不存在于词向量中\n",
      "matters,不存在于词向量中\n",
      "replies,不存在于词向量中\n",
      "17,不存在于词向量中\n",
      "fair.不存在于词向量中\n",
      "xNFP不存在于词向量中\n",
      "dear,不存在于词向量中\n",
      "alive,不存在于词向量中\n",
      "rule,不存在于词向量中\n",
      "GPA不存在于词向量中\n",
      "article.不存在于词向量中\n",
      "(about不存在于词向量中\n",
      "to...|||That不存在于词向量中\n",
      "match,不存在于词向量中\n",
      "herself.不存在于词向量中\n",
      "NTs,不存在于词向量中\n",
      "Alpha不存在于词向量中\n",
      "Oscar不存在于词向量中\n",
      "driving,不存在于词向量中\n",
      "described.不存在于词向量中\n",
      "distance.不存在于词向量中\n",
      "(yes,不存在于词向量中\n",
      "same...|||I不存在于词向量中\n",
      "three,不存在于词向量中\n",
      "weaknesses.不存在于词向量中\n",
      "arrogant.不存在于词向量中\n",
      "sentence.不存在于词向量中\n",
      "Intp不存在于词向量中\n",
      "touch,不存在于词向量中\n",
      "specific,不存在于词向量中\n",
      "films,不存在于词向量中\n",
      "message,不存在于词向量中\n",
      "bullshit,不存在于词向量中\n",
      "Tolkien不存在于词向量中\n",
      ":)|||I've不存在于词向量中\n",
      "eye.不存在于词向量中\n",
      "Classical不存在于词向量中\n",
      "Ghost不存在于词向量中\n",
      "clarify,不存在于词向量中\n",
      "Save不存在于词向量中\n",
      "A,不存在于词向量中\n",
      "running,不存在于词向量中\n",
      "MORE不存在于词向量中\n",
      "adult,不存在于词向量中\n",
      "seconds.不存在于词向量中\n",
      "goodness,不存在于词向量中\n",
      "Luna不存在于词向量中\n",
      "Tony不存在于词向量中\n",
      "return.不存在于词向量中\n",
      "nuts.不存在于词向量中\n",
      "sensors.不存在于词向量中\n",
      "rest,不存在于词向量中\n",
      "most...|||I不存在于词向量中\n",
      "Stupid不存在于词向量中\n",
      "Finally不存在于词向量中\n",
      "INFP's,不存在于词向量中\n",
      "everywhere,不存在于词向量中\n",
      "jobs,不存在于词向量中\n",
      "ha,不存在于词向量中\n",
      "population.不存在于词向量中\n",
      "Korean不存在于词向量中\n",
      "swear,不存在于词向量中\n",
      "activities,不存在于词向量中\n",
      "Louis不存在于词向量中\n",
      "friends...不存在于词向量中\n",
      "when,不存在于词向量中\n",
      "misunderstood.不存在于词向量中\n",
      "moments,不存在于词向量中\n",
      "Infp不存在于词向量中\n",
      "apparently,不存在于词向量中\n",
      "stressed.不存在于词向量中\n",
      "bad?不存在于词向量中\n",
      "lol...不存在于词向量中\n",
      "deep.不存在于词向量中\n",
      "Secret不存在于词向量中\n",
      "Biology不存在于词向量中\n",
      "faith.不存在于词向量中\n",
      "other?不存在于词向量中\n",
      "B.不存在于词向量中\n",
      "drama.不存在于词向量中\n",
      "My...|||I不存在于词向量中\n",
      "US.不存在于词向量中\n",
      "emotionally,不存在于词向量中\n",
      "weakness.不存在于词向量中\n",
      "drama,不存在于词向量中\n",
      "team.不存在于词向量中\n",
      "News不存在于词向量中\n",
      "red,不存在于词向量中\n",
      "GO不存在于词向量中\n",
      "Feeler不存在于词向量中\n",
      "artist.不存在于词向量中\n",
      "NTs.不存在于词向量中\n",
      "positive,不存在于词向量中\n",
      "asshole,不存在于词向量中\n",
      "Philosophy不存在于词向量中\n",
      "cars,不存在于词向量中\n",
      "depth,不存在于词向量中\n",
      "health.不存在于词向量中\n",
      "Coming不存在于词向量中\n",
      "Double不存在于词向量中\n",
      "'How不存在于词向量中\n",
      "worries.不存在于词向量中\n",
      "guitar.不存在于词向量中\n",
      "useful,不存在于词向量中\n",
      "spot.不存在于词向量中\n",
      "brother's不存在于词向量中\n",
      "number,不存在于词向量中\n",
      "not)不存在于词向量中\n",
      "Excuse不存在于词向量中\n",
      "Socially不存在于词向量中\n",
      "scary,不存在于词向量中\n",
      "Feelings不存在于词向量中\n",
      "America,不存在于词向量中\n",
      "scared.不存在于词向量中\n",
      "sense?不存在于词向量中\n",
      "cause.不存在于词向量中\n",
      "somehow,不存在于词向量中\n",
      "(N)不存在于词向量中\n",
      "(S)不存在于词向量中\n",
      "(he's不存在于词向量中\n",
      "90's不存在于词向量中\n",
      "flaws.不存在于词向量中\n",
      "habit.不存在于词向量中\n",
      "Design不存在于词向量中\n",
      "offer.不存在于词向量中\n",
      "problem?不存在于词向量中\n",
      "temperament,不存在于词向量中\n",
      "combination.不存在于词向量中\n",
      "December不存在于词向量中\n",
      "sarcasm,不存在于词向量中\n",
      "Disorder不存在于词向量中\n",
      "tonight,不存在于词向量中\n",
      "Joker不存在于词向量中\n",
      "on.|||I不存在于词向量中\n",
      "THINK不存在于词向量中\n",
      "INFP...不存在于词向量中\n",
      "INFJ's,不存在于词向量中\n",
      "up.|||I不存在于词向量中\n",
      "physical,不存在于词向量中\n",
      "Stark不存在于词向量中\n",
      "them)不存在于词向量中\n",
      "respond,不存在于词向量中\n",
      "(For不存在于词向量中\n",
      "Enneagram.不存在于词向量中\n",
      "well)不存在于词向量中\n",
      "Aquarius不存在于词向量中\n",
      "though).不存在于词向量中\n",
      "Wikipedia不存在于词向量中\n",
      "of)不存在于词向量中\n",
      "insightful.不存在于词向量中\n",
      "project,不存在于词向量中\n",
      "Sims不存在于词向量中\n",
      "meet,不存在于词向量中\n",
      "walk,不存在于词向量中\n",
      "a...|||When不存在于词向量中\n",
      "INTx不存在于词向量中\n",
      "(INTJ)不存在于词向量中\n",
      "INTJ's.不存在于词向量中\n",
      "INFJ's.不存在于词向量中\n",
      "scenario.不存在于词向量中\n",
      "Unlike不存在于词向量中\n",
      "used.不存在于词向量中\n",
      "add,不存在于词向量中\n",
      "joking.不存在于词向量中\n",
      "hobbies.不存在于词向量中\n",
      "in...'不存在于词向量中\n",
      "cooking,不存在于词向量中\n",
      "going?不存在于词向量中\n",
      "Who's不存在于词向量中\n",
      "Les不存在于词向量中\n",
      "July不存在于词向量中\n",
      "Freedom不存在于词向量中\n",
      "photography,不存在于词向量中\n",
      "Word不存在于词向量中\n",
      "Physics不存在于词向量中\n",
      "the...|||If不存在于词向量中\n",
      "Add不存在于词向量中\n",
      "Don不存在于词向量中\n",
      "ISTPs,不存在于词向量中\n",
      "looking,不存在于词向量中\n",
      "Romance不存在于词向量中\n",
      "INFP)不存在于词向量中\n",
      "have...|||I'm不存在于词向量中\n",
      "program.不存在于词向量中\n",
      "club,不存在于词向量中\n",
      "(But不存在于词向量中\n",
      "solution.不存在于词向量中\n",
      "my,不存在于词向量中\n",
      "boss.不存在于词向量中\n",
      "stereotypes,不存在于词向量中\n",
      "odd.不存在于词向量中\n",
      "irrelevant.不存在于词向量中\n",
      "silence.不存在于词向量中\n",
      "Reality不存在于词向量中\n",
      "ISFJs,不存在于词向量中\n",
      "Lawful不存在于词向量中\n",
      "website.不存在于词向量中\n",
      "my...|||I've不存在于词向量中\n",
      "Six不存在于词向量中\n",
      "passion,不存在于词向量中\n",
      "office.不存在于词向量中\n",
      "(such不存在于词向量中\n",
      "Certainly不存在于词向量中\n",
      "He'll不存在于词向量中\n",
      "to...|||It不存在于词向量中\n",
      "section,不存在于词向量中\n",
      "peoples'不存在于词向量中\n",
      "bro.不存在于词向量中\n",
      "planet.不存在于词向量中\n",
      "St.不存在于词向量中\n",
      "obviously.不存在于词向量中\n",
      "Belle不存在于词向量中\n",
      "...|||Thanks不存在于词向量中\n",
      "A)不存在于词向量中\n",
      "regularly.不存在于词向量中\n",
      "might've不存在于词向量中\n",
      "asleep,不存在于词向量中\n",
      "thing.|||I不存在于词向量中\n",
      "Acts不存在于词向量中\n",
      "Affirmation不存在于词向量中\n",
      "Stranger:不存在于词向量中\n",
      "functions?不存在于词向量中\n",
      "background.不存在于词向量中\n",
      "is...|||The不存在于词向量中\n",
      "pattern.不存在于词向量中\n",
      "practical,不存在于词向量中\n",
      "Face不存在于词向量中\n",
      "taste,不存在于词向量中\n",
      "RPG不存在于词向量中\n",
      "wrote.不存在于词向量中\n",
      "you...|||My不存在于词向量中\n",
      "poetry.不存在于词向量中\n",
      "surprised.不存在于词向量中\n",
      "Galaxy不存在于词向量中\n",
      "THANK不存在于词向量中\n",
      "tritype.不存在于词向量中\n",
      "MBTI?不存在于词向量中\n",
      "17.不存在于词向量中\n",
      "I'm...|||I'm不存在于词向量中\n",
      "offended.不存在于词向量中\n",
      "to...|||What不存在于词向量中\n",
      "Later不存在于词向量中\n",
      "Nope,不存在于词向量中\n",
      "Strong不存在于词向量中\n",
      "Italy不存在于词向量中\n",
      "Edward不存在于词向量中\n",
      "nowhere.不存在于词向量中\n",
      "and...|||It's不存在于词向量中\n",
      "letters,不存在于词向量中\n",
      ":p|||I不存在于词向量中\n",
      "fantastic.不存在于词向量中\n",
      "events.不存在于词向量中\n",
      "(there不存在于词向量中\n",
      "pages.不存在于词向量中\n",
      "expression.不存在于词向量中\n",
      "happy?不存在于词向量中\n",
      "born.不存在于词向量中\n",
      "importantly,不存在于词向量中\n",
      "Recently,不存在于词向量中\n",
      "INFJ!不存在于词向量中\n",
      "direct.不存在于词向量中\n",
      "sarcastic.不存在于词向量中\n",
      "won't.不存在于词向量中\n",
      "know..不存在于词向量中\n",
      "cases.不存在于词向量中\n",
      "sounds,不存在于词向量中\n",
      "me....不存在于词向量中\n",
      "overall,不存在于词向量中\n",
      "find...|||I不存在于词向量中\n",
      "Lack不存在于词向量中\n",
      "crying.不存在于词向量中\n",
      "Lewis不存在于词向量中\n",
      "me|||I不存在于词向量中\n",
      "mistakes,不存在于词向量中\n",
      "Entp不存在于词向量中\n",
      "But...不存在于词向量中\n",
      "Effect不存在于词向量中\n",
      "'So不存在于词向量中\n",
      "Sunshine不存在于词向量中\n",
      "noticed,不存在于词向量中\n",
      "few,不存在于词向量中\n",
      "go...|||I不存在于词向量中\n",
      ":S不存在于词向量中\n",
      "I...|||Yes,不存在于词向量中\n",
      "Side不存在于词向量中\n",
      "Um,不存在于词向量中\n",
      "personal.不存在于词向量中\n",
      "Keys不存在于词向量中\n",
      "teenager.不存在于词向量中\n",
      "Intelligence:不存在于词向量中\n",
      "profile,不存在于词向量中\n",
      "instead,不存在于词向量中\n",
      "watch,不存在于词向量中\n",
      "see...|||I不存在于词向量中\n",
      "Universe不存在于词向量中\n",
      "is...'不存在于词向量中\n",
      "Amazon不存在于词向量中\n",
      "race,不存在于词向量中\n",
      "gone,不存在于词向量中\n",
      "(particularly不存在于词向量中\n",
      "ESFJs,不存在于词向量中\n",
      "Younger不存在于词向量中\n",
      "charming,不存在于词向量中\n",
      "Hi,不存在于词向量中\n",
      "bitch.不存在于词向量中\n",
      "changes.不存在于词向量中\n",
      "to...|||It's不存在于词向量中\n",
      "memories.不存在于词向量中\n",
      "'Dear不存在于词向量中\n",
      "standards,不存在于词向量中\n",
      "Hello,不存在于词向量中\n",
      "and...|||Well,不存在于词向量中\n",
      "deeply,不存在于词向量中\n",
      "Hmm.不存在于词向量中\n",
      "Language不存在于词向量中\n",
      "failure.不存在于词向量中\n",
      "tendencies,不存在于词向量中\n",
      ":cool:|||I不存在于词向量中\n",
      "...|||When不存在于词向量中\n",
      "rain,不存在于词向量中\n",
      "jealous.不存在于词向量中\n",
      "way...|||I不存在于词向量中\n",
      "setting,不存在于词向量中\n",
      "Eyes不存在于词向量中\n",
      "accepted.不存在于词向量中\n",
      "dark.不存在于词向量中\n",
      "extreme.不存在于词向量中\n",
      "relevant.不存在于词向量中\n",
      "pressure.不存在于词向量中\n",
      "N/S不存在于词向量中\n",
      "see?不存在于词向量中\n",
      "to...|||When不存在于词向量中\n",
      "weak,不存在于词向量中\n",
      "JK不存在于词向量中\n",
      "service.不存在于词向量中\n",
      "daily.不存在于词向量中\n",
      "Dance不存在于词向量中\n",
      "society's不存在于词向量中\n",
      "helped.不存在于词向量中\n",
      "necessary,不存在于词向量中\n",
      "...|||Yeah,不存在于词向量中\n",
      "extroverts.不存在于词向量中\n",
      "preferences.不存在于词向量中\n",
      "heard,不存在于词向量中\n",
      "Extremely不存在于词向量中\n",
      "ha.不存在于词向量中\n",
      "GET不存在于词向量中\n",
      "asked.不存在于词向量中\n",
      "German,不存在于词向量中\n",
      "Extrovert不存在于词向量中\n",
      "Dom不存在于词向量中\n",
      "Run不存在于词向量中\n",
      "choose.不存在于词向量中\n",
      ":P.不存在于词向量中\n",
      "feeler,不存在于词向量中\n",
      "Empathy不存在于词向量中\n",
      "Dexter不存在于词向量中\n",
      "I...|||Well,不存在于词向量中\n",
      "I...不存在于词向量中\n",
      "pointless.不存在于词向量中\n",
      "nicknames?不存在于词向量中\n",
      "town,不存在于词向量中\n",
      "clean.不存在于词向量中\n",
      "facebook,不存在于词向量中\n",
      "Wonder不存在于词向量中\n",
      "NFs.不存在于词向量中\n",
      "Smart不存在于词向量中\n",
      "blunt,不存在于词向量中\n",
      "depressing.不存在于词向量中\n",
      "xSTJ不存在于词向量中\n",
      "road,不存在于词向量中\n",
      "xNTP不存在于词向量中\n",
      "love/hate不存在于词向量中\n",
      "Justin不存在于词向量中\n",
      "both?不存在于词向量中\n",
      "drive,不存在于词向量中\n",
      "tho,不存在于词向量中\n",
      "(It不存在于词向量中\n",
      "matter?不存在于词向量中\n",
      "library.不存在于词向量中\n",
      "sadness.不存在于词向量中\n",
      "familiar.不存在于词向量中\n",
      "5w6,不存在于词向量中\n",
      "frustrated.不存在于词向量中\n",
      "three.不存在于词向量中\n",
      "mode,不存在于词向量中\n",
      "top.不存在于词向量中\n",
      "(It's不存在于词向量中\n",
      "Dan不存在于词向量中\n",
      "Exactly不存在于词向量中\n",
      "okay?不存在于词向量中\n",
      "(1)不存在于词向量中\n",
      "weight.不存在于词向量中\n",
      "Along不存在于词向量中\n",
      "genre.不存在于词向量中\n",
      "low.不存在于词向量中\n",
      "frankly,不存在于词向量中\n",
      "on...|||I'm不存在于词向量中\n",
      "Hunger不存在于词向量中\n",
      "alike.不存在于词向量中\n",
      "music?不存在于词向量中\n",
      "only,不存在于词向量中\n",
      "(being不存在于词向量中\n",
      "Easy不存在于词向量中\n",
      "insult.不存在于词向量中\n",
      "Sheldon不存在于词向量中\n",
      "core,不存在于词向量中\n",
      "Southern不存在于词向量中\n",
      "mate,不存在于词向量中\n",
      "model.不存在于词向量中\n",
      "expression,不存在于词向量中\n",
      "fears.不存在于词向量中\n",
      "socionics,不存在于词向量中\n",
      "ya,不存在于词向量中\n",
      "morals,不存在于词向量中\n",
      "=/=不存在于词向量中\n",
      "3D不存在于词向量中\n",
      "forward.不存在于词向量中\n",
      "ESFP's不存在于词向量中\n",
      "freedom.不存在于词向量中\n",
      "Army不存在于词向量中\n",
      "fault,不存在于词向量中\n",
      "quote,不存在于词向量中\n",
      "I...|||Thank不存在于词向量中\n",
      "Anxiety不存在于词向量中\n",
      "projects,不存在于词向量中\n",
      "manipulation.不存在于词向量中\n",
      "Him不存在于词向量中\n",
      "Ps不存在于词向量中\n",
      "not...|||I'm不存在于词向量中\n",
      "analysis,不存在于词向量中\n",
      "tried.不存在于词向量中\n",
      "(E)不存在于词向量中\n",
      "(T)不存在于词向量中\n",
      "Everytime不存在于词向量中\n",
      "Creed不存在于词向量中\n",
      "Needless不存在于词向量中\n",
      "Ns不存在于词向量中\n",
      "a...|||Well,不存在于词向量中\n",
      "Describe不存在于词向量中\n",
      "war,不存在于词向量中\n",
      "expectations,不存在于词向量中\n",
      "sentence,不存在于词向量中\n",
      "Least不存在于词向量中\n",
      "forward,不存在于词向量中\n",
      "motivation.不存在于词向量中\n",
      "productive.不存在于词向量中\n",
      "off?不存在于词向量中\n",
      "Depression不存在于词向量中\n",
      "these...|||I不存在于词向量中\n",
      "Grand不存在于词向量中\n",
      "boundaries,不存在于词向量中\n",
      "work...不存在于词向量中\n",
      "the...|||Oh不存在于词向量中\n",
      "Information不存在于词向量中\n",
      "can't...|||I不存在于词向量中\n",
      "mistake,不存在于词向量中\n",
      "faces,不存在于词向量中\n",
      "America.不存在于词向量中\n",
      "Eastern不存在于词向量中\n",
      "Search不存在于词向量中\n",
      "Write不存在于词向量中\n",
      "Ted不存在于词向量中\n",
      "(without不存在于词向量中\n",
      "offended,不存在于词向量中\n",
      "ridiculous,不存在于词向量中\n",
      "design,不存在于词向量中\n",
      "below.不存在于词向量中\n",
      "activity.不存在于词向量中\n",
      "Heck,不存在于词向量中\n",
      "HSP不存在于词向量中\n",
      "INTJs?不存在于词向量中\n",
      "aggressive,不存在于词向量中\n",
      "members,不存在于词向量中\n",
      "(actually不存在于词向量中\n",
      "faith,不存在于词向量中\n",
      "Thus不存在于词向量中\n",
      "apart,不存在于词向量中\n",
      "Reminds不存在于词向量中\n",
      "random.不存在于词向量中\n",
      "teachers.不存在于词向量中\n",
      "ESTJs.不存在于词向量中\n",
      "usual,不存在于词向量中\n",
      "trait,不存在于词向量中\n",
      "Z不存在于词向量中\n",
      "core.不存在于词向量中\n",
      "activity,不存在于词向量中\n",
      "health,不存在于词向量中\n",
      "put.不存在于词向量中\n",
      "badly,不存在于词向量中\n",
      "clearly.不存在于词向量中\n",
      "Justice不存在于词向量中\n",
      "dinner,不存在于词向量中\n",
      "REAL不存在于词向量中\n",
      "AS不存在于词向量中\n",
      "communication,不存在于词向量中\n",
      "clearly,不存在于词向量中\n",
      "here..不存在于词向量中\n",
      "wife.不存在于词向量中\n",
      "sensors,不存在于词向量中\n",
      "where's不存在于词向量中\n",
      "moon,不存在于词向量中\n",
      "Thus,不存在于词向量中\n",
      "neutral.不存在于词向量中\n",
      "Sweden不存在于词向量中\n",
      "box,不存在于词向量中\n",
      "feel?不存在于词向量中\n",
      "Focus不存在于词向量中\n",
      "etc?不存在于词向量中\n",
      "FUCK不存在于词向量中\n",
      "deeply.不存在于词向量中\n",
      "Occasionally不存在于词向量中\n",
      "Okay.不存在于词向量中\n",
      "Sadly,不存在于词向量中\n",
      "offense,不存在于词向量中\n",
      "individuals.不存在于词向量中\n",
      "naturally,不存在于词向量中\n",
      "It鈥檚不存在于词向量中\n",
      "...|||It's不存在于词向量中\n",
      "certain.不存在于词向量中\n",
      "awful,不存在于词向量中\n",
      "perhaps,不存在于词向量中\n",
      "gentle,不存在于词向量中\n",
      "Mass不存在于词向量中\n",
      "EVER不存在于词向量中\n",
      "Us不存在于词向量中\n",
      "too..不存在于词向量中\n",
      "Nine不存在于词向量中\n",
      "freedom,不存在于词向量中\n",
      "Regardless,不存在于词向量中\n",
      "Chuck不存在于词向量中\n",
      ">.>不存在于词向量中\n",
      "Why,不存在于词向量中\n",
      "we,不存在于词向量中\n",
      ":D|||I'm不存在于词向量中\n",
      "beings.不存在于词向量中\n",
      "scene.不存在于词向量中\n",
      "IRL.不存在于词向量中\n",
      "literally.不存在于词向量中\n",
      "ESFP?不存在于词向量中\n",
      "Fe?不存在于词向量中\n",
      "Boy不存在于词向量中\n",
      "Apart不存在于词向量中\n",
      "fake,不存在于词向量中\n",
      "more...|||I'm不存在于词向量中\n",
      "Arts不存在于词向量中\n",
      "Due不存在于词向量中\n",
      "100.不存在于词向量中\n",
      "different...|||I不存在于词向量中\n",
      "and...|||When不存在于词向量中\n",
      "website,不存在于词向量中\n",
      "They've不存在于词向量中\n",
      "introversion,不存在于词向量中\n",
      "frustrated,不存在于词向量中\n",
      "minute,不存在于词向量中\n",
      "B,不存在于词向量中\n",
      "ADHD.不存在于词向量中\n",
      "surroundings.不存在于词向量中\n",
      "win,不存在于词向量中\n",
      "(F)不存在于词向量中\n",
      "inferior.不存在于词向量中\n",
      "(almost不存在于词向量中\n",
      "potential,不存在于词向量中\n",
      "Older不存在于词向量中\n",
      "fuck.不存在于词向量中\n",
      "worries,不存在于词向量中\n",
      "hot,不存在于词向量中\n",
      "directly,不存在于词向量中\n",
      "nonetheless.不存在于词向量中\n",
      "it...'不存在于词向量中\n",
      "Emotions不存在于词向量中\n",
      "conclusions.不存在于词向量中\n",
      "friendships,不存在于词向量中\n",
      "Apparently,不存在于词向量中\n",
      "brilliant.不存在于词向量中\n",
      "BIG不存在于词向量中\n",
      "complicated,不存在于词向量中\n",
      "Charlotte不存在于词向量中\n",
      "infp's不存在于词向量中\n",
      "we?不存在于词向量中\n",
      "Please,不存在于词向量中\n",
      "immature,不存在于词向量中\n",
      "own...|||I不存在于词向量中\n",
      "flawed.不存在于词向量中\n",
      "affection,不存在于词向量中\n",
      "NFs,不存在于词向量中\n",
      "'Thanks不存在于词向量中\n",
      "dumb,不存在于词向量中\n",
      "occasionally.不存在于词向量中\n",
      "languages,不存在于词向量中\n",
      "ISFJs.不存在于词向量中\n",
      "engineering.不存在于词向量中\n",
      "Kevin不存在于词向量中\n",
      "between.不存在于词向量中\n",
      "NTPs不存在于词向量中\n",
      "ESFJ?不存在于词向量中\n",
      "Dutch不存在于词向量中\n",
      "existence,不存在于词向量中\n",
      "school)不存在于词向量中\n",
      "outcome.不存在于词向量中\n",
      "the...|||Yes,不存在于词向量中\n",
      "told,不存在于词向量中\n",
      ":)|||The不存在于词向量中\n",
      "Street不存在于词向量中\n",
      "Crazy不存在于词向量中\n",
      "count.不存在于词向量中\n",
      "necessarily.不存在于词向量中\n",
      "LOL!不存在于词向量中\n",
      "you..不存在于词向量中\n",
      "Rise不存在于词向量中\n",
      "YES!不存在于词向量中\n",
      "Chemistry不存在于词向量中\n",
      "E/I不存在于词向量中\n",
      "RPGs不存在于词向量中\n",
      "-When不存在于词向量中\n",
      "is)不存在于词向量中\n",
      "introversion.不存在于词向量中\n",
      "Assuming不存在于词向量中\n",
      "someone...|||I不存在于词向量中\n",
      "forth.不存在于词向量中\n",
      "'Well,不存在于词向量中\n",
      "Early不存在于词向量中\n",
      "Eat不存在于词向量中\n",
      "responding.不存在于词向量中\n",
      "none.不存在于词向量中\n",
      "detail.不存在于词向量中\n",
      "Outside不存在于词向量中\n",
      "to...|||So不存在于词向量中\n",
      "Secondly,不存在于词向量中\n",
      "this..不存在于词向量中\n",
      "Overall不存在于词向量中\n",
      "Patrick不存在于词向量中\n",
      "Hunter不存在于词向量中\n",
      "pleasure.不存在于词向量中\n",
      "to)不存在于词向量中\n",
      "Mum不存在于词向量中\n",
      "fight,不存在于词向量中\n",
      "etc.).不存在于词向量中\n",
      "general)不存在于词向量中\n",
      "(Or不存在于词向量中\n",
      "Fallout不存在于词向量中\n",
      "I...|||What不存在于词向量中\n",
      "criticism.不存在于词向量中\n",
      "Children不存在于词向量中\n",
      "of...|||If不存在于词向量中\n",
      "in...不存在于词向量中\n",
      "oriented.不存在于词向量中\n",
      "S's不存在于词向量中\n",
      "Party不存在于词向量中\n",
      "Ne?不存在于词向量中\n",
      "like..不存在于词向量中\n",
      "really...不存在于词向量中\n",
      "Stand不存在于词向量中\n",
      "SO,不存在于词向量中\n",
      "surface.不存在于词向量中\n",
      "was...不存在于词向量中\n",
      "abilities.不存在于词向量中\n",
      "natural,不存在于词向量中\n",
      "it.|||The不存在于词向量中\n",
      "Nah不存在于词向量中\n",
      "(how不存在于词向量中\n",
      "me),不存在于词向量中\n",
      "vulnerable.不存在于词向量中\n",
      "B)不存在于词向量中\n",
      "pass.不存在于词向量中\n",
      "Facebook,不存在于词向量中\n",
      "Wing不存在于词向量中\n",
      "lost,不存在于词向量中\n",
      "Team不存在于词向量中\n",
      "Alright,不存在于词向量中\n",
      "smoke,不存在于词向量中\n",
      "ideal.不存在于词向量中\n",
      "personality?不存在于词向量中\n",
      "not...不存在于词向量中\n",
      "Intuitives不存在于词向量中\n",
      "Lana不存在于词向量中\n",
      "eh,不存在于词向量中\n",
      "thinking?不存在于词向量中\n",
      "minds,不存在于词向量中\n",
      "to...|||Thank不存在于词向量中\n",
      "Major不存在于词向量中\n",
      "9w1.不存在于词向量中\n",
      "humans,不存在于词向量中\n",
      "Floyd不存在于词向量中\n",
      "be...'不存在于词向量中\n",
      "talkative,不存在于词向量中\n",
      "M不存在于词向量中\n",
      "Quiet不存在于词向量中\n",
      "I/E不存在于词向量中\n",
      "incredible.不存在于词向量中\n",
      "This,不存在于词向量中\n",
      "to...|||Thanks不存在于词向量中\n",
      "evidence,不存在于词向量中\n",
      "...|||That's不存在于词向量中\n",
      "sun,不存在于词向量中\n",
      "window.不存在于词向量中\n",
      "Ts不存在于词向量中\n",
      "Water不存在于词向量中\n",
      "TOTALLY不存在于词向量中\n",
      "IT'S不存在于词向量中\n",
      "father's不存在于词向量中\n",
      "teachers,不存在于词向量中\n",
      "preference,不存在于词向量中\n",
      "Mike不存在于词向量中\n",
      "loop,不存在于词向量中\n",
      "eye,不存在于词向量中\n",
      "Whereas不存在于词向量中\n",
      "crowd.不存在于词向量中\n",
      "hour,不存在于词向量中\n",
      "Hang不存在于词向量中\n",
      "suggestions.不存在于词向量中\n",
      "colors,不存在于词向量中\n",
      "place?不存在于词向量中\n",
      "Sexual不存在于词向量中\n",
      "Chicago不存在于词向量中\n",
      "included.不存在于词向量中\n",
      ":'(不存在于词向量中\n",
      "whatnot.不存在于词向量中\n",
      "letters.不存在于词向量中\n",
      "walls,不存在于词向量中\n",
      "Worst不存在于词向量中\n",
      "heads.不存在于词向量中\n",
      "are...|||I'm不存在于词向量中\n",
      ":shocked:|||I不存在于词向量中\n",
      "justice.不存在于词向量中\n",
      "religious.不存在于词向量中\n",
      "knows.不存在于词向量中\n",
      "Wasn't不存在于词向量中\n",
      "field,不存在于词向量中\n",
      "depends,不存在于词向量中\n",
      "???不存在于词向量中\n",
      "Lately,不存在于词向量中\n",
      "driving.不存在于词向量中\n",
      "population,不存在于词向量中\n",
      "January不存在于词向量中\n",
      "romance.不存在于词向量中\n",
      "genuine,不存在于词向量中\n",
      "Results不存在于词向量中\n",
      "powers.不存在于词向量中\n",
      "nowadays.不存在于词向量中\n",
      "background,不存在于词向量中\n",
      "rate,不存在于词向量中\n",
      "Rain不存在于词向量中\n",
      "her...不存在于词向量中\n",
      "guess?不存在于词向量中\n",
      "it....|||I不存在于词向量中\n",
      "Sensitive不存在于词向量中\n",
      "'Thank不存在于词向量中\n",
      "middle.不存在于词向量中\n",
      "ISTP?不存在于词向量中\n",
      "ENFP's.不存在于词向量中\n",
      "P's不存在于词向量中\n",
      "7w8,不存在于词向量中\n",
      "lies.不存在于词向量中\n",
      "and...|||Thank不存在于词向量中\n",
      "scale.不存在于词向量中\n",
      "projects.不存在于词向量中\n",
      "Aspie不存在于词向量中\n",
      "ask?不存在于词向量中\n",
      "'That不存在于词向量中\n",
      "gifts,不存在于词向量中\n",
      "Buddhist不存在于词向量中\n",
      "mind...不存在于词向量中\n",
      "direct,不存在于词向量中\n",
      "assertive,不存在于词向量中\n",
      "and...|||It不存在于词向量中\n",
      "seriously?不存在于词向量中\n",
      "(i'm不存在于词向量中\n",
      "doesn't...|||I不存在于词向量中\n",
      "my...|||The不存在于词向量中\n",
      "emotions?不存在于词向量中\n",
      "Ancient不存在于词向量中\n",
      "Mario不存在于词向量中\n",
      "(Fi)不存在于词向量中\n",
      "Furthermore,不存在于词向量中\n",
      "given,不存在于词向量中\n",
      "concept,不存在于词向量中\n",
      "entertaining.不存在于词向量中\n",
      "Alcohol不存在于词向量中\n",
      "Asperger's不存在于词向量中\n",
      "signature.不存在于词向量中\n",
      "are...|||My不存在于词向量中\n",
      "infj,不存在于词向量中\n",
      "info.不存在于词向量中\n",
      "shell.不存在于词向量中\n",
      "ADHD,不存在于词向量中\n",
      "thinker,不存在于词向量中\n",
      "wanted.不存在于词向量中\n",
      "Logic不存在于词向量中\n",
      "preferences,不存在于词向量中\n",
      "data,不存在于词向量中\n",
      "in...|||You不存在于词向量中\n",
      "small.不存在于词向量中\n",
      "Yea,不存在于词向量中\n",
      "Wanna不存在于词向量中\n",
      "album.不存在于词向量中\n",
      "Haha!不存在于词向量中\n",
      "sake.不存在于词向量中\n",
      "Zen不存在于词向量中\n",
      "realistic,不存在于词向量中\n",
      "day...不存在于词向量中\n",
      "lying.不存在于词向量中\n",
      "belief.不存在于词向量中\n",
      "therapist.不存在于词向量中\n",
      "Daily不存在于词向量中\n",
      "Original不存在于词向量中\n",
      "Works不存在于词向量中\n",
      ":sad:|||I不存在于词向量中\n",
      "fake.不存在于词向量中\n",
      "Beast不存在于词向量中\n",
      "males.不存在于词向量中\n",
      "trip.不存在于词向量中\n",
      "yep,不存在于词向量中\n",
      "Off不存在于词向量中\n",
      "INTJ...不存在于词向量中\n",
      "Hahaha不存在于词向量中\n",
      "follow.不存在于词向量中\n",
      "used,不存在于词向量中\n",
      "Andrew不存在于词向量中\n",
      "Year不存在于词向量中\n",
      "INTP.|||I不存在于词向量中\n",
      "HR不存在于词向量中\n",
      "attack.不存在于词向量中\n",
      "pop,不存在于词向量中\n",
      "rational.不存在于词向量中\n",
      "SO.不存在于词向量中\n",
      "subjects.不存在于词向量中\n",
      "Woman不存在于词向量中\n",
      "make,不存在于词向量中\n",
      "4.)不存在于词向量中\n",
      "related,不存在于词向量中\n",
      "Skill不存在于词向量中\n",
      "Alan不存在于词向量中\n",
      "Ya不存在于词向量中\n",
      "NF,不存在于词向量中\n",
      "Bell不存在于词向量中\n",
      "3/4不存在于词向量中\n",
      "competitive.不存在于词向量中\n",
      "Bear不存在于词向量中\n",
      "Away不存在于词向量中\n",
      "And...|||I不存在于词向量中\n",
      "been...|||I不存在于词向量中\n",
      "come,不存在于词向量中\n",
      "Taurus不存在于词向量中\n",
      "call.不存在于词向量中\n",
      "sake,不存在于词向量中\n",
      "Wanting不存在于词向量中\n",
      "but..不存在于词向量中\n",
      "mention,不存在于词向量中\n",
      "hehe.不存在于词向量中\n",
      "intj's不存在于词向量中\n",
      "Sarah不存在于词向量中\n",
      "interesting...不存在于词向量中\n",
      "explain,不存在于词向量中\n",
      "Anime不存在于词向量中\n",
      "worst,不存在于词向量中\n",
      "possible?不存在于词向量中\n",
      "suffering.不存在于词向量中\n",
      "Hold不存在于词向量中\n",
      "mbti,不存在于词向量中\n",
      "mostly,不存在于词向量中\n",
      "4w5.不存在于词向量中\n",
      "doing...|||I不存在于词向量中\n",
      "insights.不存在于词向量中\n",
      "suicide.不存在于词向量中\n",
      "path.不存在于词向量中\n",
      "top,不存在于词向量中\n",
      "zone,不存在于词向量中\n",
      "lol).不存在于词向量中\n",
      "Second,不存在于词向量中\n",
      "IMO.不存在于词向量中\n",
      "Del不存在于词向量中\n",
      "want...|||I不存在于词向量中\n",
      "mess,不存在于词向量中\n",
      "sex?不存在于词向量中\n",
      "romance,不存在于词向量中\n",
      "ability.不存在于词向量中\n",
      "Education不存在于词向量中\n",
      "BF不存在于词向量中\n",
      "Again不存在于词向量中\n",
      "Professor不存在于词向量中\n",
      "countries,不存在于词向量中\n",
      "C.不存在于词向量中\n",
      "written.不存在于词向量中\n",
      "in...|||This不存在于词向量中\n",
      "IxTJ不存在于词向量中\n",
      "half.不存在于词向量中\n",
      "evening.不存在于词向量中\n",
      "SX不存在于词向量中\n",
      "feet.不存在于词向量中\n",
      "hour.不存在于词向量中\n",
      "teens,不存在于词向量中\n",
      "20,不存在于词向量中\n",
      "knows,不存在于词向量中\n",
      "Jackson不存在于词向量中\n",
      "criticism,不存在于词向量中\n",
      "ESxP不存在于词向量中\n",
      "follow,不存在于词向量中\n",
      "article,不存在于词向量中\n",
      "mix.不存在于词向量中\n",
      ":blushed:|||I不存在于词向量中\n",
      "doctor.不存在于词向量中\n",
      "._.不存在于词向量中\n",
      "blunt.不存在于词向量中\n",
      "...|||So不存在于词向量中\n",
      "him/her不存在于词向量中\n",
      "Profile不存在于词向量中\n",
      "Parrot不存在于词向量中\n",
      "together?不存在于词向量中\n",
      "Winter不存在于词向量中\n",
      "'Oh不存在于词向量中\n",
      "tears.不存在于词向量中\n",
      "Office不存在于词向量中\n",
      "years)不存在于词向量中\n",
      "weed,不存在于词向量中\n",
      "Emily不存在于词向量中\n",
      "stay.不存在于词向量中\n",
      "Somewhere不存在于词向量中\n",
      "was/is不存在于词向量中\n",
      "Political不存在于词向量中\n",
      "R不存在于词向量中\n",
      "minded,不存在于词向量中\n",
      "and...|||If不存在于词向量中\n",
      "Creative不存在于词向量中\n",
      "was...|||I'm不存在于词向量中\n",
      "gender.不存在于词向量中\n",
      "given.不存在于词向量中\n",
      "ok?不存在于词向量中\n",
      "occasions.不存在于词向量中\n",
      "Ravenclaw,不存在于词向量中\n",
      "abuse.不存在于词向量中\n",
      "surface,不存在于词向量中\n",
      "last,不存在于词向量中\n",
      "Body不存在于词向量中\n",
      "exactly?不存在于词向量中\n",
      "good?不存在于词向量中\n",
      "reference.不存在于词向量中\n",
      "humour.不存在于词向量中\n",
      "NT.不存在于词向量中\n",
      "something's不存在于词向量中\n",
      "jerk.不存在于词向量中\n",
      "Sweet不存在于词向量中\n",
      "wonder.不存在于词向量中\n",
      "Js不存在于词向量中\n",
      "o.o不存在于词向量中\n",
      "members.不存在于词向量中\n",
      "INFJ...不存在于词向量中\n",
      "highschool,不存在于词向量中\n",
      "Enneagram,不存在于词向量中\n",
      "Elizabeth不存在于词向量中\n",
      "version.不存在于词向量中\n",
      "Force不存在于词向量中\n",
      "gender?不存在于词向量中\n",
      "thoughtful,不存在于词向量中\n",
      "scene,不存在于词向量中\n",
      "event,不存在于词向量中\n",
      "wish.不存在于词向量中\n",
      "parent,不存在于词向量中\n",
      "Stuff不存在于词向量中\n",
      "Venus不存在于词向量中\n",
      "intellectual,不存在于词向量中\n",
      "Fox不存在于词向量中\n",
      "Level不存在于词向量中\n",
      "Frequency不存在于词向量中\n",
      "exciting.不存在于词向量中\n",
      "Stress不存在于词向量中\n",
      "Cats不存在于词向量中\n",
      "watching.不存在于词向量中\n",
      "Saw不存在于词向量中\n",
      "church,不存在于词向量中\n",
      "enjoy,不存在于词向量中\n",
      "Masters不存在于词向量中\n",
      "Ever.不存在于词向量中\n",
      "of...|||What不存在于词向量中\n",
      "me.|||I'm不存在于词向量中\n",
      "explanation,不存在于词向量中\n",
      "Wow!不存在于词向量中\n",
      "stuff...不存在于词向量中\n",
      "areas.不存在于词向量中\n",
      "S/N不存在于词向量中\n",
      "patterns,不存在于词向量中\n",
      "Head不存在于词向量中\n",
      "fits.不存在于词向量中\n",
      "OP:不存在于词向量中\n",
      "us...不存在于词向量中\n",
      "media.不存在于词向量中\n",
      "Hm,不存在于词向量中\n",
      "humanity,不存在于词向量中\n",
      "THEY不存在于词向量中\n",
      "too)不存在于词向量中\n",
      "irrational,不存在于词向量中\n",
      "Friend:不存在于词向量中\n",
      "mistyped.不存在于词向量中\n",
      "further.不存在于词向量中\n",
      "that...|||This不存在于词向量中\n",
      "Forum不存在于词向量中\n",
      "(where不存在于词向量中\n",
      "siblings,不存在于词向量中\n",
      "Born不存在于词向量中\n",
      "18,不存在于词向量中\n",
      "manipulation,不存在于词向量中\n",
      "beauty,不存在于词向量中\n",
      "Mental不存在于词向量中\n",
      "experiment.不存在于词向量中\n",
      "Starting不存在于词向量中\n",
      "Typology不存在于词向量中\n",
      "described,不存在于词向量中\n",
      ":-)|||I不存在于词向量中\n",
      "anxious.不存在于词向量中\n",
      "quick.不存在于词向量中\n",
      "Screw不存在于词向量中\n",
      "sure?不存在于词向量中\n",
      "audience.不存在于词向量中\n",
      "study.不存在于词向量中\n",
      "Gender不存在于词向量中\n",
      "the...|||That不存在于词向量中\n",
      "-.-不存在于词向量中\n",
      "concepts.不存在于词向量中\n",
      "feminine,不存在于词向量中\n",
      "acting,不存在于词向量中\n",
      "chocolate,不存在于词向量中\n",
      "describe.不存在于词向量中\n",
      "luck,不存在于词向量中\n",
      "usual.不存在于词向量中\n",
      "aggressive.不存在于词向量中\n",
      "pressure,不存在于词向量中\n",
      "pointless,不存在于词向量中\n",
      "AI不存在于词向量中\n",
      "1.5不存在于词向量中\n",
      "angry?不存在于词向量中\n",
      "Battle不存在于词向量中\n",
      "private.不存在于词向量中\n",
      "painful.不存在于词向量中\n",
      "be)不存在于词向量中\n",
      "Ignore不存在于词向量中\n",
      "chemistry.不存在于词向量中\n",
      "cheese,不存在于词向量中\n",
      "scale,不存在于词向量中\n",
      "Arthur不存在于词向量中\n",
      "Miranda不存在于词向量中\n",
      "MBTI:不存在于词向量中\n",
      "counts.不存在于词向量中\n",
      "immediately.不存在于词向量中\n",
      ":laughing:|||Welcome不存在于词向量中\n",
      "regard.不存在于词向量中\n",
      "routine.不存在于词向量中\n",
      "'As不存在于词向量中\n",
      "African不存在于词向量中\n",
      "I...|||Well不存在于词向量中\n",
      "levels,不存在于词向量中\n",
      "ESTPs,不存在于词向量中\n",
      "Hollywood不存在于词向量中\n",
      "Straight不存在于词向量中\n",
      "attraction,不存在于词向量中\n",
      "email,不存在于词向量中\n",
      "trouble,不存在于词向量中\n",
      "role,不存在于词向量中\n",
      "ugly,不存在于词向量中\n",
      "Inside不存在于词向量中\n",
      "enough?不存在于词向量中\n",
      "air,不存在于词向量中\n",
      "Zelda不存在于词向量中\n",
      "relaxed,不存在于词向量中\n",
      "Strength不存在于词向量中\n",
      "Capricorn不存在于词向量中\n",
      "weather,不存在于词向量中\n",
      "were...|||I不存在于词向量中\n",
      "INFPs?不存在于词向量中\n",
      "physics.不存在于词向量中\n",
      "and...|||That不存在于词向量中\n",
      "qualities.不存在于词向量中\n",
      "years?不存在于词向量中\n",
      "crush,不存在于词向量中\n",
      "person...|||I不存在于词向量中\n",
      "just...|||I'm不存在于词向量中\n",
      "'1.不存在于词向量中\n",
      "apologize,不存在于词向量中\n",
      "family's不存在于词向量中\n",
      "method.不存在于词向量中\n",
      "broken,不存在于词向量中\n",
      "organized.不存在于词向量中\n",
      "females,不存在于词向量中\n",
      "it|||I不存在于词向量中\n",
      "developed.不存在于词向量中\n",
      "guys?不存在于词向量中\n",
      "flirt,不存在于词向量中\n",
      "bitch,不存在于词向量中\n",
      "idealistic,不存在于词向量中\n",
      "LONG不存在于词向量中\n",
      "stage,不存在于词向量中\n",
      "friends)不存在于词向量中\n",
      "Overall,不存在于词向量中\n",
      "beauty.不存在于词向量中\n",
      "cause,不存在于词向量中\n",
      "O.o不存在于词向量中\n",
      "others...不存在于词向量中\n",
      "meat.不存在于词向量中\n",
      "meat,不存在于词向量中\n",
      "fall.不存在于词向量中\n",
      "name?不存在于词向量中\n",
      "myself...|||I不存在于词向量中\n",
      "currently,不存在于词向量中\n",
      "Fi?不存在于词向量中\n",
      "today...不存在于词向量中\n",
      "Fs不存在于词向量中\n",
      "many...|||I不存在于词向量中\n",
      "Alone不存在于词向量中\n",
      "Dr不存在于词向量中\n",
      "law.不存在于词向量中\n",
      "anywhere,不存在于词向量中\n",
      "situation?不存在于词向量中\n",
      "Primary不存在于词向量中\n",
      "insecure,不存在于词向量中\n",
      "travel,不存在于词向量中\n",
      "happening,不存在于词向量中\n",
      "scenario,不存在于词向量中\n",
      "homework.不存在于词向量中\n",
      "Yup,不存在于词向量中\n",
      "||||||不存在于词向量中\n",
      "spectrum.不存在于词向量中\n",
      "happen?不存在于词向量中\n",
      "it.'不存在于词向量中\n",
      "(assuming不存在于词向量中\n",
      "physically.不存在于词向量中\n",
      "too).不存在于词向量中\n",
      "careful.不存在于词向量中\n",
      "word?不存在于词向量中\n",
      "quality.不存在于词向量中\n",
      "I...|||Thanks不存在于词向量中\n",
      "witty,不存在于词向量中\n",
      "ENTP...不存在于词向量中\n",
      "idiots.不存在于词向量中\n",
      "friend...不存在于词向量中\n",
      "birthday,不存在于词向量中\n",
      "behind.不存在于词向量中\n",
      "(Extroverted不存在于词向量中\n",
      "the...|||So不存在于词向量中\n",
      "directly.不存在于词向量中\n",
      "Basic不存在于词向量中\n",
      "Aspergers不存在于词向量中\n",
      "strengths,不存在于词向量中\n",
      "5w4.不存在于词向量中\n",
      "piano.不存在于词向量中\n",
      "August不存在于词向量中\n",
      "stuff?不存在于词向量中\n",
      "people...|||I'm不存在于词向量中\n",
      "a...|||So不存在于词向量中\n",
      "Mexican不存在于词向量中\n",
      "Extraversion不存在于词向量中\n",
      "type.|||I不存在于词向量中\n",
      "pants,不存在于词向量中\n",
      "Persona不存在于词向量中\n",
      "kindness,不存在于词向量中\n",
      "Instinctual不存在于词向量中\n",
      "2w1,不存在于词向量中\n",
      "UP不存在于词向量中\n",
      "perception.不存在于词向量中\n",
      "One:不存在于词向量中\n",
      "dry,不存在于词向量中\n",
      "adult.不存在于词向量中\n",
      "others)不存在于词向量中\n",
      "next,不存在于词向量中\n",
      "arts,不存在于词向量中\n",
      "perspectives.不存在于词向量中\n",
      "facebook.不存在于词向量中\n",
      "Rachel不存在于词向量中\n",
      "Plan不存在于词向量中\n",
      "messy.不存在于词向量中\n",
      "a...|||Oh不存在于词向量中\n",
      "weight,不存在于词向量中\n",
      "concepts,不存在于词向量中\n",
      "socially.不存在于词向量中\n",
      "XD.不存在于词向量中\n",
      "stated,不存在于词向量中\n",
      "Buddhism不存在于词向量中\n",
      "Movies不存在于词向量中\n",
      "liked.不存在于词向量中\n",
      "Nick不存在于词向量中\n",
      "Nazi不存在于词向量中\n",
      "irrational.不存在于词向量中\n",
      "socializing.不存在于词向量中\n",
      "is...|||This不存在于词向量中\n",
      "Current不存在于词向量中\n",
      "them).不存在于词向量中\n",
      "Function不存在于词向量中\n",
      "(his不存在于词向量中\n",
      "Kim不存在于词向量中\n",
      "Key不存在于词向量中\n",
      "occasion,不存在于词向量中\n",
      "stranger.不存在于词向量中\n",
      "Play不存在于词向量中\n",
      "bar.不存在于词向量中\n",
      "travel.不存在于词向量中\n",
      "21.不存在于词向量中\n",
      "hug,不存在于词向量中\n",
      "Chances不存在于词向量中\n",
      "Christmas,不存在于词向量中\n",
      "that...|||My不存在于词向量中\n",
      "shallow,不存在于词向量中\n",
      ";).不存在于词向量中\n",
      "poll.不存在于词向量中\n",
      "definitely,不存在于词向量中\n",
      "Luckily,不存在于词向量中\n",
      "Hey!不存在于词向量中\n",
      "A's不存在于词向量中\n",
      "genre,不存在于词向量中\n",
      "everybody.不存在于词向量中\n",
      "Tests不存在于词向量中\n",
      "Songs不存在于词向量中\n",
      "habits.不存在于词向量中\n",
      "spontaneous,不存在于词向量中\n",
      "'Well不存在于词向量中\n",
      "slow,不存在于词向量中\n",
      "Anger不存在于词向量中\n",
      "Thread不存在于词向量中\n",
      "doctor,不存在于词向量中\n",
      "ESFPs,不存在于词向量中\n",
      "properly,不存在于词向量中\n",
      "Male/Female/Trans?不存在于词向量中\n",
      "Infj不存在于词向量中\n",
      "Against不存在于词向量中\n",
      "distance,不存在于词向量中\n",
      "is...|||My不存在于词向量中\n",
      "key.不存在于词向量中\n",
      "Mac不存在于词向量中\n",
      "novel,不存在于词向量中\n",
      "Avatar不存在于词向量中\n",
      "concerned,不存在于词向量中\n",
      "never.不存在于词向量中\n",
      "table,不存在于词向量中\n",
      "my.不存在于词向量中\n",
      "HS不存在于词向量中\n",
      "has,不存在于词向量中\n",
      "him...不存在于词向量中\n",
      "NP不存在于词向量中\n",
      "ignorance.不存在于词向量中\n",
      "systems,不存在于词向量中\n",
      "excited.不存在于词向量中\n",
      "step.不存在于词向量中\n",
      "(read:不存在于词向量中\n",
      "insecure.不存在于词向量中\n",
      "Swift不存在于词向量中\n",
      "plans.不存在于词向量中\n",
      "Hannibal不存在于词向量中\n",
      "insane,不存在于词向量中\n",
      "hobbies,不存在于词向量中\n",
      "Kids不存在于词向量中\n",
      "November不存在于词向量中\n",
      "6w5,不存在于词向量中\n",
      "worked.不存在于词向量中\n",
      "homework,不存在于词向量中\n",
      "fantasy,不存在于词向量中\n",
      "T's不存在于词向量中\n",
      "Dave不存在于词向量中\n",
      "belief,不存在于词向量中\n",
      "relax,不存在于词向量中\n",
      "haven't.不存在于词向量中\n",
      "Regina不存在于词向量中\n",
      "parts,不存在于词向量中\n",
      "over...|||I不存在于词向量中\n",
      "(Preference,不存在于词向量中\n",
      "Marilyn不存在于词向量中\n",
      "*I不存在于词向量中\n",
      "D.不存在于词向量中\n",
      "(based不存在于词向量中\n",
      "Rey不存在于词向量中\n",
      "focused,不存在于词向量中\n",
      "Reason不存在于词向量中\n",
      "needed,不存在于词向量中\n",
      "weather.不存在于词向量中\n",
      "Enough不存在于词向量中\n",
      "Forever不存在于词向量中\n",
      "Amazing不存在于词向量中\n",
      "sharing,不存在于词向量中\n",
      "students.不存在于词向量中\n",
      "anyone?不存在于词向量中\n",
      "said...不存在于词向量中\n",
      "Ryan不存在于词向量中\n",
      "crush.不存在于词向量中\n",
      "progress.不存在于词向量中\n",
      "safe.不存在于词向量中\n",
      "that...|||You不存在于词向量中\n",
      "sort,不存在于词向量中\n",
      "loneliness.不存在于词向量中\n",
      "anyway)不存在于词向量中\n",
      "life...|||I不存在于词向量中\n",
      "Ugh.不存在于词向量中\n",
      "church.不存在于词向量中\n",
      "skin,不存在于词向量中\n",
      "surroundings,不存在于词向量中\n",
      "Hillary不存在于词向量中\n",
      "IT!不存在于词向量中\n",
      "dance.不存在于词向量中\n",
      "Gonna不存在于词向量中\n",
      ":)|||Hi不存在于词向量中\n",
      "ending.不存在于词向量中\n",
      "Style:不存在于词向量中\n",
      "questionnaire.不存在于词向量中\n",
      "MUST不存在于词向量中\n",
      "tea?不存在于词向量中\n",
      "empathetic,不存在于词向量中\n",
      "x)不存在于词向量中\n",
      "parent.不存在于词向量中\n",
      "Welcome,不存在于词向量中\n",
      "ago...不存在于词向量中\n",
      "safe,不存在于词向量中\n",
      "fail,不存在于词向量中\n",
      "the...|||Well,不存在于词向量中\n",
      "Christopher不存在于词向量中\n",
      "I...|||That不存在于词向量中\n",
      "October不存在于词向量中\n",
      "everybody,不存在于词向量中\n",
      "LG-H343不存在于词向量中\n",
      "for...不存在于词向量中\n",
      "ESTPs.不存在于词向量中\n",
      "neither.不存在于词向量中\n",
      "laughing.不存在于词向量中\n",
      "grades.不存在于词向量中\n",
      "Maybe.不存在于词向量中\n",
      "focus,不存在于词向量中\n",
      "Link不存在于词向量中\n",
      "patience,不存在于词向量中\n",
      "Brian不存在于词向量中\n",
      "biology,不存在于词向量中\n",
      "...|||Well,不存在于词向量中\n",
      "Phil不存在于词向量中\n",
      "EXTREMELY不存在于词向量中\n",
      "Devil不存在于词向量中\n",
      "Picture不存在于词向量中\n",
      "media,不存在于词向量中\n",
      "much.|||I不存在于词向量中\n",
      "intentions.不存在于词向量中\n",
      "ideals.不存在于词向量中\n",
      "created.不存在于词向量中\n",
      "countries.不存在于词向量中\n",
      "Action不存在于词向量中\n",
      "Alex不存在于词向量中\n",
      "law,不存在于词向量中\n",
      "rejection.不存在于词向量中\n",
      "males,不存在于词向量中\n",
      "somewhat.不存在于词向量中\n",
      "14,不存在于词向量中\n",
      "phase.不存在于词向量中\n",
      "Btw不存在于词向量中\n",
      "dinner.不存在于词向量中\n",
      "Far不存在于词向量中\n",
      "crying,不存在于词向量中\n",
      "tritype,不存在于词向量中\n",
      "infj.不存在于词向量中\n",
      "cake.不存在于词向量中\n",
      "addiction.不存在于词向量中\n",
      "PS:不存在于词向量中\n",
      "HE不存在于词向量中\n",
      "lovely,不存在于词向量中\n",
      "Code不存在于词向量中\n",
      "intention.不存在于词向量中\n",
      "xSTP不存在于词向量中\n",
      "fire.不存在于词向量中\n",
      "stand.不存在于词向量中\n",
      "walk.不存在于词向量中\n",
      "compliments.不存在于词向量中\n",
      "NTP不存在于词向量中\n",
      "Eh,不存在于词向量中\n",
      "parent's不存在于词向量中\n",
      "distant,不存在于词向量中\n",
      "rejection,不存在于词向量中\n",
      "amusing.不存在于词向量中\n",
      "interactions,不存在于词向量中\n",
      "Monty不存在于词向量中\n",
      "it!|||I不存在于词向量中\n",
      "'Hey不存在于词向量中\n",
      "Wake不存在于词向量中\n",
      "fuckin'不存在于词向量中\n",
      "as.不存在于词向量中\n",
      "Brothers不存在于词向量中\n",
      "the...|||As不存在于词向量中\n",
      "Adventure不存在于词向量中\n",
      "peers.不存在于词向量中\n",
      "clingy,不存在于词向量中\n",
      "confusion.不存在于词向量中\n",
      "around...|||I不存在于词向量中\n",
      ":')不存在于词向量中\n",
      "NOW不存在于词向量中\n",
      "stubborn.不存在于词向量中\n",
      "Si?不存在于词向量中\n",
      "(mainly不存在于词向量中\n",
      "writer.不存在于词向量中\n",
      "doesn't,不存在于词向量中\n",
      "September不存在于词向量中\n",
      "pathetic.不存在于词向量中\n",
      "attraction.不存在于词向量中\n",
      "true...不存在于词向量中\n",
      "Walk不存在于词向量中\n",
      "Image不存在于词向量中\n",
      "ends.不存在于词向量中\n",
      "ENFP:不存在于词向量中\n",
      "of...|||It不存在于词向量中\n",
      "beer,不存在于词向量中\n",
      "store.不存在于词向量中\n",
      "Road不存在于词向量中\n",
      "interviews,不存在于词向量中\n",
      "loved,不存在于词向量中\n",
      "exist?不存在于词向量中\n",
      "literature,不存在于词向量中\n",
      "son,不存在于词向量中\n",
      "intp.不存在于词向量中\n",
      "NFP不存在于词向量中\n",
      ":)|||What不存在于词向量中\n",
      "sadly,不存在于词向量中\n",
      ":)|||When不存在于词向量中\n",
      "Oddly不存在于词向量中\n",
      "comfort.不存在于词向量中\n",
      "offensive.不存在于词向量中\n",
      "norm.不存在于词向量中\n",
      "night?不存在于词向量中\n",
      "Virgo不存在于词向量中\n",
      "Including不存在于词向量中\n",
      "Met不存在于词向量中\n",
      "interview,不存在于词向量中\n",
      "absolutely.不存在于词向量中\n",
      "Hill不存在于词向量中\n",
      "SOME不存在于词向量中\n",
      "wait...不存在于词向量中\n",
      "roles.不存在于词向量中\n",
      "half,不存在于词向量中\n",
      "Today,不存在于词向量中\n",
      "Rowling不存在于词向量中\n",
      "Christmas.不存在于词向量中\n",
      "table.不存在于词向量中\n",
      "draw,不存在于词向量中\n",
      "passionate,不存在于词向量中\n",
      "found.不存在于词向量中\n",
      "sing,不存在于词向量中\n",
      "pieces.不存在于词向量中\n",
      "stubborn,不存在于词向量中\n",
      "memories,不存在于词向量中\n",
      "eating,不存在于词向量中\n",
      "Dating不存在于词向量中\n",
      "stage.不存在于词向量中\n",
      "messages.不存在于词向量中\n",
      "is...|||You不存在于词向量中\n",
      "yet...不存在于词向量中\n",
      "dancing.不存在于词向量中\n",
      "numbers,不存在于词向量中\n",
      "15.不存在于词向量中\n",
      "quirky,不存在于词向量中\n",
      "broken.不存在于词向量中\n",
      "stopped.不存在于词向量中\n",
      "Sailor不存在于词向量中\n",
      "put,不存在于词向量中\n",
      "nobody's不存在于词向量中\n",
      "20s.不存在于词向量中\n",
      "episode.不存在于词向量中\n",
      "to...|||Well不存在于词向量中\n",
      "a...|||Well不存在于词向量中\n",
      "15,不存在于词向量中\n",
      "yes...不存在于词向量中\n",
      "Fiction不存在于词向量中\n",
      "feminine.不存在于词向量中\n",
      "Kiss不存在于词向量中\n",
      "ST不存在于词向量中\n",
      "Hero不存在于词向量中\n",
      "you...'不存在于词向量中\n",
      "feelers.不存在于词向量中\n",
      "winter.不存在于词向量中\n",
      "training.不存在于词向量中\n",
      "home?不存在于词向量中\n",
      "to...|||Oh不存在于词向量中\n",
      "infj's不存在于词向量中\n",
      "incorrect.不存在于词向量中\n",
      "pages,不存在于词向量中\n",
      "DOES不存在于词向量中\n",
      "he?不存在于词向量中\n",
      "material.不存在于词向量中\n",
      "popular,不存在于词向量中\n",
      "INxx不存在于词向量中\n",
      "Cute不存在于词向量中\n",
      "lot...不存在于词向量中\n",
      "teen,不存在于词向量中\n",
      "back?不存在于词向量中\n",
      "intimidating.不存在于词向量中\n",
      "appearance,不存在于词向量中\n",
      "confident.不存在于词向量中\n",
      "Hearts不存在于词向量中\n",
      "(see不存在于词向量中\n",
      "Mad不存在于词向量中\n",
      "bar,不存在于词向量中\n",
      "needy,不存在于词向量中\n",
      "xNTJ不存在于词向量中\n",
      "ENFJ:不存在于词向量中\n",
      "ya'll不存在于词向量中\n",
      "...|||Well不存在于词向量中\n",
      "Dylan不存在于词向量中\n",
      "acquaintances,不存在于词向量中\n",
      "a...|||That不存在于词向量中\n",
      "known,不存在于词向量中\n",
      "se.不存在于词向量中\n",
      "numbers.不存在于词向量中\n",
      "drawing.不存在于词向量中\n",
      "(probably)不存在于词向量中\n",
      "sometimes...不存在于词向量中\n",
      "SP's不存在于词向量中\n",
      "Special不存在于词向量中\n",
      "INFP's.不存在于词向量中\n",
      "Spanish.不存在于词向量中\n",
      "...but不存在于词向量中\n",
      "could...|||I不存在于词向量中\n",
      "CD不存在于词向量中\n",
      "world...不存在于词向量中\n",
      "wall,不存在于词向量中\n",
      "guess)不存在于词向量中\n",
      "forget.不存在于词向量中\n",
      "sight.不存在于词向量中\n",
      "lies,不存在于词向量中\n",
      "nicely.不存在于词向量中\n",
      "Cafe.不存在于词向量中\n",
      "there.|||I不存在于词向量中\n",
      "specific.不存在于词向量中\n",
      "of...|||It's不存在于词向量中\n",
      "rule.不存在于词向量中\n",
      "Break不存在于词向量中\n",
      "Similar不存在于词向量中\n",
      "senses.不存在于词向量中\n",
      "perception,不存在于词向量中\n",
      "Coffee不存在于词向量中\n",
      "community,不存在于词向量中\n",
      "Tried不存在于词向量中\n",
      "schedule.不存在于词向量中\n",
      "nope,不存在于词向量中\n",
      "Max不存在于词向量中\n",
      "(think不存在于词向量中\n",
      "ExTP不存在于词向量中\n",
      "letter.不存在于词向量中\n",
      "expert,不存在于词向量中\n",
      "Dominant:不存在于词向量中\n",
      "MANY不存在于词向量中\n",
      "(I'd不存在于词向量中\n",
      "Also:不存在于词向量中\n",
      "...|||A不存在于词向量中\n",
      "statements.不存在于词向量中\n",
      "Ray不存在于词向量中\n",
      "Python不存在于词向量中\n",
      "messages,不存在于词向量中\n",
      "hole.不存在于词向量中\n",
      "Oh!不存在于词向量中\n",
      "challenge,不存在于词向量中\n",
      "BA不存在于词向量中\n",
      "damn,不存在于词向量中\n",
      "existed.不存在于词向量中\n",
      "^^|||I不存在于词向量中\n",
      "Hm.不存在于词向量中\n",
      "unhealthy,不存在于词向量中\n",
      "You...|||I不存在于词向量中\n",
      "King,不存在于词向量中\n",
      "styles,不存在于词向量中\n",
      "US,不存在于词向量中\n",
      "video?不存在于词向量中\n",
      "the...|||That's不存在于词向量中\n",
      "Finnish不存在于词向量中\n",
      "type...|||I不存在于词向量中\n",
      "14.不存在于词向量中\n",
      "shower,不存在于词向量中\n",
      "Thanksgiving不存在于词向量中\n",
      "Eating不存在于词向量中\n",
      "processes.不存在于词向量中\n",
      "self-esteem.不存在于词向量中\n",
      "hospital,不存在于词向量中\n",
      "ENFP)不存在于词向量中\n",
      "date?不存在于词向量中\n",
      "a...|||That's不存在于词向量中\n",
      "poems,不存在于词向量中\n",
      "Russia不存在于词向量中\n",
      "6)不存在于词向量中\n",
      "Ni-dom不存在于词向量中\n",
      "oriented,不存在于词向量中\n",
      "want?不存在于词向量中\n",
      "street.不存在于词向量中\n",
      "Forget不存在于词向量中\n",
      "username,不存在于词向量中\n",
      "(something不存在于词向量中\n",
      "function?不存在于词向量中\n",
      "conclusion,不存在于词向量中\n",
      "physically,不存在于词向量中\n",
      "morality,不存在于词向量中\n",
      "I...|||Not不存在于词向量中\n",
      "Joy不存在于词向量中\n",
      "Boys不存在于词向量中\n",
      "board,不存在于词向量中\n",
      "seems,不存在于词向量中\n",
      "Use)不存在于词向量中\n",
      "(Si)不存在于词向量中\n",
      "desire.不存在于词向量中\n",
      "haha.|||I不存在于词向量中\n",
      "empty.不存在于词向量中\n",
      "this)不存在于词向量中\n",
      "haha|||I不存在于词向量中\n",
      "Jeff不存在于词向量中\n",
      "um,不存在于词向量中\n",
      "me...|||I'm不存在于词向量中\n",
      "side?不存在于词向量中\n",
      "brilliant,不存在于词向量中\n",
      "simply,不存在于词向量中\n",
      "how?不存在于词向量中\n",
      "you...|||You不存在于词向量中\n",
      "Gaga不存在于词向量中\n",
      "and...|||What不存在于词向量中\n",
      "guy?不存在于词向量中\n",
      "HAD不存在于词向量中\n",
      "trees,不存在于词向量中\n",
      "liked,不存在于词向量中\n",
      "...|||Just不存在于词向量中\n",
      "maturity,不存在于词向量中\n",
      "fascinating,不存在于词向量中\n",
      "hungry.不存在于词向量中\n",
      "floor,不存在于词向量中\n",
      "pants.不存在于词向量中\n",
      "Animals不存在于词向量中\n",
      "into,不存在于词向量中\n",
      "PLEASE不存在于词向量中\n",
      "blah,不存在于词向量中\n",
      "course)不存在于词向量中\n",
      "GF不存在于词向量中\n",
      "boys.不存在于词向量中\n",
      "first...|||I不存在于词向量中\n",
      "sexy,不存在于词向量中\n",
      "go...不存在于词向量中\n",
      "slow.不存在于词向量中\n",
      "Ann不存在于词向量中\n",
      "length.不存在于词向量中\n",
      "Clinton不存在于词向量中\n",
      "harsh,不存在于词向量中\n",
      "Spanish,不存在于词向量中\n",
      "jealous,不存在于词向量中\n",
      "If...|||I不存在于词向量中\n",
      "order)不存在于词向量中\n",
      "Started不存在于词向量中\n",
      "Congrats不存在于词向量中\n",
      "trolling.不存在于词向量中\n",
      "Beach不存在于词向量中\n",
      "I...|||As不存在于词向量中\n",
      "artists,不存在于词向量中\n",
      "bro,不存在于词向量中\n",
      "Attack不存在于词向量中\n",
      "nowhere,不存在于词向量中\n",
      "assessment.不存在于词向量中\n",
      "Wind不存在于词向量中\n",
      "aspect.不存在于词向量中\n",
      "aware,不存在于词向量中\n",
      "Somebody不存在于词向量中\n",
      "and...|||A不存在于词向量中\n",
      "judgement.不存在于词向量中\n",
      "2.5不存在于词向量中\n",
      "tool.不存在于词向量中\n",
      "Bipolar不存在于词向量中\n",
      "Fast不存在于词向量中\n",
      "semester.不存在于词向量中\n",
      "granted.不存在于词向量中\n",
      "Gray不存在于词向量中\n",
      "lead.不存在于词向量中\n",
      "studies,不存在于词向量中\n",
      "Korea不存在于词向量中\n",
      "acting.不存在于词向量中\n",
      "wise.不存在于词向量中\n",
      "again.|||I不存在于词向量中\n",
      "routine,不存在于词向量中\n",
      "office,不存在于词向量中\n",
      "need...|||I不存在于词向量中\n",
      "NO.不存在于词向量中\n",
      "settings.不存在于词向量中\n",
      "longer,不存在于词向量中\n",
      "ENTJ:不存在于词向量中\n",
      "coming.不存在于词向量中\n",
      "Ne-dom不存在于词向量中\n",
      "gift.不存在于词向量中\n",
      "speech,不存在于词向量中\n",
      "the...不存在于词向量中\n",
      "Happiness不存在于词向量中\n",
      "the...|||Well不存在于词向量中\n",
      "times.|||I不存在于词向量中\n",
      "Bon不存在于词向量中\n",
      "lot?不存在于词向量中\n",
      ":unsure:|||I不存在于词向量中\n",
      "(Just不存在于词向量中\n",
      "up)不存在于词向量中\n",
      "Generation不存在于词向量中\n",
      "(whether不存在于词向量中\n",
      "INxP不存在于词向量中\n",
      "scared,不存在于词向量中\n",
      "Said不存在于词向量中\n",
      "excited,不存在于词向量中\n",
      "4w3,不存在于词向量中\n",
      "socionics.不存在于词向量中\n",
      "Set不存在于词向量中\n",
      "'Yes,不存在于词向量中\n",
      "known.不存在于词向量中\n",
      "morals.不存在于词向量中\n",
      "but...|||I'm不存在于词向量中\n",
      "(2)不存在于词向量中\n",
      "didn't,不存在于词向量中\n",
      "fail.不存在于词向量中\n",
      "Community不存在于词向量中\n",
      "my...|||This不存在于词向量中\n",
      "9w8,不存在于词向量中\n",
      "sure...不存在于词向量中\n",
      "Golden不存在于词向量中\n",
      "YES.不存在于词向量中\n",
      "making.不存在于词向量中\n",
      "handle.不存在于词向量中\n",
      "solitude.不存在于词向量中\n",
      "annoyed.不存在于词向量中\n",
      "Day,不存在于词向量中\n",
      ".|||I不存在于词向量中\n",
      "machine.不存在于词向量中\n",
      "nightmare.不存在于词向量中\n",
      "serious?不存在于词向量中\n",
      "feedback,不存在于词向量中\n",
      "solution,不存在于词向量中\n",
      "now).不存在于词向量中\n",
      "Tales不存在于词向量中\n",
      "day.|||I不存在于词向量中\n",
      "if,不存在于词向量中\n",
      "Certain不存在于词向量中\n",
      "clingy.不存在于词向量中\n",
      "before...不存在于词向量中\n",
      "Pisces不存在于词向量中\n",
      "authority,不存在于词向量中\n",
      "after,不存在于词向量中\n",
      "(missing不存在于词向量中\n",
      "Combines不存在于词向量中\n",
      "chaos.不存在于词向量中\n",
      "lol..不存在于词向量中\n",
      "INTPs?不存在于词向量中\n",
      "(meaning不存在于词向量中\n",
      "mindset.不存在于词向量中\n",
      "neutral,不存在于词向量中\n",
      "reactions.不存在于词向量中\n",
      "Pop不存在于词向量中\n",
      "noticed.不存在于词向量中\n",
      "thing...|||I不存在于词向量中\n",
      "love...不存在于词向量中\n",
      "horrible,不存在于词向量中\n",
      "GOOD不存在于词向量中\n",
      "Skyrim不存在于词向量中\n",
      "films.不存在于词向量中\n",
      "musician,不存在于词向量中\n",
      "said?不存在于词向量中\n",
      "sleeping,不存在于词向量中\n",
      "crowd,不存在于词向量中\n",
      "therapy.不存在于词向量中\n",
      "him...|||I不存在于词向量中\n",
      "don't...|||I'm不存在于词向量中\n",
      "charming.不存在于词向量中\n",
      "though..不存在于词向量中\n",
      "enfp.不存在于词向量中\n",
      "below,不存在于词向量中\n",
      "sky,不存在于词向量中\n",
      "I...|||A不存在于词向量中\n",
      "feeling?不存在于词向量中\n",
      "Snape不存在于词向量中\n",
      "exhausting.不存在于词向量中\n",
      "socializing,不存在于词向量中\n",
      "INFJs!不存在于词向量中\n",
      "calm.不存在于词向量中\n",
      "away?不存在于词向量中\n",
      "talent.不存在于词向量中\n",
      "Mana不存在于词向量中\n",
      "the...|||I'd不存在于词向量中\n",
      "ugly.不存在于词向量中\n",
      "IM不存在于词向量中\n",
      "Yay!不存在于词向量中\n",
      "naive.不存在于词向量中\n",
      "does...|||I不存在于词向量中\n",
      "Visual不存在于词向量中\n",
      "instinct.不存在于词向量中\n",
      "four,不存在于词向量中\n",
      "effect,不存在于词向量中\n",
      "'too不存在于词向量中\n",
      "concrete,不存在于词向量中\n",
      "Jr.不存在于词向量中\n",
      "in...|||The不存在于词向量中\n",
      "Melancholy不存在于词向量中\n",
      "River不存在于词向量中\n",
      "balance,不存在于词向量中\n",
      "Shakespeare不存在于词向量中\n",
      "Die不存在于词向量中\n",
      "pretty...|||I不存在于词向量中\n",
      "Keeping不存在于词向量中\n",
      "reflection,不存在于词向量中\n",
      "died,不存在于词向量中\n",
      "Monster不存在于词向量中\n",
      "aspect,不存在于词向量中\n",
      "P/J不存在于词向量中\n",
      "quality,不存在于词向量中\n",
      "I...|||For不存在于词向量中\n",
      "replying.不存在于词向量中\n",
      "(while不存在于词向量中\n",
      "Prejudice不存在于词向量中\n",
      "times...不存在于词向量中\n",
      "Case不存在于词向量中\n",
      "Throw不存在于词向量中\n",
      "STILL不存在于词向量中\n",
      "Wisdom不存在于词向量中\n",
      "AWESOME不存在于词向量中\n",
      ":P|||I'm不存在于词向量中\n",
      "Native不存在于词向量中\n",
      "topics,不存在于词向量中\n",
      "are.|||I不存在于词向量中\n",
      "TJ不存在于词向量中\n",
      "suck,不存在于词向量中\n",
      "to...|||Well,不存在于词向量中\n",
      "growth.不存在于词向量中\n",
      "at?不存在于词向量中\n",
      "dates,不存在于词向量中\n",
      "alone?不存在于词向量中\n",
      "meditation,不存在于词向量中\n",
      "harmony.不存在于词向量中\n",
      "buddy,不存在于词向量中\n",
      "intimacy.不存在于词向量中\n",
      "Look,不存在于词向量中\n",
      "Chemical不存在于词向量中\n",
      "poor,不存在于词向量中\n",
      "quotes,不存在于词向量中\n",
      "Perhaps,不存在于词向量中\n",
      "bite.不存在于词向量中\n",
      "signs.不存在于词向量中\n",
      "Paper不存在于词向量中\n",
      "goes...不存在于词向量中\n",
      "Falling不存在于词向量中\n",
      "is..不存在于词向量中\n",
      "worth.不存在于词向量中\n",
      "wisdom.不存在于词向量中\n",
      "change?不存在于词向量中\n",
      "Shut不存在于词向量中\n",
      "you...|||This不存在于词向量中\n",
      "person)不存在于词向量中\n",
      "sounds.不存在于词向量中\n",
      "Excellent不存在于词向量中\n",
      "Yea不存在于词向量中\n",
      "Waiting不存在于词向量中\n",
      "Famous不存在于词向量中\n",
      "fall,不存在于词向量中\n",
      "Genesis不存在于词向量中\n",
      "Wolf不存在于词向量中\n",
      "Seven不存在于词向量中\n",
      "Asia不存在于词向量中\n",
      "literally,不存在于词向量中\n",
      "Watson不存在于词向量中\n",
      "wouldn't.不存在于词向量中\n",
      "hungry,不存在于词向量中\n",
      "Questions不存在于词向量中\n",
      "anyway...不存在于词向量中\n",
      "programming,不存在于词向量中\n",
      "ADD.不存在于词向量中\n",
      "generally.不存在于词向量中\n",
      "say...|||I不存在于词向量中\n",
      "Island不存在于词向量中\n",
      "factors.不存在于词向量中\n",
      "sight,不存在于词向量中\n",
      "Sound不存在于词向量中\n",
      "impulsive,不存在于词向量中\n",
      "tone.不存在于词向量中\n",
      "gross.不存在于词向量中\n",
      "Inception不存在于词向量中\n",
      "Happens不存在于词向量中\n",
      "dying.不存在于词向量中\n",
      "singing,不存在于词向量中\n",
      "Character不存在于词向量中\n",
      ":)|||Thanks不存在于词向量中\n",
      "clue.不存在于词向量中\n",
      "consciousness,不存在于词向量中\n",
      "Forgive不存在于词向量中\n",
      "Hugs不存在于词向量中\n",
      "Consider不存在于词向量中\n",
      "meh,不存在于词向量中\n",
      "because...不存在于词向量中\n",
      "pets.不存在于词向量中\n",
      "better...|||I不存在于词向量中\n",
      "weaknesses,不存在于词向量中\n",
      "LSD不存在于词向量中\n",
      "Tapatalk|||I'm不存在于词向量中\n",
      "wine,不存在于词向量中\n",
      "Al不存在于词向量中\n",
      "Itx92s不存在于词向量中\n",
      "IxFP不存在于词向量中\n",
      "Meh,不存在于词向量中\n",
      "s/he不存在于词向量中\n",
      "man...不存在于词向量中\n",
      "Damn,不存在于词向量中\n",
      "(Ni)不存在于词向量中\n",
      "ESFPs.不存在于词向量中\n",
      "everything?不存在于词向量中\n",
      "defensive.不存在于词向量中\n",
      "STOP不存在于词向量中\n",
      "Enfp不存在于词向量中\n",
      "social...|||I不存在于词向量中\n",
      "agnostic.不存在于词向量中\n",
      "troll.不存在于词向量中\n",
      "false.不存在于词向量中\n",
      "jeans.不存在于词向量中\n",
      "humour,不存在于词向量中\n",
      ":)|||Oh不存在于词向量中\n",
      "(That不存在于词向量中\n",
      "language?不存在于词向量中\n",
      "hero.不存在于词向量中\n",
      "ISFJ:不存在于词向量中\n",
      "topics.不存在于词向量中\n",
      "Dunno不存在于词向量中\n",
      "LOVED不存在于词向量中\n",
      "xD.不存在于词向量中\n",
      "Yep.不存在于词向量中\n",
      "chest.不存在于词向量中\n",
      "should,不存在于词向量中\n",
      "the...|||A不存在于词向量中\n",
      "Enneagram:不存在于词向量中\n",
      "find,不存在于词向量中\n",
      "YOU.不存在于词向量中\n",
      "Maria不存在于词向量中\n",
      "Interesting,不存在于词向量中\n",
      "24/7不存在于词向量中\n",
      "Dominant不存在于词向量中\n",
      "authority.不存在于词向量中\n",
      "daughter,不存在于词向量中\n",
      "large,不存在于词向量中\n",
      "Kingdom不存在于词向量中\n",
      "(according不存在于词向量中\n",
      "Jobs不存在于词向量中\n",
      "Uni不存在于词向量中\n",
      "interviews.不存在于词向量中\n",
      "options,不存在于词向量中\n",
      "expect.不存在于词向量中\n",
      "Dad's不存在于词向量中\n",
      "identity.不存在于词向量中\n",
      "Science,不存在于词向量中\n",
      "users,不存在于词向量中\n",
      "like...|||I'm不存在于词向量中\n",
      "compliments,不存在于词向量中\n",
      "Luke不存在于词向量中\n",
      "impression.不存在于词向量中\n",
      "note.不存在于词向量中\n",
      "Williams不存在于词向量中\n",
      "Andy不存在于词向量中\n",
      "them..不存在于词向量中\n",
      "give.不存在于词向量中\n",
      "consider.不存在于词向量中\n",
      "Internet.不存在于词向量中\n",
      "Finland不存在于词向量中\n",
      "etc..不存在于词向量中\n",
      "Socrates不存在于词向量中\n",
      "often?不存在于词向量中\n",
      "someday.不存在于词向量中\n",
      "12.不存在于词向量中\n",
      "Los不存在于词向量中\n",
      "Send不存在于词向量中\n",
      "stimulation.不存在于词向量中\n",
      "INFx不存在于词向量中\n",
      "confusing,不存在于词向量中\n",
      "2/3不存在于词向量中\n",
      "Page不存在于词向量中\n",
      "going...|||I不存在于词向量中\n",
      "lmao.不存在于词向量中\n",
      ":P)不存在于词向量中\n",
      "job?不存在于词向量中\n",
      "boyfriend's不存在于词向量中\n",
      "5's不存在于词向量中\n",
      "english,不存在于词向量中\n",
      "it....不存在于词向量中\n",
      "rain.不存在于词向量中\n",
      "naive,不存在于词向量中\n",
      "thing)不存在于词向量中\n",
      "choices,不存在于词向量中\n",
      "type(s)不存在于词向量中\n",
      "patient.不存在于词向量中\n",
      "She'll不存在于词向量中\n",
      "wild,不存在于词向量中\n",
      "Phlegmatic不存在于词向量中\n",
      "start?不存在于词向量中\n",
      "nose.不存在于词向量中\n",
      "Douglas不存在于词向量中\n",
      "xNFJ不存在于词向量中\n",
      "ect.不存在于词向量中\n",
      "hello,不存在于词向量中\n",
      "tall,不存在于词向量中\n",
      "as?不存在于词向量中\n",
      "Darth不存在于词向量中\n",
      "afraid.不存在于词向量中\n",
      "INFJ)不存在于词向量中\n",
      "frequently,不存在于词向量中\n",
      "book?不存在于词向量中\n",
      "Susan不存在于词向量中\n",
      "street,不存在于词向量中\n",
      "season,不存在于词向量中\n",
      "Napoleon不存在于词向量中\n",
      "understand?不存在于词向量中\n",
      "INTP!不存在于词向量中\n",
      "Past不存在于词向量中\n",
      "Allow不存在于词向量中\n",
      "2w3,不存在于词向量中\n",
      "restaurant.不存在于词向量中\n",
      "feet,不存在于词向量中\n",
      "bold.不存在于词向量中\n",
      "Health不存在于词向量中\n",
      "NTJs不存在于词向量中\n",
      "life)不存在于词向量中\n",
      "INTJ!不存在于词向量中\n",
      "differences,不存在于词向量中\n",
      "'In不存在于词向量中\n",
      "Bring不存在于词向量中\n",
      "loyalty,不存在于词向量中\n",
      "MAKE不存在于词向量中\n",
      "journey.不存在于词向量中\n",
      "sisters,不存在于词向量中\n",
      "(Which不存在于词向量中\n",
      "dates.不存在于词向量中\n",
      "characteristics.不存在于词向量中\n",
      "Jesus,不存在于词向量中\n",
      "park,不存在于词向量中\n",
      "21,不存在于词向量中\n",
      "seconds,不存在于词向量中\n",
      "wing.不存在于词向量中\n",
      "...when不存在于词向量中\n",
      "dress,不存在于词向量中\n",
      "hobbies?不存在于词向量中\n",
      "speech.不存在于词向量中\n",
      "for...'不存在于词向量中\n",
      "thread.|||I不存在于词向量中\n",
      "purposes,不存在于词向量中\n",
      "(Introverted不存在于词向量中\n",
      "INxJ不存在于词向量中\n",
      "Jason不存在于词向量中\n",
      "BUT,不存在于词向量中\n",
      "latter.不存在于词向量中\n",
      "Tapatalk|||The不存在于词向量中\n",
      "Group不存在于词向量中\n",
      "Hermione不存在于词向量中\n",
      "Wednesday不存在于词向量中\n",
      "Running不存在于词向量中\n",
      "guys...不存在于词向量中\n",
      "road.不存在于词向量中\n",
      "Job不存在于词向量中\n",
      "shower.不存在于词向量中\n",
      "vibe,不存在于词向量中\n",
      "Jung,不存在于词向量中\n",
      "Rolling不存在于词向量中\n",
      "Sky不存在于词向量中\n",
      "Fortunately,不存在于词向量中\n",
      "mature.不存在于词向量中\n",
      "and...|||Well不存在于词向量中\n",
      "13.不存在于词向量中\n",
      "picky.不存在于词向量中\n",
      "Suicide不存在于词向量中\n",
      "Pick不存在于词向量中\n",
      "painful,不存在于词向量中\n",
      "Sea不存在于词向量中\n",
      "glasses,不存在于词向量中\n",
      "to...|||i不存在于词向量中\n",
      "leave,不存在于词向量中\n",
      "Literature不存在于词向量中\n",
      "the...|||Just不存在于词向量中\n",
      "Bush不存在于词向量中\n",
      "fly,不存在于词向量中\n",
      "Wrong不存在于词向量中\n",
      "MB不存在于词向量中\n",
      "actually...|||I不存在于词向量中\n",
      "(can't不存在于词向量中\n",
      "smoke.不存在于词向量中\n",
      "States.不存在于词向量中\n",
      "'Just不存在于词向量中\n",
      "thoughts?不存在于词向量中\n",
      "Whoever不存在于词向量中\n",
      "patience.不存在于词向量中\n",
      "R.不存在于词向量中\n",
      "partners.不存在于词向量中\n",
      "race.不存在于词向量中\n",
      "Idea不存在于词向量中\n",
      "I...|||So不存在于词向量中\n",
      "Muslim不存在于词向量中\n",
      "those...|||I不存在于词向量中\n",
      "Eve不存在于词向量中\n",
      "grades,不存在于词向量中\n",
      "flow,不存在于词向量中\n",
      "happened?不存在于词向量中\n",
      "Parks不存在于词向量中\n",
      "to...|||As不存在于词向量中\n",
      "=/不存在于词向量中\n",
      "spectrum,不存在于词向量中\n",
      "clever,不存在于词向量中\n",
      "(Fe)不存在于词向量中\n",
      "how's不存在于词向量中\n",
      "clarification.不存在于词向量中\n",
      "am?不存在于词向量中\n",
      "Cafe!不存在于词向量中\n",
      "that...|||I've不存在于词向量中\n",
      "meeting,不存在于词向量中\n",
      "so...|||I'm不存在于词向量中\n",
      "intriguing.不存在于词向量中\n",
      "articles,不存在于词向量中\n",
      "pic.不存在于词向量中\n",
      "Classic不存在于词向量中\n",
      "Meet不存在于词向量中\n",
      "Rave:不存在于词向量中\n",
      "Internet,不存在于词向量中\n",
      "objective,不存在于词向量中\n",
      "Geass不存在于词向量中\n",
      "least)不存在于词向量中\n",
      "proof.不存在于词向量中\n",
      "felt.不存在于词向量中\n",
      "exciting,不存在于词向量中\n",
      "Tuesday不存在于词向量中\n",
      "child's不存在于词向量中\n",
      "Jokes不存在于词向量中\n",
      "concern.不存在于词向量中\n",
      "OCD,不存在于词向量中\n",
      "inferior,不存在于词向量中\n",
      "heh.不存在于词向量中\n",
      "changed,不存在于词向量中\n",
      "B:不存在于词向量中\n",
      "nope.不存在于词向量中\n",
      "in.|||I不存在于词向量中\n",
      "daily,不存在于词向量中\n",
      "intj,不存在于词向量中\n",
      "two...|||I不存在于词向量中\n",
      "debates,不存在于词向量中\n",
      "...|||Hello不存在于词向量中\n",
      "Auxiliary:不存在于词向量中\n",
      "-Posh不存在于词向量中\n",
      "Cowboy不存在于词向量中\n",
      "addition,不存在于词向量中\n",
      "birth.不存在于词向量中\n",
      "and...|||Oh不存在于词向量中\n",
      "Experience不存在于词向量中\n",
      "event.不存在于词向量中\n",
      "perhaps.不存在于词向量中\n",
      "cents.不存在于词向量中\n",
      "model,不存在于词向量中\n",
      "basically.不存在于词向量中\n",
      "world.|||I不存在于词向量中\n",
      "the...|||Not不存在于词向量中\n",
      "dilemma.不存在于词向量中\n",
      "care?不存在于词向量中\n",
      "Where's不存在于词向量中\n",
      "Nietzsche不存在于词向量中\n",
      "genuine.不存在于词向量中\n",
      "her.|||I不存在于词向量中\n",
      "listening.不存在于词向量中\n",
      "disaster.不存在于词向量中\n",
      "you!|||I不存在于词向量中\n",
      "dynamic.不存在于词向量中\n",
      "currently.不存在于词向量中\n",
      "in...|||My不存在于词向量中\n",
      "cheese.不存在于词向量中\n",
      "Rick不存在于词向量中\n",
      "systems.不存在于词向量中\n",
      "eggs,不存在于词向量中\n",
      "...|||That不存在于词向量中\n",
      "ENFPs?不存在于词向量中\n",
      "powerful.不存在于词向量中\n",
      "7w6.不存在于词向量中\n",
      "dying,不存在于词向量中\n",
      "Silent不存在于词向量中\n",
      "'Yeah,不存在于词向量中\n",
      "I...|||I'd不存在于词向量中\n",
      "the...|||Why不存在于词向量中\n",
      "metal.不存在于词向量中\n",
      "take,不存在于词向量中\n",
      "misunderstood,不存在于词向量中\n",
      "sensor.不存在于词向量中\n",
      "better.|||I不存在于词向量中\n",
      "beer.不存在于词向量中\n",
      "equal,不存在于词向量中\n",
      "Control不存在于词向量中\n",
      "husband's不存在于词向量中\n",
      "...|||Thank不存在于词向量中\n",
      "(INTP)不存在于词向量中\n",
      "Intelligent不存在于词向量中\n",
      "loner,不存在于词向量中\n",
      "Fe/Ti不存在于词向量中\n",
      "compliment,不存在于词向量中\n",
      "winter,不存在于词向量中\n",
      "Wondering不存在于词向量中\n",
      "occasionally,不存在于词向量中\n",
      "government.不存在于词向量中\n",
      "correlation.不存在于词向量中\n",
      "yes?不存在于词向量中\n",
      "track.不存在于词向量中\n",
      "abuse,不存在于词向量中\n",
      "enjoyable.不存在于词向量中\n",
      "PTSD不存在于词向量中\n",
      "relaxing.不存在于词向量中\n",
      "poem,不存在于词向量中\n",
      "probably,不存在于词向量中\n",
      "-I'm不存在于词向量中\n",
      "fix.不存在于词向量中\n",
      "TED不存在于词向量中\n",
      "One,不存在于词向量中\n",
      "of...|||So不存在于词向量中\n",
      "Heroes不存在于词向量中\n",
      "Empire不存在于词向量中\n",
      "a...|||In不存在于词向量中\n",
      "Count不存在于词向量中\n",
      "knowing.不存在于词向量中\n",
      "it.|||It不存在于词向量中\n",
      "I...|||Oh不存在于词向量中\n",
      "Austen不存在于词向量中\n",
      "Eyre不存在于词向量中\n",
      "Preferably不存在于词向量中\n",
      "E's不存在于词向量中\n",
      "Sanguine,不存在于词向量中\n",
      "red.不存在于词向量中\n",
      "Jesse不存在于词向量中\n",
      "I...|||That's不存在于词向量中\n",
      "Me?不存在于词向量中\n",
      ":3|||I不存在于词向量中\n",
      "(INFP)不存在于词向量中\n",
      "insecurities.不存在于词向量中\n",
      "and...|||So不存在于词向量中\n",
      "specifically.不存在于词向量中\n",
      "knew.不存在于词向量中\n",
      "Originally不存在于词向量中\n",
      "wants,不存在于词向量中\n",
      "cancer.不存在于词向量中\n",
      "Travel不存在于词向量中\n",
      "experienced.不存在于词向量中\n",
      "afternoon.不存在于词向量中\n",
      "1w2,不存在于词向量中\n",
      "think.|||I不存在于词向量中\n",
      "loneliness,不存在于词向量中\n",
      "competitive,不存在于词向量中\n",
      "Won't不存在于词向量中\n",
      "circle.不存在于词向量中\n",
      "stated.不存在于词向量中\n",
      "mysterious.不存在于词向量中\n",
      "Smiths不存在于词向量中\n",
      "running.不存在于词向量中\n",
      "reference,不存在于词向量中\n",
      "dangerous.不存在于词向量中\n",
      "BEST不存在于词向量中\n",
      "sky.不存在于词向量中\n",
      "Type?不存在于词向量中\n",
      "(she's不存在于词向量中\n",
      "especially.不存在于词向量中\n",
      "active,不存在于词向量中\n",
      "judgmental,不存在于词向量中\n",
      "Average不存在于词向量中\n",
      "PEOPLE不存在于词向量中\n",
      "wrong...不存在于词向量中\n",
      "the...|||Yeah不存在于词向量中\n",
      ":)|||If不存在于词向量中\n",
      "p.s.不存在于词向量中\n",
      "procrastination.不存在于词向量中\n",
      "Shape:不存在于词向量中\n",
      "No?不存在于词向量中\n",
      "(yes不存在于词向量中\n",
      "Gold不存在于词向量中\n",
      "Creativity不存在于词向量中\n",
      "manipulative.不存在于词向量中\n",
      "Twin不存在于词向量中\n",
      "trees.不存在于词向量中\n",
      "technology,不存在于词向量中\n",
      "dick.不存在于词向量中\n",
      "Intuition:不存在于词向量中\n",
      "know.|||I不存在于词向量中\n",
      "ground,不存在于词向量中\n",
      "forum...不存在于词向量中\n",
      "Yup不存在于词向量中\n",
      "ISTJ?不存在于词向量中\n",
      "Dick不存在于词向量中\n",
      "literature.不存在于词向量中\n",
      "Cancer不存在于词向量中\n",
      "Horror不存在于词向量中\n",
      "cream,不存在于词向量中\n",
      "Currently,不存在于词向量中\n",
      "realistic.不存在于词向量中\n",
      "granted,不存在于词向量中\n",
      "girl?不存在于词向量中\n",
      "jerk,不存在于词向量中\n",
      "growth,不存在于词向量中\n",
      "Knowledge不存在于词向量中\n",
      "floor.不存在于词向量中\n",
      "freakin'不存在于词向量中\n",
      "lead,不存在于词向量中\n",
      "ENFP...不存在于词向量中\n",
      "Channel不存在于词向量中\n",
      "ABOUT不存在于词向量中\n",
      "successful.不存在于词向量中\n",
      "Scientific不存在于词向量中\n",
      "something.|||I不存在于词向量中\n",
      "path,不存在于词向量中\n",
      "range.不存在于词向量中\n",
      "Ford不存在于词向量中\n",
      "Washington不存在于词向量中\n",
      "enfp,不存在于词向量中\n",
      "motivations,不存在于词向量中\n",
      "Felt不存在于词向量中\n",
      "Buy不存在于词向量中\n",
      "men's不存在于词向量中\n",
      "cruel,不存在于词向量中\n",
      "photo,不存在于词向量中\n",
      "curse.不存在于词向量中\n",
      "Henry不存在于词向量中\n",
      "dancing,不存在于词向量中\n",
      "INFJs?不存在于词向量中\n",
      "way).不存在于词向量中\n",
      "Japan,不存在于词向量中\n",
      "(Ti)不存在于词向量中\n",
      "Zealand不存在于词向量中\n",
      "alot,不存在于词向量中\n",
      "I...|||Yeah,不存在于词向量中\n",
      "lucky,不存在于词向量中\n",
      "sing.不存在于词向量中\n",
      "IRL,不存在于词向量中\n",
      "with...'不存在于词向量中\n",
      "Ugh,不存在于词向量中\n",
      "discussions,不存在于词向量中\n",
      "ESTP:不存在于词向量中\n",
      "effective.不存在于词向量中\n",
      "Ex不存在于词向量中\n",
      "ExFP不存在于词向量中\n",
      "shape,不存在于词向量中\n",
      "8w7,不存在于词向量中\n",
      "that...|||The不存在于词向量中\n",
      "is.|||I不存在于词向量中\n",
      "4w3.不存在于词向量中\n",
      "and...|||For不存在于词向量中\n",
      "no...不存在于词向量中\n",
      "fears,不存在于词向量中\n",
      "controlling.不存在于词向量中\n",
      "are...|||You不存在于词向量中\n",
      "the...|||Thanks不存在于词向量中\n",
      "felt,不存在于词向量中\n",
      "and...|||Yes,不存在于词向量中\n",
      "Project不存在于词向量中\n",
      "Keirsey's不存在于词向量中\n",
      "'You're不存在于词向量中\n",
      "post...不存在于词向量中\n",
      "Openness:不存在于词向量中\n",
      "'you不存在于词向量中\n",
      "strength.不存在于词向量中\n",
      "entp,不存在于词向量中\n",
      "YOU!不存在于词向量中\n",
      "contrary,不存在于词向量中\n",
      "professor.不存在于词向量中\n",
      "Needs不存在于词向量中\n",
      "Complete不存在于词向量中\n",
      "Turn不存在于词向量中\n",
      "to...|||In不存在于词向量中\n",
      "3w2,不存在于词向量中\n",
      "Rand不存在于词向量中\n",
      "analogy.不存在于词向量中\n",
      "Spirited不存在于词向量中\n",
      "Myself不存在于词向量中\n",
      "Typical不存在于词向量中\n",
      "Machine不存在于词向量中\n",
      "Remember,不存在于词向量中\n",
      "equally.不存在于词向量中\n",
      "Romantic不存在于词向量中\n",
      "grow.不存在于词向量中\n",
      "apartment,不存在于词向量中\n",
      "where,不存在于词向量中\n",
      "gifts.不存在于词向量中\n",
      "i...|||i不存在于词向量中\n",
      "GREAT不存在于词向量中\n",
      "Thursday不存在于词向量中\n",
      "Intellectual不存在于词向量中\n",
      "NTJ不存在于词向量中\n",
      "(Though不存在于词向量中\n",
      "failed.不存在于词向量中\n",
      "nerd,不存在于词向量中\n",
      "Spock不存在于词向量中\n",
      "to...|||Not不存在于词向量中\n",
      "abstract,不存在于词向量中\n",
      "a...|||Thank不存在于词向量中\n",
      "moment...不存在于词向量中\n",
      "constantly,不存在于词向量中\n",
      "Sp不存在于词向量中\n",
      ":laughing:.不存在于词向量中\n",
      "that).不存在于词向量中\n",
      "frustration,不存在于词向量中\n",
      "smoking.不存在于词向量中\n",
      "Yellow不存在于词向量中\n",
      "overall.不存在于词向量中\n",
      "commitment,不存在于词向量中\n",
      "intp,不存在于词向量中\n",
      "Soon不存在于词向量中\n",
      "Dancing不存在于词向量中\n",
      "suggestion.不存在于词向量中\n",
      "games?不存在于词向量中\n",
      "(now不存在于词向量中\n",
      "where...|||I不存在于词向量中\n",
      "compassionate,不存在于词向量中\n",
      "one..不存在于词向量中\n",
      "easier,不存在于词向量中\n",
      "Child不存在于词向量中\n",
      "poll,不存在于词向量中\n",
      "ex's不存在于词向量中\n",
      "service,不存在于词向量中\n",
      "Studies不存在于词向量中\n",
      "chocolate.不存在于词向量中\n",
      "Trilogy不存在于词向量中\n",
      "Shame不存在于词向量中\n",
      "LA不存在于词向量中\n",
      "Place不存在于词向量中\n",
      "advice?不存在于词向量中\n",
      "Receiving不存在于词向量中\n",
      "fights.不存在于词向量中\n",
      "for...|||You不存在于词向量中\n",
      "INTP's,不存在于词向量中\n",
      "walking,不存在于词向量中\n",
      "evening,不存在于词向量中\n",
      "critical,不存在于词向量中\n",
      "hurts,不存在于词向量中\n",
      "ideals,不存在于词向量中\n",
      "minded.不存在于词向量中\n",
      "Glass不存在于词向量中\n",
      "Russell不存在于词向量中\n",
      "work.|||I不存在于词向量中\n",
      "popular.不存在于词向量中\n",
      "(2不存在于词向量中\n",
      "Confidence不存在于词向量中\n",
      "corner.不存在于词向量中\n",
      "Spend不存在于词向量中\n",
      "Follow不存在于词向量中\n",
      "you...|||The不存在于词向量中\n",
      "OUT不存在于词向量中\n",
      "Wall不存在于词向量中\n",
      "wasn't.不存在于词向量中\n",
      ":)|||Yes,不存在于词向量中\n",
      "badass.不存在于词向量中\n",
      "Adams不存在于词向量中\n",
      "True,不存在于词向量中\n",
      "Sleeping不存在于词向量中\n",
      "Ocean不存在于词向量中\n",
      "ESTJ?不存在于词向量中\n",
      "ah,不存在于词向量中\n",
      "ENTP)不存在于词向量中\n",
      "Process不存在于词向量中\n",
      "and...|||How不存在于词向量中\n",
      "meds.不存在于词向量中\n",
      "example)不存在于词向量中\n",
      "PerC!|||Welcome不存在于词向量中\n",
      "year...不存在于词向量中\n",
      "funny?不存在于词向量中\n",
      "share,不存在于词向量中\n",
      "camera.不存在于词向量中\n",
      "cook,不存在于词向量中\n",
      "heaven,不存在于词向量中\n",
      "Earl不存在于词向量中\n",
      "So/Sp不存在于词向量中\n",
      "not.|||I不存在于词向量中\n",
      "sigh.不存在于词向量中\n",
      "focused.不存在于词向量中\n",
      "taken,不存在于词向量中\n",
      "Ha不存在于词向量中\n",
      "of...|||Yeah,不存在于词向量中\n",
      "vague.不存在于词向量中\n",
      "Sign不存在于词向量中\n",
      "animal,不存在于词向量中\n",
      "chill.不存在于词向量中\n",
      ":)|||Hello不存在于词向量中\n",
      "FEEL不存在于词向量中\n",
      "identity,不存在于词向量中\n",
      "Quick不存在于词向量中\n",
      "do..不存在于词向量中\n",
      "become.不存在于词向量中\n",
      "slowly.不存在于词向量中\n",
      "certain,不存在于词向量中\n",
      "12,不存在于词向量中\n",
      "warm.不存在于词向量中\n",
      "turn,不存在于词向量中\n",
      "Become不存在于词向量中\n",
      "Nothing.不存在于词向量中\n",
      "Nowadays不存在于词向量中\n",
      "hi.不存在于词向量中\n",
      "player,不存在于词向量中\n",
      "relative.不存在于词向量中\n",
      "sides,不存在于词向量中\n",
      "dreaming.不存在于词向量中\n",
      "favorites,不存在于词向量中\n",
      "ISFJ?不存在于词向量中\n",
      "Completely不存在于词向量中\n",
      ":D|||You不存在于词向量中\n",
      ":)|||It不存在于词向量中\n",
      "DNA不存在于词向量中\n",
      "Walt不存在于词向量中\n",
      "Zombie不存在于词向量中\n",
      "Civil不存在于词向量中\n",
      "reasoning,不存在于词向量中\n",
      "woman's不存在于词向量中\n",
      "Anthony不存在于词向量中\n",
      "Bowie不存在于词向量中\n",
      "Northern不存在于词向量中\n",
      "wanted,不存在于词向量中\n",
      "INFP.|||I不存在于词向量中\n",
      "disappointed.不存在于词向量中\n",
      "concerned.不存在于词向量中\n",
      "IT,不存在于词向量中\n",
      "(other不存在于词向量中\n",
      "(ENFP)不存在于词向量中\n",
      "fun?不存在于词向量中\n",
      "daughter.不存在于词向量中\n",
      ").不存在于词向量中\n",
      "Losing不存在于词向量中\n",
      "ladies.不存在于词向量中\n",
      "photos.不存在于词向量中\n",
      "Public不存在于词向量中\n",
      "Evangelion不存在于词向量中\n",
      "Answer不存在于词向量中\n",
      "Jean不存在于词向量中\n",
      "to...|||Just不存在于词向量中\n",
      "c)不存在于词向量中\n",
      "'Do不存在于词向量中\n",
      "so..不存在于词向量中\n",
      "ExFJ不存在于词向量中\n",
      "Leaning不存在于词向量中\n",
      "Friendship不存在于词向量中\n",
      "(Although不存在于词向量中\n",
      "UK.不存在于词向量中\n",
      "still...|||I不存在于词向量中\n",
      "fuck,不存在于词向量中\n",
      "Joseph不存在于词向量中\n",
      "...|||Oh不存在于词向量中\n",
      "SUPER不存在于词向量中\n",
      "IMO,不存在于词向量中\n",
      "ages,不存在于词向量中\n",
      "active.不存在于词向量中\n",
      "desires.不存在于词向量中\n",
      "rich.不存在于词向量中\n",
      "Note:不存在于词向量中\n",
      "quick,不存在于词向量中\n",
      "Castle不存在于词向量中\n",
      "good...不存在于词向量中\n",
      "private,不存在于词向量中\n",
      "Earth,不存在于词向量中\n",
      "DC不存在于词向量中\n",
      "shop.不存在于词向量中\n",
      "without...|||I不存在于词向量中\n",
      "Clockwork不存在于词向量中\n",
      "Move不存在于词向量中\n",
      "meditation.不存在于词向量中\n",
      "Flying不存在于词向量中\n",
      "harsh.不存在于词向量中\n",
      "Donnie不存在于词向量中\n",
      "impossible,不存在于词向量中\n",
      "Calling不存在于词向量中\n",
      "I...|||In不存在于词向量中\n",
      "joking,不存在于词向量中\n",
      "bit...不存在于词向量中\n",
      "accident.不存在于词向量中\n",
      "imagine.不存在于词向量中\n",
      "Correct不存在于词向量中\n",
      "clubs,不存在于词向量中\n",
      "different?不存在于词向量中\n",
      "milk.不存在于词向量中\n",
      "about...|||I'm不存在于词向量中\n",
      "four.不存在于词向量中\n",
      "design.不存在于词向量中\n",
      "work)不存在于词向量中\n",
      ":/|||I不存在于词向量中\n",
      "Spotless不存在于词向量中\n",
      "right...|||I不存在于词向量中\n",
      "pace.不存在于词向量中\n",
      "IxFJ不存在于词向量中\n",
      "Audrey不存在于词向量中\n",
      "Stewart不存在于词向量中\n",
      "with)不存在于词向量中\n",
      "Fairy不存在于词向量中\n",
      "survive.不存在于词向量中\n",
      "think).不存在于词向量中\n",
      "why...|||I不存在于词向量中\n",
      "Fi/Te不存在于词向量中\n",
      "of...|||That不存在于词向量中\n",
      "Stalin不存在于词向量中\n",
      "ultimately,不存在于词向量中\n",
      "responsibility.不存在于词向量中\n",
      "Chicken不存在于词向量中\n",
      "to...|||A不存在于词向量中\n",
      "am...不存在于词向量中\n",
      "period,不存在于词向量中\n",
      "mysterious,不存在于词向量中\n",
      "shopping,不存在于词向量中\n",
      "messy,不存在于词向量中\n",
      "changes,不存在于词向量中\n",
      "each.不存在于词向量中\n",
      "Granted不存在于词向量中\n",
      "slowly,不存在于词向量中\n",
      "Drunk不存在于词向量中\n",
      "teens.不存在于词向量中\n",
      "thinkers,不存在于词向量中\n",
      "therapy,不存在于词向量中\n",
      "IQ.不存在于词向量中\n",
      "can't,不存在于词向量中\n",
      "not...|||My不存在于词向量中\n",
      "MOST不存在于词向量中\n",
      "SAME不存在于词向量中\n",
      "sign.不存在于词向量中\n",
      "vibes.不存在于词向量中\n",
      ":)|||Well不存在于词向量中\n",
      "Vegas不存在于词向量中\n",
      "IQ,不存在于词向量中\n",
      "Throughout不存在于词向量中\n",
      "a...|||It's不存在于词向量中\n",
      "?|||I不存在于词向量中\n",
      "journal.不存在于词向量中\n",
      "part?不存在于词向量中\n",
      "true?不存在于词向量中\n",
      "content,不存在于词向量中\n",
      "it.|||You不存在于词向量中\n",
      "set.不存在于词向量中\n",
      "wondering.不存在于词向量中\n",
      "I...|||Hey不存在于词向量中\n",
      "Souls不存在于词向量中\n",
      "creatures.不存在于词向量中\n",
      "LOL,不存在于词向量中\n",
      "Sense不存在于词向量中\n",
      "in...|||It不存在于词向量中\n",
      "Terry不存在于词向量中\n",
      "Tertiary:不存在于词向量中\n",
      "answer?不存在于词向量中\n",
      "ISFP:不存在于词向量中\n",
      "Music,不存在于词向量中\n",
      "quite...|||I不存在于词向量中\n",
      "task.不存在于词向量中\n",
      "nerves.不存在于词向量中\n",
      "Few不存在于词向量中\n",
      "heaven.不存在于词向量中\n",
      "little...|||I不存在于词向量中\n",
      "Brave不存在于词向量中\n",
      "Wizard不存在于词向量中\n",
      "23,不存在于词向量中\n",
      ":happy:.不存在于词向量中\n",
      "(im不存在于词向量中\n",
      "energetic,不存在于词向量中\n",
      "System不存在于词向量中\n",
      "Stars不存在于词向量中\n",
      "American,不存在于词向量中\n",
      "ignorant,不存在于词向量中\n",
      "Goes不存在于词向量中\n",
      "directions.不存在于词向量中\n",
      "suicidal,不存在于词向量中\n",
      "cycle.不存在于词向量中\n",
      "words...不存在于词向量中\n",
      "clouds.不存在于词向量中\n",
      "President不存在于词向量中\n",
      "illness.不存在于词向量中\n",
      "HAPPY不存在于词向量中\n",
      "studies.不存在于词向量中\n",
      "Date不存在于词向量中\n",
      "Gone不存在于词向量中\n",
      "xD)不存在于词向量中\n",
      "extreme,不存在于词向量中\n",
      "Truly不存在于词向量中\n",
      "variety.不存在于词向量中\n",
      "harder.不存在于词向量中\n",
      "anything...不存在于词向量中\n",
      "(is不存在于词向量中\n",
      "anymore...不存在于词向量中\n",
      "anyway).不存在于词向量中\n",
      "classical,不存在于词向量中\n",
      "Sitting不存在于词向量中\n",
      "empty,不存在于词向量中\n",
      "everybody's不存在于词向量中\n",
      "(P)不存在于词向量中\n",
      "folks,不存在于词向量中\n",
      "Mrs.不存在于词向量中\n",
      "perhaps?不存在于词向量中\n",
      "ESFJs.不存在于词向量中\n",
      "frustrating,不存在于词向量中\n",
      "Multiple不存在于词向量中\n",
      "(pretty不存在于词向量中\n",
      "paragraph.不存在于词向量中\n",
      "Luther不存在于词向量中\n",
      "Warning:不存在于词向量中\n",
      "opposites.不存在于词向量中\n",
      "starters,不存在于词向量中\n",
      ":)|||That不存在于词向量中\n",
      "buddy.不存在于词向量中\n",
      "Day.不存在于词向量中\n",
      "arts.不存在于词向量中\n",
      "Hearing不存在于词向量中\n",
      "biased,不存在于词向量中\n",
      "STEM不存在于词向量中\n",
      "Gods不存在于词向量中\n",
      "Manson不存在于词向量中\n",
      "ADD,不存在于词向量中\n",
      "Tool不存在于词向量中\n",
      "schedule,不存在于词向量中\n",
      "you...|||It不存在于词向量中\n",
      "disorders.不存在于词向量中\n",
      "sign,不存在于词向量中\n",
      "pic,不存在于词向量中\n",
      "gold.不存在于词向量中\n",
      "themselves?不存在于词向量中\n",
      "chaos,不存在于词向量中\n",
      "Leonard不存在于词向量中\n",
      "Melancholy,不存在于词向量中\n",
      "O.O不存在于词向量中\n",
      "experience?不存在于词向量中\n",
      "Movie不存在于词向量中\n",
      "female)不存在于词向量中\n",
      "you're...|||I不存在于词向量中\n",
      "faster.不存在于词向量中\n",
      "Chocolate不存在于词向量中\n",
      "individuals,不存在于词向量中\n",
      "Agnostic不存在于词向量中\n",
      "Jimmy不存在于词向量中\n",
      "Web不存在于词向量中\n",
      ":-P不存在于词向量中\n",
      "Sagittarius不存在于词向量中\n",
      "USA.不存在于词向量中\n",
      "I...|||Hi不存在于词向量中\n",
      "Tomorrow不存在于词向量中\n",
      "...|||In不存在于词向量中\n",
      "desk,不存在于词向量中\n",
      "flowers,不存在于词向量中\n",
      "Edit不存在于词向量中\n",
      "few...|||I不存在于词向量中\n",
      "Hoping不存在于词向量中\n",
      "you'不存在于词向量中\n",
      "AN不存在于词向量中\n",
      "middle,不存在于词向量中\n",
      "ACTUALLY不存在于词向量中\n",
      "them),不存在于词向量中\n",
      "done?不存在于词向量中\n",
      "comfort,不存在于词向量中\n",
      "23.不存在于词向量中\n",
      "D&D不存在于词向量中\n",
      "We...|||I不存在于词向量中\n",
      "Isaac不存在于词向量中\n",
      "frustration.不存在于词向量中\n",
      "and...|||Thanks不存在于词向量中\n",
      "Elsa不存在于词向量中\n",
      "internally.不存在于词向量中\n",
      "Sometimes.不存在于词向量中\n",
      "(neutral)不存在于词向量中\n",
      "sugar.不存在于词向量中\n",
      "Choose不存在于词向量中\n",
      "SFJ不存在于词向量中\n",
      "disgusting.不存在于词向量中\n",
      "didn't...|||I不存在于词向量中\n",
      "it...|||My不存在于词向量中\n",
      "skill.不存在于词向量中\n",
      "Aw不存在于词向量中\n",
      "Emotionally不存在于词向量中\n",
      "Lights不存在于词向量中\n",
      "Goku不存在于词向量中\n",
      "He'd不存在于词向量中\n",
      "Fi-doms不存在于词向量中\n",
      "driven,不存在于词向量中\n",
      "beings,不存在于词向量中\n",
      "full.不存在于词向量中\n",
      "obnoxious,不存在于词向量中\n",
      "connections.不存在于词向量中\n",
      "idiot,不存在于词向量中\n",
      "Normal不存在于词向量中\n",
      "Drive不存在于词向量中\n",
      "Nintendo不存在于词向量中\n",
      "Dumbledore不存在于词向量中\n",
      "INFPs!不存在于词向量中\n",
      "flawed,不存在于词向量中\n",
      "consequences.不存在于词向量中\n",
      "enfp's不存在于词向量中\n",
      "Land不存在于词向量中\n",
      "pool,不存在于词向量中\n",
      "Feeling:不存在于词向量中\n",
      "Depp不存在于词向量中\n",
      "embarrassed.不存在于词向量中\n",
      "notice,不存在于词向量中\n",
      "guys'不存在于词向量中\n",
      "Thankfully不存在于词向量中\n",
      "somebody.不存在于词向量中\n",
      "Rising不存在于词向量中\n",
      "ESTP?不存在于词向量中\n",
      "(He不存在于词向量中\n",
      "you|||I不存在于词向量中\n",
      "'That's不存在于词向量中\n",
      "all).不存在于词向量中\n",
      "Communication不存在于词向量中\n",
      "it...|||You不存在于词向量中\n",
      "Spain不存在于词向量中\n",
      "Like...不存在于词向量中\n",
      "aren't.不存在于词向量中\n",
      "risk.不存在于词向量中\n",
      "troll,不存在于词向量中\n",
      "green.不存在于词向量中\n",
      "violence,不存在于词向量中\n",
      "that...|||What不存在于词向量中\n",
      "Steam不存在于词向量中\n",
      "Anonymous,不存在于词向量中\n",
      "which...|||I不存在于词向量中\n",
      "should...|||I不存在于词向量中\n",
      "Lazy不存在于词向量中\n",
      "t-shirt,不存在于词向量中\n",
      "everyone...不存在于词向量中\n",
      "fat,不存在于词向量中\n",
      "Marry:不存在于词向量中\n",
      "Bed:不存在于词向量中\n",
      "that's...|||I不存在于词向量中\n",
      "intj.不存在于词向量中\n",
      "SJs,不存在于词向量中\n",
      "hmm,不存在于词向量中\n",
      "Series不存在于词向量中\n",
      "training,不存在于词向量中\n",
      "available.不存在于词向量中\n",
      "a...|||Thanks不存在于词向量中\n",
      "got.不存在于词向量中\n",
      "code.不存在于词向量中\n",
      "Zodiac不存在于词向量中\n",
      "ENFPs!不存在于词向量中\n",
      "team,不存在于词向量中\n",
      "ears.不存在于词向量中\n",
      "altogether.不存在于词向量中\n",
      "fantastic,不存在于词向量中\n",
      "PC,不存在于词向量中\n",
      "pets,不存在于词向量中\n",
      "weakness,不存在于词向量中\n",
      "bet.不存在于词向量中\n",
      "therefore,不存在于词向量中\n",
      "lord,不存在于词向量中\n",
      "morality.不存在于词向量中\n",
      "ago)不存在于词向量中\n",
      "everything's不存在于词向量中\n",
      "it's...|||I'm不存在于词向量中\n",
      "means?不存在于词向量中\n",
      "changing,不存在于词向量中\n",
      "Spirit不存在于词向量中\n",
      "...|||Hey不存在于词向量中\n",
      "Jewish不存在于词向量中\n",
      "shallow.不存在于词向量中\n",
      "esteem.不存在于词向量中\n",
      "(too不存在于词向量中\n",
      "Annie不存在于词向量中\n",
      "of...|||Yes,不存在于词向量中\n",
      "characters?不存在于词向量中\n",
      "planning,不存在于词向量中\n",
      "perfectly,不存在于词向量中\n",
      "gym,不存在于词向量中\n",
      "Above不存在于词向量中\n",
      "woods.不存在于词向量中\n",
      "talk?不存在于词向量中\n",
      "friends.|||I不存在于词向量中\n",
      "admit.不存在于词向量中\n",
      "thinkers.不存在于词向量中\n",
      "I...|||How不存在于词向量中\n",
      "ones)不存在于词向量中\n",
      "ESFJ:不存在于词向量中\n",
      "Subtype不存在于词向量中\n",
      "insightful,不存在于词向量中\n",
      "Fellow不存在于词向量中\n",
      "masculine.不存在于词向量中\n",
      "theirs.不存在于词向量中\n",
      "breakfast.不存在于词向量中\n",
      "spot,不存在于词向量中\n",
      "responsible,不存在于词向量中\n",
      "sites.不存在于词向量中\n",
      "rough.不存在于词向量中\n",
      "bf.不存在于词向量中\n",
      "subjects,不存在于词向量中\n",
      "PC.不存在于词向量中\n",
      "mistaken.不存在于词向量中\n",
      "calls,不存在于词向量中\n",
      "between,不存在于词向量中\n",
      "feelers,不存在于词向量中\n",
      "beach,不存在于词向量中\n",
      "Example不存在于词向量中\n",
      "India不存在于词向量中\n",
      "location,不存在于词向量中\n",
      "drinking,不存在于词向量中\n",
      "Bit不存在于词向量中\n",
      "SP,不存在于词向量中\n",
      "aware.不存在于词向量中\n",
      "7)不存在于词向量中\n",
      "Thoughts不存在于词向量中\n",
      "interpretation.不存在于词向量中\n",
      "gym.不存在于词向量中\n",
      "(whatever不存在于词向量中\n",
      "that...|||If不存在于词向量中\n",
      "better...不存在于词向量中\n",
      "person...不存在于词向量中\n",
      "draining.不存在于词向量中\n",
      "cars.不存在于词向量中\n",
      "optimistic,不存在于词向量中\n",
      "decide.不存在于词向量中\n",
      "wisdom,不存在于词向量中\n",
      "moody,不存在于词向量中\n",
      "swimming,不存在于词向量中\n",
      "accent.不存在于词向量中\n",
      "mentality.不存在于词向量中\n",
      "Florence不存在于词向量中\n",
      "worlds,不存在于词向量中\n",
      "(often不存在于词向量中\n",
      "Portrait不存在于词向量中\n",
      "complete.不存在于词向量中\n",
      "I鈥檒l不存在于词向量中\n",
      "Sigur不存在于词向量中\n",
      "force,不存在于词向量中\n",
      "developed,不存在于词向量中\n",
      "rant.不存在于词向量中\n",
      "spiritual,不存在于词向量中\n",
      "as...|||I'm不存在于词向量中\n",
      "Religious不存在于词向量中\n",
      "Lance不存在于词向量中\n",
      "(insert不存在于词向量中\n",
      "jazz,不存在于词向量中\n",
      "Because,不存在于词向量中\n",
      "instead?不存在于词向量中\n",
      "or...|||My不存在于词向量中\n",
      "types)不存在于词向量中\n",
      "intimidating,不存在于词向量中\n",
      "and...|||I'd不存在于词向量中\n",
      "Technology不存在于词向量中\n",
      "Wiki不存在于词向量中\n",
      "(never不存在于词向量中\n",
      "listener,不存在于词向量中\n",
      "expressions,不存在于词向量中\n",
      "1/4不存在于词向量中\n",
      "youtube.不存在于词向量中\n",
      "relax.不存在于词向量中\n",
      "astrology,不存在于词向量中\n",
      "real?不存在于词向量中\n",
      "occasions,不存在于词向量中\n",
      "button.不存在于词向量中\n",
      "Dean不存在于词向量中\n",
      "silence,不存在于词向量中\n",
      "elsewhere.不存在于词向量中\n",
      "return,不存在于词向量中\n",
      "truth?不存在于词向量中\n",
      "(ISFJ)不存在于词向量中\n",
      "ME.不存在于词向量中\n",
      "liberal.不存在于词向量中\n",
      "Kanye不存在于词向量中\n",
      "poem.不存在于词向量中\n",
      "Slytherin,不存在于词向量中\n",
      "acceptable.不存在于词向量中\n",
      "of...|||I've不存在于词向量中\n",
      "task,不存在于词向量中\n",
      "International不存在于词向量中\n",
      "set,不存在于词向量中\n",
      "Africa不存在于词向量中\n",
      "upon.不存在于词向量中\n",
      "call,不存在于词向量中\n",
      "lunch.不存在于词向量中\n",
      "pizza,不存在于词向量中\n",
      "NO!不存在于词向量中\n",
      "reserved.不存在于词向量中\n",
      "diet.不存在于词向量中\n",
      "moon.不存在于词向量中\n",
      "Ms.不存在于词向量中\n",
      "innocent.不存在于词向量中\n",
      "afraid,不存在于词向量中\n",
      "Josh不存在于词向量中\n",
      "post.|||I不存在于词向量中\n",
      "not...'不存在于词向量中\n",
      "cares.不存在于词向量中\n",
      "mystery.不存在于词向量中\n",
      "France,不存在于词向量中\n",
      "cookies.不存在于词向量中\n",
      "independence.不存在于词向量中\n",
      "breakfast,不存在于词向量中\n",
      "it'不存在于词向量中\n",
      "sources.不存在于词向量中\n",
      "true.|||I不存在于词向量中\n",
      "Vivid不存在于词向量中\n",
      "and...|||Hi不存在于词向量中\n",
      "explode.不存在于词向量中\n",
      "a...|||Yes,不存在于词向量中\n",
      "essence,不存在于词向量中\n",
      "Specifically,不存在于词向量中\n",
      "boat,不存在于词向量中\n",
      "Choleric,不存在于词向量中\n",
      "have...不存在于词向量中\n",
      "my...|||When不存在于词向量中\n",
      "to...|||I'd不存在于词向量中\n",
      "impressed.不存在于词向量中\n",
      "chat.不存在于词向量中\n",
      "5.)不存在于词向量中\n",
      "damn.不存在于词向量中\n",
      "that?|||I不存在于词向量中\n",
      "Starbucks不存在于词向量中\n",
      "(Sorry不存在于词向量中\n",
      "it.|||I've不存在于词向量中\n",
      "Putting不存在于词向量中\n",
      "Waking不存在于词向量中\n",
      "Radio不存在于词向量中\n",
      "the...|||For不存在于词向量中\n",
      "afterwards,不存在于词向量中\n",
      "so.|||I不存在于词向量中\n",
      "conservative,不存在于词向量中\n",
      "objective.不存在于词向量中\n",
      "this...|||I'm不存在于词向量中\n",
      "Bronte不存在于词向量中\n",
      "cafe,不存在于词向量中\n",
      "Stick不存在于词向量中\n",
      "every...|||I不存在于词向量中\n",
      "French.不存在于词向量中\n",
      "mechanism.不存在于词向量中\n",
      "haha...不存在于词向量中\n",
      "planning.不存在于词向量中\n",
      "makeup,不存在于词向量中\n",
      "me...I不存在于词向量中\n",
      "might...|||I不存在于词向量中\n",
      "movie?不存在于词向量中\n",
      "die?不存在于词向量中\n",
      "February不存在于词向量中\n",
      "Compared不存在于词向量中\n",
      "expected,不存在于词向量中\n",
      "nature?不存在于词向量中\n",
      "skill,不存在于词向量中\n",
      "(good不存在于词向量中\n",
      "to...|||Yes,不存在于词向量中\n",
      "sorts.不存在于词向量中\n",
      "you).不存在于词向量中\n",
      "'good'不存在于词向量中\n",
      "advantage.不存在于词向量中\n",
      "(INFJ)不存在于词向量中\n",
      "another's不存在于词向量中\n",
      "(possibly不存在于词向量中\n",
      "yours?不存在于词向量中\n",
      "Funny,不存在于词向量中\n",
      "do...|||I'm不存在于词向量中\n",
      "overwhelming,不存在于词向量中\n",
      "Howard不存在于词向量中\n",
      "ages.不存在于词向量中\n",
      "bag,不存在于词向量中\n",
      "stars,不存在于词向量中\n",
      "stomach.不存在于词向量中\n",
      "animal.不存在于词向量中\n",
      "motives.不存在于词向量中\n",
      "blood,不存在于词向量中\n",
      "instance.不存在于词向量中\n",
      "big.不存在于词向量中\n",
      "chance?不存在于词向量中\n",
      "Jones不存在于词向量中\n",
      "a...|||1.不存在于词向量中\n",
      "age?不存在于词向量中\n",
      "wear.不存在于词向量中\n",
      "smiling,不存在于词向量中\n",
      "Nonetheless,不存在于词向量中\n",
      "INTJ)不存在于词向量中\n",
      "Police不存在于词向量中\n",
      "album,不存在于词向量中\n",
      "greatly.不存在于词向量中\n",
      "Apologies不存在于词向量中\n",
      "BPD不存在于词向量中\n",
      "someday,不存在于词向量中\n",
      "character's不存在于词向量中\n",
      "SAT不存在于词向量中\n",
      "quit.不存在于词向量中\n",
      "(besides不存在于词向量中\n",
      "bike,不存在于词向量中\n",
      "update.不存在于词向量中\n",
      "Share不存在于词向量中\n",
      "trip,不存在于词向量中\n",
      "blood.不存在于词向量中\n",
      "<-不存在于词向量中\n",
      "sure.|||I不存在于词向量中\n",
      "controlling,不存在于词向量中\n",
      "UK,不存在于词向量中\n",
      "must've不存在于词向量中\n",
      "now...|||I不存在于词向量中\n",
      "German.不存在于词向量中\n",
      "Jedi不存在于词向量中\n",
      "(people不存在于词向量中\n",
      "suicide,不存在于词向量中\n",
      "right?|||I不存在于词向量中\n",
      "mind's不存在于词向量中\n",
      "end?不存在于词向量中\n",
      "Master's不存在于词向量中\n",
      "aloof,不存在于词向量中\n",
      "sometimes.|||I不存在于词向量中\n",
      "Wonderful不存在于词向量中\n",
      "Than不存在于词向量中\n",
      "Meeting不存在于词向量中\n",
      "TIME不存在于词向量中\n",
      "assholes.不存在于词向量中\n",
      "FJ不存在于词向量中\n",
      "Austin不存在于词向量中\n",
      "Guardian不存在于词向量中\n",
      "STJ不存在于词向量中\n",
      "bands,不存在于词向量中\n",
      "NFPs不存在于词向量中\n",
      ")|||I不存在于词向量中\n",
      "(albeit不存在于词向量中\n",
      "addiction,不存在于词向量中\n",
      "(non-autistic)不存在于词向量中\n",
      "examples,不存在于词向量中\n",
      "Darko不存在于词向量中\n",
      "schools,不存在于词向量中\n",
      "english.不存在于词向量中\n",
      "technology.不存在于词向量中\n",
      "ENxP不存在于词向量中\n",
      "Seeker不存在于词向量中\n",
      "fish,不存在于词向量中\n",
      "found,不存在于词向量中\n",
      "flaws,不存在于词向量中\n",
      "(I'll不存在于词向量中\n",
      "Atlas不存在于词向量中\n",
      "I...|||Do不存在于词向量中\n",
      "Lyrics不存在于词向量中\n",
      "Breakfast不存在于词向量中\n",
      "Fi)不存在于词向量中\n",
      "Owl不存在于词向量中\n",
      "personal...|||I不存在于词向量中\n",
      "Wilson不存在于词向量中\n",
      "pieces,不存在于词向量中\n",
      "haven't,不存在于词向量中\n",
      "EVERYONE不存在于词向量中\n",
      "I'll...|||I不存在于词向量中\n",
      "time).不存在于词向量中\n",
      "to...|||1.不存在于词向量中\n",
      "Anyhow,不存在于词向量中\n",
      "(kind不存在于词向量中\n",
      "Eric不存在于词向量中\n",
      "Marvel不存在于词向量中\n",
      "Cheers不存在于词向量中\n",
      "Warcraft不存在于词向量中\n",
      "overwhelming.不存在于词向量中\n",
      "5w6.不存在于词向量中\n",
      "Ha!不存在于词向量中\n",
      "suffering,不存在于词向量中\n",
      "OK.不存在于词向量中\n",
      "kids?不存在于词向量中\n",
      "communicate,不存在于词向量中\n",
      "sociable,不存在于词向量中\n",
      "military.不存在于词向量中\n",
      "knows?不存在于词向量中\n",
      "ExxP不存在于词向量中\n",
      "peers,不存在于词向量中\n",
      "conclusions,不存在于词向量中\n",
      "Sp/Sx不存在于词向量中\n",
      "shame,不存在于词向量中\n",
      "Buffy不存在于词向量中\n",
      "^_^|||I不存在于词向量中\n",
      "forget,不存在于词向量中\n",
      "perfection.不存在于词向量中\n",
      "Ian不存在于词向量中\n",
      "me.'不存在于词向量中\n",
      "...|||You're不存在于词向量中\n",
      "even,不存在于词向量中\n",
      "fat.不存在于词向量中\n",
      "cooking.不存在于词向量中\n",
      "Curious不存在于词向量中\n",
      "Birthday不存在于词向量中\n",
      "else...不存在于词向量中\n",
      "loyal.不存在于词向量中\n",
      "Alexander不存在于词向量中\n",
      "typology.不存在于词向量中\n",
      "Gen不存在于词向量中\n",
      "Phantom不存在于词向量中\n",
      "Hobbit不存在于词向量中\n",
      "Research不存在于词向量中\n",
      "LIFE不存在于词向量中\n",
      "EXACT不存在于词向量中\n",
      "!|||I不存在于词向量中\n",
      "Earth.不存在于词向量中\n",
      "feeling...|||I不存在于词向量中\n",
      "semester,不存在于词向量中\n",
      "Cobain不存在于词向量中\n",
      "3w4,不存在于词向量中\n",
      "students,不存在于词向量中\n",
      "List不存在于词向量中\n",
      "force.不存在于词向量中\n",
      "Sp/So不存在于词向量中\n",
      "So.不存在于词向量中\n",
      "Ayn不存在于词向量中\n",
      "secret.不存在于词向量中\n",
      "posting,不存在于词向量中\n",
      "Hahaha.不存在于词向量中\n",
      "the...|||In不存在于词向量中\n",
      "ego,不存在于词向量中\n",
      "salt.不存在于词向量中\n",
      "info,不存在于词向量中\n",
      "agreed.不存在于词向量中\n",
      "Memory不存在于词向量中\n",
      "Create不存在于词向量中\n",
      "insights,不存在于词向量中\n",
      "SJ.不存在于词向量中\n",
      "overwhelmed.不存在于词向量中\n",
      "tried,不存在于词向量中\n",
      "Common不存在于词向量中\n",
      "Cognition不存在于词向量中\n",
      "Ireland不存在于词向量中\n",
      "nowadays,不存在于词向量中\n",
      "Agree不存在于词向量中\n",
      "Telling不存在于词向量中\n",
      "Malcolm不存在于词向量中\n",
      "Healthy不存在于词向量中\n",
      "robot.不存在于词向量中\n",
      "mutual.不存在于词向量中\n",
      "xoxo,不存在于词向量中\n",
      "conversation?不存在于词向量中\n",
      "Norway不存在于词向量中\n",
      "Legends不存在于词向量中\n",
      "Ninja不存在于词向量中\n",
      "Fi-Si不存在于词向量中\n",
      "latter,不存在于词向量中\n",
      ":dry:|||I不存在于词向量中\n",
      "of...|||Thanks不存在于词向量中\n",
      "although,不存在于词向量中\n",
      "ENTP!不存在于词向量中\n",
      "strongly.不存在于词向量中\n",
      ":tongue:.不存在于词向量中\n",
      "is),不存在于词向量中\n",
      "mix,不存在于词向量中\n",
      "felt...|||I不存在于词向量中\n",
      "families.不存在于词向量中\n",
      "art?不存在于词向量中\n",
      "Bernie不存在于词向量中\n",
      "withdrawn,不存在于词向量中\n",
      ":happy:|||I'm不存在于词向量中\n",
      "Style不存在于词向量中\n",
      "styles.不存在于词向量中\n",
      "(first不存在于词向量中\n",
      "while...不存在于词向量中\n",
      "refreshing.不存在于词向量中\n",
      "POV不存在于词向量中\n",
      "good.|||I不存在于词向量中\n",
      "ocean,不存在于词向量中\n",
      "Flash不存在于词向量中\n",
      "xP不存在于词向量中\n",
      "FWB不存在于词向量中\n",
      "year)不存在于词向量中\n",
      "romantically.不存在于词向量中\n",
      "entirely,不存在于词向量中\n",
      "Syndrome不存在于词向量中\n",
      "playing,不存在于词向量中\n",
      "hi,不存在于词向量中\n",
      "entertainment,不存在于词向量中\n",
      "Jennifer不存在于词向量中\n",
      "sure)不存在于词向量中\n",
      "Spencer不存在于词向量中\n",
      "Join不存在于词向量中\n",
      "actually...不存在于词向量中\n",
      "trolling,不存在于词向量中\n",
      "Typing不存在于词向量中\n",
      "alas,不存在于词向量中\n",
      "(J)不存在于词向量中\n",
      "novel.不存在于词向量中\n",
      "innocent,不存在于词向量中\n",
      "Mean不存在于词向量中\n",
      "party?不存在于词向量中\n",
      "bass,不存在于词向量中\n",
      "attack,不存在于词向量中\n",
      "Moreover,不存在于词向量中\n",
      "Calculus不存在于词向量中\n",
      "admire/respect不存在于词向量中\n",
      "course).不存在于词向量中\n",
      "owl.不存在于词向量中\n",
      "Silence不存在于词向量中\n",
      "delicious.不存在于词向量中\n",
      ":)|||It's不存在于词向量中\n",
      "Band不存在于词向量中\n",
      "journey,不存在于词向量中\n",
      "relief.不存在于词向量中\n",
      "Really.不存在于词向量中\n",
      "INFP|||I不存在于词向量中\n",
      "a...不存在于词向量中\n",
      "CAN'T不存在于词向量中\n",
      "especially,不存在于词向量中\n",
      "DEFINITELY不存在于词向量中\n",
      "influence.不存在于词向量中\n",
      "fire,不存在于词向量中\n",
      "Ironically,不存在于词向量中\n",
      "strengths.不存在于词向量中\n",
      "Single不存在于词向量中\n",
      "laptop.不存在于词向量中\n",
      "women?不存在于词向量中\n",
      "irl.不存在于词向量中\n",
      "Dirty不存在于词向量中\n",
      "head...不存在于词向量中\n",
      "Matrix不存在于词向量中\n",
      "astrology.不存在于词向量中\n",
      "violence.不存在于词向量中\n",
      "almost.不存在于词向量中\n",
      "lists,不存在于词向量中\n",
      "judgement,不存在于词向量中\n",
      "degrees.不存在于词向量中\n",
      "??不存在于词向量中\n",
      "INTP)不存在于词向量中\n",
      "salt,不存在于词向量中\n",
      "processes,不存在于词向量中\n",
      "count,不存在于词向量中\n",
      "and...|||Yeah,不存在于词向量中\n",
      "Carry不存在于词向量中\n",
      "struggle.不存在于词向量中\n",
      "a...|||I'd不存在于词向量中\n",
      "4's不存在于词向量中\n",
      "department.不存在于词向量中\n",
      "territory.不存在于词向量中\n",
      "ideal,不存在于词向量中\n",
      "is...|||When不存在于词向量中\n",
      "Pay不存在于词向量中\n",
      "moods.不存在于词向量中\n",
      "successful,不存在于词向量中\n",
      "Islam不存在于词向量中\n",
      "Gender?不存在于词向量中\n",
      "benefits.不存在于词向量中\n",
      "cat's不存在于词向量中\n",
      "awareness,不存在于词向量中\n",
      "front.不存在于词向量中\n",
      "Lelouch不存在于词向量中\n",
      "Teacher不存在于词向量中\n",
      "Film不存在于词向量中\n",
      "Germany,不存在于词向量中\n",
      "Canada,不存在于词向量中\n",
      "Alaska不存在于词向量中\n",
      "unusual.不存在于词向量中\n",
      "Lisa不存在于词向量中\n",
      "to.|||I不存在于词向量中\n",
      "Phoenix不存在于词向量中\n",
      "surprise,不存在于词向量中\n",
      "Sword不存在于词向量中\n",
      "birds,不存在于词向量中\n",
      "Ni:不存在于词向量中\n",
      "shirt.不存在于词向量中\n",
      "flirting,不存在于词向量中\n",
      "offense.不存在于词向量中\n",
      "I...|||1.不存在于词向量中\n",
      "everything...|||I不存在于词向量中\n",
      "feel...不存在于词向量中\n",
      "flirt.不存在于词向量中\n",
      "Silver不存在于词向量中\n",
      "nights,不存在于词向量中\n",
      "take...|||I不存在于词向量中\n",
      "out)不存在于词向量中\n",
      "man?不存在于词向量中\n",
      "days?不存在于词向量中\n",
      "through...|||I不存在于词向量中\n",
      "opportunity.不存在于词向量中\n",
      "Nope不存在于词向量中\n",
      "vent.不存在于词向量中\n",
      "Indeed,不存在于词向量中\n",
      "INFJ.|||I不存在于词向量中\n",
      "Large不存在于词向量中\n",
      ":-D不存在于词向量中\n",
      "connected.不存在于词向量中\n",
      "Seattle不存在于词向量中\n",
      "Japan.不存在于词向量中\n",
      "distracted.不存在于词向量中\n",
      "gets.不存在于词向量中\n",
      "government,不存在于词向量中\n",
      "rage.不存在于词向量中\n",
      "effects.不存在于词向量中\n",
      "Passion不存在于词向量中\n",
      "yeah..不存在于词向量中\n",
      "time..不存在于词向量中\n",
      "Muse不存在于词向量中\n",
      "speed.不存在于词向量中\n",
      "girls?不存在于词向量中\n",
      "Logical不存在于词向量中\n",
      "adults.不存在于词向量中\n",
      "Jerry不存在于词向量中\n",
      "Serious不存在于词向量中\n",
      "30,不存在于词向量中\n",
      "imagine,不存在于词向量中\n",
      "Colorado不存在于词向量中\n",
      "harmony,不存在于词向量中\n",
      "thought...|||I不存在于词向量中\n",
      "a.m.不存在于词向量中\n",
      "singer,不存在于词向量中\n",
      "Steven不存在于词向量中\n",
      "add.不存在于词向量中\n",
      "engineering,不存在于词向量中\n",
      "teeth.不存在于词向量中\n",
      "Criminal不存在于词向量中\n",
      "scenarios,不存在于词向量中\n",
      "Oh.不存在于词向量中\n",
      "Sherlock,不存在于词向量中\n",
      "'Your不存在于词向量中\n",
      "Dude,不存在于词向量中\n",
      "iNtuitive不存在于词向量中\n",
      "haha)不存在于词向量中\n",
      "join.不存在于词向量中\n",
      "react.不存在于词向量中\n",
      "Letting不存在于词向量中\n",
      "Crime不存在于词向量中\n",
      "aspects.不存在于词向量中\n",
      "Ultimately,不存在于词向量中\n",
      "Slow不存在于词向量中\n",
      "Grace不存在于词向量中\n",
      "Hi.不存在于词向量中\n",
      "anyway.|||I不存在于词向量中\n",
      "quiz,不存在于词向量中\n",
      "guilty,不存在于词向量中\n",
      "Her:不存在于词向量中\n",
      "expressions.不存在于词向量中\n",
      "disorders,不存在于词向量中\n",
      "Spam不存在于词向量中\n",
      "WoW不存在于词向量中\n",
      "piece.不存在于词向量中\n",
      "intensity.不存在于词向量中\n",
      "it.|||My不存在于词向量中\n",
      "a...|||i不存在于词向量中\n",
      "Among不存在于词向量中\n",
      "stronger.不存在于词向量中\n",
      "possibility,不存在于词向量中\n",
      "letter,不存在于词向量中\n",
      "of...|||Oh不存在于词向量中\n",
      "Amelie不存在于词向量中\n",
      "...|||1.不存在于词向量中\n",
      "shame.不存在于词向量中\n",
      "stars.不存在于词向量中\n",
      "(ie.不存在于词向量中\n",
      "Jeremy不存在于词向量中\n",
      "status.不存在于词向量中\n",
      "appreciated,不存在于词向量中\n",
      "off...|||I不存在于词向量中\n",
      "makeup.不存在于词向量中\n",
      "probably...|||I不存在于词向量中\n",
      "conscious,不存在于词向量中\n",
      "Pie不存在于词向量中\n",
      "Ti-Fe不存在于词向量中\n",
      "scenarios.不存在于词向量中\n",
      "listening,不存在于词向量中\n",
      "promise.不存在于词向量中\n",
      "Te/Fi不存在于词向量中\n",
      "reasonable,不存在于词向量中\n",
      "center,不存在于词向量中\n",
      "(high不存在于词向量中\n",
      "Blue,不存在于词向量中\n",
      "25,不存在于词向量中\n",
      "family?不存在于词向量中\n",
      "ESTJs,不存在于词向量中\n",
      "version,不存在于词向量中\n",
      "or...|||You不存在于词向量中\n",
      "dies.不存在于词向量中\n",
      "Socionics.不存在于词向量中\n",
      "romantically,不存在于词向量中\n",
      "gut.不存在于词向量中\n",
      "understandable.不存在于词向量中\n",
      "abstract.不存在于词向量中\n",
      "30.不存在于词向量中\n",
      "standpoint,不存在于词向量中\n",
      "snow.不存在于词向量中\n",
      "the...|||1.不存在于词向量中\n",
      "thinks.不存在于词向量中\n",
      "appealing.不存在于词向量中\n",
      "City,不存在于词向量中\n",
      "Good,不存在于词向量中\n",
      "hiking,不存在于词向量中\n",
      "genius,不存在于词向量中\n",
      "things)不存在于词向量中\n",
      "Suddenly不存在于词向量中\n",
      "is...|||I've不存在于词向量中\n",
      "'不存在于词向量中\n",
      "species.不存在于词向量中\n",
      "work...|||I不存在于词向量中\n",
      "England,不存在于词向量中\n",
      "strength,不存在于词向量中\n",
      "I'd...|||I不存在于词向量中\n",
      "dick,不存在于词向量中\n",
      "Already不存在于词向量中\n",
      "2000's不存在于词向量中\n",
      "invisible.不存在于词向量中\n",
      "Rather,不存在于词向量中\n",
      "habits,不存在于词向量中\n",
      "partner's不存在于词向量中\n",
      "of...|||When不存在于词向量中\n",
      "temperament.不存在于词向量中\n",
      "heads,不存在于词向量中\n",
      "reaction,不存在于词向量中\n",
      "lose.不存在于词向量中\n",
      "sincere.不存在于词向量中\n",
      "in...|||I've不存在于词向量中\n",
      "connections,不存在于词向量中\n",
      "Q不存在于词向量中\n",
      "soft,不存在于词向量中\n",
      "in...|||What不存在于词向量中\n",
      "atm.不存在于词向量中\n",
      "off.|||I不存在于词向量中\n",
      "tone,不存在于词向量中\n",
      "INTJ.|||I不存在于词向量中\n",
      "INTP's.不存在于词向量中\n",
      "ESFP:不存在于词向量中\n",
      "Murder不存在于词向量中\n",
      "eventually,不存在于词向量中\n",
      "Late不存在于词向量中\n",
      "Slytherin.不存在于词向量中\n",
      "GT-N7100不存在于词向量中\n",
      "and...|||Just不存在于词向量中\n",
      "friend.|||I不存在于词向量中\n",
      "studying.不存在于词向量中\n",
      "regularly,不存在于词向量中\n",
      "boat.不存在于词向量中\n",
      "maturity.不存在于词向量中\n",
      ":laughing:|||I'm不存在于词向量中\n",
      "Dude不存在于词向量中\n",
      "just..不存在于词向量中\n",
      "mean..不存在于词向量中\n",
      "6w5.不存在于词向量中\n",
      "friends...|||I不存在于词向量中\n",
      "both...|||I不存在于词向量中\n",
      "Time.不存在于词向量中\n",
      "saw.不存在于词向量中\n",
      "1/3不存在于词向量中\n",
      "Brad不存在于词向量中\n",
      "trying,不存在于词向量中\n",
      "BEING不存在于词向量中\n",
      "Vendetta不存在于词向量中\n",
      "Nirvana不存在于词向量中\n",
      "but....不存在于词向量中\n",
      "that),不存在于词向量中\n",
      "'a不存在于词向量中\n",
      "idealism.不存在于词向量中\n",
      "pleasure,不存在于词向量中\n",
      "hat.不存在于词向量中\n",
      "unhappy.不存在于词向量中\n",
      "ready.不存在于词向量中\n",
      "touching.不存在于词向量中\n",
      "bold,不存在于词向量中\n",
      "strategy,不存在于词向量中\n",
      "holidays.不存在于词向量中\n",
      "medicine.不存在于词向量中\n",
      "Gryffindor,不存在于词向量中\n",
      "sense...不存在于词向量中\n",
      "ends,不存在于词向量中\n",
      "you....不存在于词向量中\n",
      "vulnerable,不存在于词向量中\n",
      "babies.不存在于词向量中\n",
      "overrated.不存在于词向量中\n",
      "areas,不存在于词向量中\n",
      "consciousness.不存在于词向量中\n",
      "Tea不存在于词向量中\n",
      "career?不存在于词向量中\n",
      "without.不存在于词向量中\n",
      "Hi!不存在于词向量中\n",
      "relaxed.不存在于词向量中\n",
      "INTJs!不存在于词向量中\n",
      "subforum,不存在于词向量中\n",
      "the...|||Dear不存在于词向量中\n",
      "a...|||Just不存在于词向量中\n",
      "Government不存在于词向量中\n",
      "the...|||No不存在于词向量中\n",
      "on...|||I've不存在于词向量中\n",
      "etc),不存在于词向量中\n",
      "Se?不存在于词向量中\n",
      "They'd不存在于词向量中\n",
      "moving.不存在于词向量中\n",
      "Roger不存在于词向量中\n",
      "Ne:不存在于词向量中\n",
      "factors,不存在于词向量中\n",
      "location.不存在于词向量中\n",
      "'There不存在于词向量中\n",
      "artists.不存在于词向量中\n",
      "bother.不存在于词向量中\n",
      "goodness.不存在于词向量中\n",
      "moment?不存在于词向量中\n",
      "Junior不存在于词向量中\n",
      "wish,不存在于词向量中\n",
      "'For不存在于词向量中\n",
      "Anybody不存在于词向量中\n",
      "though.|||I'm不存在于词向量中\n",
      "holidays,不存在于词向量中\n",
      "balls.不存在于词向量中\n",
      "Rice不存在于词向量中\n",
      "best?不存在于词向量中\n",
      "completely...|||I不存在于词向量中\n",
      "Hitchhiker's不存在于词向量中\n",
      "rights,不存在于词向量中\n",
      "butter.不存在于词向量中\n",
      "obnoxious.不存在于词向量中\n",
      "'Hi不存在于词向量中\n",
      "(long不存在于词向量中\n",
      ":)|||Hey不存在于词向量中\n",
      ":tongue:|||I'm不存在于词向量中\n",
      "bipolar,不存在于词向量中\n",
      "F/T不存在于词向量中\n",
      "Additionally,不存在于词向量中\n",
      "tough,不存在于词向量中\n",
      "Ni-Fi不存在于词向量中\n",
      "Allen不存在于词向量中\n",
      "theory?不存在于词向量中\n",
      "I...|||Just不存在于词向量中\n",
      "ahead,不存在于词向量中\n",
      "because.不存在于词向量中\n",
      "was...|||This不存在于词向量中\n",
      "exam.不存在于词向量中\n",
      "lady.不存在于词向量中\n",
      "Global不存在于词向量中\n",
      "card.不存在于词向量中\n",
      "folks.不存在于词向量中\n",
      "anybody.不存在于词向量中\n",
      "meantime,不存在于词向量中\n",
      "illogical.不存在于词向量中\n",
      "ill.不存在于词向量中\n",
      "Secondary不存在于词向量中\n",
      "cities,不存在于词向量中\n",
      "gorgeous.不存在于词向量中\n",
      "programming.不存在于词向量中\n",
      "assumptions.不存在于词向量中\n",
      "Rule不存在于词向量中\n",
      "somebody,不存在于词向量中\n",
      "Takes不存在于词向量中\n",
      "of...|||Just不存在于词向量中\n",
      "cares?不存在于词向量中\n",
      "20's.不存在于词向量中\n",
      "headache.不存在于词向量中\n",
      "Somehow,不存在于词向量中\n",
      "NYC不存在于词向量中\n",
      "Lucy不存在于词向量中\n",
      "based.不存在于词向量中\n",
      "wild.不存在于词向量中\n",
      "mask.不存在于词向量中\n",
      "Twitter不存在于词向量中\n",
      "friend...|||I不存在于词向量中\n",
      "ANYTHING不存在于词向量中\n",
      "inspiration,不存在于词向量中\n",
      "ambitious,不存在于词向量中\n",
      "Maybe,不存在于词向量中\n",
      "(i.e.,不存在于词向量中\n",
      "error.不存在于词向量中\n",
      "describing.不存在于词向量中\n",
      "Capital不存在于词向量中\n",
      "track,不存在于词向量中\n",
      "it...|||When不存在于词向量中\n",
      "consideration.不存在于词向量中\n",
      "extraverted,不存在于词向量中\n",
      "notes,不存在于词向量中\n",
      "Tina不存在于词向量中\n",
      "links,不存在于词向量中\n",
      "me.|||The不存在于词向量中\n",
      "be...|||You不存在于词向量中\n",
      "who'd不存在于词向量中\n",
      "a...|||What不存在于词向量中\n",
      "problems?不存在于词向量中\n",
      "bit...|||I不存在于词向量中\n",
      "22.不存在于词向量中\n",
      "debates.不存在于词向量中\n",
      "God!不存在于词向量中\n",
      "mum's不存在于词向量中\n",
      "stuck.不存在于词向量中\n",
      "'til不存在于词向量中\n",
      "magic,不存在于词向量中\n",
      "alike,不存在于词向量中\n",
      "Notice不存在于词向量中\n",
      "a...|||As不存在于词向量中\n",
      "comparison.不存在于词向量中\n",
      "Capitalism不存在于词向量中\n",
      "mindset,不存在于词向量中\n",
      "for...|||The不存在于词向量中\n",
      "arrogance,不存在于词向量中\n",
      "Hello!不存在于词向量中\n",
      "ENXP不存在于词向量中\n",
      "drinks.不存在于词向量中\n",
      "with...|||This不存在于词向量中\n",
      "further,不存在于词向量中\n",
      "lists.不存在于词向量中\n",
      "organization,不存在于词向量中\n",
      "speed,不存在于词向量中\n",
      "like...|||My不存在于词向量中\n",
      "times?不存在于词向量中\n",
      "everyone?不存在于词向量中\n",
      "adventurous,不存在于词向量中\n",
      "driver,不存在于词向量中\n",
      "someone...不存在于词向量中\n",
      "9's不存在于词向量中\n",
      "6's不存在于词向量中\n",
      "parents?不存在于词向量中\n",
      "Languages不存在于词向量中\n",
      "Nearly不存在于词向量中\n",
      "Times不存在于词向量中\n",
      "tree.不存在于词向量中\n",
      "song...不存在于词向量中\n",
      "chart.不存在于词向量中\n",
      "Wanted不存在于词向量中\n",
      "Professional不存在于词向量中\n",
      "adventure,不存在于词向量中\n",
      "nose,不存在于词向量中\n",
      "disturbing.不存在于词向量中\n",
      "There,不存在于词向量中\n",
      "object,不存在于词向量中\n",
      "highschool.不存在于词向量中\n",
      "Theres不存在于词向量中\n",
      "the...|||i不存在于词向量中\n",
      "Success不存在于词向量中\n",
      "......不存在于词向量中\n",
      "program,不存在于词向量中\n",
      "acquaintances.不存在于词向量中\n",
      "suggestions,不存在于词向量中\n",
      "situation...不存在于词向量中\n",
      "9/11不存在于词向量中\n",
      "INTP...不存在于词向量中\n",
      "chill,不存在于词向量中\n",
      "habit,不存在于词向量中\n",
      "Atheism不存在于词向量中\n",
      "limit.不存在于词向量中\n",
      "suit.不存在于词向量中\n",
      "well...|||I不存在于词向量中\n",
      "sentiment.不存在于词向量中\n",
      "Therapy不存在于词向量中\n",
      "future?不存在于词向量中\n",
      "Rainbow不存在于词向量中\n",
      "opinion?不存在于词向量中\n",
      "entertaining,不存在于词向量中\n",
      "FP不存在于词向量中\n",
      "myself..不存在于词向量中\n",
      "don't...|||My不存在于词向量中\n",
      "HA不存在于词向量中\n",
      "What...|||I不存在于词向量中\n",
      "author,不存在于词向量中\n",
      "principles.不存在于词向量中\n",
      "Elliott不存在于词向量中\n",
      "shop,不存在于词向量中\n",
      "tastes.不存在于词向量中\n",
      "Sydney不存在于词向量中\n",
      "discovery.不存在于词向量中\n",
      "(myself不存在于词向量中\n",
      "circle,不存在于词向量中\n",
      "Lawrence不存在于词向量中\n",
      "glasses.不存在于词向量中\n",
      "...|||For不存在于词向量中\n",
      "mirror,不存在于词向量中\n",
      "signature,不存在于词向量中\n",
      "Quit不存在于词向量中\n",
      "Bleach不存在于词向量中\n",
      "his.不存在于词向量中\n",
      "states,不存在于词向量中\n",
      "Near不存在于词向量中\n",
      "ACT不存在于词向量中\n",
      "couple.不存在于词向量中\n",
      "Alchemist不存在于词向量中\n",
      "episodes,不存在于词向量中\n",
      "qualities,不存在于词向量中\n",
      "Awkward不存在于词向量中\n",
      "Hmmm,不存在于词向量中\n",
      "peaceful,不存在于词向量中\n",
      "questionnaire,不存在于词向量中\n",
      "Tertiary不存在于词向量中\n",
      "valid.不存在于词向量中\n",
      "Thinking,不存在于词向量中\n",
      "violent,不存在于词向量中\n",
      "scientist,不存在于词向量中\n",
      "guess...不存在于词向量中\n",
      "(due不存在于词向量中\n",
      "ISFJ...不存在于词向量中\n",
      "Alignment:不存在于词向量中\n",
      "bitter,不存在于词向量中\n",
      "having...|||I不存在于词向量中\n",
      "a...|||How不存在于词向量中\n",
      "chicken,不存在于词向量中\n",
      "Iam不存在于词向量中\n",
      "YouTube,不存在于词向量中\n",
      "Cooper不存在于词向量中\n",
      "8)不存在于词向量中\n",
      "fantasy.不存在于词向量中\n",
      "the...|||You're不存在于词向量中\n",
      "member.不存在于词向量中\n",
      "spontaneous.不存在于词向量中\n",
      "with...|||My不存在于词向量中\n",
      "(male)不存在于词向量中\n",
      "Tommy不存在于词向量中\n",
      "me...|||My不存在于词向量中\n",
      "Britney不存在于词向量中\n",
      "fits,不存在于词向量中\n",
      "Ne/Si不存在于词向量中\n",
      "learned.不存在于词向量中\n",
      "stores.不存在于词向量中\n",
      "seasons,不存在于词向量中\n",
      "around?不存在于词向量中\n",
      "EQ不存在于词向量中\n",
      "condition.不存在于词向量中\n",
      "house?不存在于词向量中\n",
      "feminism,不存在于词向量中\n",
      "accident,不存在于词向量中\n",
      "eating.不存在于词向量中\n",
      ":(.不存在于词向量中\n",
      "harm.不存在于词向量中\n",
      "norms.不存在于词向量中\n",
      "Thinking:不存在于词向量中\n",
      "Literally不存在于词向量中\n",
      "sure...|||I不存在于词向量中\n",
      "Romeo不存在于词向量中\n",
      "OCD.不存在于词向量中\n",
      "extravert.不存在于词向量中\n",
      "Kitty不存在于词向量中\n",
      "19,不存在于词向量中\n",
      "'Don't不存在于词向量中\n",
      "took.不存在于词向量中\n",
      "Welcome.不存在于词向量中\n",
      "Republic不存在于词向量中\n",
      "Jay不存在于词向量中\n",
      ":)|||Yeah,不存在于词向量中\n",
      "shouldn't.不存在于词向量中\n",
      "communicate.不存在于词向量中\n",
      "equal.不存在于词向量中\n",
      "Mexico不存在于词向量中\n",
      "Chapter不存在于词向量中\n",
      "Loves不存在于词向量中\n",
      "year's不存在于词向量中\n",
      "loop?不存在于词向量中\n",
      "feelings...不存在于词向量中\n",
      "Ed不存在于词向量中\n",
      "called.不存在于词向量中\n",
      "idea?不存在于词向量中\n",
      "incompetent.不存在于词向量中\n",
      "Elementary不存在于词向量中\n",
      "thus,不存在于词向量中\n",
      "Socionics,不存在于词向量中\n",
      "paranoid,不存在于词向量中\n",
      "bus,不存在于词向量中\n",
      "Hanging不存在于词向量中\n",
      "dull.不存在于词向量中\n",
      "Hmmm...不存在于词向量中\n",
      "Ni-Se不存在于词向量中\n",
      "problem...不存在于词向量中\n",
      "robots.不存在于词向量中\n",
      "defense,不存在于词向量中\n",
      "this?|||I不存在于词向量中\n",
      "He...|||I不存在于词向量中\n",
      "to...|||How不存在于词向量中\n",
      "thread's不存在于词向量中\n",
      "8w7.不存在于词向量中\n",
      "disappointed,不存在于词向量中\n",
      "Congratulations不存在于词向量中\n",
      "intp's不存在于词向量中\n",
      "medication.不存在于词向量中\n",
      "(despite不存在于词向量中\n",
      "may...|||I不存在于词向量中\n",
      "bunch.不存在于词向量中\n",
      "Christ,不存在于词向量中\n",
      "Machs,不存在于词向量中\n",
      "Avatar:不存在于词向量中\n",
      "Francisco不存在于词向量中\n",
      "back...|||I不存在于词向量中\n",
      "sudden,不存在于词向量中\n",
      "ExTJ不存在于词向量中\n",
      "apologies.不存在于词向量中\n",
      "did?不存在于词向量中\n",
      "born?不存在于词向量中\n",
      "Period.不存在于词向量中\n",
      "perC不存在于词向量中\n",
      "Catholic,不存在于词向量中\n",
      "argue,不存在于词向量中\n",
      "principles,不存在于词向量中\n",
      "an...|||The不存在于词向量中\n",
      "(thank不存在于词向量中\n",
      "Zero不存在于词向量中\n",
      "traditions,不存在于词向量中\n",
      "commitment.不存在于词向量中\n",
      "Done不存在于词向量中\n",
      "Reply不存在于词向量中\n",
      "Attraction不存在于词向量中\n",
      "'To不存在于词向量中\n",
      "Musical不存在于词向量中\n",
      "me?|||I不存在于词向量中\n",
      "insomnia,不存在于词向量中\n",
      "Treat不存在于词向量中\n",
      "esteem,不存在于词向量中\n",
      "Loving不存在于词向量中\n",
      "pleasant.不存在于词向量中\n",
      "Narcissistic不存在于词向量中\n",
      "purposes.不存在于词向量中\n",
      "-People不存在于词向量中\n",
      "-My不存在于词向量中\n",
      "experiences?不存在于词向量中\n",
      "of...|||Well不存在于词向量中\n",
      "intellectual.不存在于词向量中\n",
      "practical.不存在于词向量中\n",
      "Gets不存在于词向量中\n",
      "Stranger不存在于词向量中\n",
      "insecurity.不存在于词向量中\n",
      "to...|||Why不存在于词向量中\n",
      "III不存在于词向量中\n",
      "rage,不存在于词向量中\n",
      "Rarely不存在于词向量中\n",
      "feels,不存在于词向量中\n",
      "Avoid不存在于词向量中\n",
      "Exactly.不存在于词向量中\n",
      "independent.不存在于词向量中\n",
      "WHO不存在于词向量中\n",
      "silent,不存在于词向量中\n",
      "generation.不存在于词向量中\n",
      "Man.不存在于词向量中\n",
      "diet,不存在于词向量中\n",
      "absurd.不存在于词向量中\n",
      "JRR不存在于词向量中\n",
      "Canada.不存在于词向量中\n",
      "be...|||This不存在于词向量中\n",
      "Jonathan不存在于词向量中\n",
      "paint,不存在于词向量中\n",
      "to...|||No,不存在于词向量中\n",
      "presence,不存在于词向量中\n",
      "did...|||I不存在于词向量中\n",
      "smiling.不存在于词向量中\n",
      "(Yes,不存在于词向量中\n",
      "person.|||I不存在于词向量中\n",
      "with.|||I不存在于词向量中\n",
      "disease.不存在于词向量中\n",
      "life..不存在于词向量中\n",
      "making,不存在于词向量中\n",
      "the...|||How不存在于词向量中\n",
      "siblings.不存在于词向量中\n",
      "intentions,不存在于词向量中\n",
      "excellent.不存在于词向量中\n",
      "environments,不存在于词向量中\n",
      "have...'不存在于词向量中\n",
      "nerd.不存在于词向量中\n",
      "youth,不存在于词向量中\n",
      "CS不存在于词向量中\n",
      "freak,不存在于词向量中\n",
      "playful,不存在于词向量中\n",
      "tattoos,不存在于词向量中\n",
      "upbringing,不存在于词向量中\n",
      "more)不存在于词向量中\n",
      "judge,不存在于词向量中\n",
      "circles.不存在于词向量中\n",
      "Gordon不存在于词向量中\n",
      "dangerous,不存在于词向量中\n",
      "appropriate.不存在于词向量中\n",
      "Unhealthy不存在于词向量中\n",
      "Danny不存在于词向量中\n",
      "Grateful不存在于词向量中\n",
      "IxTP不存在于词向量中\n",
      "etc.),不存在于词向量中\n",
      "Tower不存在于词向量中\n",
      "challenges,不存在于词向量中\n",
      "spirit.不存在于词向量中\n",
      "'not不存在于词向量中\n",
      "knew,不存在于词向量中\n",
      "esp.不存在于词向量中\n",
      "Seriously?不存在于词向量中\n",
      "SFs不存在于词向量中\n",
      "try...不存在于词向量中\n",
      "(thanks不存在于词向量中\n",
      "use?不存在于词向量中\n",
      "indecisive,不存在于词向量中\n",
      "mirror.不存在于词向量中\n",
      "yoga,不存在于词向量中\n",
      "Meepers不存在于词向量中\n",
      "its...|||I不存在于词向量中\n",
      "sucked.不存在于词向量中\n",
      "unconscious.不存在于词向量中\n",
      "thinking...|||I不存在于词向量中\n",
      "Katy不存在于词向量中\n",
      "personally?不存在于词向量中\n",
      "Hitler's不存在于词向量中\n",
      "to...|||Yeah,不存在于词向量中\n",
      "quotes.不存在于词向量中\n",
      "Class不存在于词向量中\n",
      "smell.不存在于词向量中\n",
      "misleading.不存在于词向量中\n",
      "Norwegian不存在于词向量中\n",
      "he's...|||I不存在于词向量中\n",
      "Psych不存在于词向量中\n",
      "seriously...不存在于词向量中\n",
      "accuracy.不存在于词向量中\n",
      "kindness.不存在于词向量中\n",
      "Gives不存在于词向量中\n",
      "hobby,不存在于词向量中\n",
      "creatures,不存在于词向量中\n",
      "said...|||I不存在于词向量中\n",
      "Tokyo不存在于词向量中\n",
      "excuse.不存在于词向量中\n",
      "Color不存在于词向量中\n",
      "States,不存在于词向量中\n",
      "success,不存在于词向量中\n",
      "Cake不存在于词向量中\n",
      "mentally,不存在于词向量中\n",
      "vision.不存在于词向量中\n",
      "learned,不存在于词向量中\n",
      "sorts,不存在于词向量中\n",
      "concern,不存在于词向量中\n",
      "Meditation不存在于词向量中\n",
      "similarities.不存在于词向量中\n",
      "hell?不存在于词向量中\n",
      "whore.不存在于词向量中\n",
      "center.不存在于词向量中\n",
      "Coke不存在于词向量中\n",
      "with...|||The不存在于词向量中\n",
      "I:不存在于词向量中\n",
      "Absolutely.不存在于词向量中\n",
      "moods,不存在于词向量中\n",
      "lot...|||I不存在于词向量中\n",
      "BS.不存在于词向量中\n",
      "seeing,不存在于词向量中\n",
      "immediately,不存在于词向量中\n",
      "it,...|||I不存在于词向量中\n",
      "complain.不存在于词向量中\n",
      "Abstract不存在于词向量中\n",
      "Respect不存在于词向量中\n",
      "everything.|||I不存在于词向量中\n",
      "are...|||This不存在于词向量中\n",
      "DVD不存在于词向量中\n",
      "temper.不存在于词向量中\n",
      "X,不存在于词向量中\n",
      "tv.不存在于词向量中\n",
      "Rocky不存在于词向量中\n",
      "Hogwarts不存在于词向量中\n",
      "now),不存在于词向量中\n",
      "differ.不存在于词向量中\n",
      "Atheist不存在于词向量中\n",
      "LOOK不存在于词向量中\n",
      "Se)不存在于词向量中\n",
      "Le不存在于词向量中\n",
      "I's不存在于词向量中\n",
      "stuff)不存在于词向量中\n",
      "studying,不存在于词向量中\n",
      "(me不存在于词向量中\n",
      "Intense不存在于词向量中\n",
      "corner,不存在于词向量中\n",
      "record.不存在于词向量中\n",
      "Software不存在于词向量中\n",
      "mentally.不存在于词向量中\n",
      "repeat.不存在于词向量中\n",
      "SEE不存在于词向量中\n",
      "anymore?不存在于词向量中\n",
      "PS不存在于词向量中\n",
      "Two:不存在于词向量中\n",
      "structure.不存在于词向量中\n",
      "procrastination,不存在于词向量中\n",
      "Disorder.不存在于词向量中\n",
      "trend.不存在于词向量中\n",
      "forth,不存在于词向量中\n",
      "episode,不存在于词向量中\n",
      "Tree不存在于词向量中\n",
      "whatever)不存在于词向量中\n",
      "responded.不存在于词向量中\n",
      "Ni-Fe不存在于词向量中\n",
      "joy.不存在于词向量中\n",
      "CEO不存在于词向量中\n",
      "privacy.不存在于词向量中\n",
      "porn.不存在于词向量中\n",
      "or...|||This不存在于词向量中\n",
      "be...|||My不存在于词向量中\n",
      "istp.不存在于词向量中\n",
      "Caring不存在于词向量中\n",
      "may,不存在于词向量中\n",
      "SHE不存在于词向量中\n",
      "Elder不存在于词向量中\n",
      "DJ不存在于词向量中\n",
      "SJs.不存在于词向量中\n",
      "depression?不存在于词向量中\n",
      "I'm...|||My不存在于词向量中\n",
      "the...|||Hey不存在于词向量中\n",
      "offensive,不存在于词向量中\n",
      "response?不存在于词向量中\n",
      "Functions:不存在于词向量中\n",
      "bubbly,不存在于词向量中\n",
      "claim.不存在于词向量中\n",
      "score.不存在于词向量中\n",
      "Wilde不存在于词向量中\n",
      "gaming,不存在于词向量中\n",
      "are...'不存在于词向量中\n",
      "I...|||There不存在于词向量中\n",
      "included)不存在于词向量中\n",
      "(yet不存在于词向量中\n",
      "NFJ不存在于词向量中\n",
      "superficial,不存在于词向量中\n",
      "H不存在于词向量中\n",
      "tasks.不存在于词向量中\n",
      "ready,不存在于词向量中\n",
      "Christianity,不存在于词向量中\n",
      "Accept不存在于词向量中\n",
      "besides,不存在于词向量中\n",
      "checked,不存在于词向量中\n",
      "expensive.不存在于词向量中\n",
      "Lucky不存在于词向量中\n",
      "You.不存在于词向量中\n",
      "am.|||I不存在于词向量中\n",
      "bright,不存在于词向量中\n",
      "villain.不存在于词向量中\n",
      "available,不存在于词向量中\n",
      "it...|||I've不存在于词向量中\n",
      "the...|||Yeah,不存在于词向量中\n",
      "Them不存在于词向量中\n",
      "original.不存在于词向量中\n",
      "being...|||I'm不存在于词向量中\n",
      "insensitive,不存在于词向量中\n",
      "five,不存在于词向量中\n",
      "XNTP不存在于词向量中\n",
      "backwards.不存在于词向量中\n",
      "idk.不存在于词向量中\n",
      "GOT不存在于词向量中\n",
      "coming,不存在于词向量中\n",
      "Ni/Se不存在于词向量中\n",
      "iNtuitives不存在于词向量中\n",
      "everything...不存在于词向量中\n",
      "debating,不存在于词向量中\n",
      "counselor.不存在于词向量中\n",
      ",I不存在于词向量中\n",
      "SJ,不存在于词向量中\n",
      "Ok.不存在于词向量中\n",
      "(depending不存在于词向量中\n",
      "COULD不存在于词向量中\n",
      "(oh不存在于词向量中\n",
      "window,不存在于词向量中\n",
      "):不存在于词向量中\n",
      "Karma不存在于词向量中\n",
      "colour.不存在于词向量中\n",
      "individual's不存在于词向量中\n",
      "anything...|||I不存在于词向量中\n",
      "Fisher不存在于词向量中\n",
      "heal.不存在于词向量中\n",
      "relationship...不存在于词向量中\n",
      "walls.不存在于词向量中\n",
      "I...|||Hello不存在于词向量中\n",
      "responding,不存在于词向量中\n",
      "stronger,不存在于词向量中\n",
      "format.不存在于词向量中\n",
      "though...|||I不存在于词向量中\n",
      "thread..不存在于词向量中\n",
      "all...|||I'm不存在于词向量中\n",
      "walks,不存在于词向量中\n",
      "Haruki不存在于词向量中\n",
      "Minecraft不存在于词向量中\n",
      "confrontation,不存在于词向量中\n",
      "hat,不存在于词向量中\n",
      "apartment.不存在于词向量中\n",
      "vague,不存在于词向量中\n",
      "(You不存在于词向量中\n",
      "competition,不存在于词向量中\n",
      "19.不存在于词向量中\n",
      "vision,不存在于词向量中\n",
      ":tongue:|||You不存在于词向量中\n",
      "(1不存在于词向量中\n",
      "Android不存在于词向量中\n",
      "Billy不存在于词向量中\n",
      "unpredictable,不存在于词向量中\n",
      "Shit不存在于词向量中\n",
      "...|||Dear不存在于词向量中\n",
      "group?不存在于词向量中\n",
      "(we're不存在于词向量中\n",
      "bear.不存在于词向量中\n",
      "structure,不存在于词向量中\n",
      "missing.不存在于词向量中\n",
      "Thai不存在于词向量中\n",
      "Drinking不存在于词向量中\n",
      "Rebel不存在于词向量中\n",
      "Ha.不存在于词向量中\n",
      "sciences,不存在于词向量中\n",
      "Bright不存在于词向量中\n",
      "outgoing.不存在于词向量中\n",
      "'Hello不存在于词向量中\n",
      "tears,不存在于词向量中\n",
      "to...|||To不存在于词向量中\n",
      "13,不存在于词向量中\n",
      "figure.不存在于词向量中\n",
      "=)|||I不存在于词向量中\n",
      "effects,不存在于词向量中\n",
      "status,不存在于词向量中\n",
      "(sorry,不存在于词向量中\n",
      "xSFP不存在于词向量中\n",
      "and...|||Dear不存在于词向量中\n",
      "stranger,不存在于词向量中\n",
      "Digger不存在于词向量中\n",
      "ENTPs?不存在于词向量中\n",
      "upbringing.不存在于词向量中\n",
      "surprised,不存在于词向量中\n",
      "can...不存在于词向量中\n",
      "ignored.不存在于词向量中\n",
      "eyes...不存在于词向量中\n",
      "correlation,不存在于词向量中\n",
      "lessons.不存在于词向量中\n",
      "Duty不存在于词向量中\n",
      "shot,不存在于词向量中\n",
      "treatment.不存在于词向量中\n",
      "shops,不存在于词向量中\n",
      "read?不存在于词向量中\n",
      "lights,不存在于词向量中\n",
      "Bass不存在于词向量中\n",
      "justice,不存在于词向量中\n",
      "material,不存在于词向量中\n",
      "backwards,不存在于词向量中\n",
      "step,不存在于词向量中\n",
      "is...|||Thank不存在于词向量中\n",
      "3.5不存在于词向量中\n",
      "etc.|||I不存在于词向量中\n",
      "Morgan不存在于词向量中\n",
      "playful.不存在于词向量中\n",
      "me,...|||I不存在于词向量中\n",
      "Algebra不存在于词向量中\n",
      "grey,不存在于词向量中\n",
      "fly.不存在于词向量中\n",
      "boredom.不存在于词向量中\n",
      "phrase.不存在于词向量中\n",
      "Lincoln不存在于词向量中\n",
      "adults,不存在于词向量中\n",
      "slightest.不存在于词向量中\n",
      "fights,不存在于词向量中\n",
      "dated,不存在于词向量中\n",
      "symptoms.不存在于词向量中\n",
      "Private不存在于词向量中\n",
      "ago?不存在于词向量中\n",
      "Hotel不存在于词向量中\n",
      "Plenty不存在于词向量中\n",
      "attention?不存在于词向量中\n",
      "Worth不存在于词向量中\n",
      "throat.不存在于词向量中\n",
      "avatar?不存在于词向量中\n",
      "argumentative,不存在于词向量中\n",
      "away...不存在于词向量中\n",
      "indecisive.不存在于词向量中\n",
      "ambivert.不存在于词向量中\n",
      "THEN不存在于词向量中\n",
      "hmm...不存在于词向量中\n",
      "school's不存在于词向量中\n",
      "valid,不存在于词向量中\n",
      "necessarily,不存在于词向量中\n",
      "sympathy.不存在于词向量中\n",
      "changing.不存在于词向量中\n",
      "Europe,不存在于词向量中\n",
      "to...|||That's不存在于词向量中\n",
      "(We不存在于词向量中\n",
      "SHOULD不存在于词向量中\n",
      "sun.不存在于词向量中\n",
      "Dragons不存在于词向量中\n",
      "code,不存在于词向量中\n",
      "original,不存在于词向量中\n",
      "...|||Do不存在于词向量中\n",
      "single?不存在于词向量中\n",
      "Episode不存在于词向量中\n",
      "Astrology不存在于词向量中\n",
      "liberal,不存在于词向量中\n",
      "pride.不存在于词向量中\n",
      "TIME.不存在于词向量中\n",
      "cousin's不存在于词向量中\n",
      "awkwardness.不存在于词向量中\n",
      "counts,不存在于词向量中\n",
      "Australia,不存在于词向量中\n",
      ":D|||The不存在于词向量中\n",
      "grammar.不存在于词向量中\n",
      "Navy不存在于词向量中\n",
      "BDSM不存在于词向量中\n",
      "than,不存在于词向量中\n",
      "Victor不存在于词向量中\n",
      "ones?不存在于词向量中\n",
      "INTP|||I不存在于词向量中\n",
      "money?不存在于词向量中\n",
      "friend)不存在于词向量中\n",
      "(ie不存在于词向量中\n",
      "brothers,不存在于词向量中\n",
      "member,不存在于词向量中\n",
      "teaching,不存在于词向量中\n",
      "limits.不存在于词向量中\n",
      "IxFP,不存在于词向量中\n",
      "exclusive.不存在于词向量中\n",
      "P!不存在于词向量中\n",
      "far?不存在于词向量中\n",
      "laptop,不存在于词向量中\n",
      "for...|||This不存在于词向量中\n",
      "25.不存在于词向量中\n",
      "fighting,不存在于词向量中\n",
      "'my不存在于词向量中\n",
      "Mumford不存在于词向量中\n",
      "cream.不存在于词向量中\n",
      "music...不存在于词向量中\n",
      "lot.|||I不存在于词向量中\n",
      "combo.不存在于词向量中\n",
      "(before不存在于词向量中\n",
      "efficient,不存在于词向量中\n",
      "INTJ's,不存在于词向量中\n",
      "they...|||I'm不存在于词向量中\n",
      "objects,不存在于词向量中\n",
      "COMPLETELY不存在于词向量中\n",
      ":frustrating:|||I不存在于词向量中\n",
      "it...|||The不存在于词向量中\n",
      "since,不存在于词向量中\n",
      "dreamy,不存在于词向量中\n",
      "analytical,不存在于词向量中\n",
      "responsibility,不存在于词向量中\n",
      "(She不存在于词向量中\n",
      "get's不存在于词向量中\n",
      "enough...不存在于词向量中\n",
      "Thankfully,不存在于词向量中\n",
      "laughing,不存在于词向量中\n",
      "meaningful.不存在于词向量中\n",
      "matter)不存在于词向量中\n",
      "Friday,不存在于词向量中\n",
      "thoughtful.不存在于词向量中\n",
      "tattoos.不存在于词向量中\n",
      "OS不存在于词向量中\n",
      "dreaming,不存在于词向量中\n",
      "pace,不存在于词向量中\n",
      "impression,不存在于词向量中\n",
      "confrontation.不存在于词向量中\n",
      "hobby.不存在于词向量中\n",
      "Idk,不存在于词向量中\n",
      "1-5,不存在于词向量中\n",
      "tongue,不存在于词向量中\n",
      "driver.不存在于词向量中\n",
      "entj,不存在于词向量中\n",
      "images,不存在于词向量中\n",
      "a...|||Hi不存在于词向量中\n",
      "Friday.不存在于词向量中\n",
      "Se:不存在于词向量中\n",
      "Frozen不存在于词向量中\n",
      "grammar,不存在于词向量中\n",
      "24.不存在于词向量中\n",
      "Muslims不存在于词向量中\n",
      "pop.不存在于词向量中\n",
      "notes.不存在于词向量中\n",
      "Hugh不存在于词向量中\n",
      "a,不存在于词向量中\n",
      "Rant:不存在于词向量中\n",
      "(mostly)不存在于词向量中\n",
      "really)不存在于词向量中\n",
      "my...|||It不存在于词向量中\n",
      "standpoint.不存在于词向量中\n",
      "stressful,不存在于词向量中\n",
      "forest,不存在于词向量中\n",
      "credit.不存在于词向量中\n",
      "Came不存在于词向量中\n",
      "consideration,不存在于词向量中\n",
      "loser.不存在于词向量中\n",
      "disease,不存在于词向量中\n",
      "texts,不存在于词向量中\n",
      "my...|||Well,不存在于词向量中\n",
      "I...|||Yeah不存在于词向量中\n",
      "concur.不存在于词向量中\n",
      "idk,不存在于词向量中\n",
      "HAS不存在于词向量中\n",
      "Dreamer不存在于词向量中\n",
      "Culture不存在于词向量中\n",
      "observant,不存在于词向量中\n",
      "exam,不存在于词向量中\n",
      "cried.不存在于词向量中\n",
      "self-esteem,不存在于词向量中\n",
      "of...|||How不存在于词向量中\n",
      "Kudos不存在于词向量中\n",
      "with...|||I've不存在于词向量中\n",
      "painting.不存在于词向量中\n",
      "check,不存在于词向量中\n",
      "(lol)不存在于词向量中\n",
      "down?不存在于词向量中\n",
      "daydreaming,不存在于词向量中\n",
      "Supernatural不存在于词向量中\n",
      "anonymous,不存在于词向量中\n",
      "Admittedly,不存在于词向量中\n",
      "robot,不存在于词向量中\n",
      "Gary不存在于词向量中\n",
      "epic.不存在于词向量中\n",
      "rights.不存在于词向量中\n",
      "Constantly不存在于词向量中\n",
      "isfp,不存在于词向量中\n",
      "features.不存在于词向量中\n",
      "-You不存在于词向量中\n",
      "own?不存在于词向量中\n",
      "and...|||i不存在于词向量中\n",
      "recharge.不存在于词向量中\n",
      "realize,不存在于词向量中\n",
      "Least:不存在于词向量中\n",
      "vent,不存在于词向量中\n",
      "annoyed,不存在于词向量中\n",
      "Ralph不存在于词向量中\n",
      "Blind不存在于词向量中\n",
      "loner.不存在于词向量中\n",
      "Dawkins不存在于词向量中\n",
      "affectionate,不存在于词向量中\n",
      "'bout不存在于词向量中\n",
      "Specially不存在于词向量中\n",
      "Fe-Ti不存在于词向量中\n",
      "industry.不存在于词向量中\n",
      "deeper,不存在于词向量中\n",
      "against.不存在于词向量中\n",
      "mind.|||I不存在于词向量中\n",
      "Infinite不存在于词向量中\n",
      "Pure不存在于词向量中\n",
      "Eddie不存在于词向量中\n",
      "this....不存在于词向量中\n",
      "failure,不存在于词向量中\n",
      "pattern,不存在于词向量中\n",
      "Java不存在于词向量中\n",
      "careful,不存在于词向量中\n",
      "master's不存在于词向量中\n",
      "fish.不存在于词向量中\n",
      "Forgot不存在于词向量中\n",
      "Arabic不存在于词向量中\n",
      "competition.不存在于词向量中\n",
      "Contrary不存在于词向量中\n",
      "milk,不存在于词向量中\n",
      "just...|||My不存在于词向量中\n",
      "meaningful,不存在于词向量中\n",
      "survey,不存在于词向量中\n",
      "norms,不存在于词向量中\n",
      "thinking...不存在于词向量中\n",
      "Neon不存在于词向量中\n",
      "characters'不存在于词向量中\n",
      "movement.不存在于词向量中\n",
      "Artistic不存在于词向量中\n",
      "11.不存在于词向量中\n",
      "that...|||Well不存在于词向量中\n",
      "pride,不存在于词向量中\n",
      "therapist,不存在于词向量中\n",
      "priority.不存在于词向量中\n",
      "if...不存在于词向量中\n",
      "internet?不存在于词向量中\n",
      "children?不存在于词向量中\n",
      "passive,不存在于词向量中\n",
      "Sylvia不存在于词向量中\n",
      "(ISTJ)不存在于词向量中\n",
      "Cave不存在于词向量中\n",
      "Poetry不存在于词向量中\n",
      "Linux不存在于词向量中\n",
      "Scandinavian不存在于词向量中\n",
      "Seinfeld不存在于词向量中\n",
      "tbh,不存在于词向量中\n",
      "and...|||That's不存在于词向量中\n",
      "What,不存在于词向量中\n",
      "Cut不存在于词向量中\n",
      "...|||i不存在于词向量中\n",
      "LOTS不存在于词向量中\n",
      "sexuality.不存在于词向量中\n",
      "(always不存在于词向量中\n",
      "right.|||I不存在于词向量中\n",
      "much)不存在于词向量中\n",
      "a.不存在于词向量中\n",
      "BECAUSE不存在于词向量中\n",
      "(yeah,不存在于词向量中\n",
      "fallacy.不存在于词向量中\n",
      "b.不存在于词向量中\n",
      "Girl,不存在于词向量中\n",
      "Finally,不存在于词向量中\n",
      "exhausted,不存在于词向量中\n",
      "is).不存在于词向量中\n",
      "opposites,不存在于词向量中\n",
      "LGBT不存在于词向量中\n",
      "ended.不存在于词向量中\n",
      "dresses,不存在于词向量中\n",
      "create.不存在于词向量中\n",
      "Je不存在于词向量中\n",
      "communicating.不存在于词向量中\n",
      "instruments.不存在于词向量中\n",
      "(That's不存在于词向量中\n",
      "advance.不存在于词向量中\n",
      "manager.不存在于词向量中\n",
      "'em.不存在于词向量中\n",
      "speaker,不存在于词向量中\n",
      "...|||I'd不存在于词向量中\n",
      "me!|||I不存在于词向量中\n",
      "(their不存在于词向量中\n",
      "imaginative,不存在于词向量中\n",
      "initially.不存在于词向量中\n",
      "FF不存在于词向量中\n",
      "Schizoid不存在于词向量中\n",
      "writer's不存在于词向量中\n",
      "reason?不存在于词向量中\n",
      "lbs.不存在于词向量中\n",
      "70's不存在于词向量中\n",
      ":)|||A不存在于词向量中\n",
      "Fortunately不存在于词向量中\n",
      "SFJs不存在于词向量中\n",
      "intent,不存在于词向量中\n",
      "birth,不存在于词向量中\n",
      "cookie.不存在于词向量中\n",
      "accordingly.不存在于词向量中\n",
      "awesome.|||I不存在于词向量中\n",
      "idea...不存在于词向量中\n",
      "Study不存在于词向量中\n",
      "anything.|||I不存在于词向量中\n",
      "ESTJ:不存在于词向量中\n",
      "spirituality,不存在于词向量中\n",
      "amusing,不存在于词向量中\n",
      ".I不存在于词向量中\n",
      "actor,不存在于词向量中\n",
      "Life's不存在于词向量中\n",
      "diagnosis.不存在于词向量中\n",
      "spirit,不存在于词向量中\n",
      "...|||As不存在于词向量中\n",
      "Cry不存在于词向量中\n",
      "Wonderland不存在于词向量中\n",
      "instincts.不存在于词向量中\n",
      "family...|||I不存在于词向量中\n",
      "(They不存在于词向量中\n",
      "Oh...不存在于词向量中\n",
      "expressive,不存在于词向量中\n",
      "schools.不存在于词向量中\n",
      "sincere,不存在于词向量中\n",
      "name's不存在于词向量中\n",
      "School,不存在于词向量中\n",
      "Tywin不存在于词向量中\n",
      "Wife不存在于词向量中\n",
      "shirts.不存在于词向量中\n",
      "ability,不存在于词向量中\n",
      "^^.不存在于词向量中\n",
      "10,000不存在于词向量中\n",
      "Satan不存在于词向量中\n",
      "behaviors.不存在于词向量中\n",
      "struggle,不存在于词向量中\n",
      "Shall不存在于词向量中\n",
      "relations.不存在于词向量中\n",
      "give,不存在于词向量中\n",
      "Lives不存在于词向量中\n",
      "Huh?不存在于词向量中\n",
      "shirt,不存在于词向量中\n",
      "yet.|||I不存在于词向量中\n",
      "Pi不存在于词向量中\n",
      "mates.不存在于词向量中\n",
      "wrong)不存在于词向量中\n",
      "Jordan不存在于词向量中\n",
      "Weed不存在于词向量中\n",
      "Hybrid不存在于词向量中\n",
      "dreamer,不存在于词向量中\n",
      "Definitely.不存在于词向量中\n",
      "lover,不存在于词向量中\n",
      "ISxJ不存在于词向量中\n",
      "Opera不存在于词向量中\n",
      "idealist.不存在于词向量中\n",
      "building,不存在于词向量中\n",
      "psychologist.不存在于词向量中\n",
      "phenomenon.不存在于词向量中\n",
      "correct?不存在于词向量中\n",
      "the16types.info不存在于词向量中\n",
      "went.不存在于词向量中\n",
      "unsure.不存在于词向量中\n",
      "Idealist不存在于词向量中\n",
      "example?不存在于词向量中\n",
      "Naturally不存在于词向量中\n",
      "Borderline不存在于词向量中\n",
      "photos,不存在于词向量中\n",
      "Canon不存在于词向量中\n",
      "Dogs不存在于词向量中\n",
      "banned.不存在于词向量中\n",
      "ISFp不存在于词向量中\n",
      "develop,不存在于词向量中\n",
      "screen.不存在于词向量中\n",
      "IDK不存在于词向量中\n",
      "Dealing不存在于词向量中\n",
      "on)不存在于词向量中\n",
      "Melody不存在于词向量中\n",
      "thread)不存在于词向量中\n",
      "the...|||Oh,不存在于词向量中\n",
      "building.不存在于词向量中\n",
      "daydreaming.不存在于词向量中\n",
      "information?不存在于词向量中\n",
      "land.不存在于词向量中\n",
      "Self,不存在于词向量中\n",
      "Enviado不存在于词向量中\n",
      "Cab不存在于词向量中\n",
      "SelfKill不存在于词向量中\n",
      "INFPs...不存在于词向量中\n",
      "G8141不存在于词向量中\n",
      "Support不存在于词向量中\n",
      "YOU'RE不存在于词向量中\n",
      "XNTJ不存在于词向量中\n",
      "whatnot,不存在于词向量中\n",
      "explore,不存在于词向量中\n",
      "sad...不存在于词向量中\n",
      "Openness不存在于词向量中\n",
      "(actually,不存在于词向量中\n",
      "Te-Fi不存在于词向量中\n",
      "stupid?不存在于词向量中\n",
      "email.不存在于词向量中\n",
      "(hence不存在于词向量中\n",
      "very...|||I'm不存在于词向量中\n",
      "Figure不存在于词向量中\n",
      "motives,不存在于词向量中\n",
      "Cant不存在于词向量中\n",
      "cigarettes.不存在于词向量中\n",
      "using...|||I不存在于词向量中\n",
      "would...|||I'm不存在于词向量中\n",
      "there)不存在于词向量中\n",
      "degrees,不存在于词向量中\n",
      "Told不存在于词向量中\n",
      "stable,不存在于词向量中\n",
      "conditions.不存在于词向量中\n",
      "poems.不存在于词向量中\n",
      "describe,不存在于词向量中\n",
      "and...|||There不存在于词向量中\n",
      "darkness.不存在于词向量中\n",
      "Kid不存在于词向量中\n",
      "play?不存在于词向量中\n",
      "alone...不存在于词向量中\n",
      "pregnant.不存在于词向量中\n",
      "draw.不存在于词向量中\n",
      "after...|||I不存在于词向量中\n",
      "society?不存在于词向量中\n",
      "abilities,不存在于词向量中\n",
      "Leadership不存在于词向量中\n",
      "sometime.不存在于词向量中\n",
      "A+不存在于词向量中\n",
      "Morning不存在于词向量中\n",
      "efficient.不存在于词向量中\n",
      "playing.不存在于词向量中\n",
      "observations,不存在于词向量中\n",
      "confusion,不存在于词向量中\n",
      "like...'不存在于词向量中\n",
      "weird?不存在于词向量中\n",
      "worked,不存在于词向量中\n",
      "offer,不存在于词向量中\n",
      "grumpy,不存在于词向量中\n",
      "Female.不存在于词向量中\n",
      "visual,不存在于词向量中\n",
      "(do不存在于词向量中\n",
      "row.不存在于词向量中\n",
      "cookies,不存在于词向量中\n",
      "Blues不存在于词向量中\n",
      "between...|||I不存在于词向量中\n",
      "worlds.不存在于词向量中\n",
      "on...|||You不存在于词向量中\n",
      "'Why不存在于词向量中\n",
      "Whilst不存在于词向量中\n",
      "and...|||1.不存在于词向量中\n",
      "Belgium不存在于词向量中\n",
      "(either不存在于词向量中\n",
      "Mom's不存在于词向量中\n",
      "(Te)不存在于词向量中\n",
      "),不存在于词向量中\n",
      "Ross不存在于词向量中\n",
      "behavior?不存在于词向量中\n",
      "chess.不存在于词向量中\n",
      "(Why?)不存在于词向量中\n",
      "at...|||I'm不存在于词向量中\n",
      "useless,不存在于词向量中\n",
      "Ability不存在于词向量中\n",
      "can...|||I'm不存在于词向量中\n",
      "Miley不存在于词向量中\n",
      "family)不存在于词向量中\n",
      "Kant不存在于词向量中\n",
      "ENFP's,不存在于词向量中\n",
      "discipline.不存在于词向量中\n",
      "begin.不存在于词向量中\n",
      "Teen不存在于词向量中\n",
      "Joey不存在于词向量中\n",
      "they,不存在于词向量中\n",
      "ironic,不存在于词向量中\n",
      "sober.不存在于词向量中\n",
      "Aussie不存在于词向量中\n",
      "ears,不存在于词向量中\n",
      "ISTJ)不存在于词向量中\n",
      "Doom不存在于词向量中\n",
      "Scientists不存在于词向量中\n",
      "Grow不存在于词向量中\n",
      "entertainment.不存在于词向量中\n",
      "Edgar不存在于词向量中\n",
      "haha..不存在于词向量中\n",
      "papers,不存在于词向量中\n",
      "Yep不存在于词向量中\n",
      "Apocalypse不存在于词向量中\n",
      "Everyone's不存在于词向量中\n",
      "closed,不存在于词向量中\n",
      "gossip,不存在于词向量中\n",
      "higher.不存在于词向量中\n",
      "Door不存在于词向量中\n",
      "Hobbies不存在于词向量中\n",
      "Inner不存在于词向量中\n",
      "'No,不存在于词向量中\n",
      "some...|||I'm不存在于词向量中\n",
      "wings.不存在于词向量中\n",
      "mountains,不存在于词向量中\n",
      "10/10不存在于词向量中\n",
      "Dawn不存在于词向量中\n",
      "quietly,不存在于词向量中\n",
      "unstable,不存在于词向量中\n",
      "to...|||You're不存在于词向量中\n",
      "cliche,不存在于词向量中\n",
      "trustworthy,不存在于词向量中\n",
      "wing,不存在于词向量中\n",
      "ugh.不存在于词向量中\n",
      "20's,不存在于词向量中\n",
      "military,不存在于词向量中\n",
      "Downey不存在于词向量中\n",
      "come...|||I不存在于词向量中\n",
      "Frankly,不存在于词向量中\n",
      "hard...|||I不存在于词向量中\n",
      "mbti.不存在于词向量中\n",
      "Crystal不存在于词向量中\n",
      "Moon:不存在于词向量中\n",
      "daughter's不存在于词向量中\n",
      "decide,不存在于词向量中\n",
      "is...|||It's不存在于词向量中\n",
      "food?不存在于词向量中\n",
      "last...|||I不存在于词向量中\n",
      "warning,不存在于词向量中\n",
      "lol|||I'm不存在于词向量中\n",
      "judgment.不存在于词向量中\n",
      "time.|||I'm不存在于词向量中\n",
      "blah.不存在于词向量中\n",
      "(same不存在于词向量中\n",
      "Baptist不存在于词向量中\n",
      "distant.不存在于词向量中\n",
      "dramatic,不存在于词向量中\n",
      "novels,不存在于词向量中\n",
      "usually...|||I不存在于词向量中\n",
      "sensor,不存在于词向量中\n",
      "Solid不存在于词向量中\n",
      "loss,不存在于词向量中\n",
      "adventure.不存在于词向量中\n",
      "show?不存在于词向量中\n",
      "Ss不存在于词向量中\n",
      "Potential不存在于词向量中\n",
      "Sean不存在于词向量中\n",
      "mark,不存在于词向量中\n",
      "you...|||When不存在于词向量中\n",
      "productivity.不存在于词向量中\n",
      "Ivy不存在于词向量中\n",
      "ill,不存在于词向量中\n",
      "England.不存在于词向量中\n",
      "Skywalker不存在于词向量中\n",
      "Spiritual不存在于词向量中\n",
      "feeling...不存在于词向量中\n",
      "Royal不存在于词向量中\n",
      "appealing,不存在于词向量中\n",
      "ethics,不存在于词向量中\n",
      "fix,不存在于词向量中\n",
      "fields.不存在于词向量中\n",
      "Florida不存在于词向量中\n",
      "ignorant.不存在于词向量中\n",
      "episodes.不存在于词向量中\n",
      "is...|||It不存在于词向量中\n",
      "Ti?不存在于词向量中\n",
      "Pope不存在于词向量中\n",
      "sentences.不存在于词向量中\n",
      "extrovert?不存在于词向量中\n",
      "understand...|||I不存在于词向量中\n",
      "miserable.不存在于词向量中\n",
      "Firefly不存在于词向量中\n",
      "sociopath.不存在于词向量中\n",
      "my...|||That不存在于词向量中\n",
      "the...|||To不存在于词向量中\n",
      "shopping.不存在于词向量中\n",
      "Ni?不存在于词向量中\n",
      "words?不存在于词向量中\n",
      "Titan不存在于词向量中\n",
      "categories.不存在于词向量中\n",
      "liking.不存在于词向量中\n",
      "IxFx不存在于词向量中\n",
      "morning?不存在于词向量中\n",
      "agenda.不存在于词向量中\n",
      "are...|||The不存在于词向量中\n",
      "Hank不存在于词向量中\n",
      "assumption.不存在于词向量中\n",
      "cheating.不存在于词向量中\n",
      "virgin.不存在于词向量中\n",
      "Visionary不存在于词向量中\n",
      ":D'不存在于词向量中\n",
      "Guitar不存在于词向量中\n",
      "waste.不存在于词向量中\n",
      "fields,不存在于词向量中\n",
      "mentality,不存在于词向量中\n",
      "desire,不存在于词向量中\n",
      "'Yeah不存在于词向量中\n",
      "Value不存在于词向量中\n",
      "often...|||I不存在于词向量中\n",
      "unnecessary.不存在于词向量中\n",
      "souls.不存在于词向量中\n",
      "poor.不存在于词向量中\n",
      "Grandma不存在于词向量中\n",
      "(ENTP)不存在于词向量中\n",
      "develop.不存在于词向量中\n",
      "Verbal不存在于词向量中\n",
      "react,不存在于词向量中\n",
      "smoking,不存在于词向量中\n",
      "a...|||And不存在于词向量中\n",
      "Kung不存在于词向量中\n",
      "Pottermore不存在于词向量中\n",
      "Parents不存在于词向量中\n",
      "the...|||There不存在于词向量中\n",
      "Compare不存在于词向量中\n",
      "Practical不存在于词向量中\n",
      "or...|||When不存在于词向量中\n",
      "boots,不存在于词向量中\n",
      "'Not不存在于词向量中\n",
      "breath.不存在于词向量中\n",
      "pass,不存在于词向量中\n",
      "manipulated,不存在于词向量中\n",
      "self?不存在于词向量中\n",
      "handed,不存在于词向量中\n",
      "cars?不存在于词向量中\n",
      "cards,不存在于词向量中\n",
      "kidding?不存在于词向量中\n",
      "Act不存在于词向量中\n",
      "mathematics,不存在于词向量中\n",
      "People,不存在于词向量中\n",
      "score,不存在于词向量中\n",
      "behaviors,不存在于词向量中\n",
      "but...|||The不存在于词向量中\n",
      "expensive,不存在于词向量中\n",
      "(Even不存在于词向量中\n",
      "heck,不存在于词向量中\n",
      "insults,不存在于词向量中\n",
      "tested,不存在于词向量中\n",
      "finished,不存在于词向量中\n",
      "Military不存在于词向量中\n",
      "security.不存在于词向量中\n",
      "DAMN不存在于词向量中\n",
      "noise.不存在于词向量中\n",
      "an...|||You不存在于词向量中\n",
      "...|||To不存在于词向量中\n",
      "player.不存在于词向量中\n",
      "long?不存在于词向量中\n",
      "back...不存在于词向量中\n",
      "guy...不存在于词向量中\n",
      "Ne-Ti不存在于词向量中\n",
      "importance.不存在于词向量中\n",
      "wealth,不存在于词向量中\n",
      "Me.不存在于词向量中\n",
      "Italian,不存在于词向量中\n",
      "drinking.不存在于词向量中\n",
      "Benjamin不存在于词向量中\n",
      "chess,不存在于词向量中\n",
      "ride.不存在于词向量中\n",
      "lunch,不存在于词向量中\n",
      "balanced.不存在于词向量中\n",
      "maths,不存在于词向量中\n",
      "neat,不存在于词向量中\n",
      "consistent.不存在于词向量中\n",
      "method,不存在于词向量中\n",
      "place.|||I不存在于词向量中\n",
      "either.|||I不存在于词向量中\n",
      "boys,不存在于词向量中\n",
      "my...|||If不存在于词向量中\n",
      "ball.不存在于词向量中\n",
      "sport,不存在于词向量中\n",
      "third,不存在于词向量中\n",
      "succeed.不存在于词向量中\n",
      "Brazil不存在于词向量中\n",
      "me.|||This不存在于词向量中\n",
      "won.不存在于词向量中\n",
      "Scrolls不存在于词向量中\n",
      "waiting.不存在于词向量中\n",
      "IxxJ不存在于词向量中\n",
      "Studying不存在于词向量中\n",
      "calls.不存在于词向量中\n",
      "nuts,不存在于词向量中\n",
      "physical.不存在于词向量中\n",
      "Typically,不存在于词向量中\n",
      "before...|||I不存在于词向量中\n",
      "medicine,不存在于词向量中\n",
      "stupidity,不存在于词向量中\n",
      "(apparently不存在于词向量中\n",
      "glass.不存在于词向量中\n",
      "consequences,不存在于词向量中\n",
      "Ix92ll不存在于词向量中\n",
      "discussions.不存在于词向量中\n",
      "guilt.不存在于词向量中\n",
      "paranoid.不存在于词向量中\n",
      "either...不存在于词向量中\n",
      "narcissist.不存在于词向量中\n",
      "but...|||My不存在于词向量中\n",
      "answered,不存在于词向量中\n",
      "W不存在于词向量中\n",
      "wife's不存在于词向量中\n",
      "introspective,不存在于词向量中\n",
      "eh.不存在于词向量中\n",
      "Higher不存在于词向量中\n",
      "(eg.不存在于词向量中\n",
      "and...|||As不存在于词向量中\n",
      "stare.不存在于词向量中\n",
      "impressive.不存在于词向量中\n",
      "and...|||Not不存在于词向量中\n",
      "novels.不存在于词向量中\n",
      "Cafe,不存在于词向量中\n",
      "subject?不存在于词向量中\n",
      "resources.不存在于词向量中\n",
      "needy.不存在于词向量中\n",
      "(Don't不存在于词向量中\n",
      ":)|||As不存在于词向量中\n",
      "your...|||You不存在于词向量中\n",
      "Tonight不存在于词向量中\n",
      "my...|||You不存在于词向量中\n",
      "(perhaps不存在于词向量中\n",
      "Hans不存在于词向量中\n",
      "Lemme不存在于词向量中\n",
      "aspects,不存在于词向量中\n",
      "awareness.不存在于词向量中\n",
      "Pain不存在于词向量中\n",
      ":mellow:|||I不存在于词向量中\n",
      "embarrassing.不存在于词向量中\n",
      "chest,不存在于词向量中\n",
      "AMAZING不存在于词向量中\n",
      "China.不存在于词向量中\n",
      "so)不存在于词向量中\n",
      "Ne-Si不存在于词向量中\n",
      "questions...不存在于词向量中\n",
      "20s,不存在于词向量中\n",
      "scenes,不存在于词向量中\n",
      "Scores不存在于词向量中\n",
      "for...|||My不存在于词向量中\n",
      "INTj不存在于词向量中\n",
      "ANYONE不存在于词向量中\n",
      "ISTp不存在于词向量中\n",
      "forms.不存在于词向量中\n",
      "Bach不存在于词向量中\n",
      "bedroom.不存在于词向量中\n",
      "my...不存在于词向量中\n",
      "bird.不存在于词向量中\n",
      "That'd不存在于词向量中\n",
      "Communist不存在于词向量中\n",
      "very...不存在于词向量中\n",
      "Pacific不存在于词向量中\n",
      "(specifically不存在于词向量中\n",
      "Ideally,不存在于词向量中\n",
      "part)不存在于词向量中\n",
      "me...'不存在于词向量中\n",
      "see..不存在于词向量中\n",
      "driver's不存在于词向量中\n",
      "Everyone,不存在于词向量中\n",
      "manga,不存在于词向量中\n",
      "that...|||It's不存在于词向量中\n",
      "contrast,不存在于词向量中\n",
      "Heavy不存在于词向量中\n",
      "basement.不存在于词向量中\n",
      "Line不存在于词向量中\n",
      "ideas?不存在于词向量中\n",
      "help...不存在于词向量中\n",
      "or...不存在于词向量中\n",
      "ENFJ!不存在于词向量中\n",
      "mum,不存在于词向量中\n",
      "living?不存在于词向量中\n",
      "O_o不存在于词向量中\n",
      ":wink:|||I'm不存在于词向量中\n",
      "Switzerland不存在于词向量中\n",
      "Savage不存在于词向量中\n",
      "issue?不存在于词向量中\n",
      "Bloody不存在于词向量中\n",
      "Hobbes不存在于词向量中\n",
      "'He不存在于词向量中\n",
      "right?)不存在于词向量中\n",
      "Marina不存在于词向量中\n",
      "'No不存在于词向量中\n",
      "hearts.不存在于词向量中\n",
      "category,不存在于词向量中\n",
      "mad?不存在于词向量中\n",
      "Taken不存在于词向量中\n",
      "laughter.不存在于词向量中\n",
      "Linkin不存在于词向量中\n",
      "stack.不存在于词向量中\n",
      "suggestion,不存在于词向量中\n",
      "meal,不存在于词向量中\n",
      "relevant,不存在于词向量中\n",
      "i.e.,不存在于词向量中\n",
      "sx/sp.不存在于词向量中\n",
      ":)|||In不存在于词向量中\n",
      "cheap,不存在于词向量中\n",
      "was...|||My不存在于词向量中\n",
      "Asperger不存在于词向量中\n",
      "online?不存在于词向量中\n",
      "um...不存在于词向量中\n",
      "moving,不存在于词向量中\n",
      "it...|||This不存在于词向量中\n",
      "sciences.不存在于词向量中\n",
      "Psychology.不存在于词向量中\n",
      "Jessica不存在于词向量中\n",
      "Hands不存在于词向量中\n",
      "racist.不存在于词向量中\n",
      "here....不存在于词向量中\n",
      "mean...|||I不存在于词向量中\n",
      "talkative.不存在于词向量中\n",
      "INTJ|||I不存在于词向量中\n",
      "Knights不存在于词向量中\n",
      "ILI不存在于词向量中\n",
      "condition,不存在于词向量中\n",
      "Z936L不存在于词向量中\n",
      "Functions?不存在于词向量中\n",
      "welcome!|||Hiya不存在于词向量中\n",
      "channel.不存在于词向量中\n",
      "cheating,不存在于词向量中\n",
      "them.|||I'm不存在于词向量中\n",
      "auxiliary.不存在于词向量中\n",
      "Bebop不存在于词向量中\n",
      "ENTP's.不存在于词向量中\n",
      "saying...不存在于词向量中\n",
      "Saturday,不存在于词向量中\n",
      "Senior不存在于词向量中\n",
      "Media不存在于词向量中\n",
      "there'd不存在于词向量中\n",
      "somebody's不存在于词向量中\n",
      "A...|||I不存在于词向量中\n",
      "ENFJ)不存在于词向量中\n",
      "Trump's不存在于词向量中\n",
      "Warrior不存在于词向量中\n",
      "initially,不存在于词向量中\n",
      "share?不存在于词向量中\n",
      "attacks,不存在于词向量中\n",
      "...|||Not不存在于词向量中\n",
      "enneagram?不存在于词向量中\n",
      "Ideas不存在于词向量中\n",
      "Alas,不存在于词向量中\n",
      "(me)不存在于词向量中\n",
      "Hufflepuff.不存在于词向量中\n",
      "plus,不存在于词向量中\n",
      "majority.不存在于词向量中\n",
      "THAT'S不存在于词向量中\n",
      "Pandora不存在于词向量中\n",
      "decade.不存在于词向量中\n",
      "enthusiastic,不存在于词向量中\n",
      "Darcy不存在于词向量中\n",
      "senses,不存在于词向量中\n",
      "basic,不存在于词向量中\n",
      "respectively.不存在于词向量中\n",
      "isolation.不存在于词向量中\n",
      "fighting.不存在于词向量中\n",
      "Orwell不存在于词向量中\n",
      "irl,不存在于词向量中\n",
      "missing,不存在于词向量中\n",
      "nah,不存在于词向量中\n",
      "suicide?不存在于词向量中\n",
      "times)不存在于词向量中\n",
      "E.g.不存在于词向量中\n",
      "must.不存在于词向量中\n",
      "Comedy不存在于词向量中\n",
      ";)|||I'm不存在于词向量中\n",
      "kitty.不存在于词向量中\n",
      "college?不存在于词向量中\n",
      "just...|||This不存在于词向量中\n",
      "(As不存在于词向量中\n",
      "Disorder,不存在于词向量中\n",
      "or...|||The不存在于词向量中\n",
      "irritating.不存在于词向量中\n",
      "LOTR不存在于词向量中\n",
      "Machiavelli不存在于词向量中\n",
      "Karl不存在于词向量中\n",
      "snow,不存在于词向量中\n",
      "beach.不存在于词向量中\n",
      "guesses.不存在于词向量中\n",
      "joy,不存在于词向量中\n",
      "thinks,不存在于词向量中\n",
      "be...|||The不存在于词向量中\n",
      "Mi不存在于词向量中\n",
      "NPs不存在于词向量中\n",
      "net.不存在于词向量中\n",
      "beforehand,不存在于词向量中\n",
      "challenges.不存在于词向量中\n",
      "Fi-dom.不存在于词向量中\n",
      "me....|||I不存在于词向量中\n",
      "a...|||There不存在于词向量中\n",
      "Intj不存在于词向量中\n",
      "Network不存在于词向量中\n",
      "tradition.不存在于词向量中\n",
      "xSFJ不存在于词向量中\n",
      "phase,不存在于词向量中\n",
      "Ain't不存在于词向量中\n",
      "obsession.不存在于词向量中\n",
      "yourselves.不存在于词向量中\n",
      "Lad不存在于词向量中\n",
      "Procrastination不存在于词向量中\n",
      "people...|||My不存在于词向量中\n",
      "hero,不存在于词向量中\n",
      "that...|||Yes,不存在于词向量中\n",
      "I'm...'不存在于词向量中\n",
      "park.不存在于词向量中\n",
      "isn't...|||I不存在于词向量中\n",
      "INTX不存在于词向量中\n",
      "be.|||I不存在于词向量中\n",
      "Scientist不存在于词向量中\n",
      "Coldplay不存在于词向量中\n",
      "SURE不存在于词向量中\n",
      "singing.不存在于词向量中\n",
      "socially,不存在于词向量中\n",
      "handle,不存在于词向量中\n",
      "reliable,不存在于词向量中\n",
      "artistic,不存在于词向量中\n",
      "Spending不存在于词向量中\n",
      "here!|||I不存在于词向量中\n",
      "genres.不存在于词向量中\n",
      "Quantum不存在于词向量中\n",
      "huge,不存在于词向量中\n",
      "Source:不存在于词向量中\n",
      "reason.|||I不存在于词向量中\n",
      "night's不存在于词向量中\n",
      "me.|||It's不存在于词向量中\n",
      "50/50.不存在于词向量中\n",
      "Kylo不存在于词向量中\n",
      "Reasons不存在于词向量中\n",
      "mark.不存在于词向量中\n",
      "And...不存在于词向量中\n",
      "Monkey不存在于词向量中\n",
      "this).不存在于词向量中\n",
      "boredom,不存在于词向量中\n",
      "Mockingbird不存在于词向量中\n",
      "helping.不存在于词向量中\n",
      "cafe.不存在于词向量中\n",
      "Hit不存在于词向量中\n",
      "bachelor's不存在于词向量中\n",
      "<3|||I'm不存在于词向量中\n",
      "Agent不存在于词向量中\n",
      ":)|||i不存在于词向量中\n",
      "...|||Why不存在于词向量中\n",
      "Sugar不存在于词向量中\n",
      "Autism不存在于词向量中\n",
      "tiring.不存在于词向量中\n",
      "ME,不存在于词向量中\n",
      "AFTER不存在于词向量中\n",
      "Approach不存在于词向量中\n",
      "out..不存在于词向量中\n",
      "grass,不存在于词向量中\n",
      "distracted,不存在于词向量中\n",
      "introverted?不存在于词向量中\n",
      "FE不存在于词向量中\n",
      ":confused:|||I不存在于词向量中\n",
      "friends..不存在于词向量中\n",
      "Please.不存在于词向量中\n",
      "Punch不存在于词向量中\n",
      "open-minded,不存在于词向量中\n",
      "Casual不存在于词向量中\n",
      "'Have不存在于词向量中\n",
      "explain?不存在于词向量中\n",
      "fails,不存在于词向量中\n",
      "Celtic不存在于词向量中\n",
      "pregnant,不存在于词向量中\n",
      "comedy,不存在于词向量中\n",
      "encouragement.不存在于词向量中\n",
      "(Ni不存在于词向量中\n",
      "way),不存在于词向量中\n",
      "son.不存在于词向量中\n",
      "home...不存在于词向量中\n",
      "attached.不存在于词向量中\n",
      "-A不存在于词向量中\n",
      "explore.不存在于词向量中\n",
      "an...|||This不存在于词向量中\n",
      "YOU,不存在于词向量中\n",
      "forgot.不存在于词向量中\n",
      "that...|||Well,不存在于词向量中\n",
      "request.不存在于词向量中\n",
      "Student不存在于词向量中\n",
      "rarely,不存在于词向量中\n",
      "Indiana不存在于词向量中\n",
      "BAD不存在于词向量中\n",
      "miss.不存在于词向量中\n",
      "him.|||I不存在于词向量中\n",
      "sociopath,不存在于词向量中\n",
      "Goodbye不存在于词向量中\n",
      "amount.不存在于词向量中\n",
      "Exercise不存在于词向量中\n",
      "intuitives,不存在于词向量中\n",
      "Doc不存在于词向量中\n",
      "In...|||I不存在于词向量中\n",
      "Aww,不存在于词向量中\n",
      "...you不存在于词向量中\n",
      "blog,不存在于词向量中\n",
      "btw)不存在于词向量中\n",
      "Intuition.不存在于词向量中\n",
      "within.不存在于词向量中\n",
      "watching,不存在于词向量中\n",
      "myself).不存在于词向量中\n",
      "lessons,不存在于词向量中\n",
      "Wicked不存在于词向量中\n",
      "critical.不存在于词向量中\n",
      "if...'不存在于词向量中\n",
      "mask,不存在于词向量中\n",
      "me...but不存在于词向量中\n",
      "another?不存在于词向量中\n",
      "professional,不存在于词向量中\n",
      "contribute.不存在于词向量中\n",
      "resist.不存在于词向量中\n",
      "Sure.不存在于词向量中\n",
      "bad...|||I不存在于词向量中\n",
      "enthusiasm.不存在于词向量中\n",
      "Calm不存在于词向量中\n",
      "houses,不存在于词向量中\n",
      "surprising.不存在于词向量中\n",
      "knowledge?不存在于词向量中\n",
      ":)|||Well,不存在于词向量中\n",
      "Simpsons不存在于词向量中\n",
      "got...|||I不存在于词向量中\n",
      "items.不存在于词向量中\n",
      "''不存在于词向量中\n",
      "Essentially,不存在于词向量中\n",
      "a...|||Yeah,不存在于词向量中\n",
      "wedding.不存在于词向量中\n",
      "as...|||My不存在于词向量中\n",
      "HP不存在于词向量中\n",
      "that....不存在于词向量中\n",
      "favourite.不存在于词向量中\n",
      "I...|||Yes不存在于词向量中\n",
      ":tongue:)不存在于词向量中\n",
      "carefully.不存在于词向量中\n",
      "obsessive,不存在于词向量中\n",
      "evil?不存在于词向量中\n",
      "uh...不存在于词向量中\n",
      "Madoka不存在于词向量中\n",
      "Angelina不存在于词向量中\n",
      "you...|||Well,不存在于词向量中\n",
      "really...|||I'm不存在于词向量中\n",
      "arms.不存在于词向量中\n",
      "Carol不存在于词向量中\n",
      "arguing.不存在于词向量中\n",
      "SAY不存在于词向量中\n",
      "others.|||I不存在于词向量中\n",
      "I...|||No不存在于词向量中\n",
      "expressive.不存在于词向量中\n",
      "of...|||For不存在于词向量中\n",
      "imo,不存在于词向量中\n",
      "real...|||I不存在于词向量中\n",
      "WHERE不存在于词向量中\n",
      "days...不存在于词向量中\n",
      "Which,不存在于词向量中\n",
      "in...|||It's不存在于词向量中\n",
      "speaker.不存在于词向量中\n",
      "twenties.不存在于词向量中\n",
      "(low不存在于词向量中\n",
      "Ideal不存在于词向量中\n",
      "sites,不存在于词向量中\n",
      "stone.不存在于词向量中\n",
      "Lake不存在于词向量中\n",
      "websites,不存在于词向量中\n",
      "FPS不存在于词向量中\n",
      "Characteristics不存在于词向量中\n",
      "error,不存在于词向量中\n",
      "'how不存在于词向量中\n",
      "garbage.不存在于词向量中\n",
      "enemy.不存在于词向量中\n",
      "crushes,不存在于词向量中\n",
      "here).不存在于词向量中\n",
      "getting...|||I不存在于词向量中\n",
      "of...|||In不存在于词向量中\n",
      "to...|||Do不存在于词向量中\n",
      "Sir不存在于词向量中\n",
      "Harley不存在于词向量中\n",
      "Garden不存在于词向量中\n",
      "sincerely,不存在于词向量中\n",
      "defensive,不存在于词向量中\n",
      "revenge.不存在于词向量中\n",
      "Enfps不存在于词向量中\n",
      "experienced,不存在于词向量中\n",
      "put...|||I不存在于词向量中\n",
      "learned?不存在于词向量中\n",
      "So...|||I不存在于词向量中\n",
      ".-.不存在于词向量中\n",
      "cruel.不存在于词向量中\n",
      "Prepare不存在于词向量中\n",
      "Tesla不存在于词向量中\n",
      "Tiger不存在于词向量中\n",
      "fully.不存在于词向量中\n",
      "perfectionist,不存在于词向量中\n",
      "apply.不存在于词向量中\n",
      "miserable,不存在于词向量中\n",
      "creepy,不存在于词向量中\n",
      "up..不存在于词向量中\n",
      "resources,不存在于词向量中\n",
      "Digital不存在于词向量中\n",
      "integrity.不存在于词向量中\n",
      "clever.不存在于词向量中\n",
      "Hence,不存在于词向量中\n",
      "Form不存在于词向量中\n",
      "tennis,不存在于词向量中\n",
      "become,不存在于词向量中\n",
      "The...|||I'm不存在于词向量中\n",
      "breakup.不存在于词向量中\n",
      "Sweden,不存在于词向量中\n",
      "insensitive.不存在于词向量中\n",
      "photography.不存在于词向量中\n",
      "when...|||I'm不存在于词向量中\n",
      "F's不存在于词向量中\n",
      "totally.不存在于词向量中\n",
      "Harrison不存在于词向量中\n",
      "Quote不存在于词向量中\n",
      "porn,不存在于词向量中\n",
      "judge.不存在于词向量中\n",
      "(any不存在于词向量中\n",
      "Fe-dom不存在于词向量中\n",
      "ProcessLevel不存在于词向量中\n",
      "engineer,不存在于词向量中\n",
      "Spears不存在于词向量中\n",
      "lesson.不存在于词向量中\n",
      "traveling.不存在于词向量中\n",
      "Fi...不存在于词向量中\n",
      "was?不存在于词向量中\n",
      "Mbti不存在于词向量中\n",
      "predictable.不存在于词向量中\n",
      "violin,不存在于词向量中\n",
      "breakdown.不存在于词向量中\n",
      "Black,不存在于词向量中\n",
      "(A不存在于词向量中\n",
      "I...|||Haha,不存在于词向量中\n",
      "Egypt不存在于词向量中\n",
      "size,不存在于词向量中\n",
      "that...|||It不存在于词向量中\n",
      "Spent不存在于词向量中\n",
      "Tapatalk'不存在于词向量中\n",
      "clothing,不存在于词向量中\n",
      "Relations不存在于词向量中\n",
      "casual,不存在于词向量中\n",
      "(Is不存在于词向量中\n",
      "word)不存在于词向量中\n",
      "a...|||A不存在于词向量中\n",
      "only)不存在于词向量中\n",
      "while...|||I不存在于词向量中\n",
      "people'不存在于词向量中\n",
      "dichotomy.不存在于词向量中\n",
      "the...|||One不存在于词向量中\n",
      "least).不存在于词向量中\n",
      "not).不存在于词向量中\n",
      "Occasionally,不存在于词向量中\n",
      "up'不存在于词向量中\n",
      "months)不存在于词向量中\n",
      "danger.不存在于词向量中\n",
      "to...|||There不存在于词向量中\n",
      "intended.不存在于词向量中\n",
      "Haha...不存在于词向量中\n",
      "Face:不存在于词向量中\n",
      "logically,不存在于词向量中\n",
      "Slightly不存在于词向量中\n",
      "insecurity,不存在于词向量中\n",
      "played.不存在于词向量中\n",
      "INTJ).不存在于词向量中\n",
      "Cream不存在于词向量中\n",
      "NY不存在于词向量中\n",
      "past?不存在于词向量中\n",
      "supportive.不存在于词向量中\n",
      "household.不存在于词向量中\n",
      "ESXP不存在于词向量中\n",
      "suddenly,不存在于词向量中\n",
      "EU不存在于词向量中\n",
      "Year's不存在于词向量中\n",
      "This...|||I不存在于词向量中\n",
      "INFp不存在于词向量中\n",
      "round.不存在于词向量中\n",
      "you.|||I'm不存在于词向量中\n",
      "computers,不存在于词向量中\n",
      "pie.不存在于词向量中\n",
      "idealistic.不存在于词向量中\n",
      "neat.不存在于词向量中\n",
      "great...|||I不存在于词向量中\n",
      "colour,不存在于词向量中\n",
      "dirty,不存在于词向量中\n",
      "wings,不存在于词向量中\n",
      "us...|||I不存在于词向量中\n",
      "guy)不存在于词向量中\n",
      "(read不存在于词向量中\n",
      "temper,不存在于词向量中\n",
      "considered.不存在于词向量中\n",
      "that...|||When不存在于词向量中\n",
      "high...|||I不存在于词向量中\n",
      "powerful,不存在于词向量中\n",
      "theme.不存在于词向量中\n",
      "Hmm..不存在于词向量中\n",
      "liar.不存在于词向量中\n",
      "analogy,不存在于词向量中\n",
      "ENTP's,不存在于词向量中\n",
      "superior,不存在于词向量中\n",
      "superficial.不存在于词向量中\n",
      "bossy,不存在于词向量中\n",
      "Sensory不存在于词向量中\n",
      "Initially不存在于词向量中\n",
      "exception.不存在于词向量中\n",
      "be...|||I've不存在于词向量中\n",
      "heroes.不存在于词向量中\n",
      "biased.不存在于词向量中\n",
      "NOTHING不存在于词向量中\n",
      "source,不存在于词向量中\n",
      "crisis.不存在于词向量中\n",
      "Obvious不存在于词向量中\n",
      "EDM不存在于词向量中\n",
      "about.|||I不存在于词向量中\n",
      "Family,不存在于词向量中\n",
      "articles.不存在于词向量中\n",
      "(100%)不存在于词向量中\n",
      "adventures,不存在于词向量中\n",
      "Staying不存在于词向量中\n",
      "later...不存在于词向量中\n",
      "Lies不存在于词向量中\n",
      "for...|||I've不存在于词向量中\n",
      "people),不存在于词向量中\n",
      "hello.不存在于词向量中\n",
      "clouds,不存在于词向量中\n",
      "planet,不存在于词向量中\n",
      "Honest不存在于词向量中\n",
      "Liz不存在于词向量中\n",
      "traveling,不存在于词向量中\n",
      "new...|||I不存在于词向量中\n",
      "(was不存在于词向量中\n",
      ":D|||It's不存在于词向量中\n",
      "vacation.不存在于词向量中\n",
      "XXXX不存在于词向量中\n",
      "enough...|||I不存在于词向量中\n",
      "Sasuke不存在于词向量中\n",
      "bathroom.不存在于词向量中\n",
      "isn't,不存在于词向量中\n",
      "Music.不存在于词向量中\n",
      "4.0不存在于词向量中\n",
      "validation.不存在于词向量中\n",
      "you...|||It's不存在于词向量中\n",
      "sensitivity.不存在于词向量中\n",
      "why...不存在于词向量中\n",
      "sources,不存在于词向量中\n",
      "equally,不存在于词向量中\n",
      "lifestyle.不存在于词向量中\n",
      "Amazon.com:不存在于词向量中\n",
      "Main不存在于词向量中\n",
      "rate.不存在于词向量中\n",
      "Graphic不存在于词向量中\n",
      "SJWs不存在于词向量中\n",
      "3w4.不存在于词向量中\n",
      "handwriting.不存在于词向量中\n",
      "Likes不存在于词向量中\n",
      "Wood不存在于词向量中\n",
      "Silly不存在于词向量中\n",
      "noises.不存在于词向量中\n",
      "Katniss不存在于词向量中\n",
      "EVER.不存在于词向量中\n",
      "brown,不存在于词向量中\n",
      "improve.不存在于词向量中\n",
      "...|||How不存在于词向量中\n",
      "sea.不存在于词向量中\n",
      "(your不存在于词向量中\n",
      "cons.不存在于词向量中\n",
      "Jamie不存在于词向量中\n",
      "my...|||What不存在于词向量中\n",
      "Bachelor不存在于词向量中\n",
      "overwhelmed,不存在于词向量中\n",
      "privacy,不存在于词向量中\n",
      "Revenge不存在于词向量中\n",
      "gosh.不存在于词向量中\n",
      "Carlin不存在于词向量中\n",
      "based,不存在于词向量中\n",
      "rarely.不存在于词向量中\n",
      "combination,不存在于词向量中\n",
      "ease.不存在于词向量中\n",
      "Sensing,不存在于词向量中\n",
      "army.不存在于词向量中\n",
      "II.不存在于词向量中\n",
      "fans,不存在于词向量中\n",
      "clumsy,不存在于词向量中\n",
      "Marriage不存在于词向量中\n",
      "head)不存在于词向量中\n",
      "secrets.不存在于词向量中\n",
      "movement,不存在于词向量中\n",
      "extroversion.不存在于词向量中\n",
      "MMA不存在于词向量中\n",
      "Order不存在于词向量中\n",
      "Build不存在于词向量中\n",
      "I...|||Oh,不存在于词向量中\n",
      "1w9,不存在于词向量中\n",
      "Person:不存在于词向量中\n",
      "HELL不存在于词向量中\n",
      "Ravenclaw.不存在于词向量中\n",
      "called,不存在于词向量中\n",
      "lady,不存在于词向量中\n",
      "Lily不存在于词向量中\n",
      "Weasley不存在于词向量中\n",
      "basketball,不存在于词向量中\n",
      "syndrome.不存在于词向量中\n",
      "religions,不存在于词向量中\n",
      "crowds,不存在于词向量中\n",
      "LOL|||I不存在于词向量中\n",
      "Explain不存在于词向量中\n",
      "Humor不存在于词向量中\n",
      "an...|||I'm不存在于词向量中\n",
      "Tyler不存在于词向量中\n",
      "am)不存在于词向量中\n",
      "Infps不存在于词向量中\n",
      "intended,不存在于词向量中\n",
      "Fours不存在于词向量中\n",
      "or...|||If不存在于词向量中\n",
      "point...不存在于词向量中\n",
      "SP/SX不存在于词向量中\n",
      "meaningless.不存在于词向量中\n",
      "long...不存在于词向量中\n",
      "GT-P3100不存在于词向量中\n",
      "female?不存在于词向量中\n",
      "Spike不存在于词向量中\n",
      "EVEN不存在于词向量中\n",
      "web,不存在于词向量中\n",
      "different...不存在于词向量中\n",
      "think...|||I'm不存在于词向量中\n",
      "ambition.不存在于词向量中\n",
      "characteristics,不存在于词向量中\n",
      "No!不存在于词向量中\n",
      "Si-Ne不存在于词向量中\n",
      "supermarket,不存在于词向量中\n",
      "Ti-Ne不存在于词向量中\n",
      "Pilgrim不存在于词向量中\n",
      "exercising,不存在于词向量中\n",
      "days)不存在于词向量中\n",
      "depressing,不存在于词向量中\n",
      "what...|||I'm不存在于词向量中\n",
      "For...|||I不存在于词向量中\n",
      "Agreed.不存在于词向量中\n",
      "because...|||I'm不存在于词向量中\n",
      "Stage不存在于词向量中\n",
      "former,不存在于词向量中\n",
      "unusual,不存在于词向量中\n",
      "an...|||It不存在于词向量中\n",
      "...|||Hi不存在于词向量中\n",
      "(3不存在于词向量中\n",
      "considerate,不存在于词向量中\n",
      "H.不存在于词向量中\n",
      "all..不存在于词向量中\n",
      "(female)不存在于词向量中\n",
      "Bible.不存在于词向量中\n",
      "whatsoever,不存在于词向量中\n",
      "more.|||I不存在于词向量中\n",
      "famous,不存在于词向量中\n",
      "Avengers不存在于词向量中\n",
      "soccer,不存在于词向量中\n",
      "rather...|||I不存在于词向量中\n",
      "Mountain不存在于词向量中\n",
      "fishing,不存在于词向量中\n",
      "agnostic,不存在于词向量中\n",
      "lifetime,不存在于词向量中\n",
      "or...'不存在于词向量中\n",
      "harder,不存在于词向量中\n",
      "London,不存在于词向量中\n",
      "Wishing不存在于词向量中\n",
      "Flickr:不存在于词向量中\n",
      "oneself.不存在于词向量中\n",
      "Bay不存在于词向量中\n",
      "Batman.不存在于词向量中\n",
      "(using不存在于词向量中\n",
      "Storm不存在于词向量中\n",
      "compatible.不存在于词向量中\n",
      "net,不存在于词向量中\n",
      "validation,不存在于词向量中\n",
      "pretentious,不存在于词向量中\n",
      "risk,不存在于词向量中\n",
      "I...|||One不存在于词向量中\n",
      "manager,不存在于词向量中\n",
      "biology.不存在于词向量中\n",
      "heart.|||I不存在于词向量中\n",
      "(doesn't不存在于词向量中\n",
      "(Fi不存在于词向量中\n",
      "Aaron不存在于词向量中\n",
      "along...|||I不存在于词向量中\n",
      "Te?不存在于词向量中\n",
      "time),不存在于词向量中\n",
      "Se-dom不存在于词向量中\n",
      "24/7.不存在于词向量中\n",
      "Ni)不存在于词向量中\n",
      "persona.不存在于词向量中\n",
      "Socialism不存在于词向量中\n",
      "Europe.不存在于词向量中\n",
      "pair,不存在于词向量中\n",
      "(until不存在于词向量中\n",
      "shoulders,不存在于词向量中\n",
      "Veronica不存在于词向量中\n",
      "Chrome不存在于词向量中\n",
      "battle.不存在于词向量中\n",
      "doors,不存在于词向量中\n",
      "China,不存在于词向量中\n",
      "Renaissance不存在于词向量中\n",
      "mine)不存在于词向量中\n",
      "babies,不存在于词向量中\n",
      "coworkers,不存在于词向量中\n",
      "intellect,不存在于词向量中\n",
      "lame.不存在于词向量中\n",
      "Spektor不存在于词向量中\n",
      "Camus不存在于词向量中\n",
      "abused,不存在于词向量中\n",
      "restaurant,不存在于词向量中\n",
      "sensing.不存在于词向量中\n",
      "head.|||I不存在于词向量中\n",
      "Caffeine不存在于词向量中\n",
      "Marine不存在于词向量中\n",
      "girlfriend's不存在于词向量中\n",
      "lived.不存在于词向量中\n",
      ":)|||How不存在于词向量中\n",
      "Beta不存在于词向量中\n",
      "RIGHT不存在于词向量中\n",
      "Week不存在于词向量中\n",
      "Shell不存在于词向量中\n",
      "Monte不存在于词向量中\n",
      "Uh,不存在于词向量中\n",
      "Jung.不存在于词向量中\n",
      "property,不存在于词向量中\n",
      "it.|||Yeah,不存在于词向量中\n",
      "Cheese不存在于词向量中\n",
      "Alot不存在于词向量中\n",
      "clothing.不存在于词向量中\n",
      "L.不存在于词向量中\n",
      "Indie不存在于词向量中\n",
      "the...|||Don't不存在于词向量中\n",
      "default,不存在于词向量中\n",
      "(plus不存在于词向量中\n",
      "guess...|||I不存在于词向量中\n",
      "Harper不存在于词向量中\n",
      "supportive,不存在于词向量中\n",
      "up...|||I'm不存在于词向量中\n",
      "ended,不存在于词向量中\n",
      "Heaven不存在于词向量中\n",
      "not...|||The不存在于词向量中\n",
      "circles,不存在于词向量中\n",
      "Autumn不存在于词向量中\n",
      "Naranjo不存在于词向量中\n",
      "land,不存在于词向量中\n",
      "gave.不存在于词向量中\n",
      "hypothesis.不存在于词向量中\n",
      "100%,不存在于词向量中\n",
      "o.O不存在于词向量中\n",
      "candy.不存在于词向量中\n",
      "Lord,不存在于词向量中\n",
      "curious...不存在于词向量中\n",
      "to...|||Oh,不存在于词向量中\n",
      "more...|||I've不存在于词向量中\n",
      "how'd不存在于词向量中\n",
      "INXX不存在于词向量中\n",
      "elaborate,不存在于词向量中\n",
      "Hood不存在于词向量中\n",
      "Theme不存在于词向量中\n",
      "wrong...|||I不存在于词向量中\n",
      "arrogance.不存在于词向量中\n",
      "gift,不存在于词向量中\n",
      "NFJs不存在于词向量中\n",
      ":)|||Just不存在于词向量中\n",
      "decisive,不存在于词向量中\n",
      "I...|||Your不存在于词向量中\n",
      "true..不存在于词向量中\n",
      "dating?不存在于词向量中\n",
      "rant,不存在于词向量中\n",
      "Anthropology不存在于词向量中\n",
      "MS不存在于词向量中\n",
      "Orderliness不存在于词向量中\n",
      "capable,不存在于词向量中\n",
      "(through不存在于词向量中\n",
      "bunch,不存在于词向量中\n",
      "game?不存在于词向量中\n",
      "hearts,不存在于词向量中\n",
      "have...|||My不存在于词向量中\n",
      "ignored,不存在于词向量中\n",
      "Tale不存在于词向量中\n",
      "ours.不存在于词向量中\n",
      "that...|||As不存在于词向量中\n",
      "inspiration.不存在于词向量中\n",
      "bad...不存在于词向量中\n",
      "economy.不存在于词向量中\n",
      "roll.不存在于词向量中\n",
      "(almost)不存在于词向量中\n",
      "for...|||If不存在于词向量中\n",
      "head?不存在于词向量中\n",
      "King.不存在于词向量中\n",
      "Sincerely不存在于词向量中\n",
      "MBTI)不存在于词向量中\n",
      "Prime不存在于词向量中\n",
      "Sonic不存在于词向量中\n",
      "Conan不存在于词向量中\n",
      "Teach不存在于词向量中\n",
      "making...|||I不存在于词向量中\n",
      "selves.不存在于词向量中\n",
      "do),不存在于词向量中\n",
      "Temperament不存在于词向量中\n",
      "Pinkie不存在于词向量中\n",
      "violin.不存在于词向量中\n",
      "typed,不存在于词向量中\n",
      "one).不存在于词向量中\n",
      "fully,不存在于词向量中\n",
      "York,不存在于词向量中\n",
      "G不存在于词向量中\n",
      "Sons不存在于词向量中\n",
      "Lovers不存在于词向量中\n",
      "meal.不存在于词向量中\n",
      "Easter不存在于词向量中\n",
      ":happy:|||My不存在于词向量中\n",
      "Gay不存在于词向量中\n",
      "Yoda不存在于词向量中\n",
      "links.不存在于词向量中\n",
      "figure,不存在于词向量中\n",
      "ethics.不存在于词向量中\n",
      "song?不存在于词向量中\n",
      "Wayne不存在于词向量中\n",
      "using.不存在于词向量中\n",
      "INFj不存在于词向量中\n",
      "Album不存在于词向量中\n",
      "read...|||I不存在于词向量中\n",
      "Core不存在于词向量中\n",
      "nightmares.不存在于词向量中\n",
      "charge.不存在于词向量中\n",
      "perfectionist.不存在于词向量中\n",
      "Note,不存在于词向量中\n",
      "freak.不存在于词向量中\n",
      "Purple不存在于词向量中\n",
      "swimming.不存在于词向量中\n",
      "Mozart不存在于词向量中\n",
      "cultures.不存在于词向量中\n",
      "use...|||I不存在于词向量中\n",
      "ESxx不存在于词向量中\n",
      "Czech不存在于词向量中\n",
      "Cure不存在于词向量中\n",
      "De不存在于词向量中\n",
      "Speak不存在于词向量中\n",
      "Lonely不存在于词向量中\n",
      "Tears不存在于词向量中\n",
      "Lennon不存在于词向量中\n",
      "bat,不存在于词向量中\n",
      "worried.不存在于词向量中\n",
      "Oregon不存在于词向量中\n",
      "afternoon,不存在于词向量中\n",
      "reader,不存在于词向量中\n",
      "ALSO不存在于词向量中\n",
      "Japanese.不存在于词向量中\n",
      "Wait...不存在于词向量中\n",
      "foods,不存在于词向量中\n",
      "11,不存在于词向量中\n",
      "about...'不存在于词向量中\n",
      "Milk不存在于词向量中\n",
      "Cash不存在于词向量中\n",
      "Michelle不存在于词向量中\n",
      "intent.不存在于词向量中\n",
      "giving,不存在于词向量中\n",
      "more...|||My不存在于词向量中\n",
      "NPD不存在于词向量中\n",
      "cut.不存在于词向量中\n",
      "Chronicles不存在于词向量中\n",
      "Arya不存在于词向量中\n",
      "Victoria不存在于词向量中\n",
      "Dale不存在于词向量中\n",
      "Walter不存在于词向量中\n",
      "CANNOT不存在于词向量中\n",
      "(could不存在于词向量中\n",
      "is...|||If不存在于词向量中\n",
      "The.不存在于词向量中\n",
      "ABSOLUTELY不存在于词向量中\n",
      "injustice.不存在于词向量中\n",
      "Airbender不存在于词向量中\n",
      "Finn不存在于词向量中\n",
      "Bonus不存在于词向量中\n",
      "teaching.不存在于词向量中\n",
      "he...|||My不存在于词向量中\n",
      "House,不存在于词向量中\n",
      "states.不存在于词向量中\n",
      "tell...|||I不存在于词向量中\n",
      "are...|||It's不存在于词向量中\n",
      "Aw,不存在于词向量中\n",
      "bitter.不存在于词向量中\n",
      "FEELING不存在于词向量中\n",
      "hours)不存在于词向量中\n",
      "desires,不存在于词向量中\n",
      "dearly.不存在于词向量中\n",
      "(last不存在于词向量中\n",
      "quit,不存在于词向量中\n",
      "(hopefully)不存在于词向量中\n",
      "Valentines不存在于词向量中\n",
      "instinct,不存在于词向量中\n",
      "that.|||I'm不存在于词向量中\n",
      "anxiety?不存在于词向量中\n",
      "4s,不存在于词向量中\n",
      "birds.不存在于词向量中\n",
      ";D|||I不存在于词向量中\n",
      "Batman,不存在于词向量中\n",
      "Israel不存在于词向量中\n",
      "me.|||My不存在于词向量中\n",
      "more...'不存在于词向量中\n",
      "Saint不存在于词向量中\n",
      "enfj,不存在于词向量中\n",
      "Terrible不存在于词向量中\n",
      "Miller不存在于词向量中\n",
      "Mode不存在于词向量中\n",
      "Assassin's不存在于词向量中\n",
      "Drugs不存在于词向量中\n",
      "dreams?不存在于词向量中\n",
      "...|||There不存在于词向量中\n",
      "comparison,不存在于词向量中\n",
      "Ash不存在于词向量中\n",
      "gestures,不存在于词向量中\n",
      "polite.不存在于词向量中\n",
      "neighbor's不存在于词向量中\n",
      "opinionated,不存在于词向量中\n",
      "wasn't,不存在于词向量中\n",
      "K.不存在于词向量中\n",
      "classic.不存在于词向量中\n",
      "Ethical不存在于词向量中\n",
      "awake.不存在于词向量中\n",
      "know...|||I'm不存在于词向量中\n",
      "Financial不存在于词向量中\n",
      "Danish不存在于词向量中\n",
      "thin,不存在于词向量中\n",
      "Detective不存在于词向量中\n",
      "albums.不存在于词向量中\n",
      "Pearl不存在于词向量中\n",
      "Say,不存在于词向量中\n",
      "Chaos不存在于词向量中\n",
      "of...|||1.不存在于词向量中\n",
      "illusion.不存在于词向量中\n",
      "RPGs,不存在于词向量中\n",
      "dislike,不存在于词向量中\n",
      "Warm不存在于词向量中\n",
      "dislike.不存在于词向量中\n",
      "a...|||Dear不存在于词向量中\n",
      "'One不存在于词向量中\n",
      "presence.不存在于词向量中\n",
      "realized,不存在于词向量中\n",
      "rich,不存在于词向量中\n",
      "Life.不存在于词向量中\n",
      "glance,不存在于词向量中\n",
      "unhappy,不存在于词向量中\n",
      "accounts.不存在于词向量中\n",
      "you.|||The不存在于词向量中\n",
      "Spiderman不存在于词向量中\n",
      "Define不存在于词向量中\n",
      "Ne)不存在于词向量中\n",
      "(esp.不存在于词向量中\n",
      "me.|||When不存在于词向量中\n",
      "Tapatalk|||How不存在于词向量中\n",
      "Endless不存在于词向量中\n",
      ":-(不存在于词向量中\n",
      "gossip.不存在于词向量中\n",
      "fixed.不存在于词向量中\n",
      "that...|||That不存在于词向量中\n",
      "(rather不存在于词向量中\n",
      "girl)不存在于词向量中\n",
      "maybe...不存在于词向量中\n",
      "okay...不存在于词向量中\n",
      "bullies.不存在于词向量中\n",
      "Rome不存在于词向量中\n",
      "aloof.不存在于词向量中\n",
      "consider,不存在于词向量中\n",
      "procrastinating.不存在于词向量中\n",
      "Potter,不存在于词向量中\n",
      "Kenshin不存在于词向量中\n",
      "hmm.不存在于词向量中\n",
      "oblivious.不存在于词向量中\n",
      "cheat.不存在于词向量中\n",
      "lives?不存在于词向量中\n",
      "famous.不存在于词向量中\n",
      "racist,不存在于词向量中\n",
      "INFPish不存在于词向量中\n",
      "conscious.不存在于词向量中\n",
      "tree,不存在于词向量中\n",
      "ES不存在于词向量中\n",
      "purpose?不存在于词向量中\n",
      "a...|||Hey不存在于词向量中\n",
      "might.不存在于词向量中\n",
      "courage,不存在于词向量中\n",
      "subtle,不存在于词向量中\n",
      "vegetarian,不存在于词向量中\n",
      ":),不存在于词向量中\n",
      "empathize.不存在于词向量中\n",
      "OTHER不存在于词向量中\n",
      "Pooh不存在于词向量中\n",
      "twenties,不存在于词向量中\n",
      "OVER不存在于词向量中\n",
      "SOMEONE不存在于词向量中\n",
      "the...|||Do不存在于词向量中\n",
      "History,不存在于词向量中\n",
      "smell,不存在于词向量中\n",
      "suggested,不存在于词向量中\n",
      "source.不存在于词向量中\n",
      "Sunny不存在于词向量中\n",
      "school...不存在于词向量中\n",
      "majority,不存在于词向量中\n",
      "drinks,不存在于词向量中\n",
      "coworker.不存在于词向量中\n",
      "Aba不存在于词向量中\n",
      "School.不存在于词向量中\n",
      "escape.不存在于词向量中\n",
      "Unicorn不存在于词向量中\n",
      "judgmental.不存在于词向量中\n",
      "Pony不存在于词向量中\n",
      "BEFORE不存在于词向量中\n",
      "Superman不存在于词向量中\n",
      "(Like不存在于词向量中\n",
      "interesting?不存在于词向量中\n",
      "years.|||I不存在于词向量中\n",
      "so....不存在于词向量中\n",
      "9w8.不存在于词向量中\n",
      "istj,不存在于词向量中\n",
      "stores,不存在于词向量中\n",
      "FPs不存在于词向量中\n",
      "do).不存在于词向量中\n",
      "Well.不存在于词向量中\n",
      "it...but不存在于词向量中\n",
      "Happened不存在于词向量中\n",
      "nothing...|||I不存在于词向量中\n",
      "signals,不存在于词向量中\n",
      "Hmmm不存在于词向量中\n",
      "efficiently.不存在于词向量中\n",
      "Howl's不存在于词向量中\n",
      "man.|||I不存在于词向量中\n",
      "Christianity.不存在于词向量中\n",
      "ID不存在于词向量中\n",
      "people..不存在于词向量中\n",
      "tips,不存在于词向量中\n",
      "clutter.不存在于词向量中\n",
      "Tend不存在于词向量中\n",
      "five.不存在于词向量中\n",
      "converse.不存在于词向量中\n",
      "Scottish不存在于词向量中\n",
      "Maiden不存在于词向量中\n",
      "to...|||For不存在于词向量中\n",
      "Fine不存在于词向量中\n",
      "independence,不存在于词向量中\n",
      "have...|||You不存在于词向量中\n",
      "stick.不存在于词向量中\n",
      "ISTJ's.不存在于词向量中\n",
      "test...不存在于词向量中\n",
      "realize.不存在于词向量中\n",
      "tools,不存在于词向量中\n",
      "Lovely不存在于词向量中\n",
      "Miles不存在于词向量中\n",
      "you.'不存在于词向量中\n",
      "improvement.不存在于词向量中\n",
      "Congratulations,不存在于词向量中\n",
      "Fresh不存在于词向量中\n",
      "istp,不存在于词向量中\n",
      "already...不存在于词向量中\n",
      "tv,不存在于词向量中\n",
      "logically.不存在于词向量中\n",
      "the...|||First不存在于词向量中\n",
      "you...|||That's不存在于词向量中\n",
      "create,不存在于词向量中\n",
      ":).|||I不存在于词向量中\n",
      "Physics,不存在于词向量中\n",
      "touched.不存在于词向量中\n",
      "Odyssey不存在于词向量中\n",
      "Anytime不存在于词向量中\n",
      "gain.不存在于词向量中\n",
      "Gear不存在于词向量中\n",
      "Australia.不存在于词向量中\n",
      "Somewhat不存在于词向量中\n",
      "narcissistic,不存在于词向量中\n",
      "limited,不存在于词向量中\n",
      "as...|||The不存在于词向量中\n",
      "sexuality,不存在于词向量中\n",
      "denial.不存在于词向量中\n",
      "Shouldn't不存在于词向量中\n",
      "cave.不存在于词向量中\n",
      "meeting.不存在于词向量中\n",
      "seven,不存在于词向量中\n",
      "might,不存在于词向量中\n",
      "factor,不存在于词向量中\n",
      "viewpoint,不存在于词向量中\n",
      "Philip不存在于词向量中\n",
      "any?不存在于词向量中\n",
      "learner.不存在于词向量中\n",
      "(obviously不存在于词向量中\n",
      "garden,不存在于词向量中\n",
      "balanced,不存在于词向量中\n",
      "Cross不存在于词向量中\n",
      "giggle.不存在于词向量中\n",
      "Couple不存在于词向量中\n",
      "my...|||Thank不存在于词向量中\n",
      "THEIR不存在于词向量中\n",
      "6w7.不存在于词向量中\n",
      "wind,不存在于词向量中\n",
      "considered,不存在于词向量中\n",
      "get...|||I'm不存在于词向量中\n",
      "god?不存在于词向量中\n",
      "6w7,不存在于词向量中\n",
      "unrealistic.不存在于词向量中\n",
      "bag.不存在于词向量中\n",
      "Punk不存在于词向量中\n",
      "emotions...不存在于词向量中\n",
      "least...|||I不存在于词向量中\n",
      "measure.不存在于词向量中\n",
      "likes.不存在于词向量中\n",
      "and...|||Why不存在于词向量中\n",
      "Driving不存在于词向量中\n",
      "Architecture不存在于词向量中\n",
      "created,不存在于词向量中\n",
      "towards.不存在于词向量中\n",
      "species,不存在于词向量中\n",
      "THEM不存在于词向量中\n",
      "'Are不存在于词向量中\n",
      "hop,不存在于词向量中\n",
      "XNFP不存在于词向量中\n",
      "<---不存在于词向量中\n",
      "are...|||I've不存在于词向量中\n",
      "something)不存在于词向量中\n",
      "Istp不存在于词向量中\n",
      "w/o不存在于词向量中\n",
      "Fi/Fe不存在于词向量中\n",
      "labels,不存在于词向量中\n",
      "bird,不存在于词向量中\n",
      "almost...|||I不存在于词向量中\n",
      "Glee不存在于词向量中\n",
      "scientific,不存在于词向量中\n",
      "us.|||I不存在于词向量中\n",
      "Management不存在于词向量中\n",
      "to...|||Dear不存在于词向量中\n",
      "it...|||It's不存在于词向量中\n",
      "Ended不存在于词向量中\n",
      "RTS不存在于词向量中\n",
      "Artist不存在于词向量中\n",
      "bottom.不存在于词向量中\n",
      "Juliet不存在于词向量中\n",
      "Behind不存在于词向量中\n",
      "Math,不存在于词向量中\n",
      "Systems不存在于词向量中\n",
      "motivations.不存在于词向量中\n",
      "Card不存在于词向量中\n",
      "god...不存在于词向量中\n",
      "unknown.不存在于词向量中\n",
      "finished.不存在于词向量中\n",
      "football,不存在于词向量中\n",
      "out'不存在于词向量中\n",
      "vary.不存在于词向量中\n",
      "youtube,不存在于词向量中\n",
      "killed,不存在于词向量中\n",
      "ISFP!不存在于词向量中\n",
      "it.|||This不存在于词向量中\n",
      "century.不存在于词向量中\n",
      "hours...不存在于词向量中\n",
      "huge.不存在于词向量中\n",
      "Indeed不存在于词向量中\n",
      "intellect.不存在于词向量中\n",
      "day...|||I不存在于词向量中\n",
      "Twain不存在于词向量中\n",
      "of...|||That's不存在于词向量中\n",
      "Suppose不存在于词向量中\n",
      "isfp.不存在于词向量中\n",
      "one),不存在于词向量中\n",
      "II,不存在于词向量中\n",
      "partners,不存在于词向量中\n",
      "Helps不存在于词向量中\n",
      "Economics不存在于词向量中\n",
      "opportunity,不存在于词向量中\n",
      "ISFJ.|||I不存在于词向量中\n",
      "nap.不存在于词向量中\n",
      "said.|||I不存在于词向量中\n",
      "drink?不存在于词向量中\n",
      "Halo不存在于词向量中\n",
      "programmer.不存在于词向量中\n",
      "Julia不存在于词向量中\n",
      "Ugh不存在于词向量中\n",
      "Natural不存在于词向量中\n",
      "block.不存在于词向量中\n",
      "are..不存在于词向量中\n",
      "aswell.不存在于词向量中\n",
      "Smiling不存在于词向量中\n",
      "Funky不存在于词向量中\n",
      "away...|||I不存在于词向量中\n",
      "seasons.不存在于词向量中\n",
      "son's不存在于词向量中\n",
      "oil,不存在于词向量中\n",
      "Essentially不存在于词向量中\n",
      "leaving.不存在于词向量中\n",
      "carefully,不存在于词向量中\n",
      "ENTP.|||I不存在于词向量中\n",
      "my...|||It's不存在于词向量中\n",
      "7w8.不存在于词向量中\n",
      "sleep?不存在于词向量中\n",
      "Psychology,不存在于词向量中\n",
      "Isfp不存在于词向量中\n",
      "Career不存在于词向量中\n",
      "Studio不存在于词向量中\n",
      "Africa.不存在于词向量中\n",
      "sexual,不存在于词向量中\n",
      "me'不存在于词向量中\n",
      "until...|||I不存在于词向量中\n",
      "stuff...|||I不存在于词向量中\n",
      "Box不存在于词向量中\n",
      "statements,不存在于词向量中\n",
      "cake,不存在于词向量中\n",
      "Inferior:不存在于词向量中\n",
      "Independent不存在于词向量中\n",
      "shorts,不存在于词向量中\n",
      "retarded.不存在于词向量中\n",
      "post)不存在于词向量中\n",
      "Tritype不存在于词向量中\n",
      "trick.不存在于词向量中\n",
      "Feminine不存在于词向量中\n",
      "Pro不存在于词向量中\n",
      "Firefox不存在于词向量中\n",
      "SM-A500F不存在于词向量中\n",
      "Sodium不存在于词向量中\n",
      "...here's不存在于词向量中\n",
      "full,不存在于词向量中\n",
      "enough.|||I不存在于词向量中\n",
      "eachother.不存在于词向量中\n",
      "progress,不存在于词向量中\n",
      "behind,不存在于词向量中\n",
      "pizza.不存在于词向量中\n",
      "Ender's不存在于词向量中\n",
      "then.|||I不存在于词向量中\n",
      "dry.不存在于词向量中\n",
      "Republican不存在于词向量中\n",
      "numb.不存在于词向量中\n",
      "inaccurate.不存在于词向量中\n",
      "MBTI's不存在于词向量中\n",
      "voices.不存在于词向量中\n",
      "shit?不存在于词向量中\n",
      "IEI不存在于词向量中\n",
      "Cage不存在于词向量中\n",
      "often)不存在于词向量中\n",
      "(less不存在于词向量中\n",
      "dosen't不存在于词向量中\n",
      "piece,不存在于词向量中\n",
      "pure,不存在于词向量中\n",
      "ignorance,不存在于词向量中\n",
      "murder,不存在于词向量中\n",
      "insulting.不存在于词向量中\n",
      "essay,不存在于词向量中\n",
      "vibes,不存在于词向量中\n",
      "scores.不存在于词向量中\n",
      "train.不存在于词向量中\n",
      "of...|||There不存在于词向量中\n",
      "is...|||Thanks不存在于词向量中\n",
      "reading?不存在于词向量中\n",
      "used...|||I不存在于词向量中\n",
      "'Can不存在于词向量中\n",
      "poorly.不存在于词向量中\n",
      "sarcasm?不存在于词向量中\n",
      "drawings,不存在于词向量中\n",
      "begin,不存在于词向量中\n",
      "Vanilla不存在于词向量中\n",
      "time.|||sorry不存在于词向量中\n",
      "vulnerability.不存在于词向量中\n",
      "asking?不存在于词向量中\n",
      "author.不存在于词向量中\n",
      "camping,不存在于词向量中\n",
      "management,不存在于词向量中\n",
      "worthwhile.不存在于词向量中\n",
      "Cultural不存在于词向量中\n",
      "minor.不存在于词向量中\n",
      "'Good不存在于词向量中\n",
      "neck.不存在于词向量中\n",
      "fool,不存在于词向量中\n",
      "Beat不存在于词向量中\n",
      "Um不存在于词向量中\n",
      "Maternal不存在于词向量中\n",
      "Grandmother不存在于词向量中\n",
      "Greater不存在于词向量中\n",
      "stance.不存在于词向量中\n",
      "due.不存在于词向量中\n",
      "awake,不存在于词向量中\n",
      "60's不存在于词向量中\n",
      "makes...|||I不存在于词向量中\n",
      "bullied,不存在于词向量中\n",
      "(which,不存在于词向量中\n",
      "him)不存在于词向量中\n",
      "Feeler.不存在于词向量中\n",
      "I'm...|||You不存在于词向量中\n",
      "in...|||i不存在于词向量中\n",
      "curse,不存在于词向量中\n",
      "yourself.|||I不存在于词向量中\n",
      "own)不存在于词向量中\n",
      "and...|||Your不存在于词向量中\n",
      "Cannot不存在于词向量中\n",
      "actor.不存在于词向量中\n",
      "typings.不存在于词向量中\n",
      "power?不存在于词向量中\n",
      "9/10不存在于词向量中\n",
      "efficiency.不存在于词向量中\n",
      "Vladimir不存在于词向量中\n",
      "colours,不存在于词向量中\n",
      "n'不存在于词向量中\n",
      "uncommon.不存在于词向量中\n",
      "optimistic.不存在于词向量中\n",
      "4?不存在于词向量中\n",
      "Amanda不存在于词向量中\n",
      "span.不存在于词向量中\n",
      "Jake不存在于词向量中\n",
      "Sara不存在于词向量中\n",
      "rap,不存在于词向量中\n",
      "kids'不存在于词向量中\n",
      "viewpoint.不存在于词向量中\n",
      "unexpected.不存在于词向量中\n",
      "smarter,不存在于词向量中\n",
      "alive?不存在于词向量中\n",
      "(currently不存在于词向量中\n",
      "LIVE不存在于词向量中\n",
      "creation,不存在于词向量中\n",
      "bisexual.不存在于词向量中\n",
      "far)不存在于词向量中\n",
      "extravert,不存在于词向量中\n",
      "Perception不存在于词向量中\n",
      "cues,不存在于词向量中\n",
      "January.不存在于词向量中\n",
      "sea,不存在于词向量中\n",
      "not...|||I've不存在于词向量中\n",
      "simply...|||I不存在于词向量中\n",
      "Witch不存在于词向量中\n",
      "Edition不存在于词向量中\n",
      "card,不存在于词向量中\n",
      "wit,不存在于词向量中\n",
      "regardless.不存在于词向量中\n",
      "enemies.不存在于词向量中\n",
      "solved.不存在于词向量中\n",
      "Carrie不存在于词向量中\n",
      "Technically,不存在于词向量中\n",
      "Thinker,不存在于词向量中\n",
      "Biology,不存在于词向量中\n",
      "terrifying.不存在于词向量中\n",
      "shape.不存在于词向量中\n",
      "humorous,不存在于词向量中\n",
      "priceless.不存在于词向量中\n",
      "Bond不存在于词向量中\n",
      "you.|||You不存在于词向量中\n",
      "be...|||If不存在于词向量中\n",
      "i.e不存在于词向量中\n",
      "illogical,不存在于词向量中\n",
      "order):不存在于词向量中\n",
      "Vader不存在于词向量中\n",
      "Massive不存在于词向量中\n",
      "bullying,不存在于词向量中\n",
      "humanity's不存在于词向量中\n",
      "deserve.不存在于词向量中\n",
      "Ren不存在于词向量中\n",
      "laughed.不存在于词向量中\n",
      "Poe不存在于词向量中\n",
      "chair.不存在于词向量中\n",
      "Darkness不存在于词向量中\n",
      "behave.不存在于词向量中\n",
      "option?不存在于词向量中\n",
      "Writing,不存在于词向量中\n",
      "I...|||Can不存在于词向量中\n",
      "Difficult不存在于词向量中\n",
      "there'll不存在于词向量中\n",
      "C,不存在于词向量中\n",
      "say.|||I不存在于词向量中\n",
      "Gift不存在于词向量中\n",
      "Shop不存在于词向量中\n",
      "excitement,不存在于词向量中\n",
      "(there's不存在于词向量中\n",
      "proud.不存在于词向量中\n",
      "Gave不存在于词向量中\n",
      "replied.不存在于词向量中\n",
      "sexual.不存在于词向量中\n",
      "8's不存在于词向量中\n",
      "John's不存在于词向量中\n",
      "Till不存在于词向量中\n",
      "instruments,不存在于词向量中\n",
      "seems...|||I不存在于词向量中\n",
      "products.不存在于词向量中\n",
      ";)|||You不存在于词向量中\n",
      "Pluto不存在于词向量中\n",
      "FINALLY不存在于词向量中\n",
      "clarity,不存在于词向量中\n",
      "reasons?不存在于词向量中\n",
      "Meyers不存在于词向量中\n",
      "Boston不存在于词向量中\n",
      "tools.不存在于词向量中\n",
      "introspection,不存在于词向量中\n",
      "resume.不存在于词向量中\n",
      "Ni-Te不存在于词向量中\n",
      "'get不存在于词向量中\n",
      "INTJs:不存在于词向量中\n",
      "engineer.不存在于词向量中\n",
      "by...|||I'm不存在于词向量中\n",
      "him..不存在于词向量中\n",
      "thing..不存在于词向量中\n",
      "post..不存在于词向量中\n",
      "Him:不存在于词向量中\n",
      "name...不存在于词向量中\n",
      "you...|||Well不存在于词向量中\n",
      "animals?不存在于词向量中\n",
      "Drop不存在于词向量中\n",
      "with...|||What不存在于词向量中\n",
      "Es不存在于词向量中\n",
      "surprise.不存在于词向量中\n",
      "(and,不存在于词向量中\n",
      "one.|||I'm不存在于词向量中\n",
      "hurting.不存在于词向量中\n",
      "apologies,不存在于词向量中\n",
      "kitchen,不存在于词向量中\n",
      "ending,不存在于词向量中\n",
      "MA不存在于词向量中\n",
      "Clark不存在于词向量中\n",
      "jazz.不存在于词向量中\n",
      ":D|||My不存在于词向量中\n",
      "size.不存在于词向量中\n",
      "Clean不存在于词向量中\n",
      "opinion)不存在于词向量中\n",
      "up).不存在于词向量中\n",
      "sanity.不存在于词向量中\n",
      "er,不存在于词向量中\n",
      "prefer.不存在于词向量中\n",
      "normally,不存在于词向量中\n",
      "doors.不存在于词向量中\n",
      "demanding,不存在于词向量中\n",
      "obsession,不存在于词向量中\n",
      "observations.不存在于词向量中\n",
      "realist.不存在于词向量中\n",
      "like...|||You不存在于词向量中\n",
      "gesture.不存在于词向量中\n",
      "precise.不存在于词向量中\n",
      "mine...不存在于词向量中\n",
      "also...不存在于词向量中\n",
      "an...'不存在于词向量中\n",
      "Vegeta不存在于词向量中\n",
      "it.|||If不存在于词向量中\n",
      "EDIT不存在于词向量中\n",
      "INxJs不存在于词向量中\n",
      "you...|||What不存在于词向量中\n",
      "Pulp不存在于词向量中\n",
      "Planet不存在于词向量中\n",
      "Preference不存在于词向量中\n",
      "Fi:不存在于词向量中\n",
      "Avril不存在于词向量中\n",
      "nice?不存在于词向量中\n",
      "good)不存在于词向量中\n",
      "try...|||I不存在于词向量中\n",
      "to...|||Your不存在于词向量中\n",
      "or...|||I've不存在于词向量中\n",
      "Slight不存在于词向量中\n",
      "Doors不存在于词向量中\n",
      "CK不存在于词向量中\n",
      "pessimistic,不存在于词向量中\n",
      "thing's不存在于词向量中\n",
      "pot,不存在于词向量中\n",
      "roommate.不存在于词向量中\n",
      "years).不存在于词向量中\n",
      "Ned不存在于词向量中\n",
      "laziness,不存在于词向量中\n",
      "Rush不存在于词向量中\n",
      "Um...不存在于词向量中\n",
      "agree...不存在于词向量中\n",
      "YouTube.不存在于词向量中\n",
      "need?不存在于词向量中\n",
      "on...'不存在于词向量中\n",
      "they...|||The不存在于词向量中\n",
      "cards.不存在于词向量中\n",
      "guide.不存在于词向量中\n",
      "Memories不存在于词向量中\n",
      "mates,不存在于词向量中\n",
      "(why不存在于词向量中\n",
      "feel...|||I'm不存在于词向量中\n",
      "Shy不存在于词向量中\n",
      "athletic,不存在于词向量中\n",
      "Rises不存在于词向量中\n",
      "Flowers不存在于词向量中\n",
      "Ball不存在于词向量中\n",
      "dominance,不存在于词向量中\n",
      "kid?不存在于词向量中\n",
      "regrets.不存在于词向量中\n",
      "test)不存在于词向量中\n",
      "to...|||Don't不存在于词向量中\n",
      "YES,不存在于词向量中\n",
      "soulmate.不存在于词向量中\n",
      "Piano不存在于词向量中\n",
      "like?|||I不存在于词向量中\n",
      "inspired,不存在于词向量中\n",
      "people).不存在于词向量中\n",
      "statistics.不存在于词向量中\n",
      "start...|||I不存在于词向量中\n",
      "but...|||This不存在于词向量中\n",
      "VS不存在于词向量中\n",
      "anxiety)不存在于词向量中\n",
      "vote.不存在于词向量中\n",
      "Thursday.不存在于词向量中\n",
      "fate,不存在于词向量中\n",
      "Rest不存在于词向量中\n",
      "Puerto不存在于词向量中\n",
      "night...不存在于词向量中\n",
      "vote,不存在于词向量中\n",
      "(10不存在于词向量中\n",
      "(Your不存在于词向量中\n",
      "regret.不存在于词向量中\n",
      "Samuel不存在于词向量中\n",
      "<--不存在于词向量中\n",
      ":o|||I不存在于词向量中\n",
      "Jehovah's不存在于词向量中\n",
      "passive.不存在于词向量中\n",
      "they...|||This不存在于词向量中\n",
      "speculation.不存在于词向量中\n",
      "and...|||In不存在于词向量中\n",
      "don't...|||When不存在于词向量中\n",
      "America's不存在于词向量中\n",
      "(INFJ不存在于词向量中\n",
      "Known不存在于词向量中\n",
      "interview.不存在于词向量中\n",
      "Square不存在于词向量中\n",
      "you,...|||I不存在于词向量中\n",
      "television.不存在于词向量中\n",
      "Tapatalk|||This不存在于词向量中\n",
      "bias.不存在于词向量中\n",
      "punishment,不存在于词向量中\n",
      "I`m不存在于词向量中\n",
      "(have不存在于词向量中\n",
      "nothing?不存在于词向量中\n",
      "industry,不存在于词向量中\n",
      "Gossip不存在于词向量中\n",
      "blog.不存在于词向量中\n",
      "comes,不存在于词向量中\n",
      "noted.不存在于词向量中\n",
      "done...不存在于词向量中\n",
      "bathroom,不存在于词向量中\n",
      "sense.|||I不存在于词向量中\n",
      "closely.不存在于词向量中\n",
      "happy...|||I不存在于词向量中\n",
      "St不存在于词向量中\n",
      "loose.不存在于词向量中\n",
      "skills?不存在于词向量中\n",
      "dynamic,不存在于词向量中\n",
      "I...|||Are不存在于词向量中\n",
      "fingers,不存在于词向量中\n",
      "ask...不存在于词向量中\n",
      "'friends'不存在于词向量中\n",
      "happens?不存在于词向量中\n",
      "Mensa不存在于词向量中\n",
      "television,不存在于词向量中\n",
      "price.不存在于词向量中\n",
      "regard,不存在于词向量中\n",
      "'oh不存在于词向量中\n",
      "habits?不存在于词向量中\n",
      "the...|||Wow,不存在于词向量中\n",
      "(trying不存在于词向量中\n",
      "help...|||I不存在于词向量中\n",
      "Further不存在于词向量中\n",
      "Lois不存在于词向量中\n",
      "Meh.不存在于词向量中\n",
      "be...|||So不存在于词向量中\n",
      "atmosphere,不存在于词向量中\n",
      "flat,不存在于词向量中\n",
      "else...|||I不存在于词向量中\n",
      "Supposedly不存在于词向量中\n",
      "to...|||Yeah不存在于词向量中\n",
      "Gandalf不存在于词向量中\n",
      "Sensation不存在于词向量中\n",
      "intensity,不存在于词向量中\n",
      "in...|||Thank不存在于词向量中\n",
      "[I不存在于词向量中\n",
      "ENFx不存在于词向量中\n",
      "stress?不存在于词向量中\n",
      "others..不存在于词向量中\n",
      "suit,不存在于词向量中\n",
      "to...|||No不存在于词向量中\n",
      "machine,不存在于词向量中\n",
      "mum.不存在于词向量中\n",
      "lol?不存在于词向量中\n",
      "TJs不存在于词向量中\n",
      "8/10不存在于词向量中\n",
      "interest?不存在于词向量中\n",
      "legs.不存在于词向量中\n",
      "Queens不存在于词向量中\n",
      "Arcade不存在于词向量中\n",
      "Alright不存在于词向量中\n",
      "solutions.不存在于词向量中\n",
      "ten,不存在于词向量中\n",
      "definitions.不存在于词向量中\n",
      "spiders.不存在于词向量中\n",
      "grow,不存在于词向量中\n",
      "market.不存在于词向量中\n",
      "pillow.不存在于词向量中\n",
      "INFJ|||I不存在于词向量中\n",
      "Lying不存在于词向量中\n",
      "fixed,不存在于词向量中\n",
      "Attention不存在于词向量中\n",
      "included,不存在于词向量中\n",
      "Leaves不存在于词向量中\n",
      "Bored不存在于词向量中\n",
      "Drink不存在于词向量中\n",
      "Elliot不存在于词向量中\n",
      "plot,不存在于词向量中\n",
      "Worst:不存在于词向量中\n",
      "opportunities.不存在于词向量中\n",
      "professor,不存在于词向量中\n",
      "angle.不存在于词向量中\n",
      "challenging,不存在于词向量中\n",
      "Portuguese不存在于词向量中\n",
      "phrase,不存在于词向量中\n",
      "(Fe不存在于词向量中\n",
      "Ti)不存在于词向量中\n",
      "secret,不存在于词向量中\n",
      "Lie不存在于词向量中\n",
      "Art,不存在于词向量中\n",
      "well.|||I'm不存在于词向量中\n",
      "elaborate?不存在于词向量中\n",
      "Haruhi不存在于词向量中\n",
      "Zelda,不存在于词向量中\n",
      "Dreams:不存在于词向量中\n",
      "a...|||You're不存在于词向量中\n",
      "Fantastic不存在于词向量中\n",
      "market,不存在于词向量中\n",
      "Johnson不存在于词向量中\n",
      "type..不存在于词向量中\n",
      "(like,不存在于词向量中\n",
      "coincidence.不存在于词向量中\n",
      "bond.不存在于词向量中\n",
      "Kelly不存在于词向量中\n",
      "(5不存在于词向量中\n",
      "Ricky不存在于词向量中\n",
      "genres,不存在于词向量中\n",
      "intuitives.不存在于词向量中\n",
      "Nevertheless,不存在于词向量中\n",
      "universal,不存在于词向量中\n",
      "Picking不存在于词向量中\n",
      "pink,不存在于词向量中\n",
      "xNFPs不存在于词向量中\n",
      "Joan不存在于词向量中\n",
      "(There不存在于词向量中\n",
      "Fantasy,不存在于词向量中\n",
      "with...|||If不存在于词向量中\n",
      "done...|||I不存在于词向量中\n",
      "Tyrion不存在于词向量中\n",
      "quirks.不存在于词向量中\n",
      "(best不存在于词向量中\n",
      "Isfj不存在于词向量中\n",
      "misunderstanding.不存在于词向量中\n",
      "trap.不存在于词向量中\n",
      "assumptions,不存在于词向量中\n",
      "30's不存在于词向量中\n",
      "Rider不存在于词向量中\n",
      "it.|||Well,不存在于词向量中\n",
      "World.不存在于词向量中\n",
      "be...|||What不存在于词向量中\n",
      "Hitler,不存在于词向量中\n",
      "pairing.不存在于词向量中\n",
      "arguing,不存在于词向量中\n",
      ":)|||No不存在于词向量中\n",
      "Crossing不存在于词向量中\n",
      "ladies,不存在于词向量中\n",
      "grip.不存在于词向量中\n",
      "PM.不存在于词向量中\n",
      "religious?不存在于词向量中\n",
      "color?不存在于词向量中\n",
      "panic.不存在于词向量中\n",
      "told.不存在于词向量中\n",
      "retreat.不存在于词向量中\n",
      "empathetic.不存在于词向量中\n",
      "movie)不存在于词向量中\n",
      "xNTJs不存在于词向量中\n",
      "wrong.|||I不存在于词向量中\n",
      "Hawaii不存在于词向量中\n",
      "danger,不存在于词向量中\n",
      "who.不存在于词向量中\n",
      "Manager不存在于词向量中\n",
      "entp's不存在于词向量中\n",
      "maths.不存在于词向量中\n",
      "K,不存在于词向量中\n",
      "3DS不存在于词向量中\n",
      "5'不存在于词向量中\n",
      "again..不存在于词向量中\n",
      "you...|||Thank不存在于词向量中\n",
      "sometime,不存在于词向量中\n",
      "Winnie不存在于词向量中\n",
      "acceptance.不存在于词向量中\n",
      "at...|||The不存在于词向量中\n",
      "WOULD不存在于词向量中\n",
      "XD|||I'm不存在于词向量中\n",
      "charm.不存在于词向量中\n",
      "Now.不存在于词向量中\n",
      "roommate,不存在于词向量中\n",
      "actions?不存在于词向量中\n",
      "posters,不存在于词向量中\n",
      "motivated,不存在于词向量中\n",
      "Jasmine不存在于词向量中\n",
      "get?不存在于词向量中\n",
      "variants.不存在于词向量中\n",
      "are...|||When不存在于词向量中\n",
      "unclear.不存在于词向量中\n",
      "these?不存在于词向量中\n",
      "satisfied.不存在于词向量中\n",
      "assume.不存在于词向量中\n",
      "heart's不存在于词向量中\n",
      "over?不存在于词向量中\n",
      "have...|||The不存在于词向量中\n",
      "C:不存在于词向量中\n",
      "nails,不存在于词向量中\n",
      "M.不存在于词向量中\n",
      ";)'不存在于词向量中\n",
      "Monday,不存在于词向量中\n",
      "Titanic不存在于词向量中\n",
      "fun...不存在于词向量中\n",
      "your...|||My不存在于词向量中\n",
      "Mother's不存在于词向量中\n",
      "easily?不存在于词向量中\n",
      "I...|||Dear不存在于词向量中\n",
      "to...|||One不存在于词向量中\n",
      "sake?不存在于词向量中\n",
      "When...|||I不存在于词向量中\n",
      "Electric不存在于词向量中\n",
      "paint.不存在于词向量中\n",
      "Y'all不存在于词向量中\n",
      "pet.不存在于词向量中\n",
      "guilty.不存在于词向量中\n",
      "Moriarty不存在于词向量中\n",
      "minor,不存在于词向量中\n",
      "took,不存在于词向量中\n",
      "say)不存在于词向量中\n",
      "leaves,不存在于词向量中\n",
      "woods,不存在于词向量中\n",
      "I...|||No,不存在于词向量中\n",
      "forum's不存在于词向量中\n",
      "where.不存在于词向量中\n",
      "productive,不存在于词向量中\n",
      "the...|||Hi不存在于词向量中\n",
      "Zone不存在于词向量中\n",
      "Rational不存在于词向量中\n",
      "Ti-Ni不存在于词向量中\n",
      "doubts,不存在于词向量中\n",
      "kiss.不存在于词向量中\n",
      "orange,不存在于词向量中\n",
      "Diamonds不存在于词向量中\n",
      ":D|||This不存在于词向量中\n",
      "it...|||It不存在于词向量中\n",
      "finish.不存在于词向量中\n",
      "Ideally不存在于词向量中\n",
      "already...|||I不存在于词向量中\n",
      "assignment,不存在于词向量中\n",
      "Anyway.不存在于词向量中\n",
      "Libertarian不存在于词向量中\n",
      "day's不存在于词向量中\n",
      "familiar,不存在于词向量中\n",
      "persona,不存在于词向量中\n",
      "Masculine不存在于词向量中\n",
      "Bobby不存在于词向量中\n",
      "Jesus.不存在于词向量中\n",
      "straightforward.不存在于词向量中\n",
      "stable.不存在于词向量中\n",
      "reasonable.不存在于词向量中\n",
      "Sunday.不存在于词向量中\n",
      "protection.不存在于词向量中\n",
      "NF's.不存在于词向量中\n",
      "Nicholas不存在于词向量中\n",
      "essays.不存在于词向量中\n",
      "dated.不存在于词向量中\n",
      "Duck不存在于词向量中\n",
      "Yo不存在于词向量中\n",
      "Theater不存在于词向量中\n",
      "Ti-dom不存在于词向量中\n",
      "Catherine不存在于词向量中\n",
      "writers,不存在于词向量中\n",
      "Toy不存在于词向量中\n",
      "nerdy,不存在于词向量中\n",
      "Se-Ni不存在于词向量中\n",
      "Feeling,不存在于词向量中\n",
      "Theory,不存在于词向量中\n",
      "typed.不存在于词向量中\n",
      "avoid.不存在于词向量中\n",
      "elaborate.不存在于词向量中\n",
      "instrument,不存在于词向量中\n",
      "Korra不存在于词向量中\n",
      "Course不存在于词向量中\n",
      "soup.不存在于词向量中\n",
      "bills,不存在于词向量中\n",
      "2012.不存在于词向量中\n",
      "directions,不存在于词向量中\n",
      "baseball,不存在于词向量中\n",
      "aliens,不存在于词向量中\n",
      "abusive.不存在于词向量中\n",
      "or...|||It不存在于词向量中\n",
      "Wuthering不存在于词向量中\n",
      "Loud不存在于词向量中\n",
      "minority.不存在于词向量中\n",
      "yet)不存在于词向量中\n",
      "TRY不存在于词向量中\n",
      "Xbox不存在于词向量中\n",
      "she...|||I'm不存在于词向量中\n",
      "Triple不存在于词向量中\n",
      "gold,不存在于词向量中\n",
      "AA不存在于词向量中\n",
      "INFPness不存在于词向量中\n",
      "clarity.不存在于词向量中\n",
      "in...|||For不存在于词向量中\n",
      "with...|||When不存在于词向量中\n",
      "F***不存在于词向量中\n",
      ":rolleyes:|||I不存在于词向量中\n",
      "Jump不存在于词向量中\n",
      "darkness,不存在于词向量中\n",
      "precise,不存在于词向量中\n",
      "post|||I不存在于词向量中\n",
      "Cloud不存在于词向量中\n",
      "WELL不存在于词向量中\n",
      "Thou不存在于词向量中\n",
      "Ni-dom,不存在于词向量中\n",
      "Resident不存在于词向量中\n",
      "and...|||Yeah不存在于词向量中\n",
      "Score不存在于词向量中\n",
      "replied,不存在于词向量中\n",
      "the...|||Hey,不存在于词向量中\n",
      "Figured不存在于词向量中\n",
      "judging.不存在于词向量中\n",
      "disorganized,不存在于词向量中\n",
      "Official不存在于词向量中\n",
      "gut,不存在于词向量中\n",
      "numb,不存在于词向量中\n",
      "Lol!不存在于词向量中\n",
      "around.|||I不存在于词向量中\n",
      "uncertain.不存在于词向量中\n",
      "heavy,不存在于词向量中\n",
      "TAKE不存在于词向量中\n",
      "smells,不存在于词向量中\n",
      "fear?不存在于词向量中\n",
      "VS990不存在于词向量中\n",
      "quizzes,不存在于词向量中\n",
      "profiles,不存在于词向量中\n",
      "unpredictable.不存在于词向量中\n",
      "joke?不存在于词向量中\n",
      "teeth,不存在于词向量中\n",
      "climbing,不存在于词向量中\n",
      "chair,不存在于词向量中\n",
      "scratch.不存在于词向量中\n",
      "Mom,不存在于词向量中\n",
      "procrastinate.不存在于词向量中\n",
      "sadly.不存在于词向量中\n",
      "angle,不存在于词向量中\n",
      "Plato不存在于词向量中\n",
      "context?不存在于词向量中\n",
      "mean?|||I不存在于词向量中\n",
      "cleaning,不存在于词向量中\n",
      "clueless.不存在于词向量中\n",
      "Assume不存在于词向量中\n",
      "Aww不存在于词向量中\n",
      "defined.不存在于词向量中\n",
      "none,不存在于词向量中\n",
      "Portal不存在于词向量中\n",
      "Picard不存在于词向量中\n",
      "switch.不存在于词向量中\n",
      "havn't不存在于词向量中\n",
      "Evans不存在于词向量中\n",
      "promise,不存在于词向量中\n",
      "accepted,不存在于词向量中\n",
      "Sparrow不存在于词向量中\n",
      "types...不存在于词向量中\n",
      "Regret不存在于词向量中\n",
      "(similar不存在于词向量中\n",
      "...|||Oh,不存在于词向量中\n",
      "Denmark不存在于词向量中\n",
      "strategy.不存在于词向量中\n",
      "Creation不存在于词向量中\n",
      "Organic不存在于词向量中\n",
      "types'不存在于词向量中\n",
      "hah.不存在于词向量中\n",
      "how...|||I'm不存在于词向量中\n",
      "Riso不存在于词向量中\n",
      "watched.不存在于词向量中\n",
      "Bachelor's不存在于词向量中\n",
      "thing).不存在于词向量中\n",
      "(or,不存在于词向量中\n",
      ":sad:.不存在于词向量中\n",
      "books?不存在于词向量中\n",
      "the...|||Welcome不存在于词向量中\n",
      "the...|||We不存在于词向量中\n",
      "was...'不存在于词向量中\n",
      "uncle.不存在于词向量中\n",
      "weapons,不存在于词向量中\n",
      "lifetime.不存在于词向量中\n",
      "hint.不存在于词向量中\n",
      "ambiguous.不存在于词向量中\n",
      "leaving,不存在于词向量中\n",
      "alone.|||I不存在于词向量中\n",
      "each,不存在于词向量中\n",
      "SUCH不存在于词向量中\n",
      "..and不存在于词向量中\n",
      "Copy不存在于词向量中\n",
      "Greeks不存在于词向量中\n",
      "Aristotle不存在于词向量中\n",
      "Planning不存在于词向量中\n",
      "dress.不存在于词向量中\n",
      "me.|||I've不存在于词向量中\n",
      "meds,不存在于词向量中\n",
      "Shes不存在于词向量中\n",
      "so...'不存在于词向量中\n",
      "passions.不存在于词向量中\n",
      "24,不存在于词向量中\n",
      "Liberal不存在于词向量中\n",
      "Environmental不存在于词向量中\n",
      "yep.不存在于词向量中\n",
      "(What不存在于词向量中\n",
      "Pete不存在于词向量中\n",
      "to..不存在于词向量中\n",
      "accounts,不存在于词向量中\n",
      "case...不存在于词向量中\n",
      "divorce,不存在于词向量中\n",
      "California,不存在于词向量中\n",
      "first?不存在于词向量中\n",
      "'And不存在于词向量中\n",
      "sport.不存在于词向量中\n",
      "is/was不存在于词向量中\n",
      "t-shirts,不存在于词向量中\n",
      "age...不存在于词向量中\n",
      "humble,不存在于词向量中\n",
      "humble.不存在于词向量中\n",
      "talented,不存在于词向量中\n",
      "Dare不存在于词向量中\n",
      "Fe/Fi不存在于词向量中\n",
      "'Some不存在于词向量中\n",
      "Freddie不存在于词向量中\n",
      "pain?不存在于词向量中\n",
      "Imma不存在于词向量中\n",
      "just...'不存在于词向量中\n",
      "it.)不存在于词向量中\n",
      "Eerie:不存在于词向量中\n",
      "...|||Maybe不存在于词向量中\n",
      "evolution,不存在于词向量中\n",
      "wasted.不存在于词向量中\n",
      "crushes.不存在于词向量中\n",
      "heart...不存在于词向量中\n",
      "pick.不存在于词向量中\n",
      "and...|||I'll不存在于词向量中\n",
      "Friedrich不存在于词向量中\n",
      "methods.不存在于词向量中\n",
      "mind)不存在于词向量中\n",
      "tricky.不存在于词向量中\n",
      "motion.不存在于词向量中\n",
      "experience.|||I不存在于词向量中\n",
      "comedy.不存在于词向量中\n",
      "profession,不存在于词向量中\n",
      "workplace.不存在于词向量中\n",
      "(preferably不存在于词向量中\n",
      "is...|||In不存在于词向量中\n",
      "listed.不存在于词向量中\n",
      "ago).不存在于词向量中\n",
      "Leading不存在于词向量中\n",
      "though.|||This不存在于词向量中\n",
      "rocks.不存在于词向量中\n",
      "archetype.不存在于词向量中\n",
      "(be不存在于词向量中\n",
      "'First不存在于词向量中\n",
      "October.不存在于词向量中\n",
      "Dungeons不存在于词向量中\n",
      "appreciate.不存在于词向量中\n",
      "Interestingly,不存在于词向量中\n",
      "Killing不存在于词向量中\n",
      "Stones不存在于词向量中\n",
      "Embrace不存在于词向量中\n",
      "sounds...|||I不存在于词向量中\n",
      "norm,不存在于词向量中\n",
      "Brand不存在于词向量中\n",
      "Stream不存在于词向量中\n",
      "Fred不存在于词向量中\n",
      "president,不存在于词向量中\n",
      "discuss.不存在于词向量中\n",
      "ENTJ...不存在于词向量中\n",
      "THOUGHT不存在于词向量中\n",
      "'ere不存在于词向量中\n",
      "weren't?不存在于词向量中\n",
      "Moon,不存在于词向量中\n",
      "'Oh,不存在于词向量中\n",
      "ISFJ)不存在于词向量中\n",
      "Crash不存在于词向量中\n",
      "Thor不存在于词向量中\n",
      "camera,不存在于词向量中\n",
      "you...|||So不存在于词向量中\n",
      "circumstance,不存在于词向量中\n",
      "out...|||I'm不存在于词向量中\n",
      "ISTJ's,不存在于词向量中\n",
      "HOWEVER,不存在于词向量中\n",
      "keyboard.不存在于词向量中\n",
      "not?|||I不存在于词向量中\n",
      "Naturally,不存在于词向量中\n",
      "Giant不存在于词向量中\n",
      "Devil's不存在于词向量中\n",
      "approval.不存在于词向量中\n",
      "Married不存在于词向量中\n",
      "forced,不存在于词向量中\n",
      "Adventures不存在于词向量中\n",
      "charge,不存在于词向量中\n",
      "beneficial.不存在于词向量中\n",
      "Diamond不存在于词向量中\n",
      "compassion,不存在于词向量中\n",
      "settings,不存在于词向量中\n",
      "satisfaction.不存在于词向量中\n",
      "lifestyle,不存在于词向量中\n",
      "swear.不存在于词向量中\n",
      "objects.不存在于词向量中\n",
      "furniture,不存在于词向量中\n",
      "keys,不存在于词向量中\n",
      "picture?不存在于词向量中\n",
      "experiencing.不存在于词向量中\n",
      "Ten不存在于词向量中\n",
      "I'm...不存在于词向量中\n",
      "nevermind.不存在于词向量中\n",
      "advice...不存在于词向量中\n",
      "Perks不存在于词向量中\n",
      "Lovegood不存在于词向量中\n",
      "seem...|||I不存在于词向量中\n",
      "did...不存在于词向量中\n",
      "look?不存在于词向量中\n",
      "it...I不存在于词向量中\n",
      "for...|||Yes,不存在于词向量中\n",
      "Iver不存在于词向量中\n",
      "M:不存在于词向量中\n",
      "Speech不存在于词向量中\n",
      "coin.不存在于词向量中\n",
      "Wars,不存在于词向量中\n",
      "Debate不存在于词向量中\n",
      "behave,不存在于词向量中\n",
      "STJs不存在于词向量中\n",
      "type).不存在于词向量中\n",
      "forum.|||I不存在于词向量中\n",
      "talks,不存在于词向量中\n",
      "Las不存在于词向量中\n",
      "shadow.不存在于词向量中\n",
      ":)|||That's不存在于词向量中\n",
      "having,不存在于词向量中\n",
      "Envy不存在于词向量中\n",
      "do...|||You不存在于词向量中\n",
      "basis?不存在于词向量中\n",
      "breakup,不存在于词向量中\n",
      "absolutely,不存在于词向量中\n",
      ":crying:|||I不存在于词向量中\n",
      "sub-forum,不存在于词向量中\n",
      "Montana不存在于词向量中\n",
      "else.|||I不存在于词向量中\n",
      "Hell.不存在于词向量中\n",
      "Virginia不存在于词向量中\n",
      "ALOT不存在于词向量中\n",
      "OMG,不存在于词向量中\n",
      "elsewhere,不存在于词向量中\n",
      ":D|||What不存在于词向量中\n",
      "Cuz不存在于词向量中\n",
      "forced.不存在于词向量中\n",
      "consistently,不存在于词向量中\n",
      "introversion/extroversion不存在于词向量中\n",
      "radio.不存在于词向量中\n",
      "accurate.|||I不存在于词向量中\n",
      "melancholy,不存在于词向量中\n",
      "villain,不存在于词向量中\n",
      "drained.不存在于词向量中\n",
      "weird...不存在于词向量中\n",
      "kiss,不存在于词向量中\n",
      "back.|||I不存在于词向量中\n",
      "Hehe,不存在于词向量中\n",
      "point.|||I不存在于词向量中\n",
      "received.不存在于词向量中\n",
      "ocean.不存在于词向量中\n",
      "Gandhi不存在于词向量中\n",
      "poetic,不存在于词向量中\n",
      "Mercury不存在于词向量中\n",
      "organization.不存在于词向量中\n",
      "mistyped,不存在于词向量中\n",
      "your...'不存在于词向量中\n",
      "ever...|||I不存在于词向量中\n",
      "far...不存在于词向量中\n",
      "ESPECIALLY不存在于词向量中\n",
      "others...|||I不存在于词向量中\n",
      "encouraging.不存在于词向量中\n",
      "...|||Yeah不存在于词向量中\n",
      "cancer,不存在于词向量中\n",
      "(they're不存在于词向量中\n",
      "-Being不存在于词向量中\n",
      "socialize.不存在于词向量中\n",
      "tick,不存在于词向量中\n",
      "those...不存在于词向量中\n",
      "screen,不存在于词向量中\n",
      "Mermaid不存在于词向量中\n",
      "apparent.不存在于词向量中\n",
      "the...|||From不存在于词向量中\n",
      "August.不存在于词向量中\n",
      "magical.不存在于词向量中\n",
      "Mona不存在于词向量中\n",
      "Ethics不存在于词向量中\n",
      "HERE不存在于词向量中\n",
      "assessment,不存在于词向量中\n",
      "Glasses:不存在于词向量中\n",
      "Fe:不存在于词向量中\n",
      "Te:不存在于词向量中\n",
      "answering,不存在于词向量中\n",
      "Fake不存在于词向量中\n",
      "(Maybe不存在于词向量中\n",
      "the...|||Hello不存在于词向量中\n",
      "not..不存在于词向量中\n",
      "'No.不存在于词向量中\n",
      "bf,不存在于词向量中\n",
      "Holiday不存在于词向量中\n",
      "Velvet不存在于词向量中\n",
      "police.不存在于词向量中\n",
      "they're...|||I不存在于词向量中\n",
      "(two不存在于词向量中\n",
      "burden.不存在于词向量中\n",
      "name)不存在于词向量中\n",
      "Melanie不存在于词向量中\n",
      "Continue不存在于词向量中\n",
      "Introversion:不存在于词向量中\n",
      "quiet?不存在于词向量中\n",
      "like...|||The不存在于词向量中\n",
      "chick.不存在于词向量中\n",
      "wishes,不存在于词向量中\n",
      "first...不存在于词向量中\n",
      "Decided不存在于词向量中\n",
      "god's不存在于词向量中\n",
      ":-/不存在于词向量中\n",
      "ease,不存在于词向量中\n",
      "don't...'不存在于词向量中\n",
      "Right?不存在于词向量中\n",
      "roles,不存在于词向量中\n",
      "policy.不存在于词向量中\n",
      "Jupiter不存在于词向量中\n",
      "Brandon不存在于词向量中\n",
      "strangers?不存在于词向量中\n",
      "debating.不存在于词向量中\n",
      "bothered.不存在于词向量中\n",
      "old...不存在于词向量中\n",
      "week?不存在于词向量中\n",
      "relationship.|||I不存在于词向量中\n",
      "Catcher不存在于词向量中\n",
      "versa,不存在于词向量中\n",
      "improvement,不存在于词向量中\n",
      "ESTP|||I不存在于词向量中\n",
      "moody.不存在于词向量中\n",
      "the...|||All不存在于词向量中\n",
      "(then不存在于词向量中\n",
      "occur,不存在于词向量中\n",
      "Faith不存在于词向量中\n",
      "ear.不存在于词向量中\n",
      "your...|||I'm不存在于词向量中\n",
      "-Is不存在于词向量中\n",
      "avoidant,不存在于词向量中\n",
      "cautious,不存在于词向量中\n",
      "Ohio不存在于词向量中\n",
      "insult,不存在于词向量中\n",
      "costs.不存在于词向量中\n",
      "pink.不存在于词向量中\n",
      "Photoshop不存在于词向量中\n",
      "disappointing.不存在于词向量中\n",
      "King's不存在于词向量中\n",
      "enlightening.不存在于词向量中\n",
      "she?不存在于词向量中\n",
      "items,不存在于词向量中\n",
      "victim.不存在于词向量中\n",
      "answer...不存在于词向量中\n",
      "Earth's不存在于词向量中\n",
      "Hes不存在于词向量中\n",
      "guys..不存在于词向量中\n",
      "day)不存在于词向量中\n",
      "is...|||That不存在于词向量中\n",
      "Meanwhile,不存在于词向量中\n",
      "forest.不存在于词向量中\n",
      "El不存在于词向量中\n",
      "Helena不存在于词向量中\n",
      "rice,不存在于词向量中\n",
      "Journey不存在于词向量中\n",
      "walking.不存在于词向量中\n",
      "XSTJ不存在于词向量中\n",
      "look...|||I不存在于词向量中\n",
      "reactions,不存在于词向量中\n",
      "loyalty.不存在于词向量中\n",
      "(Im不存在于词向量中\n",
      "user?不存在于词向量中\n",
      "divorce.不存在于词向量中\n",
      "Archives不存在于词向量中\n",
      "determined,不存在于词向量中\n",
      "cousin.不存在于词向量中\n",
      "sense)不存在于词向量中\n",
      "Dorian不存在于词向量中\n",
      "home.|||I不存在于词向量中\n",
      "Hidden不存在于词向量中\n",
      "Depeche不存在于词向量中\n",
      "that...|||Thanks不存在于词向量中\n",
      "Hand不存在于词向量中\n",
      "on...|||The不存在于词向量中\n",
      "shell,不存在于词向量中\n",
      "awesome...不存在于词向量中\n",
      "(its不存在于词向量中\n",
      "Honey不存在于词向量中\n",
      ":D)不存在于词向量中\n",
      "SP.不存在于词向量中\n",
      "shadow,不存在于词向量中\n",
      "handed.不存在于词向量中\n",
      "brave,不存在于词向量中\n",
      "narcissism.不存在于词向量中\n",
      "Seek不存在于词向量中\n",
      "accept.不存在于词向量中\n",
      "Then...|||I不存在于词向量中\n",
      "'1)不存在于词向量中\n",
      "Childhood不存在于词向量中\n",
      "era.不存在于词向量中\n",
      "Great,不存在于词向量中\n",
      "repetitive,不存在于词向量中\n",
      "Fat不存在于词向量中\n",
      "Who,不存在于词向量中\n",
      "Cool,不存在于词向量中\n",
      "We,不存在于词向量中\n",
      "fuck?不存在于词向量中\n",
      "but...'不存在于词向量中\n",
      "infps.不存在于词向量中\n",
      "psychopath.不存在于词向量中\n",
      "my...|||Oh不存在于词向量中\n",
      "hide.不存在于词向量中\n",
      "clubs.不存在于词向量中\n",
      "Evolution不存在于词向量中\n",
      "assholes,不存在于词向量中\n",
      "C.S.不存在于词向量中\n",
      "eat?不存在于词向量中\n",
      "iNtuition不存在于词向量中\n",
      "evolution.不存在于词向量中\n",
      "Apdenoatis:不存在于词向量中\n",
      "Vaan:不存在于词向量中\n",
      "HTC6525LVW不存在于词向量中\n",
      "Firstly不存在于词向量中\n",
      "Nuff不存在于词向量中\n",
      "Melbourne不存在于词向量中\n",
      "lol.|||I'm不存在于词向量中\n",
      "their...|||You不存在于词向量中\n",
      "I...|||i不存在于词向量中\n",
      "were...|||I'm不存在于词向量中\n",
      "biologist,不存在于词向量中\n",
      "(Star不存在于词向量中\n",
      "Shake不存在于词向量中\n",
      "planned,不存在于词向量中\n",
      "DAY不存在于词向量中\n",
      "Newton不存在于词向量中\n",
      "kid's不存在于词向量中\n",
      "agreement.不存在于词向量中\n",
      "INFPS不存在于词向量中\n",
      "eccentric,不存在于词向量中\n",
      "Curious,不存在于词向量中\n",
      "Hehe不存在于词向量中\n",
      ":D|||If不存在于词向量中\n",
      "talents,不存在于词向量中\n",
      ":P'不存在于词向量中\n",
      "Chase不存在于词向量中\n",
      "wear,不存在于词向量中\n",
      "playlist.不存在于词向量中\n",
      "Piece不存在于词向量中\n",
      "youth.不存在于词向量中\n",
      "I'm...|||It's不存在于词向量中\n",
      "months?不存在于词向量中\n",
      "Bunny不存在于词向量中\n",
      "Nah.不存在于词向量中\n",
      "Europeans不存在于词向量中\n",
      "22,不存在于词向量中\n",
      "body?不存在于词向量中\n",
      "generous,不存在于词向量中\n",
      "a...|||For不存在于词向量中\n",
      "Biology.不存在于词向量中\n",
      "istj.不存在于词向量中\n",
      "off...不存在于词向量中\n",
      "periods,不存在于词向量中\n",
      "Ph.D.不存在于词向量中\n",
      "bodies.不存在于词向量中\n",
      "same?不存在于词向量中\n",
      ":laughing:|||This不存在于词向量中\n",
      "O_O不存在于词向量中\n",
      "in...|||As不存在于词向量中\n",
      "not...|||This不存在于词向量中\n",
      "ISxP不存在于词向量中\n",
      "Fighting不存在于词向量中\n",
      "button,不存在于词向量中\n",
      "old)不存在于词向量中\n",
      "Ex:不存在于词向量中\n",
      "Gatsby不存在于词向量中\n",
      "Pizza不存在于词向量中\n",
      "school...|||I不存在于词向量中\n",
      "'Hi,不存在于词向量中\n",
      "(a)不存在于词向量中\n",
      "T-shirt不存在于词向量中\n",
      "Escape不存在于词向量中\n",
      "Fi-Te不存在于词向量中\n",
      "advance,不存在于词向量中\n",
      "Alysaria:不存在于词向量中\n",
      "MusicBird:不存在于词向量中\n",
      "long...|||I不存在于词向量中\n",
      "route,不存在于词向量中\n",
      "death?不存在于词向量中\n",
      "Extroverted,不存在于词向量中\n",
      "do...|||This不存在于词向量中\n",
      "lovers,不存在于词向量中\n",
      "Marx不存在于词向量中\n",
      "breathing.不存在于词向量中\n",
      "your...|||If不存在于词向量中\n",
      "was...|||The不存在于词向量中\n",
      "Sx/Sp不存在于词向量中\n",
      "to...|||Hello不存在于词向量中\n",
      "Japanese,不存在于词向量中\n",
      "seem.不存在于词向量中\n",
      "(didn't不存在于词向量中\n",
      "torture.不存在于词向量中\n",
      "hug?不存在于词向量中\n",
      "now.|||I'm不存在于词向量中\n",
      "SJW不存在于词向量中\n",
      "'All不存在于词向量中\n",
      "charm,不存在于词向量中\n",
      "Genius不存在于词向量中\n",
      "exact.不存在于词向量中\n",
      "bridge.不存在于词向量中\n",
      "Tbh不存在于词向量中\n",
      "Hm...不存在于词向量中\n",
      "Yours不存在于词向量中\n",
      "Ghibli不存在于词向量中\n",
      "complaining,不存在于词向量中\n",
      "(So不存在于词向量中\n",
      "(&不存在于词向量中\n",
      "generalization.不存在于词向量中\n",
      "Angeles不存在于词向量中\n",
      "won,不存在于词向量中\n",
      "Chess不存在于词向量中\n",
      "Rules不存在于词向量中\n",
      "drums,不存在于词向量中\n",
      "(Well,不存在于词向量中\n",
      "a...|||Wow,不存在于词向量中\n",
      "Spot不存在于词向量中\n",
      "ENTPs:不存在于词向量中\n",
      "Ignoring不存在于词向量中\n",
      "talking...|||I不存在于词向量中\n",
      "cannot.不存在于词向量中\n",
      "ironic.不存在于词向量中\n",
      "deadlines,不存在于词向量中\n",
      "pie,不存在于词向量中\n",
      "Diablo不存在于词向量中\n",
      "soup,不存在于词向量中\n",
      "Urban不存在于词向量中\n",
      "Eight不存在于词向量中\n",
      "Intro不存在于词向量中\n",
      "sex...不存在于词向量中\n",
      "of...|||Thank不存在于词向量中\n",
      "Jews不存在于词向量中\n",
      "cents,不存在于词向量中\n",
      "(ex:不存在于词向量中\n",
      "murder.不存在于词向量中\n",
      "sisters.不存在于词向量中\n",
      "Normally,不存在于词向量中\n",
      "of...|||A不存在于词向量中\n",
      "forgive.不存在于词向量中\n",
      "Valentine不存在于词向量中\n",
      "hey.不存在于词向量中\n",
      "GPS不存在于词向量中\n",
      "Witcher不存在于词向量中\n",
      "Mum:不存在于词向量中\n",
      "istp's不存在于词向量中\n",
      "she's...|||I不存在于词向量中\n",
      "brain?不存在于词向量中\n",
      "Missing不存在于词向量中\n",
      "theater,不存在于词向量中\n",
      "ironically,不存在于词向量中\n",
      "Iceland不存在于词向量中\n",
      "ISTx不存在于词向量中\n",
      "Daft不存在于词向量中\n",
      "designer,不存在于词向量中\n",
      "Range?不存在于词向量中\n",
      "friendship?不存在于词向量中\n",
      "shock.不存在于词向量中\n",
      "HA!不存在于词向量中\n",
      "pocket.不存在于词向量中\n",
      "vain,不存在于词向量中\n",
      "Foreign不存在于词向量中\n",
      "believe...|||I不存在于词向量中\n",
      "Fairly不存在于词向量中\n",
      "introvert?不存在于词向量中\n",
      "Pokemon,不存在于词向量中\n",
      "afterlife.不存在于词向量中\n",
      ":)|||Your不存在于词向量中\n",
      "Father-不存在于词向量中\n",
      "||||||||||||||不存在于词向量中\n",
      "Socialist不存在于词向量中\n",
      "smoothly.不存在于词向量中\n",
      "level?不存在于词向量中\n",
      "sometimes)不存在于词向量中\n",
      "paranoia,不存在于词向量中\n",
      "two?不存在于词向量中\n",
      "things...|||I'm不存在于词向量中\n",
      "Buddha不存在于词向量中\n",
      "trends.不存在于词向量中\n",
      "smoke?不存在于词向量中\n",
      "come?不存在于词向量中\n",
      "other)不存在于词向量中\n",
      "(type不存在于词向量中\n",
      "Leaving不存在于词向量中\n",
      "folk.不存在于词向量中\n",
      "Weather不存在于词向量中\n",
      "Comic不存在于词向量中\n",
      "close...|||I不存在于词向量中\n",
      "Vitamin不存在于词向量中\n",
      "illusion,不存在于词向量中\n",
      "Advice不存在于词向量中\n",
      "y'all.不存在于词向量中\n",
      "vacation,不存在于词向量中\n",
      "autism.不存在于词向量中\n",
      "type),不存在于词向量中\n",
      "shirts,不存在于词向量中\n",
      "character?不存在于词向量中\n",
      "counselor,不存在于词向量中\n",
      "outcome,不存在于词向量中\n",
      "relaxing,不存在于词向量中\n",
      "Hated不存在于词向量中\n",
      "Science.不存在于词向量中\n",
      "tongue.不存在于词向量中\n",
      "Sx/So不存在于词向量中\n",
      "ESFJ|||I不存在于词向量中\n",
      "is...|||What不存在于词向量中\n",
      "Mail不存在于词向量中\n",
      "ride,不存在于词向量中\n",
      "Toed不存在于词向量中\n",
      "CBT不存在于词向量中\n",
      "features,不存在于词向量中\n",
      "desk.不存在于词向量中\n",
      "Oxford不存在于词向量中\n",
      "Murphy不存在于词向量中\n",
      "caffeine.不存在于词向量中\n",
      ";))不存在于词向量中\n",
      "honey.不存在于词向量中\n",
      "dialogue,不存在于词向量中\n",
      "spiders,不存在于词向量中\n",
      "<3.不存在于词向量中\n",
      "idealist,不存在于词向量中\n",
      ":(|||I'm不存在于词向量中\n",
      "list?不存在于词向量中\n",
      "Changing不存在于词向量中\n",
      "WHEN不存在于词向量中\n",
      "a...|||Not不存在于词向量中\n",
      "SX/SO不存在于词向量中\n",
      "Tapatalk|||So不存在于词向量中\n",
      "stuff.|||I不存在于词向量中\n",
      "Love.不存在于词向量中\n",
      "exceptions,不存在于词向量中\n",
      "Text不存在于词向量中\n",
      "Grade不存在于词向量中\n",
      "under.不存在于词向量中\n",
      "Photo不存在于词向量中\n",
      "Gregory不存在于词向量中\n",
      "that?!不存在于词向量中\n",
      "hooked.不存在于词向量中\n",
      "expert.不存在于词向量中\n",
      "Maths不存在于词向量中\n",
      "Rock,不存在于词向量中\n",
      "so...|||This不存在于词向量中\n",
      "Wait.不存在于词向量中\n",
      "jealousy,不存在于词向量中\n",
      "Pepper不存在于词向量中\n",
      "the...|||And不存在于词向量中\n",
      "Trump.不存在于词向量中\n",
      "metaphors.不存在于词向量中\n",
      "streak.不存在于词向量中\n",
      "tumblr.不存在于词向量中\n",
      "Oil不存在于词向量中\n",
      "but...|||You不存在于词向量中\n",
      "computers.不存在于词向量中\n",
      "Right,不存在于词向量中\n",
      "Peaks不存在于词向量中\n",
      "Train不存在于词向量中\n",
      "'in不存在于词向量中\n",
      "mystery,不存在于词向量中\n",
      "certain...|||I不存在于词向量中\n",
      "Phone不存在于词向量中\n",
      "in...|||Yes,不存在于词向量中\n",
      "buy.不存在于词向量中\n",
      "(instead不存在于词向量中\n",
      "cousin,不存在于词向量中\n",
      "Ring不存在于词向量中\n",
      "Colbert不存在于词向量中\n",
      "Temple不存在于词向量中\n",
      "he,不存在于词向量中\n",
      "tension.不存在于词向量中\n",
      "(haven't不存在于词向量中\n",
      ":)|||So不存在于词向量中\n",
      "Central不存在于词向量中\n",
      "Else不存在于词向量中\n",
      "penis.不存在于词向量中\n",
      "Crush不存在于词向量中\n",
      "Pierce不存在于词向量中\n",
      "strongly,不存在于词向量中\n",
      "Company不存在于词向量中\n",
      "relatable.不存在于词向量中\n",
      "Mechanical不存在于词向量中\n",
      "kill.不存在于词向量中\n",
      "Library不存在于词向量中\n",
      "combined.不存在于词向量中\n",
      "destiny?不存在于词向量中\n",
      "sales,不存在于词向量中\n",
      "Ix92d不存在于词向量中\n",
      "sx/so.不存在于词向量中\n",
      "Microsoft不存在于词向量中\n",
      "courses.不存在于词向量中\n",
      "INTp不存在于词向量中\n",
      "hopeful,不存在于词向量中\n",
      "Chat不存在于词向量中\n",
      "Reserved不存在于词向量中\n",
      "edge.不存在于词向量中\n",
      "Option不存在于词向量中\n",
      "I...|||To不存在于词向量中\n",
      "gross,不存在于词向量中\n",
      "thought...不存在于词向量中\n",
      "Gogh不存在于词向量中\n",
      "routines.不存在于词向量中\n",
      "concert,不存在于词向量中\n",
      "Proof不存在于词向量中\n",
      "(:|||I不存在于词向量中\n",
      "Idealists不存在于词向量中\n",
      "Types:不存在于词向量中\n",
      "professional.不存在于词向量中\n",
      "escape,不存在于词向量中\n",
      "magic.不存在于词向量中\n",
      "substance.不存在于词向量中\n",
      "significantly.不存在于词向量中\n",
      "SFP不存在于词向量中\n",
      "who're不存在于词向量中\n",
      "Following不存在于词向量中\n",
      "Ahh,不存在于词向量中\n",
      "(No不存在于词向量中\n",
      "anybody,不存在于词向量中\n",
      "Polish不存在于词向量中\n",
      "went,不存在于词向量中\n",
      "sauce.不存在于词向量中\n",
      "dream?不存在于词向量中\n",
      "Angels不存在于词向量中\n",
      "men)不存在于词向量中\n",
      "holes.不存在于词向量中\n",
      "'just不存在于词向量中\n",
      "shops.不存在于词向量中\n",
      "Adult不存在于词向量中\n",
      "Loki不存在于词向量中\n",
      "Enemy不存在于词向量中\n",
      "island.不存在于词向量中\n",
      "as...'不存在于词向量中\n",
      "of...|||Hi不存在于词向量中\n",
      "conscience.不存在于词向量中\n",
      "purple,不存在于词向量中\n",
      "Park.不存在于词向量中\n",
      "Candy不存在于词向量中\n",
      "hour)不存在于词向量中\n",
      "Harmony不存在于词向量中\n",
      "frank,不存在于词向量中\n",
      "Incredibly不存在于词向量中\n",
      "God?不存在于词向量中\n",
      "photo.不存在于词向量中\n",
      "Leslie不存在于词向量中\n",
      "shared.不存在于词向量中\n",
      "motivated.不存在于词向量中\n",
      "debt,不存在于词向量中\n",
      "Introvert,不存在于词向量中\n",
      "'type'不存在于词向量中\n",
      "failed,不存在于词向量中\n",
      "performance.不存在于词向量中\n",
      "shoulder,不存在于词向量中\n",
      "survive,不存在于词向量中\n",
      "Kings不存在于词向量中\n",
      "20)不存在于词向量中\n",
      "Starcraft不存在于词向量中\n",
      "range,不存在于词向量中\n",
      "False不存在于词向量中\n",
      "alternative,不存在于词向量中\n",
      "Inch不存在于词向量中\n",
      "'love'不存在于词向量中\n",
      "Fi-Ni不存在于词向量中\n",
      "abroad.不存在于词向量中\n",
      "Oliver不存在于词向量中\n",
      "childish,不存在于词向量中\n",
      "normally.不存在于词向量中\n",
      "recent.不存在于词向量中\n",
      "Eren不存在于词向量中\n",
      "Tired不存在于词向量中\n",
      "Atheists不存在于词向量中\n",
      "as...|||I've不存在于词向量中\n",
      "Numbers不存在于词向量中\n",
      "Birth不存在于词向量中\n",
      "Q:不存在于词向量中\n",
      "noise,不存在于词向量中\n",
      "Runner不存在于词向量中\n",
      "eyes?不存在于词向量中\n",
      "Robot不存在于词向量中\n",
      "Woody不存在于词向量中\n",
      "like...|||I've不存在于词向量中\n",
      "down...不存在于词向量中\n",
      "aliens.不存在于词向量中\n",
      ":D|||Hello不存在于词向量中\n",
      "the...|||Maybe不存在于词向量中\n",
      "Earlier不存在于词向量中\n",
      "Naruto,不存在于词向量中\n",
      "Desire不存在于词向量中\n",
      "peaceful.不存在于词向量中\n",
      "whole...|||I不存在于词向量中\n",
      "I'm...|||I've不存在于词向量中\n",
      "stoic,不存在于词向量中\n",
      "positions,不存在于词向量中\n",
      "I'm...|||This不存在于词向量中\n",
      "Level)不存在于词向量中\n",
      "paragraph,不存在于词向量中\n",
      "can...|||My不存在于词向量中\n",
      "Butterfly不存在于词向量中\n",
      "LG-D850不存在于词向量中\n",
      "must,不存在于词向量中\n",
      "lacking.不存在于词向量中\n",
      "I...|||Don't不存在于词向量中\n",
      "Often,不存在于词向量中\n",
      "Blonde不存在于词向量中\n",
      "Scores:不存在于词向量中\n",
      "(MBTI)不存在于词向量中\n",
      "Brody.Adrien不存在于词向量中\n",
      "Win不存在于词向量中\n",
      "territory,不存在于词向量中\n",
      "SOMETHING不存在于词向量中\n",
      "Conversations不存在于词向量中\n",
      "(along不存在于词向量中\n",
      "extraverted.不存在于词向量中\n",
      "repetitive.不存在于词向量中\n",
      "Olympics不存在于词向量中\n",
      "Noble不存在于词向量中\n",
      "Factor不存在于词向量中\n",
      "Anyway...不存在于词向量中\n",
      "Tis不存在于词向量中\n",
      "dog's不存在于词向量中\n",
      "of...|||You're不存在于词向量中\n",
      "Naomi不存在于词向量中\n",
      "vid.不存在于词向量中\n",
      "Tao不存在于词向量中\n",
      "Hudson不存在于词向量中\n",
      "TP不存在于词向量中\n",
      "(note:不存在于词向量中\n",
      "Imagination不存在于词向量中\n",
      "sometimes...|||I不存在于词向量中\n",
      "leadership.不存在于词向量中\n",
      "steps.不存在于词向量中\n",
      "WOW不存在于词向量中\n",
      "believe?不存在于词向量中\n",
      "u.不存在于词向量中\n",
      "dramatic.不存在于词向量中\n",
      "Grammar不存在于词向量中\n",
      "Michio不存在于词向量中\n",
      "unsure,不存在于词向量中\n",
      "intended)不存在于词向量中\n",
      "competent,不存在于词向量中\n",
      "OFF不存在于词向量中\n",
      "guests.不存在于词向量中\n",
      "there..不存在于词向量中\n",
      "Name:不存在于词向量中\n",
      "Location:不存在于词向量中\n",
      "it.|||When不存在于词向量中\n",
      "attractive?不存在于词向量中\n",
      "Raven不存在于词向量中\n",
      "Mafia不存在于词向量中\n",
      "Severus不存在于词向量中\n",
      "darling.不存在于词向量中\n",
      "me.|||If不存在于词向量中\n",
      "Center不存在于词向量中\n",
      "Heres不存在于词向量中\n",
      "Eagle不存在于词向量中\n",
      "instances,不存在于词向量中\n",
      "that...|||Not不存在于词向量中\n",
      "perceptions.不存在于词向量中\n",
      "be...|||Not不存在于词向量中\n",
      "Grandfather不存在于词向量中\n",
      "genetics,不存在于词向量中\n",
      "Spotify不存在于词向量中\n",
      "indie,不存在于词向量中\n",
      "tasks,不存在于词向量中\n",
      "Gathering不存在于词向量中\n",
      "asexual.不存在于词向量中\n",
      "baking,不存在于词向量中\n",
      "tend...|||I不存在于词向量中\n",
      "racism,不存在于词向量中\n",
      "Skype.不存在于词向量中\n",
      "the...|||Is不存在于词向量中\n",
      "oh...不存在于词向量中\n",
      "tricky,不存在于词向量中\n",
      "place)不存在于词向量中\n",
      "careers,不存在于词向量中\n",
      "listed,不存在于词向量中\n",
      "of...|||Sorry不存在于词向量中\n",
      "Reddit不存在于词向量中\n",
      "FB,不存在于词向量中\n",
      "isolation,不存在于词向量中\n",
      "significant.不存在于词向量中\n",
      "hunting,不存在于词向量中\n",
      "theatre,不存在于词向量中\n",
      "LET不存在于词向量中\n",
      "GoT不存在于词向量中\n",
      ":)|||Why不存在于词向量中\n",
      "Ariel不存在于词向量中\n",
      "it...|||That's不存在于词向量中\n",
      "INFP).不存在于词向量中\n",
      "inaccurate,不存在于词向量中\n",
      "Fleetwood不存在于词向量中\n",
      "Nights不存在于词向量中\n",
      "know).不存在于词向量中\n",
      "I鈥檇不存在于词向量中\n",
      "live...|||I不存在于词向量中\n",
      "stare,不存在于词向量中\n",
      "closed.不存在于词向量中\n",
      "inevitable.不存在于词向量中\n",
      "story?不存在于词向量中\n",
      "recall,不存在于词向量中\n",
      "Choleric不存在于词向量中\n",
      "arms,不存在于词向量中\n",
      "FIND不存在于词向量中\n",
      "flat.不存在于词向量中\n",
      "Blair不存在于词向量中\n",
      "untrue.不存在于词向量中\n",
      "necessary?不存在于词向量中\n",
      "Pictures不存在于词向量中\n",
      "Race不存在于词向量中\n",
      "Interestingly不存在于词向量中\n",
      "awkwardness,不存在于词向量中\n",
      "ways?不存在于词向量中\n",
      "TBH不存在于词向量中\n",
      "limited.不存在于词向量中\n",
      "Just...不存在于词向量中\n",
      "me.|||You不存在于词向量中\n",
      "acid,不存在于词向量中\n",
      "difference?不存在于词向量中\n",
      "grandmother,不存在于词向量中\n",
      "2014.不存在于词向量中\n",
      "impressions.不存在于词向量中\n",
      "incompetent,不存在于词向量中\n",
      "'do不存在于词向量中\n",
      "those?不存在于词向量中\n",
      "albums,不存在于词向量中\n",
      "THOSE不存在于词向量中\n",
      "FAR不存在于词向量中\n",
      "Isabel不存在于词向量中\n",
      "Lenore不存在于词向量中\n",
      "Forgiveness不存在于词向量中\n",
      "married?不存在于词向量中\n",
      "legs,不存在于词向量中\n",
      "timid,不存在于词向量中\n",
      "(One不存在于词向量中\n",
      "times...|||I不存在于词向量中\n",
      "embarrassed,不存在于词向量中\n",
      "Civilization不存在于词向量中\n",
      "Summer.不存在于词向量中\n",
      "contrary.不存在于词向量中\n",
      "Killers不存在于词向量中\n",
      "(used不存在于词向量中\n",
      "G.不存在于词向量中\n",
      "Giver不存在于词向量中\n",
      "style?不存在于词向量中\n",
      "pm.不存在于词向量中\n",
      "doctor's不存在于词向量中\n",
      "BEEN不存在于词向量中\n",
      "upon,不存在于词向量中\n",
      "glad.不存在于词向量中\n",
      "nostalgic,不存在于词向量中\n",
      "or...|||It's不存在于词向量中\n",
      "Once,不存在于词向量中\n",
      "hopeful.不存在于词向量中\n",
      "HSP,不存在于词向量中\n",
      "Uranus不存在于词向量中\n",
      "chicken.不存在于词向量中\n",
      "Swordsman不存在于词向量中\n",
      "normal?不存在于词向量中\n",
      "(INTJ不存在于词向量中\n",
      "unfair.不存在于词向量中\n",
      "#1.不存在于词向量中\n",
      "Waste不存在于词向量中\n",
      "ISTP.|||I不存在于词向量中\n",
      "chameleon.不存在于词向量中\n",
      "MBA不存在于词向量中\n",
      "Time,不存在于词向量中\n",
      "wholeheartedly.不存在于词向量中\n",
      "appreciate,不存在于词向量中\n",
      "stay,不存在于词向量中\n",
      "to...|||And不存在于词向量中\n",
      "retrospect,不存在于词向量中\n",
      "BFF不存在于词向量中\n",
      "dammit.不存在于词向量中\n",
      "lot)不存在于词向量中\n",
      "outsider,不存在于词向量中\n",
      "Margaret不存在于词向量中\n",
      "Oldest不存在于词向量中\n",
      "long)不存在于词向量中\n",
      "beautiful.|||I不存在于词向量中\n",
      "Clint不存在于词向量中\n",
      "nutshell.不存在于词向量中\n",
      "EVERYTHING.不存在于词向量中\n",
      "Trouble不存在于词向量中\n",
      "Pirates不存在于词向量中\n",
      "Commitment不存在于词向量中\n",
      "doses.不存在于词向量中\n",
      "spot-on.不存在于词向量中\n",
      "But.不存在于词向量中\n",
      "Shooting不存在于词向量中\n",
      "Monday.不存在于词向量中\n",
      "subforum.不存在于词向量中\n",
      "with...|||Oh不存在于词向量中\n",
      ":happy:|||You不存在于词向量中\n",
      "Aurora不存在于词向量中\n",
      "here),不存在于词向量中\n",
      "part.|||I不存在于词向量中\n",
      "standard.不存在于词向量中\n",
      "Soviet不存在于词向量中\n",
      "Shirley不存在于词向量中\n",
      "meh.不存在于词向量中\n",
      "actual,不存在于词向量中\n",
      "theirs,不存在于词向量中\n",
      "Sue不存在于词向量中\n",
      "2008.不存在于词向量中\n",
      "her)不存在于词向量中\n",
      "Gus不存在于词向量中\n",
      "Berlin不存在于词向量中\n",
      "One.不存在于词向量中\n",
      "actress,不存在于词向量中\n",
      "preference?不存在于词向量中\n",
      "uni.不存在于词向量中\n",
      "Abraham不存在于词向量中\n",
      "Arizona不存在于词向量中\n",
      "(generally不存在于词向量中\n",
      "(nothing不存在于词向量中\n",
      "sorry...不存在于词向量中\n",
      "Life,不存在于词向量中\n",
      "connect.不存在于词向量中\n",
      "Adolf不存在于词向量中\n",
      "this...'不存在于词向量中\n",
      "Shows不存在于词向量中\n",
      "Choosing不存在于词向量中\n",
      "object.不存在于词向量中\n",
      "breaks,不存在于词向量中\n",
      "overcome.不存在于词向量中\n",
      "last?不存在于词向量中\n",
      "superior.不存在于词向量中\n",
      "instantly.不存在于词向量中\n",
      "insecurities,不存在于词向量中\n",
      "talk...|||I不存在于词向量中\n",
      "Ti/Fe不存在于词向量中\n",
      ":D|||I've不存在于词向量中\n",
      "sentences,不存在于词向量中\n",
      "by...'不存在于词向量中\n",
      "Skip不存在于词向量中\n",
      ":tongue:'不存在于词向量中\n",
      "laws.不存在于词向量中\n",
      "on).不存在于词向量中\n",
      "breathing,不存在于词向量中\n",
      "friends/family不存在于词向量中\n",
      "admire.不存在于词向量中\n",
      "experience...|||I不存在于词向量中\n",
      "...|||No,不存在于词向量中\n",
      "Whose不存在于词向量中\n",
      "Male.不存在于词向量中\n",
      ":)|||For不存在于词向量中\n",
      "work..不存在于词向量中\n",
      "diagnosed,不存在于词向量中\n",
      "Swan不存在于词向量中\n",
      "Played不存在于词向量中\n",
      ":P|||It不存在于词向量中\n",
      ":P).不存在于词向量中\n",
      "Psycho不存在于词向量中\n",
      ":)|||Haha不存在于词向量中\n",
      "participate.不存在于词向量中\n",
      "bottom,不存在于词向量中\n",
      "ENFJ's.不存在于词向量中\n",
      "Story.不存在于词向量中\n",
      "poster.不存在于词向量中\n",
      "holiday,不存在于词向量中\n",
      "less...|||I不存在于词向量中\n",
      "persons,不存在于词向量中\n",
      "Curiosity不存在于词向量中\n",
      "raised.不存在于词向量中\n",
      "easily...|||I不存在于词向量中\n",
      "lame,不存在于词向量中\n",
      "manga.不存在于词向量中\n",
      "subtle.不存在于词向量中\n",
      "point...|||I不存在于词向量中\n",
      "feminism.不存在于词向量中\n",
      "economics,不存在于词向量中\n",
      "EP不存在于词向量中\n",
      "addict,不存在于词向量中\n",
      "week...不存在于词向量中\n",
      "Biblical不存在于词向量中\n",
      "Lane不存在于词向量中\n",
      "Lizzie不存在于词向量中\n",
      "flag,不存在于词向量中\n",
      "That'll不存在于词向量中\n",
      "income,不存在于词向量中\n",
      "pair.不存在于词向量中\n",
      "Tapatalk|||My不存在于词向量中\n",
      "back..不存在于词向量中\n",
      "and...|||No不存在于词向量中\n",
      "Invisible不存在于词向量中\n",
      "analyze,不存在于词向量中\n",
      "clarifying.不存在于词向量中\n",
      "Technical不存在于词向量中\n",
      "ft.不存在于词向量中\n",
      "closer,不存在于词向量中\n",
      "MIGHT不存在于词向量中\n",
      "Possibility:不存在于词向量中\n",
      "Helping不存在于词向量中\n",
      "subconscious,不存在于词向量中\n",
      "all),不存在于词向量中\n",
      "limit,不存在于词向量中\n",
      "Conversation不存在于词向量中\n",
      "first.|||I不存在于词向量中\n",
      "Daria不存在于词向量中\n",
      "plague.不存在于词向量中\n",
      "Hands-on,不存在于词向量中\n",
      "assertive.不存在于词向量中\n",
      "give...|||I不存在于词向量中\n",
      "Nicole不存在于词向量中\n",
      "problems...不存在于词向量中\n",
      "beat.不存在于词向量中\n",
      "TreeBob不存在于词向量中\n",
      "vegetarian.不存在于词向量中\n",
      "butter,不存在于词向量中\n",
      "ignore.不存在于词向量中\n",
      "trapped.不存在于词向量中\n",
      "emotionless,不存在于词向量中\n",
      "(depends不存在于词向量中\n",
      "Flight不存在于词向量中\n",
      "Stanley不存在于词向量中\n",
      "Mars,不存在于词向量中\n",
      "not...|||If不存在于词向量中\n",
      "love)不存在于词向量中\n",
      "ENFPs...不存在于词向量中\n",
      "valuable.不存在于词向量中\n",
      "N?不存在于词向量中\n",
      "nerds,不存在于词向量中\n",
      "compatibility.不存在于词向量中\n",
      "Clarity不存在于词向量中\n",
      "pm,不存在于词向量中\n",
      "comes.不存在于词向量中\n",
      "rejected,不存在于词向量中\n",
      "bear,不存在于词向量中\n",
      "the...|||No,不存在于词向量中\n",
      "Fits不存在于词向量中\n",
      "weekends.不存在于词向量中\n",
      "you...|||Yes,不存在于词向量中\n",
      "ENTJ)不存在于词向量中\n",
      "for...|||For不存在于词向量中\n",
      "tumblr,不存在于词向量中\n",
      "Ixxx不存在于词向量中\n",
      "movements,不存在于词向量中\n",
      "Sour不存在于词向量中\n",
      "you.|||My不存在于词向量中\n",
      "themes,不存在于词向量中\n",
      "generalization,不存在于词向量中\n",
      "Billie不存在于词向量中\n",
      "fitness,不存在于词向量中\n",
      "Feynman不存在于词向量中\n",
      "posters.不存在于词向量中\n",
      "Canadians不存在于词向量中\n",
      "Minds不存在于词向量中\n",
      "reason...|||I不存在于词向量中\n",
      "marry.不存在于词向量中\n",
      "Osama不存在于词向量中\n",
      "on...|||My不存在于词向量中\n",
      "of...|||Well,不存在于词向量中\n",
      "Punishment不存在于词向量中\n",
      "girl...不存在于词向量中\n",
      "Fault不存在于词向量中\n",
      "(once不存在于词向量中\n",
      "of...|||Do不存在于词向量中\n",
      "Greece不存在于词向量中\n",
      "in...|||A不存在于词向量中\n",
      "Midnight不存在于词向量中\n",
      "vocals.不存在于词向量中\n",
      "username?不存在于词向量中\n",
      "compute.不存在于词向量中\n",
      "singer.不存在于词向量中\n",
      "Tapatalk|||What不存在于词向量中\n",
      "chores,不存在于词向量中\n",
      "controlled,不存在于词向量中\n",
      "traditional,不存在于词向量中\n",
      "Hebrew不存在于词向量中\n",
      "much..不存在于词向量中\n",
      "28.不存在于词向量中\n",
      "once...不存在于词向量中\n",
      "Dying不存在于词向量中\n",
      "artistic.不存在于词向量中\n",
      "D,不存在于词向量中\n",
      "is....不存在于词向量中\n",
      "flowers.不存在于词向量中\n",
      "Philosophy,不存在于词向量中\n",
      "Islamic不存在于词向量中\n",
      "accomplishments,不存在于词向量中\n",
      "inappropriate.不存在于词向量中\n",
      "calculating,不存在于词向量中\n",
      "towards,不存在于词向量中\n",
      "music...|||I不存在于词向量中\n",
      "exams,不存在于词向量中\n",
      "99.9%不存在于词向量中\n",
      "Shawshank不存在于词向量中\n",
      "Wants不存在于词向量中\n",
      "Tori不存在于词向量中\n",
      "song's不存在于词向量中\n",
      "of...|||No,不存在于词向量中\n",
      "Bad,不存在于词向量中\n",
      "survival.不存在于词向量中\n",
      "within,不存在于词向量中\n",
      "worrying.不存在于词向量中\n",
      "now?|||I不存在于词向量中\n",
      "justified.不存在于词向量中\n",
      "'We不存在于词向量中\n",
      "Ultimate不存在于词向量中\n",
      "attitudes.不存在于词向量中\n",
      "puns,不存在于词向量中\n",
      "ordinary,不存在于词向量中\n",
      "(basically不存在于词向量中\n",
      "Eater不存在于词向量中\n",
      "naked.不存在于词向量中\n",
      "MAN不存在于词向量中\n",
      "Waldo不存在于词向量中\n",
      "Mystery不存在于词向量中\n",
      "extremely...|||I不存在于词向量中\n",
      "offend.不存在于词向量中\n",
      "default.不存在于词向量中\n",
      "achieve.不存在于词向量中\n",
      "methods,不存在于词向量中\n",
      ":proud:|||I'm不存在于词向量中\n",
      "Metallica不存在于词向量中\n",
      "to),不存在于词向量中\n",
      "tradition,不存在于词向量中\n",
      "surprisingly,不存在于词向量中\n",
      "Photos不存在于词向量中\n",
      "Wear不存在于词向量中\n",
      "Arctic不存在于词向量中\n",
      "fun.|||I不存在于词向量中\n",
      "Korea.不存在于词向量中\n",
      "order...不存在于词向量中\n",
      "theme,不存在于词向量中\n",
      "show...|||I不存在于词向量中\n",
      "friends),不存在于词向量中\n",
      "everyone...|||I不存在于词向量中\n",
      "solid,不存在于词向量中\n",
      "leaders,不存在于词向量中\n",
      "Tennis不存在于词向量中\n",
      "Swimming不存在于词向量中\n",
      "noted,不存在于词向量中\n",
      "clumsy.不存在于词向量中\n",
      "crisis,不存在于词向量中\n",
      "revolution.不存在于词向量中\n",
      "'till不存在于词向量中\n",
      "hatred.不存在于词向量中\n",
      "dies,不存在于词向量中\n",
      "aggression.不存在于词向量中\n",
      ":laughing:'不存在于词向量中\n",
      "length,不存在于词向量中\n",
      "Se/Ni不存在于词向量中\n",
      "Tennessee不存在于词向量中\n",
      "fate.不存在于词向量中\n",
      "Murray不存在于词向量中\n",
      "boxes,不存在于词向量中\n",
      "FREAKING不存在于词向量中\n",
      "All,不存在于词向量中\n",
      "FI不存在于词向量中\n",
      "time.|||You不存在于词向量中\n",
      "lavender,不存在于词向量中\n",
      "fancy.不存在于词向量中\n",
      "Tapatalk|||When不存在于词向量中\n",
      "Ken不存在于词向量中\n",
      "puzzles.不存在于词向量中\n",
      "concerts,不存在于词向量中\n",
      "tattoo,不存在于词向量中\n",
      "treated.不存在于词向量中\n",
      ":'D不存在于词向量中\n",
      "pet,不存在于词向量中\n",
      "Hear不存在于词向量中\n",
      "(cause不存在于词向量中\n",
      "them....|||I不存在于词向量中\n",
      "forgotten.不存在于词向量中\n",
      "cares,不存在于词向量中\n",
      "drugs?不存在于词向量中\n",
      "heels.不存在于词向量中\n",
      "birthdays,不存在于词向量中\n",
      "hard...不存在于词向量中\n",
      "shocked.不存在于词向量中\n",
      "situations?不存在于词向量中\n",
      "that.|||If不存在于词向量中\n",
      "Hail不存在于词向量中\n",
      "TWO不存在于词向量中\n",
      "broke.不存在于词向量中\n",
      "(ENTJ)不存在于词向量中\n",
      "remember)不存在于词向量中\n",
      "sensing,不存在于词向量中\n",
      "map.不存在于词向量中\n",
      "User不存在于词向量中\n",
      "solitude,不存在于词向量中\n",
      "Worked不存在于词向量中\n",
      "side...不存在于词向量中\n",
      "third.不存在于词向量中\n",
      "goals?不存在于词向量中\n",
      "gray,不存在于词向量中\n",
      "enemies,不存在于词向量中\n",
      "goofy,不存在于词向量中\n",
      "interesting.|||I不存在于词向量中\n",
      "gun.不存在于词向量中\n",
      "Singing不存在于词向量中\n",
      "McDonald's不存在于词向量中\n",
      "libertarian.不存在于词向量中\n",
      "ALL.不存在于词向量中\n",
      "that...|||No不存在于词向量中\n",
      "pragmatic.不存在于词向量中\n",
      "INTPs:不存在于词向量中\n",
      "raw,不存在于词向量中\n",
      "star,不存在于词向量中\n",
      "pessimistic.不存在于词向量中\n",
      "that,...|||I不存在于词向量中\n",
      "foot,不存在于词向量中\n",
      "Sloth不存在于词向量中\n",
      "Test.不存在于词向量中\n",
      "Videos不存在于词向量中\n",
      "Hawking不存在于词向量中\n",
      "50.不存在于词向量中\n",
      "laughs.不存在于词向量中\n",
      "each...|||I不存在于词向量中\n",
      "Sharing不存在于词向量中\n",
      "hahaha,不存在于词向量中\n",
      "Questions:不存在于词向量中\n",
      "capitalism.不存在于词向量中\n",
      "shitty,不存在于词向量中\n",
      "Sit不存在于词向量中\n",
      "does?不存在于词向量中\n",
      "NEW不存在于词向量中\n",
      "poster,不存在于词向量中\n",
      "Father,不存在于词向量中\n",
      "here.'不存在于词向量中\n",
      "Netflix.不存在于词向量中\n",
      "greatly,不存在于词向量中\n",
      "case)不存在于词向量中\n",
      "Watched不存在于词向量中\n",
      "Odd不存在于词向量中\n",
      "GOING不存在于词向量中\n",
      "(am不存在于词向量中\n",
      "benefit.不存在于词向量中\n",
      "thought?不存在于词向量中\n",
      "DBZ不存在于词向量中\n",
      "Boss不存在于词向量中\n",
      "Combined不存在于词向量中\n",
      "notion.不存在于词向量中\n",
      "specifics,不存在于词向量中\n",
      "orientation.不存在于词向量中\n",
      "Judy不存在于词向量中\n",
      "quiz.不存在于词向量中\n",
      "PMs不存在于词向量中\n",
      "introspective.不存在于词向量中\n",
      "Burn不存在于词向量中\n",
      "free...|||I不存在于词向量中\n",
      "there's...|||I不存在于词向量中\n",
      "rings,不存在于词向量中\n",
      "author's不存在于词向量中\n",
      "breathe,不存在于词向量中\n",
      "lose,不存在于词向量中\n",
      "Samurai不存在于词向量中\n",
      "happy.|||I不存在于词向量中\n",
      "who...|||I'm不存在于词向量中\n",
      ":happy:'不存在于词向量中\n",
      "credit,不存在于词向量中\n",
      "Cards不存在于词向量中\n",
      "aswell,不存在于词向量中\n",
      "caffeine,不存在于词向量中\n",
      "this...|||My不存在于词向量中\n",
      "Frankly不存在于词向量中\n",
      "of...|||Dear不存在于词向量中\n",
      "ones...不存在于词向量中\n",
      "country?不存在于词向量中\n",
      "Explains不存在于词向量中\n",
      "room...不存在于词向量中\n",
      "27,不存在于词向量中\n",
      "souls,不存在于词向量中\n",
      "venting.不存在于词向量中\n",
      "Minnesota不存在于词向量中\n",
      "Anatomy不存在于词向量中\n",
      "x,不存在于词向量中\n",
      "guess.|||I不存在于词向量中\n",
      "my...|||1.不存在于词向量中\n",
      "Bought不存在于词向量中\n",
      "ESXJ不存在于词向量中\n",
      "companies,不存在于词向量中\n",
      "Bachelors不存在于词向量中\n",
      "ISTP...不存在于词向量中\n",
      "Youtube.不存在于词向量中\n",
      "closet.不存在于词向量中\n",
      "to...|||Maybe不存在于词向量中\n",
      "cool...不存在于词向量中\n",
      "asexual,不存在于词向量中\n",
      "perspectives,不存在于词向量中\n",
      "decent.不存在于词向量中\n",
      "series)不存在于词向量中\n",
      "is...|||Yeah,不存在于词向量中\n",
      "Guys,不存在于词向量中\n",
      "Trent不存在于词向量中\n",
      "Republicans不存在于词向量中\n",
      "friends).不存在于词向量中\n",
      "I...|||From不存在于词向量中\n",
      "semantics,不存在于词向量中\n",
      "cheat,不存在于词向量中\n",
      "lips.不存在于词向量中\n",
      "Julian不存在于词向量中\n",
      "Disney's不存在于词向量中\n",
      "Grandmother:不存在于词向量中\n",
      "houses.不存在于词向量中\n",
      "ISFP's,不存在于词向量中\n",
      "Fish不存在于词向量中\n",
      "challenged.不存在于词向量中\n",
      "Camp不存在于词向量中\n",
      "stimulating.不存在于词向量中\n",
      "Darwin不存在于词向量中\n",
      "as...|||This不存在于词向量中\n",
      "affectionate.不存在于词向量中\n",
      "unattractive.不存在于词向量中\n",
      "commit.不存在于词向量中\n",
      "sane.不存在于词向量中\n",
      "PE不存在于词向量中\n",
      "answering.不存在于词向量中\n",
      "happening?不存在于词向量中\n",
      "experience...不存在于词向量中\n",
      "variables.不存在于词向量中\n",
      "read...不存在于词向量中\n",
      "narcissistic.不存在于词向量中\n",
      "Merlin不存在于词向量中\n",
      "Michigan不存在于词向量中\n",
      "Developed不存在于词向量中\n",
      "Latin,不存在于词向量中\n",
      "good...|||I'm不存在于词向量中\n",
      "risks,不存在于词向量中\n",
      "succeed,不存在于词向量中\n",
      "Vincent不存在于词向量中\n",
      "Hinata不存在于词向量中\n",
      "'real不存在于词向量中\n",
      "26.不存在于词向量中\n",
      "submissive.不存在于词向量中\n",
      "survey.不存在于词向量中\n",
      "income.不存在于词向量中\n",
      "most)不存在于词向量中\n",
      "go.|||I不存在于词向量中\n",
      "Whatever.不存在于词向量中\n",
      "hard?不存在于词向量中\n",
      "(sort不存在于词向量中\n",
      "means...|||I不存在于词向量中\n",
      "argue.不存在于词向量中\n",
      "through...不存在于词向量中\n",
      "problematic.不存在于词向量中\n",
      "Ones不存在于词向量中\n",
      "I...|||I'll不存在于词向量中\n",
      "hole,不存在于词向量中\n",
      "update,不存在于词向量中\n",
      "from...不存在于词向量中\n",
      "my...|||Yeah,不存在于词向量中\n",
      "Scotland不存在于词向量中\n",
      "doubts.不存在于词向量中\n",
      "(=不存在于词向量中\n",
      "jacket,不存在于词向量中\n",
      "concerns.不存在于词向量中\n",
      "OUR不存在于词向量中\n",
      "Jazz不存在于词向量中\n",
      "plant.不存在于词向量中\n",
      "models.不存在于词向量中\n",
      "the...|||Your不存在于词向量中\n",
      "July.不存在于词向量中\n",
      "Naked不存在于词向量中\n",
      "IxxP不存在于词向量中\n",
      "Places不存在于词向量中\n",
      "California.不存在于词向量中\n",
      "Larry不存在于词向量中\n",
      "Corporate不存在于词向量中\n",
      "guilt,不存在于词向量中\n",
      "such...|||I不存在于词向量中\n",
      "Potato不存在于词向量中\n",
      "childish.不存在于词向量中\n",
      "dreamer.不存在于词向量中\n",
      "country's不存在于词向量中\n",
      "Noah不存在于词向量中\n",
      "may.不存在于词向量中\n",
      "mainstream,不存在于词向量中\n",
      "functions)不存在于词向量中\n",
      "Becoming不存在于词向量中\n",
      "do...|||My不存在于词向量中\n",
      "well),不存在于词向量中\n",
      "(can不存在于词向量中\n",
      "Extraverts不存在于词向量中\n",
      "IV不存在于词向量中\n",
      "talents.不存在于词向量中\n",
      "Drawing不存在于词向量中\n",
      "sp/sx.不存在于词向量中\n",
      "Gentle不存在于词向量中\n",
      "Chloe不存在于词向量中\n",
      "analyzing,不存在于词向量中\n",
      "boring?不存在于词向量中\n",
      "parks,不存在于词向量中\n",
      "Comes不存在于词向量中\n",
      "Heights不存在于词向量中\n",
      "visit.不存在于词向量中\n",
      "over...不存在于词向量中\n",
      "????不存在于词向量中\n",
      "Jawz不存在于词向量中\n",
      "conflicts,不存在于词向量中\n",
      "TYPE不存在于词向量中\n",
      "Daddy不存在于词向量中\n",
      "determination.不存在于词向量中\n",
      "Interpersonal不存在于词向量中\n",
      "in...|||Well,不存在于词向量中\n",
      "compatibility,不存在于词向量中\n",
      "already?不存在于词向量中\n",
      "unconscious,不存在于词向量中\n",
      "Ni-doms不存在于词向量中\n",
      "extremes.不存在于词向量中\n",
      "funny...不存在于词向量中\n",
      "'Sorry不存在于词向量中\n",
      "2.0不存在于词向量中\n",
      "lol),不存在于词向量中\n",
      "philosopher,不存在于词向量中\n",
      "Non不存在于词向量中\n",
      "higher,不存在于词向量中\n",
      "toes.不存在于词向量中\n",
      "is...|||Well,不存在于词向量中\n",
      "shoulder.不存在于词向量中\n",
      "Frodo不存在于词向量中\n",
      "Onion不存在于词向量中\n",
      "Nice.不存在于词向量中\n",
      "Georgia不存在于词向量中\n",
      "ever?不存在于词向量中\n",
      "...or不存在于词向量中\n",
      "Foster不存在于词向量中\n",
      "capacity,不存在于词向量中\n",
      "dudes.不存在于词向量中\n",
      "don't...不存在于词向量中\n",
      "Bella不存在于词向量中\n",
      "Lot不存在于词向量中\n",
      "really..不存在于词向量中\n",
      "e.g.,不存在于词向量中\n",
      "happiness?不存在于词向量中\n",
      "man..不存在于词向量中\n",
      "school.|||I不存在于词向量中\n",
      "cute?不存在于词向量中\n",
      "music)不存在于词向量中\n",
      "to...|||Hi不存在于词向量中\n",
      "Ego不存在于词向量中\n",
      "Discovery不存在于词向量中\n",
      "Omg不存在于词向量中\n",
      "Doubt不存在于词向量中\n",
      "Gene不存在于词向量中\n",
      "Means不存在于词向量中\n",
      "TYPE:不存在于词向量中\n",
      "jk.不存在于词向量中\n",
      "phobia,不存在于词向量中\n",
      "killer.不存在于词向量中\n",
      "accomplished.不存在于词向量中\n",
      "skinny,不存在于词向量中\n",
      "and...|||Hello不存在于词向量中\n",
      "astronomy,不存在于词向量中\n",
      "type(s):不存在于词向量中\n",
      "the...|||lol不存在于词向量中\n",
      "Thanks!|||If不存在于词向量中\n",
      "signs,不存在于词向量中\n",
      "(right不存在于词向量中\n",
      "Spongebob不存在于词向量中\n",
      "certainly,不存在于词向量中\n",
      "Lemon不存在于词向量中\n",
      "think..不存在于词向量中\n",
      "SCH-I545不存在于词向量中\n",
      "Tapatalk|||You不存在于词向量中\n",
      "things..不存在于词向量中\n",
      "drug,不存在于词向量中\n",
      "Scarlet不存在于词向量中\n",
      "Bieber不存在于词向量中\n",
      "Ahhh不存在于词向量中\n",
      "Maybe?不存在于词向量中\n",
      "damage.不存在于词向量中\n",
      "-Get不存在于词向量中\n",
      "favourites.不存在于词向量中\n",
      "chat,不存在于词向量中\n",
      "envy.不存在于词向量中\n",
      "'Yes不存在于词向量中\n",
      "ENTp不存在于词向量中\n",
      "not...|||Well,不存在于词向量中\n",
      "the...|||At不存在于词向量中\n",
      "talented.不存在于词向量中\n",
      "mainstream.不存在于词向量中\n",
      "but.不存在于词向量中\n",
      "Smoking不存在于词向量中\n",
      "Sensors,不存在于词向量中\n",
      "ago.|||I不存在于词向量中\n",
      "me...|||This不存在于词向量中\n",
      "Red,不存在于词向量中\n",
      "Eminem不存在于词向量中\n",
      "lacking,不存在于词向量中\n",
      "trend,不存在于词向量中\n",
      "Gravity不存在于词向量中\n",
      "Karen不存在于词向量中\n",
      "I...|||Why不存在于词向量中\n",
      "Unless,不存在于词向量中\n",
      "||||||||||||||||不存在于词向量中\n",
      "NFL不存在于词向量中\n",
      "application.不存在于词向量中\n",
      "discipline,不存在于词向量中\n",
      "...|||Wow,不存在于词向量中\n",
      "They...|||I不存在于词向量中\n",
      "itself?不存在于词向量中\n",
      "part...不存在于词向量中\n",
      "Learned不存在于词向量中\n",
      "Saul不存在于词向量中\n",
      "Park,不存在于词向量中\n",
      "THIS.不存在于词向量中\n",
      "SP/SO不存在于词向量中\n",
      "selfless,不存在于词向量中\n",
      "honest...不存在于词向量中\n",
      "very...|||My不存在于词向量中\n",
      "SAMSUNG-SM-G360AZ不存在于词向量中\n",
      "flirty,不存在于词向量中\n",
      "rap.不存在于词向量中\n",
      "isolated.不存在于词向量中\n",
      "Oops,不存在于词向量中\n",
      "friendship,...|||Explaining不存在于词向量中\n",
      "IQs不存在于词向量中\n",
      "pow|||hey不存在于词向量中\n",
      ":hugs:|||Hello不存在于词向量中\n",
      "SM-G955U不存在于词向量中\n",
      "EVA-L09不存在于词向量中\n",
      "determination,不存在于词向量中\n",
      "compromise,不存在于词向量中\n",
      "XD|||My不存在于词向量中\n",
      "MUCH.不存在于词向量中\n",
      "Compliments不存在于词向量中\n",
      "thoughts...不存在于词向量中\n",
      "data?不存在于词向量中\n",
      "Gates不存在于词向量中\n",
      "Ha,不存在于词向量中\n",
      "Freudian不存在于词向量中\n",
      "laws,不存在于词向量中\n",
      "Freshman不存在于词向量中\n",
      "beforehand.不存在于词向量中\n",
      "nice.|||I不存在于词向量中\n",
      "profession.不存在于词向量中\n",
      "(ENFP不存在于词向量中\n",
      "geek,不存在于词向量中\n",
      "chuckle.不存在于词向量中\n",
      "MIT不存在于词向量中\n",
      "Dead,不存在于词向量中\n",
      "surgery.不存在于词向量中\n",
      "Result:不存在于词向量中\n",
      "VI不存在于词向量中\n",
      "someone...|||I'm不存在于词向量中\n",
      "some...|||The不存在于词向量中\n",
      "Mind,不存在于词向量中\n",
      "MMO不存在于词向量中\n",
      "my...|||Thanks不存在于词向量中\n",
      "(will不存在于词向量中\n",
      "Actualized不存在于词向量中\n",
      "USA,不存在于词向量中\n",
      "ie.不存在于词向量中\n",
      "...|||People不存在于词向量中\n",
      "(age不存在于词向量中\n",
      "today)不存在于词向量中\n",
      "planned.不存在于词向量中\n",
      "incompetence,不存在于词向量中\n",
      "to...|||Are不存在于词向量中\n",
      "Farm不存在于词向量中\n",
      "liar,不存在于词向量中\n",
      "sleepy,不存在于词向量中\n",
      "Fe)不存在于词向量中\n",
      "lecture,不存在于词向量中\n",
      "Heh,不存在于词向量中\n",
      "University,不存在于词向量中\n",
      "Gifted不存在于词向量中\n",
      "Rage不存在于词向量中\n",
      "Lover不存在于词向量中\n",
      "lover.不存在于词向量中\n",
      "much...|||My不存在于词向量中\n",
      "enjoy...|||I不存在于词向量中\n",
      "my...|||Hello不存在于词向量中\n",
      "(working不存在于词向量中\n",
      "weekends,不存在于词向量中\n",
      "though),不存在于词向量中\n",
      "Gosh不存在于词向量中\n",
      "sentimental.不存在于词向量中\n",
      "American.不存在于词向量中\n",
      "Car不存在于词向量中\n",
      "in...|||I'd不存在于词向量中\n",
      "Cousin不存在于词向量中\n",
      "Fry不存在于词向量中\n",
      "USE不存在于词向量中\n",
      "v.不存在于词向量中\n",
      "experience)不存在于词向量中\n",
      "Explore!不存在于词向量中\n",
      "Franz不存在于词向量中\n",
      "bully.不存在于词向量中\n",
      "be..不存在于词向量中\n",
      "exceptions.不存在于词向量中\n",
      "Ne-doms不存在于词向量中\n",
      "incredible,不存在于词向量中\n",
      "Ellen不存在于词向量中\n",
      ":)))不存在于词向量中\n",
      "(let's不存在于词向量中\n",
      "Hahaha!不存在于词向量中\n",
      "(At不存在于词向量中\n",
      "is...|||That's不存在于词向量中\n",
      "breath,不存在于词向量中\n",
      "Helen不存在于词向量中\n",
      "false,不存在于词向量中\n",
      "Tritype:不存在于词向量中\n",
      "sx/sp,不存在于词向量中\n",
      "actually)不存在于词向量中\n",
      "(making不存在于词向量中\n",
      "Laura不存在于词向量中\n",
      "clearer.不存在于词向量中\n",
      "attacks.不存在于词向量中\n",
      "connect,不存在于词向量中\n",
      ":laughing:|||The不存在于词向量中\n",
      "Olivia不存在于词向量中\n",
      "Tough不存在于词向量中\n",
      "butt,不存在于词向量中\n",
      "Zodiac:不存在于词向量中\n",
      "Path不存在于词向量中\n",
      "opposite?不存在于词向量中\n",
      "(again,不存在于词向量中\n",
      "well-being.不存在于词向量中\n",
      "tastes,不存在于词向量中\n",
      "traffic.不存在于词向量中\n",
      "distraction.不存在于词向量中\n",
      "too|||I不存在于词向量中\n",
      "Complex不存在于词向量中\n",
      "destroyed.不存在于词向量中\n",
      "person).不存在于词向量中\n",
      "perspective?不存在于词向量中\n",
      "Politics不存在于词向量中\n",
      "difficulty.不存在于词向量中\n",
      "Cult不存在于词向量中\n",
      "Spice不存在于词向量中\n",
      "'if不存在于词向量中\n",
      "Sci-Fi不存在于词向量中\n",
      "...And不存在于词向量中\n",
      "World,不存在于词向量中\n",
      "Aladdin不存在于词向量中\n",
      "hilarious.|||I不存在于词向量中\n",
      "Ready不存在于词向量中\n",
      "I...|||All不存在于词向量中\n",
      "Filipino不存在于词向量中\n",
      "Hopefully,不存在于词向量中\n",
      "excuse,不存在于词向量中\n",
      "Heck不存在于词向量中\n",
      "Jenna不存在于词向量中\n",
      "ENFP|||I不存在于词向量中\n",
      "Shane不存在于词向量中\n",
      "space?不存在于词向量中\n",
      "informative.不存在于词向量中\n",
      "Mouse不存在于词向量中\n",
      ";)|||The不存在于词向量中\n",
      "Keirsey,不存在于词向量中\n",
      "wedding,不存在于词向量中\n",
      "care...不存在于词向量中\n",
      "Traits不存在于词向量中\n",
      "(6不存在于词向量中\n",
      "gap.不存在于词向量中\n",
      "excitement.不存在于词向量中\n",
      "metaphors,不存在于词向量中\n",
      "Genuine不存在于词向量中\n",
      "Harris不存在于词向量中\n",
      "Watts不存在于词向量中\n",
      "People's不存在于词向量中\n",
      "ring,不存在于词向量中\n",
      "True.不存在于词向量中\n",
      "nostalgic.不存在于词向量中\n",
      "(around不存在于词向量中\n",
      "Imperial不存在于词向量中\n",
      "Heath不存在于词向量中\n",
      "Examples不存在于词向量中\n",
      "tendency,不存在于词向量中\n",
      "Foundation不存在于词向量中\n",
      "obsessed,不存在于词向量中\n",
      "viewpoints.不存在于词向量中\n",
      "will...不存在于词向量中\n",
      "horse,不存在于词向量中\n",
      "Ultimately不存在于词向量中\n",
      "sugar,不存在于词向量中\n",
      "true...|||I不存在于词向量中\n",
      "planet?不存在于词向量中\n",
      "V.不存在于词向量中\n",
      "'Cause不存在于词向量中\n",
      "Them:不存在于词向量中\n",
      "least.|||I不存在于词向量中\n",
      "purple.不存在于词向量中\n",
      "Cinnamon不存在于词向量中\n",
      "Alive不存在于词向量中\n",
      "wording.不存在于词向量中\n",
      "once?不存在于词向量中\n",
      "mind...|||I不存在于词向量中\n",
      "anymore.|||I不存在于词向量中\n",
      "worker.不存在于词向量中\n",
      "exhausted.不存在于词向量中\n",
      "grandmother.不存在于词向量中\n",
      "meditate,不存在于词向量中\n",
      "laundry,不存在于词向量中\n",
      "killers,不存在于词向量中\n",
      "life.|||I'm不存在于词向量中\n",
      "KNEW不存在于词向量中\n",
      "(ISFP)不存在于词向量中\n",
      "Dat不存在于词向量中\n",
      "reality?不存在于词向量中\n",
      "IFP不存在于词向量中\n",
      "Hehe.不存在于词向量中\n",
      "Letters不存在于词向量中\n",
      "loves,不存在于词向量中\n",
      "rush,不存在于词向量中\n",
      "lol|||What不存在于词向量中\n",
      ":proud:.不存在于词向量中\n",
      "I'm...|||What不存在于词向量中\n",
      "Boyfriend不存在于词向量中\n",
      "signals.不存在于词向量中\n",
      "solve.不存在于词向量中\n",
      "sooner,不存在于词向量中\n",
      "bus.不存在于词向量中\n",
      "venting,不存在于词向量中\n",
      "lightly.不存在于词向量中\n",
      "How'd不存在于词向量中\n",
      "when...|||The不存在于词向量中\n",
      "Debating不存在于词向量中\n",
      "wars,不存在于词向量中\n",
      "(correct不存在于词向量中\n",
      "the...|||Some不存在于词向量中\n",
      "happier.不存在于词向量中\n",
      "yes..不存在于词向量中\n",
      "ago..不存在于词向量中\n",
      "two...不存在于词向量中\n",
      "READ不存在于词向量中\n",
      "FIRST不存在于词向量中\n",
      "beat,不存在于词向量中\n",
      "on...|||This不存在于词向量中\n",
      "some...不存在于词向量中\n",
      "STP不存在于词向量中\n",
      "costs,不存在于词向量中\n",
      "yellow,不存在于词向量中\n",
      "listener.不存在于词向量中\n",
      "ISXJ不存在于词向量中\n",
      "mainly.不存在于词向量中\n",
      "response...不存在于词向量中\n",
      "more...|||You不存在于词向量中\n",
      "Wikisocion不存在于词向量中\n",
      "I...|||Is不存在于词向量中\n",
      "closure,不存在于词向量中\n",
      "old?不存在于词向量中\n",
      "Table不存在于词向量中\n",
      "Trump,不存在于词向量中\n",
      "nonsense,不存在于词向量中\n",
      "pairing,不存在于词向量中\n",
      "bridge,不存在于词向量中\n",
      "Technically不存在于词向量中\n",
      "Fleet不存在于词向量中\n",
      "LDR不存在于词向量中\n",
      "Deep,不存在于词向量中\n",
      "3Image不存在于词向量中\n",
      "hearing.不存在于词向量中\n",
      "cry?不存在于词向量中\n",
      "wit.不存在于词向量中\n",
      "Auxiliary不存在于词向量中\n",
      "characters...不存在于词向量中\n",
      "Instagram不存在于词向量中\n",
      "Ps.不存在于词向量中\n",
      "orientation,不存在于词向量中\n",
      "Spain,不存在于词向量中\n",
      "Hong不存在于词向量中\n",
      "images.不存在于词向量中\n",
      "Kong不存在于词向量中\n",
      "ordinary.不存在于词向量中\n",
      "lol'd不存在于词向量中\n",
      ":D|||When不存在于词向量中\n",
      "ME!不存在于词向量中\n",
      "nurturing,不存在于词向量中\n",
      "engaging,不存在于词向量中\n",
      "am...|||I'm不存在于词向量中\n",
      "great?不存在于词向量中\n",
      "stretch.不存在于词向量中\n",
      "anytime.不存在于词向量中\n",
      "really...'不存在于词向量中\n",
      "absolute.不存在于词向量中\n",
      "classic,不存在于词向量中\n",
      "personality.|||I不存在于词向量中\n",
      "June,不存在于词向量中\n",
      "Yoga不存在于词向量中\n",
      "Beethoven不存在于词向量中\n",
      "standards?不存在于词向量中\n",
      "guard.不存在于词向量中\n",
      "stupidity.不存在于词向量中\n",
      "just...|||I've不存在于词向量中\n",
      "large.不存在于词向量中\n",
      "Aux不存在于词向量中\n",
      "sunshine,不存在于词向量中\n",
      "spotlight,不存在于词向量中\n",
      "ESxJ不存在于词向量中\n",
      "websites.不存在于词向量中\n",
      "Nicki不存在于词向量中\n",
      ":laughing:|||You不存在于词向量中\n",
      "tense,不存在于词向量中\n",
      "Dust不存在于词向量中\n",
      "last.fm不存在于词向量中\n",
      "entirety.不存在于词向量中\n",
      "rare)不存在于词向量中\n",
      "little...不存在于词向量中\n",
      "egg,不存在于词向量中\n",
      "is...|||Oh不存在于词向量中\n",
      "passed.不存在于词向量中\n",
      "met?不存在于词向量中\n",
      "girl.|||I不存在于词向量中\n",
      "HARD不存在于词向量中\n",
      "story)不存在于词向量中\n",
      "dichotomy,不存在于词向量中\n",
      "Wikipedia.不存在于词向量中\n",
      "Perceiving:不存在于词向量中\n",
      "let...|||I不存在于词向量中\n",
      "Fullmetal不存在于词向量中\n",
      "Brotherhood不存在于词向量中\n",
      "trash,不存在于词向量中\n",
      "FOUND不存在于词向量中\n",
      "Sebastian不存在于词向量中\n",
      "Fighter不存在于词向量中\n",
      "sit,不存在于词向量中\n",
      "racism.不存在于词向量中\n",
      "Able不存在于词向量中\n",
      "recently...不存在于词向量中\n",
      "claim,不存在于词向量中\n",
      "though,...|||I不存在于词向量中\n",
      "anxiety).不存在于词向量中\n",
      "ENTJ|||I不存在于词向量中\n",
      "objectively.不存在于词向量中\n",
      ":P|||You不存在于词向量中\n",
      "DIY不存在于词向量中\n",
      "musician.不存在于词向量中\n",
      "my...|||So不存在于词向量中\n",
      "ISFPs?不存在于词向量中\n",
      "can...'不存在于词向量中\n",
      "meanings.不存在于词向量中\n",
      "marriage?不存在于词向量中\n",
      "Sansa不存在于词向量中\n",
      "Romney不存在于词向量中\n",
      "judger.不存在于词向量中\n",
      "Marie不存在于词向量中\n",
      "Dame不存在于词向量中\n",
      "a...|||Have不存在于词向量中\n",
      "Trees不存在于词向量中\n",
      "a...|||Why不存在于词向量中\n",
      "dishes,不存在于词向量中\n",
      "dominance.不存在于词向量中\n",
      "mean)不存在于词向量中\n",
      "Africa,不存在于词向量中\n",
      "phenomenon,不存在于词向量中\n",
      "Teaching不存在于词向量中\n",
      "secondly,不存在于词向量中\n",
      "me?!不存在于词向量中\n",
      "Hahaha,不存在于词向量中\n",
      "psychologist,不存在于词向量中\n",
      "Hah,不存在于词向量中\n",
      "mine's不存在于词向量中\n",
      "volatile,不存在于词向量中\n",
      "xNxP不存在于词向量中\n",
      "Iris不存在于词向量中\n",
      "google.不存在于词向量中\n",
      "(INFP不存在于词向量中\n",
      "reflection.不存在于词向量中\n",
      "Eventually,不存在于词向量中\n",
      "charismatic,不存在于词向量中\n",
      "Variant不存在于词向量中\n",
      "Exactly!不存在于词向量中\n",
      "in...|||If不存在于词向量中\n",
      "...|||Yes.不存在于词向量中\n",
      "withdrawn.不存在于词向量中\n",
      "exchange.不存在于词向量中\n",
      "verbal,不存在于词向量中\n",
      "Depressed不存在于词向量中\n",
      "jerks.不存在于词向量中\n",
      "suffer.不存在于词向量中\n",
      "mention.不存在于词向量中\n",
      "gun,不存在于词向量中\n",
      "care...|||I不存在于词向量中\n",
      "heavy.不存在于词向量中\n",
      "Fu不存在于词向量中\n",
      "immensely.不存在于词向量中\n",
      "yellow.不存在于词向量中\n",
      "Bottom不存在于词向量中\n",
      "Raised不存在于词向量中\n",
      "crazy.|||I不存在于词向量中\n",
      "before)不存在于词向量中\n",
      "religions.不存在于词向量中\n",
      "time....|||I不存在于词向量中\n",
      "estp,不存在于词向量中\n",
      "that...|||Yeah,不存在于词向量中\n",
      "OWN不存在于词向量中\n",
      "Evanescence不存在于词向量中\n",
      "Most:不存在于词向量中\n",
      "bigger.不存在于词向量中\n",
      "Merry不存在于词向量中\n",
      "Boring不存在于词向量中\n",
      "Beware不存在于词向量中\n",
      "poker.不存在于词向量中\n",
      "Scarlett不存在于词向量中\n",
      "have...|||Thank不存在于词向量中\n",
      "speak/have不存在于词向量中\n",
      "(excluding不存在于词向量中\n",
      "Leonardo不存在于词向量中\n",
      "IDK,不存在于词向量中\n",
      "construct.不存在于词向量中\n",
      "on...|||A不存在于词向量中\n",
      "brain's不存在于词向量中\n",
      "teacher's不存在于词向量中\n",
      "smiles,不存在于词向量中\n",
      "2nd,不存在于词向量中\n",
      "to...|||We不存在于词向量中\n",
      "audience,不存在于词向量中\n",
      "investment.不存在于词向量中\n",
      "ITS不存在于词向量中\n",
      "reason...不存在于词向量中\n",
      "in...|||When不存在于词向量中\n",
      "condescending.不存在于词向量中\n",
      "it...|||If不存在于词向量中\n",
      "dynamics.不存在于词向量中\n",
      "mushrooms,不存在于词向量中\n",
      "car?不存在于词向量中\n",
      "sense..不存在于词向量中\n",
      "Data不存在于词向量中\n",
      "Duality不存在于词向量中\n",
      "LOT,不存在于词向量中\n",
      "29,不存在于词向量中\n",
      "thread....不存在于词向量中\n",
      "department,不存在于词向量中\n",
      "lab,不存在于词向量中\n",
      "ISTJ-不存在于词向量中\n",
      "(getting不存在于词向量中\n",
      "Feminism不存在于词向量中\n",
      "ENTPs!不存在于词向量中\n",
      "it.|||A不存在于词向量中\n",
      "(Ti不存在于词向量中\n",
      "is...|||As不存在于词向量中\n",
      "(ok不存在于词向量中\n",
      "subjectivity.不存在于词向量中\n",
      "girls)不存在于词向量中\n",
      "Truman不存在于词向量中\n",
      "Paris,不存在于词向量中\n",
      "Clearly,不存在于词向量中\n",
      "LOL)不存在于词向量中\n",
      "'feel'不存在于词向量中\n",
      "(no,不存在于词向量中\n",
      "P-ness不存在于词向量中\n",
      "colours.不存在于词向量中\n",
      "woman?不存在于词向量中\n",
      "Explorer不存在于词向量中\n",
      "emotionally?不存在于词向量中\n",
      "year?不存在于词向量中\n",
      "'m不存在于词向量中\n",
      "e.g不存在于词向量中\n",
      "CIA不存在于词向量中\n",
      "Appreciate不存在于词向量中\n",
      "Smells不存在于词向量中\n",
      "Harvey不存在于词向量中\n",
      "Motorcycle不存在于词向量中\n",
      "circumstance.不存在于词向量中\n",
      "equality,不存在于词向量中\n",
      "Question:不存在于词向量中\n",
      "more..不存在于词向量中\n",
      "times..不存在于词向量中\n",
      "help.|||I不存在于词向量中\n",
      "whatever...不存在于词向量中\n",
      "daydream.不存在于词向量中\n",
      "really...|||So不存在于词向量中\n",
      "unknown,不存在于词向量中\n",
      "that...|||That's不存在于词向量中\n",
      "blonde.不存在于词向量中\n",
      "previously,不存在于词向量中\n",
      "is...|||i不存在于词向量中\n",
      "trauma,不存在于词向量中\n",
      "play...|||I不存在于词向量中\n",
      "Lannister不存在于词向量中\n",
      "(whom不存在于词向量中\n",
      "songs?不存在于词向量中\n",
      "Forrest不存在于词向量中\n",
      "spirits,不存在于词向量中\n",
      "Indeed.不存在于词向量中\n",
      "Violence不存在于词向量中\n",
      "Gosh,不存在于词向量中\n",
      "Uh不存在于词向量中\n",
      "accept,不存在于词向量中\n",
      "wishes.不存在于词向量中\n",
      "mall,不存在于词向量中\n",
      "calling,不存在于词向量中\n",
      "7/10不存在于词向量中\n",
      "best...不存在于词向量中\n",
      "Yu不存在于词向量中\n",
      "be...|||Oh不存在于词向量中\n",
      "forum!|||Welcome不存在于词向量中\n",
      "said)不存在于词向量中\n",
      "compatible,不存在于词向量中\n",
      "Probably.不存在于词向量中\n",
      "Jefferson不存在于词向量中\n",
      "calling.不存在于词向量中\n",
      "king,不存在于词向量中\n",
      "invalid.不存在于词向量中\n",
      "'I'll不存在于词向量中\n",
      ":wink:|||Oh不存在于词向量中\n",
      "Meanwhile不存在于词向量中\n",
      "consent.不存在于词向量中\n",
      "taxes,不存在于词向量中\n",
      "twin,不存在于词向量中\n",
      "relate...不存在于词向量中\n",
      "in...|||So不存在于词向量中\n",
      "VR不存在于词向量中\n",
      "fairness,不存在于词向量中\n",
      "difficult...|||I不存在于词向量中\n",
      "shitty.不存在于词向量中\n",
      "teach.不存在于词向量中\n",
      "Introduction不存在于词向量中\n",
      "protagonist,不存在于词向量中\n",
      "prefer,不存在于词向量中\n",
      "ENFP-不存在于词向量中\n",
      "C'mon不存在于词向量中\n",
      "depressed?不存在于词向量中\n",
      "lucky.不存在于词向量中\n",
      "rice.不存在于词向量中\n",
      "C++不存在于词向量中\n",
      "NE不存在于词向量中\n",
      "required,不存在于词向量中\n",
      "emotional?不存在于词向量中\n",
      "Schizoid:不存在于词向量中\n",
      "Hendrix不存在于词向量中\n",
      "along?不存在于词向量中\n",
      "psychic,不存在于词向量中\n",
      "detached,不存在于词向量中\n",
      "trades,不存在于词向量中\n",
      "discovery,不存在于词向量中\n",
      "Auditory不存在于词向量中\n",
      "meetings,不存在于词向量中\n",
      "Football不存在于词向量中\n",
      "offline.不存在于词向量中\n",
      "domination,不存在于词向量中\n",
      "misery.不存在于词向量中\n",
      "is...|||Well不存在于词向量中\n",
      "my...|||You're不存在于词向量中\n",
      "talent,不存在于词向量中\n",
      "selfishness,不存在于词向量中\n",
      "so/sx.不存在于词向量中\n",
      "Loyal不存在于词向量中\n",
      "Cancer.不存在于词向量中\n",
      "Just,不存在于词向量中\n",
      "this...|||The不存在于词向量中\n",
      "row,不存在于词向量中\n",
      "sooner.不存在于词向量中\n",
      "Google.不存在于词向量中\n",
      "Greed不存在于词向量中\n",
      "BBQ不存在于词向量中\n",
      "periods.不存在于词向量中\n",
      "University.不存在于词向量中\n",
      "Holocaust不存在于词向量中\n",
      "won't,不存在于词向量中\n",
      "emails,不存在于词向量中\n",
      "job...不存在于词向量中\n",
      "3...不存在于词向量中\n",
      "W.不存在于词向量中\n",
      "plot.不存在于词向量中\n",
      "gee,不存在于词向量中\n",
      "today.|||I不存在于词向量中\n",
      "Thrones,不存在于词向量中\n",
      "writers.不存在于词向量中\n",
      "INFX不存在于词向量中\n",
      "beliefs?不存在于词向量中\n",
      "app.不存在于词向量中\n",
      "Coast不存在于词向量中\n",
      "IPs不存在于词向量中\n",
      "us..不存在于词向量中\n",
      "Enfj不存在于词向量中\n",
      "lesbian,不存在于词向量中\n",
      "aside.不存在于词向量中\n",
      "Peeta不存在于词向量中\n",
      "Gale不存在于词向量中\n",
      "them?|||I不存在于词向量中\n",
      "pool.不存在于词向量中\n",
      "the...|||Can不存在于词向量中\n",
      "such?不存在于词向量中\n",
      "loudly,不存在于词向量中\n",
      "height,不存在于词向量中\n",
      "been?不存在于词向量中\n",
      "maybe...|||I不存在于词向量中\n",
      "surprising,不存在于词向量中\n",
      "disappear.不存在于词向量中\n",
      "on...|||If不存在于词向量中\n",
      "unpleasant,不存在于词向量中\n",
      "course),不存在于词向量中\n",
      "GONNA不存在于词向量中\n",
      "Electronic不存在于词向量中\n",
      "Hurt不存在于词向量中\n",
      "NC不存在于词向量中\n",
      "Games,不存在于词向量中\n",
      "recognition.不存在于词向量中\n",
      "entity,不存在于词向量中\n",
      "reclusive,不存在于词向量中\n",
      "SX/SP不存在于词向量中\n",
      "CP不存在于词向量中\n",
      "judgemental.不存在于词向量中\n",
      "cover,不存在于词向量中\n",
      "Rights不存在于词向量中\n",
      "Genuinely不存在于词向量中\n",
      "Counselor不存在于词向量中\n",
      "couple,不存在于词向量中\n",
      "'ve不存在于词向量中\n",
      "brains.不存在于词向量中\n",
      "movies?不存在于词向量中\n",
      "appreciation.不存在于词向量中\n",
      "t-shirt.不存在于词向量中\n",
      "ESFx不存在于词向量中\n",
      "Nobel不存在于词向量中\n",
      "'Every不存在于词向量中\n",
      "Turned不存在于词向量中\n",
      "2011.不存在于词向量中\n",
      "it?!不存在于词向量中\n",
      "so...|||I've不存在于词向量中\n",
      "you),不存在于词向量中\n",
      "(Yes不存在于词向量中\n",
      "like....不存在于词向量中\n",
      "affirmation.不存在于词向量中\n",
      "they...'不存在于词向量中\n",
      "dom?不存在于词向量中\n",
      "lesson,不存在于词向量中\n",
      "Sin不存在于词向量中\n",
      "imagery.不存在于词向量中\n",
      "emo,不存在于词向量中\n",
      "Loyalty不存在于词向量中\n",
      "'I'd不存在于词向量中\n",
      "bias,不存在于词向量中\n",
      ":p.不存在于词向量中\n",
      "irritated,不存在于词向量中\n",
      "repeat,不存在于词向量中\n",
      "humorous.不存在于词向量中\n",
      "Toronto不存在于词向量中\n",
      "sentimental,不存在于词向量中\n",
      "your...|||This不存在于词向量中\n",
      "it...|||What不存在于词向量中\n",
      "Liberty不存在于词向量中\n",
      "remember...|||I不存在于词向量中\n",
      "irony,不存在于词向量中\n",
      "with...|||You不存在于词向量中\n",
      "started...|||I不存在于词向量中\n",
      "story...不存在于词向量中\n",
      "Youth不存在于词向量中\n",
      "loving.不存在于词向量中\n",
      "forms,不存在于词向量中\n",
      "Applied不存在于词向量中\n",
      "differently?不存在于词向量中\n",
      "Region?不存在于词向量中\n",
      "stereotyping.不存在于词向量中\n",
      "charisma,不存在于词向量中\n",
      "star.不存在于词向量中\n",
      "musical,不存在于词向量中\n",
      "contest.不存在于词向量中\n",
      "well....不存在于词向量中\n",
      "(thus不存在于词向量中\n",
      "Samantha不存在于词向量中\n",
      "moves,不存在于词向量中\n",
      "and...|||Yes不存在于词向量中\n",
      "UGH不存在于词向量中\n",
      "my...|||That's不存在于词向量中\n",
      "Sensors.不存在于词向量中\n",
      "Singapore不存在于词向量中\n",
      "Combine不存在于词向量中\n",
      "truly.不存在于词向量中\n",
      "XP不存在于词向量中\n",
      "I...|||Most不存在于词向量中\n",
      "dirty.不存在于词向量中\n",
      "infjs.不存在于词向量中\n",
      "Marketing不存在于词向量中\n",
      "buttons.不存在于词向量中\n",
      "Neuroscience不存在于词向量中\n",
      "Hurricane不存在于词向量中\n",
      "sp/so.不存在于词向量中\n",
      "esfp.不存在于词向量中\n",
      "will...|||I'm不存在于词向量中\n",
      "ENFP).不存在于词向量中\n",
      "hahah.不存在于词向量中\n",
      "INFJ-不存在于词向量中\n",
      "total.不存在于词向量中\n",
      "to...|||Hey不存在于词向量中\n",
      "cognition.不存在于词向量中\n",
      "Moses不存在于词向量中\n",
      "learner,不存在于词向量中\n",
      "there're不存在于词向量中\n",
      "makeup?不存在于词向量中\n",
      "Sucks不存在于词向量中\n",
      "orange.不存在于词向量中\n",
      "concert.不存在于词向量中\n",
      "Consciousness不存在于词向量中\n",
      "Lovecraft不存在于词向量中\n",
      "misconception.不存在于词向量中\n",
      "Neutral.不存在于词向量中\n",
      "Marry不存在于词向量中\n",
      "ISFJ|||I不存在于词向量中\n",
      "Results:不存在于词向量中\n",
      "on..不存在于词向量中\n",
      "missed.不存在于词向量中\n",
      "photographer,不存在于词向量中\n",
      "Jr不存在于词向量中\n",
      "FL不存在于词向量中\n",
      "Meat不存在于词向量中\n",
      "Sun,不存在于词向量中\n",
      "feat.不存在于词向量中\n",
      "introduction,不存在于词向量中\n",
      "Adding不存在于词向量中\n",
      "London.不存在于词向量中\n",
      "troubles.不存在于词向量中\n",
      "Indigo不存在于词向量中\n",
      ";)|||My不存在于词向量中\n",
      "self-centered,不存在于词向量中\n",
      "principle.不存在于词向量中\n",
      "Gerard不存在于词向量中\n",
      "types.|||I不存在于词向量中\n",
      "tan,不存在于词向量中\n",
      "pissed,不存在于词向量中\n",
      "exhausting,不存在于词向量中\n",
      "2010's不存在于词向量中\n",
      "Fringe不存在于词向量中\n",
      "Reznor不存在于词向量中\n",
      "prom.不存在于词向量中\n",
      ":p)不存在于词向量中\n",
      "Infjs不存在于词向量中\n",
      "am..不存在于词向量中\n",
      "a...|||Yeah不存在于词向量中\n",
      "etc.)?不存在于词向量中\n",
      "irritating,不存在于词向量中\n",
      "pack,不存在于词向量中\n",
      "contradictions.不存在于词向量中\n",
      "Paternal不存在于词向量中\n",
      "Uhm,不存在于词向量中\n",
      "emotion?不存在于词向量中\n",
      "manual.不存在于词向量中\n",
      "mr.不存在于词向量中\n",
      "guys)不存在于词向量中\n",
      "Positive不存在于词向量中\n",
      "statistics,不存在于词向量中\n",
      "paragraphs.不存在于词向量中\n",
      "I.e.不存在于词向量中\n",
      "authentic.不存在于词向量中\n",
      "Individual不存在于词向量中\n",
      "cook.不存在于词向量中\n",
      "Anderson不存在于词向量中\n",
      "week's不存在于词向量中\n",
      "stands.不存在于词向量中\n",
      "McDonalds不存在于词向量中\n",
      "christian,不存在于词向量中\n",
      "Maynard不存在于词向量中\n",
      "Circle不存在于词向量中\n",
      "get...|||My不存在于词向量中\n",
      ":P|||I've不存在于词向量中\n",
      "friggin'不存在于词向量中\n",
      "grounded,不存在于词向量中\n",
      "simultaneously.不存在于词向量中\n",
      "to...|||Wow,不存在于词向量中\n",
      "phones,不存在于词向量中\n",
      "Arguing不存在于词向量中\n",
      "football.不存在于词向量中\n",
      "detached.不存在于词向量中\n",
      "yourself...不存在于词向量中\n",
      "of...|||Wow,不存在于词向量中\n",
      "She'd不存在于词向量中\n",
      "(ESTJ)不存在于词向量中\n",
      "Girl:不存在于词向量中\n",
      "manners,不存在于词向量中\n",
      "Distribution不存在于词向量中\n",
      "Easier不存在于词向量中\n",
      "overbearing,不存在于词向量中\n",
      "crime,不存在于词向量中\n",
      "ethic,不存在于词向量中\n",
      "his...|||I'm不存在于词向量中\n",
      "are),不存在于词向量中\n",
      "Fashion不存在于词向量中\n",
      "flesh.不存在于词向量中\n",
      "Cox不存在于词向量中\n",
      "anyway),不存在于词向量中\n",
      "melancholic,不存在于词向量中\n",
      "kitty,不存在于词向量中\n",
      "PS3不存在于词向量中\n",
      "say..不存在于词向量中\n",
      "he.不存在于词向量中\n",
      "in...|||Thanks不存在于词向量中\n",
      "lived,不存在于词向量中\n",
      "small...|||I不存在于词向量中\n",
      "videogames,不存在于词向量中\n",
      "live)不存在于词向量中\n",
      "caught.不存在于词向量中\n",
      "Stories不存在于词向量中\n",
      "'nice'不存在于词向量中\n",
      "comforting.不存在于词向量中\n",
      "witty.不存在于词向量中\n",
      "but...|||What不存在于词向量中\n",
      "Candle不存在于词向量中\n",
      "authenticity,不存在于词向量中\n",
      "kindergarten,不存在于词向量中\n",
      "(many不存在于词向量中\n",
      "drained,不存在于词向量中\n",
      "laid-back,不存在于词向量中\n",
      "looking...|||I不存在于词向量中\n",
      "eachother,不存在于词向量中\n",
      "My...|||I'm不存在于词向量中\n",
      "best...|||I不存在于词向量中\n",
      "Avoiding不存在于词向量中\n",
      "Blake不存在于词向量中\n",
      "legal,不存在于词向量中\n",
      "universe?不存在于词向量中\n",
      "If,不存在于词向量中\n",
      "CGI不存在于词向量中\n",
      "to...|||I'll不存在于词向量中\n",
      "Civ不存在于词向量中\n",
      "Tan,不存在于词向量中\n",
      "kid...不存在于词向量中\n",
      "WORLD不存在于词向量中\n",
      "Influence不存在于词向量中\n",
      "another...不存在于词向量中\n",
      "Boots不存在于词向量中\n",
      "want...不存在于词向量中\n",
      "entp.不存在于词向量中\n",
      "Freud不存在于词向量中\n",
      "brothers.不存在于词向量中\n",
      "apathy.不存在于词向量中\n",
      "vocabulary,不存在于词向量中\n",
      ":blushed:.不存在于词向量中\n",
      "the,不存在于词向量中\n",
      "INTJs...不存在于词向量中\n",
      "solved,不存在于词向量中\n",
      "wasn't...|||I不存在于词向量中\n",
      "gods,不存在于词向量中\n",
      "tidy.不存在于词向量中\n",
      "umm,不存在于词向量中\n",
      "Queen,不存在于词向量中\n",
      "Or...不存在于词向量中\n",
      "movies)不存在于词向量中\n",
      "assignment.不存在于词向量中\n",
      "clash.不存在于词向量中\n",
      "Quotient不存在于词向量中\n",
      "for...|||It's不存在于词向量中\n",
      "school),不存在于词向量中\n",
      "functions...不存在于词向量中\n",
      "Penny不存在于词向量中\n",
      "Irish,不存在于词向量中\n",
      "careers.不存在于词向量中\n",
      "IXFP不存在于词向量中\n",
      "animation,不存在于词向量中\n",
      "route.不存在于词向量中\n",
      "ENFP...|||I不存在于词向量中\n",
      "solitary,不存在于词向量中\n",
      "don't...|||You不存在于词向量中\n",
      "FJs不存在于词向量中\n",
      "Kendrick不存在于词向量中\n",
      "Awesome.不存在于词向量中\n",
      "bars,不存在于词向量中\n",
      "misleading,不存在于词向量中\n",
      "hand...不存在于词向量中\n",
      "vegan,不存在于词向量中\n",
      "Meaning,不存在于词向量中\n",
      "limits,不存在于词向量中\n",
      "Processes不存在于词向量中\n",
      "void.不存在于词向量中\n",
      "spring.不存在于词向量中\n",
      "observe,不存在于词向量中\n",
      "Sacral:不存在于词向量中\n",
      "Monica不存在于词向量中\n",
      "unstable.不存在于词向量中\n",
      "Ya,不存在于词向量中\n",
      "cheesy,不存在于词向量中\n",
      "bullied.不存在于词向量中\n",
      "(definitely不存在于词向量中\n",
      "foundation,不存在于词向量中\n",
      "me...|||You不存在于词向量中\n",
      "topic?不存在于词向量中\n",
      "intelligence?不存在于词向量中\n",
      "really...|||I've不存在于词向量中\n",
      "PS4不存在于词向量中\n",
      "cult.不存在于词向量中\n",
      "tool,不存在于词向量中\n",
      "Scrubs不存在于词向量中\n",
      "language)不存在于词向量中\n",
      "day..不存在于词向量中\n",
      "Awesome!不存在于词向量中\n",
      "intention,不存在于词向量中\n",
      "Rap不存在于词向量中\n",
      "Low:不存在于词向量中\n",
      "Zoe不存在于词向量中\n",
      "to...|||Hmm,不存在于词向量中\n",
      "Slayer不存在于词向量中\n",
      "Greatest不存在于词向量中\n",
      "video...不存在于词向量中\n",
      "Der不存在于词向量中\n",
      "appropriate,不存在于词向量中\n",
      "accurately.不存在于词向量中\n",
      "like.|||I不存在于词向量中\n",
      "SAD不存在于词向量中\n",
      "pathetic,不存在于词向量中\n",
      "it.|||It's不存在于词向量中\n",
      "Energy不存在于词向量中\n",
      "Never,不存在于词向量中\n",
      "Denver不存在于词向量中\n",
      "required.不存在于词向量中\n",
      "simply.不存在于词向量中\n",
      ":)|||To不存在于词向量中\n",
      "Boy:不存在于词向量中\n",
      "taxes.不存在于词向量中\n",
      "hopeless.不存在于词向量中\n",
      "bacon,不存在于词向量中\n",
      "turn.不存在于词向量中\n",
      "(let不存在于词向量中\n",
      "verbally.不存在于词向量中\n",
      "INFP...|||I不存在于词向量中\n",
      "appeal.不存在于词向量中\n",
      "cynical.不存在于词向量中\n",
      "intriguing,不存在于词向量中\n",
      "self-confidence.不存在于词向量中\n",
      "decisive.不存在于词向量中\n",
      "INTJ/ENFP不存在于词向量中\n",
      "Wellsy不存在于词向量中\n",
      "decades.不存在于词向量中\n",
      "concise,不存在于词向量中\n",
      "Burger不存在于词向量中\n",
      "fool.不存在于词向量中\n",
      "Einstein,不存在于词向量中\n",
      "but...|||I've不存在于词向量中\n",
      "yea.不存在于词向量中\n",
      "Vietnamese不存在于词向量中\n",
      "insults.不存在于词向量中\n",
      "was...|||I've不存在于词向量中\n",
      "right..不存在于词向量中\n",
      "physical...|||I不存在于词向量中\n",
      "typology,不存在于词向量中\n",
      "base.不存在于词向量中\n",
      "you...|||That不存在于词向量中\n",
      "Fruits不存在于词向量中\n",
      "handwriting,不存在于词向量中\n",
      "shoulders.不存在于词向量中\n",
      "(over不存在于词向量中\n",
      "ISFP.|||I不存在于词向量中\n",
      "else)不存在于词向量中\n",
      "Pros:不存在于词向量中\n",
      "specific?不存在于词向量中\n",
      "works?不存在于词向量中\n",
      "inside...不存在于词向量中\n",
      "bat.不存在于词向量中\n",
      "spelling.不存在于词向量中\n",
      "Acting不存在于词向量中\n",
      "Honor不存在于词向量中\n",
      "observer.不存在于词向量中\n",
      "Reason:不存在于词向量中\n",
      "N/S,不存在于词向量中\n",
      "continue.不存在于词向量中\n",
      "Room不存在于词向量中\n",
      "brains,不存在于词向量中\n",
      "legal.不存在于词向量中\n",
      "Notre不存在于词向量中\n",
      "belong,不存在于词向量中\n",
      "Wars.不存在于词向量中\n",
      "hurt?不存在于词向量中\n",
      "anyone...不存在于词向量中\n",
      "nothingness.不存在于词向量中\n",
      "about...|||This不存在于词向量中\n",
      "idiots,不存在于词向量中\n",
      "8?不存在于词向量中\n",
      "Huh,不存在于词向量中\n",
      "Draw不存在于词向量中\n",
      "affirmation,不存在于词向量中\n",
      "a...|||I'll不存在于词向量中\n",
      "...|||Some不存在于词向量中\n",
      "stomach,不存在于词向量中\n",
      "||||||||||||不存在于词向量中\n",
      "Cutie不存在于词向量中\n",
      "War,不存在于词向量中\n",
      "grounded.不存在于词向量中\n",
      "hated,不存在于词向量中\n",
      "Scared不存在于词向量中\n",
      "feelings)不存在于词向量中\n",
      "Showing不存在于词向量中\n",
      "optimism.不存在于词向量中\n",
      "capitalism,不存在于词向量中\n",
      "act?不存在于词向量中\n",
      "Thread.不存在于词向量中\n",
      "Perceiver不存在于词向量中\n",
      "Internal不存在于词向量中\n",
      "similarly,不存在于词向量中\n",
      "Easily不存在于词向量中\n",
      "Mastermind不存在于词向量中\n",
      "concrete.不存在于词向量中\n",
      "acceptance,不存在于词向量中\n",
      "wins.不存在于词向量中\n",
      "funk,不存在于词向量中\n",
      "Afterwards不存在于词向量中\n",
      "(also,不存在于词向量中\n",
      "Idealism不存在于词向量中\n",
      "(who's不存在于词向量中\n",
      "sincerity.不存在于词向量中\n",
      "BY不存在于词向量中\n",
      "failing.不存在于词向量中\n",
      "(aside不存在于词向量中\n",
      "silent.不存在于词向量中\n",
      "robots,不存在于词向量中\n",
      "matches.不存在于词向量中\n",
      "absurd,不存在于词向量中\n",
      "auxiliary,不存在于词向量中\n",
      "well....|||I不存在于词向量中\n",
      "gf.不存在于词向量中\n",
      "interact.不存在于词向量中\n",
      "be...|||Thanks不存在于词向量中\n",
      "socialize,不存在于词向量中\n",
      "FiNe不存在于词向量中\n",
      "nurse.不存在于词向量中\n",
      "sometimes..不存在于词向量中\n",
      "worthy.不存在于词向量中\n",
      "Sun18不存在于词向量中\n",
      "soul?不存在于词向量中\n",
      "parents)不存在于词向量中\n",
      "lol|||You不存在于词向量中\n",
      "Doms-不存在于词向量中\n",
      "Envoy茅不存在于词向量中\n",
      "on/off不存在于词向量中\n",
      "opera,不存在于词向量中\n",
      "classroom.不存在于词向量中\n",
      "'Maybe不存在于词向量中\n",
      "nerves,不存在于词向量中\n",
      "Heh.不存在于词向量中\n",
      "environment?不存在于词向量中\n",
      "atmosphere.不存在于词向量中\n",
      "artsy,不存在于词向量中\n",
      "Keeps不存在于词向量中\n",
      "Democratic不存在于词向量中\n",
      "essay.不存在于词向量中\n",
      "headphones,不存在于词向量中\n",
      "too!|||I不存在于词向量中\n",
      "definitions,不存在于词向量中\n",
      "admire,不存在于词向量中\n",
      "Americans,不存在于词向量中\n",
      "most...|||I'm不存在于词向量中\n",
      "assume,不存在于词向量中\n",
      "LII不存在于词向量中\n",
      "sleep.|||I不存在于词向量中\n",
      "tests?不存在于词向量中\n",
      "novelty,不存在于词向量中\n",
      "Hesse不存在于词向量中\n",
      "to...|||There's不存在于词向量中\n",
      "(With不存在于词向量中\n",
      "Literally.不存在于词向量中\n",
      "xSTJs不存在于词向量中\n",
      "picky,不存在于词向量中\n",
      "XD)不存在于词向量中\n",
      "sexist.不存在于词向量中\n",
      "Sigh,不存在于词向量中\n",
      "if...|||I'm不存在于词向量中\n",
      "26,不存在于词向量中\n",
      "outcast,不存在于词向量中\n",
      "ask...|||I不存在于词向量中\n",
      "you...|||Yeah不存在于词向量中\n",
      "doms.不存在于词向量中\n",
      "Preferred不存在于词向量中\n",
      "usage.不存在于词向量中\n",
      ":laughing:|||My不存在于词向量中\n",
      "valuable,不存在于词向量中\n",
      "basics,不存在于词向量中\n",
      "Divine不存在于词向量中\n",
      "enemy,不存在于词向量中\n",
      "Hufflepuff,不存在于词向量中\n",
      "Oops不存在于词向量中\n",
      "lord.不存在于词向量中\n",
      "Customer不存在于词向量中\n",
      "Recreation不存在于词向量中\n",
      "dull,不存在于词向量中\n",
      "Panic!不存在于词向量中\n",
      "xD|||I'm不存在于词向量中\n",
      "Message不存在于词向量中\n",
      "seeing.不存在于词向量中\n",
      "Sooo不存在于词向量中\n",
      "(might不存在于词向量中\n",
      "Fascinating不存在于词向量中\n",
      "chaotic.不存在于词向量中\n",
      "french,不存在于词向量中\n",
      "target.不存在于词向量中\n",
      "Unsure不存在于词向量中\n",
      "Honesty不存在于词向量中\n",
      "brief,不存在于词向量中\n",
      "that.|||You不存在于词向量中\n",
      "Gut不存在于词向量中\n",
      "Area不存在于词向量中\n",
      "chosen,不存在于词向量中\n",
      "cup.不存在于词向量中\n",
      "Keith不存在于词向量中\n",
      "exes.不存在于词向量中\n",
      "release,不存在于词向量中\n",
      "hatred,不存在于词向量中\n",
      "eccentric.不存在于词向量中\n",
      "Fi-dom,不存在于词向量中\n",
      "Ti/Si不存在于词向量中\n",
      "Elon不存在于词向量中\n",
      "Instant不存在于词向量中\n",
      "authenticity.不存在于词向量中\n",
      "too),不存在于词向量中\n",
      "express.不存在于词向量中\n",
      "storm.不存在于词向量中\n",
      "Jaime不存在于词向量中\n",
      "trolling?不存在于词向量中\n",
      "vulnerability,不存在于词向量中\n",
      "Instinct不存在于词向量中\n",
      "So..不存在于词向量中\n",
      "9?不存在于词向量中\n",
      "'this不存在于词向量中\n",
      "part).不存在于词向量中\n",
      "8w9.不存在于词向量中\n",
      "following.不存在于词向量中\n",
      "Pool不存在于词向量中\n",
      "recall.不存在于词向量中\n",
      "XYZ不存在于词向量中\n",
      "stack,不存在于词向量中\n",
      "FYI,不存在于词向量中\n",
      "(ESFP)不存在于词向量中\n",
      "Movement不存在于词向量中\n",
      "layers.不存在于词向量中\n",
      "Huge不存在于词向量中\n",
      "workplace,不存在于词向量中\n",
      "the...|||1)不存在于词向量中\n",
      "this),不存在于词向量中\n",
      "texts.不存在于词向量中\n",
      "are...|||What不存在于词向量中\n",
      "intensely.不存在于词向量中\n",
      "that...|||Hey不存在于词向量中\n",
      "Looked不存在于词向量中\n",
      "LEAST不存在于词向量中\n",
      "planets,不存在于词向量中\n",
      "Mathematics不存在于词向量中\n",
      "label,不存在于词向量中\n",
      "Division不存在于词向量中\n",
      "class?不存在于词向量中\n",
      "loose,不存在于词向量中\n",
      "eyebrows.不存在于词向量中\n",
      "Pixar不存在于词向量中\n",
      "completed.不存在于词向量中\n",
      "Perry不存在于词向量中\n",
      "As...|||I不存在于词向量中\n",
      "specifically?不存在于词向量中\n",
      "That鈥檚不存在于词向量中\n",
      "alien,不存在于词向量中\n",
      "Lust不存在于词向量中\n",
      "lust.不存在于词向量中\n",
      "Nolan不存在于词向量中\n",
      "Modest不存在于词向量中\n",
      "disorder?不存在于词向量中\n",
      "sober,不存在于词向量中\n",
      "pleasant,不存在于词向量中\n",
      "course...不存在于词向量中\n",
      "DOESN'T不存在于词向量中\n",
      "Anywho,不存在于词向量中\n",
      "Except,不存在于词向量中\n",
      "questioned.不存在于词向量中\n",
      "Partly不存在于词向量中\n",
      "ETA:不存在于词向量中\n",
      "Someone's不存在于词向量中\n",
      "INXP不存在于词向量中\n",
      "Dario不存在于词向量中\n",
      "tag,不存在于词向量中\n",
      "engaged,不存在于词向量中\n",
      "cuddly,不存在于词向量中\n",
      "(new不存在于词向量中\n",
      "(our不存在于词向量中\n",
      "(may不存在于词向量中\n",
      "static.不存在于词向量中\n",
      "knife,不存在于词向量中\n",
      "build.不存在于词向量中\n",
      "nothing's不存在于词向量中\n",
      "battle,不存在于词向量中\n",
      "win?不存在于词向量中\n",
      "courage.不存在于词向量中\n",
      ":laughing:|||Well不存在于词向量中\n",
      "nice...不存在于词向量中\n",
      "WERE不存在于词向量中\n",
      "occur.不存在于词向量中\n",
      "Bro不存在于词向量中\n",
      "envy,不存在于词向量中\n",
      "WHOLE不存在于词向量中\n",
      "Hmmm.不存在于词向量中\n",
      "Again.不存在于词向量中\n",
      "Types.不存在于词向量中\n",
      "science?不存在于词向量中\n",
      "their...|||I'm不存在于词向量中\n",
      "away.|||I不存在于词向量中\n",
      "iTunes不存在于词向量中\n",
      ":)|||Not不存在于词向量中\n",
      "'like'不存在于词向量中\n",
      "(keep不存在于词向量中\n",
      "guess..不存在于词向量中\n",
      "Saturn不存在于词向量中\n",
      "Alright.不存在于词向量中\n",
      "birthdays.不存在于词向量中\n",
      "still...不存在于词向量中\n",
      "destination.不存在于词向量中\n",
      "can...|||It不存在于词向量中\n",
      "dependable,不存在于词向量中\n",
      "it.|||That不存在于词向量中\n",
      "hints.不存在于词向量中\n",
      "Ascendant不存在于词向量中\n",
      "Snake不存在于词向量中\n",
      "Risk不存在于词向量中\n",
      "judgers,不存在于词向量中\n",
      "wrong).不存在于词向量中\n",
      "transfusion.不存在于词向量中\n",
      "functioning,不存在于词向量中\n",
      "Per不存在于词向量中\n",
      "forgive,不存在于词向量中\n",
      "TE不存在于词向量中\n",
      "'no不存在于词向量中\n",
      "'INTJ不存在于词向量中\n",
      "advice.|||I不存在于词向量中\n",
      ":)|||I'd不存在于词向量中\n",
      "really...|||Yes,不存在于词向量中\n",
      "dammit,不存在于词向量中\n",
      "term)不存在于词向量中\n",
      "big...|||I不存在于词向量中\n",
      "ear,不存在于词向量中\n",
      "trash.不存在于词向量中\n",
      "manly,不存在于词向量中\n",
      "afar.不存在于词向量中\n",
      "hand?不存在于词向量中\n",
      "a...|||Most不存在于词向量中\n",
      "demeanor,不存在于词向量中\n",
      "(ENFJ)不存在于词向量中\n",
      "Examples:不存在于词向量中\n",
      "dorm.不存在于词向量中\n",
      "1w9.不存在于词向量中\n",
      "Yep!不存在于词向量中\n",
      "speak?不存在于词向量中\n",
      "it.|||What不存在于词向量中\n",
      "bedroom,不存在于词向量中\n",
      "coworkers.不存在于词向量中\n",
      "...|||Like不存在于词向量中\n",
      "avoid,不存在于词向量中\n",
      "Ti-Si不存在于词向量中\n",
      "...|||Have不存在于词向量中\n",
      "(hopefully不存在于词向量中\n",
      "heat.不存在于词向量中\n",
      "THe不存在于词向量中\n",
      "laundry.不存在于词向量中\n",
      "ISFJ's.不存在于词向量中\n",
      "Nowadays,不存在于词向量中\n",
      "apply,不存在于词向量中\n",
      "religion?不存在于词向量中\n",
      "Moon.不存在于词向量中\n",
      "Light.不存在于词向量中\n",
      "Work,不存在于词向量中\n",
      "FUN不存在于词向量中\n",
      "Umm,不存在于词向量中\n",
      "cool.|||I不存在于词向量中\n",
      "show's不存在于词向量中\n",
      "crazy...不存在于词向量中\n",
      "suggested.不存在于词向量中\n",
      "There.不存在于词向量中\n",
      "ISFx不存在于词向量中\n",
      "to...|||People不存在于词向量中\n",
      "command.不存在于词向量中\n",
      "fitting.不存在于词向量中\n",
      "christian.不存在于词向量中\n",
      "Authority不存在于词向量中\n",
      "instances.不存在于词向量中\n",
      "thankfully.不存在于词向量中\n",
      "think?|||I不存在于词向量中\n",
      "else?|||I不存在于词向量中\n",
      "LITERALLY不存在于词向量中\n",
      "user's不存在于词向量中\n",
      "products,不存在于词向量中\n",
      "guessing.不存在于词向量中\n",
      "SAID不存在于词向量中\n",
      "(has不存在于词向量中\n",
      "bully,不存在于词向量中\n",
      "selfishness.不存在于词向量中\n",
      "Ti:不存在于词向量中\n",
      "Negative不存在于词向量中\n",
      "no.|||I不存在于词向量中\n",
      "Broken不存在于词向量中\n",
      "Skin不存在于词向量中\n",
      "ppl.不存在于词向量中\n",
      "Realizing不存在于词向量中\n",
      "unfortunate.不存在于词向量中\n",
      "take?不存在于词向量中\n",
      "paradox,不存在于词向量中\n",
      "awesome?不存在于词向量中\n",
      "But..不存在于词向量中\n",
      "*I*不存在于词向量中\n",
      "Socratic不存在于词向量中\n",
      "Christ.不存在于词向量中\n",
      "IxTP.不存在于词向量中\n",
      "arm.不存在于词向量中\n",
      "Italy,不存在于词向量中\n",
      "though|||I不存在于词向量中\n",
      "Valley不存在于词向量中\n",
      "Winning不存在于词向量中\n",
      "grey.不存在于词向量中\n",
      "Oz不存在于词向量中\n",
      "Sparkle不存在于词向量中\n",
      "y/o不存在于词向量中\n",
      "'best不存在于词向量中\n",
      "just...|||It不存在于词向量中\n",
      "endless.不存在于词向量中\n",
      "way....|||I不存在于词向量中\n",
      "hopefully,不存在于词向量中\n",
      "Reasoning不存在于词向量中\n",
      "virgin,不存在于词向量中\n",
      "desperate,不存在于词向量中\n",
      "traditional.不存在于词向量中\n",
      "difficulty,不存在于词向量中\n",
      "experiment,不存在于词向量中\n",
      "nostalgia.不存在于词向量中\n",
      "at.|||I不存在于词向量中\n",
      "flexible.不存在于词向量中\n",
      "judged.不存在于词向量中\n",
      "ship.不存在于词向量中\n",
      "favor.不存在于词向量中\n",
      "I've...|||I'm不存在于词向量中\n",
      "all...|||I've不存在于词向量中\n",
      "AWESOME.不存在于词向量中\n",
      "not...|||What不存在于词向量中\n",
      "Mitch不存在于词向量中\n",
      "mathematics.不存在于词向量中\n",
      "crowds.不存在于词向量中\n",
      "sensors?不存在于词向量中\n",
      "Ti-不存在于词向量中\n",
      "Scandinavia不存在于词向量中\n",
      "Nowhere不存在于词向量中\n",
      "(real不存在于词向量中\n",
      "Glenn不存在于词向量中\n",
      "fact?不存在于词向量中\n",
      "Like...|||I不存在于词向量中\n",
      "oops,不存在于词向量中\n",
      "(Sorry,不存在于词向量中\n",
      "Oblivion不存在于词向量中\n",
      "Rye不存在于词向量中\n",
      "I...|||Haha不存在于词向量中\n",
      "neither,不存在于词向量中\n",
      "dynamics,不存在于词向量中\n",
      "IxTx不存在于词向量中\n",
      "LoL不存在于词向量中\n",
      "of...|||Not不存在于词向量中\n",
      "a...|||Hello不存在于词向量中\n",
      "Saturday.不存在于词向量中\n",
      "be...|||1.不存在于词向量中\n",
      "Artists不存在于词向量中\n",
      "Rabbit不存在于词向量中\n",
      ":)|||But不存在于词向量中\n",
      "Practice不存在于词向量中\n",
      "(ESFJ)不存在于词向量中\n",
      "Hip不存在于词向量中\n",
      "teen.不存在于词向量中\n",
      "lol|||The不存在于词向量中\n",
      "and...|||All不存在于词向量中\n",
      "that!|||I不存在于词向量中\n",
      "more...|||It's不存在于词向量中\n",
      "Vancouver不存在于词向量中\n",
      "intellectually,不存在于词向量中\n",
      "uneasy.不存在于词向量中\n",
      "production,不存在于词向量中\n",
      "far...|||I不存在于词向量中\n",
      "ambition,不存在于词向量中\n",
      "necessity,不存在于词向量中\n",
      "metaphor.不存在于词向量中\n",
      "me...and不存在于词向量中\n",
      "addicted.不存在于词向量中\n",
      "because...|||You不存在于词向量中\n",
      "F)不存在于词向量中\n",
      "Nina不存在于词向量中\n",
      "em.不存在于词向量中\n",
      "Solitude不存在于词向量中\n",
      "whiny,不存在于词向量中\n",
      "am...|||The不存在于词向量中\n",
      "and...|||Hmm,不存在于词向量中\n",
      "Burton不存在于词向量中\n",
      "engaged.不存在于词向量中\n",
      "despair.不存在于词向量中\n",
      "Netherlands不存在于词向量中\n",
      "Percentages不存在于词向量中\n",
      "'Wow,不存在于词向量中\n",
      "8D不存在于词向量中\n",
      "ENFP.|||I不存在于词向量中\n",
      "Wrath不存在于词向量中\n",
      "Man's不存在于词向量中\n",
      "BOTH不存在于词向量中\n",
      "ENFJs!不存在于词向量中\n",
      "Teachers不存在于词向量中\n",
      "Bible,不存在于词向量中\n",
      "Integrity不存在于词向量中\n",
      "Magician不存在于词向量中\n",
      "comics,不存在于词向量中\n",
      "Gilmore不存在于词向量中\n",
      "Model不存在于词向量中\n",
      "INFP-ish不存在于词向量中\n",
      "here.)不存在于词向量中\n",
      "Goddess不存在于词向量中\n",
      "height.不存在于词向量中\n",
      "gray.不存在于词向量中\n",
      "Claire不存在于词向量中\n",
      "Seth不存在于词向量中\n",
      "Francis不存在于词向量中\n",
      "Godfather不存在于词向量中\n",
      "that...|||Thank不存在于词向量中\n",
      "outlet.不存在于词向量中\n",
      "GTA不存在于词向量中\n",
      "anyways?不存在于词向量中\n",
      "bands.不存在于词向量中\n",
      "anyone...|||I不存在于词向量中\n",
      "Sick不存在于词向量中\n",
      "JFK不存在于词向量中\n",
      "destiny,不存在于词向量中\n",
      "penalty.不存在于词向量中\n",
      "economy,不存在于词向量中\n",
      "my...|||As不存在于词向量中\n",
      "tear.不存在于词向量中\n",
      "Fiona不存在于词向量中\n",
      "prison.不存在于词向量中\n",
      "expertise.不存在于词向量中\n",
      "(pun不存在于词向量中\n",
      "waters.不存在于词向量中\n",
      "universal.不存在于词向量中\n",
      "mine).不存在于词向量中\n",
      "gatherings.不存在于词向量中\n",
      "Moderate,不存在于词向量中\n",
      "don'不存在于词向量中\n",
      "Introverted,不存在于词向量中\n",
      "Drives不存在于词向量中\n",
      "flight,不存在于词向量中\n",
      "diagnosed.不存在于词向量中\n",
      "Montreal不存在于词向量中\n",
      "paths.不存在于词向量中\n",
      "Pushing不存在于词向量中\n",
      "'why不存在于词向量中\n",
      "Shakespeare's不存在于词向量中\n",
      "the...|||People不存在于词向量中\n",
      "offence,不存在于词向量中\n",
      "Player不存在于词向量中\n",
      "amount,不存在于词向量中\n",
      "Confessions不存在于词向量中\n",
      "Critique不存在于词向量中\n",
      "Stevens不存在于词向量中\n",
      "thoughts...|||I不存在于词向量中\n",
      "madness.不存在于词向量中\n",
      "relationship...|||I不存在于词向量中\n",
      "coffee?不存在于词向量中\n",
      "ups,不存在于词向量中\n",
      "(her不存在于词向量中\n",
      "efficiency,不存在于词向量中\n",
      "'real'不存在于词向量中\n",
      "the...|||Hmm,不存在于词向量中\n",
      "MMOs不存在于词向量中\n",
      ":tongue:|||If不存在于词向量中\n",
      "MJ不存在于词向量中\n",
      "OMG!不存在于词向量中\n",
      "thinking)不存在于词向量中\n",
      "resolved.不存在于词向量中\n",
      "cried,不存在于词向量中\n",
      "toxic,不存在于词向量中\n",
      "-If不存在于词向量中\n",
      "bullying.不存在于词向量中\n",
      "instead.|||I不存在于词向量中\n",
      "Bin不存在于词向量中\n",
      "just...|||When不存在于词向量中\n",
      "embarrassment.不存在于词向量中\n",
      "male)不存在于词向量中\n",
      "wind.不存在于词向量中\n",
      "Blink不存在于词向量中\n",
      "entj.不存在于词向量中\n",
      "ESFP-不存在于词向量中\n",
      "procrastinator.不存在于词向量中\n",
      "change.|||I不存在于词向量中\n",
      "Shrugged不存在于词向量中\n",
      "Diaries不存在于词向量中\n",
      "acceptable,不存在于词向量中\n",
      "achieve,不存在于词向量中\n",
      "THINGS不存在于词向量中\n",
      "Pan不存在于词向量中\n",
      "decent,不存在于词向量中\n",
      "GOP不存在于词向量中\n",
      "fulfilling.不存在于词向量中\n",
      "Bone不存在于词向量中\n",
      "pissed.不存在于词向量中\n",
      "of...|||Hello不存在于词向量中\n",
      "duty.不存在于词向量中\n",
      "Powers不存在于词向量中\n",
      "DOING不存在于词向量中\n",
      "attributes.不存在于词向量中\n",
      "shocked,不存在于词向量中\n",
      "PJ不存在于词向量中\n",
      "Laughing不存在于词向量中\n",
      "distraction,不存在于词向量中\n",
      "bookstore.不存在于词向量中\n",
      "closely,不存在于词向量中\n",
      "Three:不存在于词向量中\n",
      "of...|||Yeah不存在于词向量中\n",
      "but...I不存在于词向量中\n",
      "Poland不存在于词向量中\n",
      "faults.不存在于词向量中\n",
      "dominate.不存在于词向量中\n",
      "Independence不存在于词向量中\n",
      "just...|||You不存在于词向量中\n",
      "'Is不存在于词向量中\n",
      "wouldn't...|||I不存在于词向量中\n",
      "that...|||i不存在于词向量中\n",
      "'don't不存在于词向量中\n",
      "environments.不存在于词向量中\n",
      "for...|||i不存在于词向量中\n",
      "Motivation不存在于词向量中\n",
      "downs.不存在于词向量中\n",
      "Intuitive,不存在于词向量中\n",
      "Sawyer不存在于词向量中\n",
      "almost,不存在于词向量中\n",
      "irrelevant,不存在于词向量中\n",
      "Medium不存在于词向量中\n",
      "brown.不存在于词向量中\n",
      "Piper不存在于词向量中\n",
      "Interview不存在于词向量中\n",
      "Situation:不存在于词向量中\n",
      "(personality)不存在于词向量中\n",
      "backyard.不存在于词向量中\n",
      "old...|||I不存在于词向量中\n",
      "gets...|||I不存在于词向量中\n",
      "I...|||Hi,不存在于词向量中\n",
      "I...|||So,不存在于词向量中\n",
      "Sunday,不存在于词向量中\n",
      "CA,不存在于词向量中\n",
      "Counseling不存在于词向量中\n",
      "casual.不存在于词向量中\n",
      "It...|||I'm不存在于词向量中\n",
      "Sith不存在于词向量中\n",
      "Huh.不存在于词向量中\n",
      "Dinner不存在于词向量中\n",
      "Requiem不存在于词向量中\n",
      "steady,不存在于词向量中\n",
      "Rurouni不存在于词向量中\n",
      "phones.不存在于词向量中\n",
      "differ,不存在于词向量中\n",
      "side.|||I不存在于词向量中\n",
      "empathy?不存在于词向量中\n",
      "(those不存在于词向量中\n",
      "Stuck不存在于词向量中\n",
      "well).不存在于词向量中\n",
      "boards,不存在于词向量中\n",
      "clue,不存在于词向量中\n",
      "heart...|||I不存在于词向量中\n",
      "Harold不存在于词向量中\n",
      "huh.不存在于词向量中\n",
      "smart?不存在于词向量中\n",
      "Emerson不存在于词向量中\n",
      "Epic不存在于词向量中\n",
      "Apples不存在于词向量中\n",
      ".......不存在于词向量中\n",
      "happened...不存在于词向量中\n",
      "Guardians不存在于词向量中\n",
      "SOOOO不存在于词向量中\n",
      "tritype?不存在于词向量中\n",
      "Mysterious不存在于词向量中\n",
      "Foot不存在于词向量中\n",
      "bite,不存在于词向量中\n",
      "admittedly,不存在于词向量中\n",
      "contradictory.不存在于词向量中\n",
      "Lucid不存在于词向量中\n",
      "Schizotypal:不存在于词向量中\n",
      "mountains.不存在于词向量中\n",
      "performance,不存在于词向量中\n",
      "c.不存在于词向量中\n",
      "bike.不存在于词向量中\n",
      "Sagan不存在于词向量中\n",
      "Percy不存在于词向量中\n",
      "kinda.不存在于词向量中\n",
      "Daba不存在于词向量中\n",
      "realistically,不存在于词向量中\n",
      "shorts.不存在于词向量中\n",
      "temperaments.不存在于词向量中\n",
      "Christians.不存在于词向量中\n",
      "HIM不存在于词向量中\n",
      "search.不存在于词向量中\n",
      "Jenny不存在于词向量中\n",
      "XSFP不存在于词向量中\n",
      "nicely,不存在于词向量中\n",
      "Russian,不存在于词向量中\n",
      "FTW!不存在于词向量中\n",
      "'Most不存在于词向量中\n",
      "days...|||I不存在于词向量中\n",
      "smarter.不存在于词向量中\n",
      "Drama不存在于词向量中\n",
      "bastard,不存在于词向量中\n",
      "tragedy.不存在于词向量中\n",
      "NT's,不存在于词向量中\n",
      "INTJs)不存在于词向量中\n",
      "crime.不存在于词向量中\n",
      "soulmates.不存在于词向量中\n",
      "withdraw.不存在于词向量中\n",
      "pushy,不存在于词向量中\n",
      "Brilliant不存在于词向量中\n",
      "times).不存在于词向量中\n",
      "we...|||This不存在于词向量中\n",
      "strange...不存在于词向量中\n",
      "Tapatalk|||That不存在于词向量中\n",
      "Sherlock.不存在于词向量中\n",
      "Istj不存在于词向量中\n",
      "YES!!不存在于词向量中\n",
      "Dang不存在于词向量中\n",
      "Mister不存在于词向量中\n",
      "generalizations.不存在于词向量中\n",
      "clock,不存在于词向量中\n",
      "all.|||I'm不存在于词向量中\n",
      "Monk不存在于词向量中\n",
      "infjs,不存在于词向量中\n",
      "post...|||I不存在于词向量中\n",
      "Holding不存在于词向量中\n",
      "intrigued.不存在于词向量中\n",
      "Ns,不存在于词向量中\n",
      "agreed,不存在于词向量中\n",
      "devil.不存在于词向量中\n",
      "destruction.不存在于词向量中\n",
      "identity?不存在于词向量中\n",
      "attached,不存在于词向量中\n",
      "MC不存在于词向量中\n",
      "(lol不存在于词向量中\n",
      "a...|||Yes.不存在于词向量中\n",
      "we're...|||I不存在于词向量中\n",
      "cautious.不存在于词向量中\n",
      "Prison不存在于词向量中\n",
      "that...|||Why不存在于词向量中\n",
      "demons,不存在于词向量中\n",
      "Kindness不存在于词向量中\n",
      "WORST不存在于词向量中\n",
      "stacking.不存在于词向量中\n",
      "To...|||I不存在于词向量中\n",
      "example...不存在于词向量中\n",
      "URL不存在于词向量中\n",
      "collection.不存在于词向量中\n",
      "NSFW不存在于词向量中\n",
      "former.不存在于词向量中\n",
      "openly.不存在于词向量中\n",
      "being?不存在于词向量中\n",
      "e.不存在于词向量中\n",
      "burn.不存在于词向量中\n",
      "release.不存在于词向量中\n",
      "coincidence,不存在于词向量中\n",
      "she,不存在于词向量中\n",
      "persuasion.不存在于词向量中\n",
      "medium.不存在于词向量中\n",
      "Mystic不存在于词向量中\n",
      "hiking.不存在于词向量中\n",
      "monologue.不存在于词向量中\n",
      "interest...不存在于词向量中\n",
      "Brazilian不存在于词向量中\n",
      "the...|||But不存在于词向量中\n",
      "Conservative不存在于词向量中\n",
      "Harvard不存在于词向量中\n",
      "Broke不存在于词向量中\n",
      "is...|||Yes,不存在于词向量中\n",
      "conclusion?不存在于词向量中\n",
      "you...|||If不存在于词向量中\n",
      "Bride不存在于词向量中\n",
      "safety.不存在于词向量中\n",
      "faster,不存在于词向量中\n",
      "hurtful,不存在于词向量中\n",
      "standard,不存在于词向量中\n",
      "it...|||Well不存在于词向量中\n",
      "texting.不存在于词向量中\n",
      "Chemistry,不存在于词向量中\n",
      "hold.不存在于词向量中\n",
      "'Sometimes不存在于词向量中\n",
      "Knows不存在于词向量中\n",
      "the...|||Most不存在于词向量中\n",
      "counterproductive.不存在于词向量中\n",
      "bible,不存在于词向量中\n",
      "'nuff不存在于词向量中\n",
      "narcissist,不存在于词向量中\n",
      "Clinical不存在于词向量中\n",
      "sci-fi,不存在于词向量中\n",
      "Mood不存在于词向量中\n",
      "Everything.不存在于词向量中\n",
      "island,不存在于词向量中\n",
      "disgusting,不存在于词向量中\n",
      "Seeking不存在于词向量中\n",
      "stereotyping,不存在于词向量中\n",
      "an...|||I've不存在于词向量中\n",
      "Hitchens不存在于词向量中\n",
      "mechanism,不存在于词向量中\n",
      "computer?不存在于词向量中\n",
      ":crazy:'不存在于词向量中\n",
      "examples?不存在于词向量中\n",
      "guns,不存在于词向量中\n",
      "Century不存在于词向量中\n",
      "ex)不存在于词向量中\n",
      "that...|||We不存在于词向量中\n",
      "Paradise不存在于词向量中\n",
      "2w1.不存在于词向量中\n",
      "that...|||For不存在于词向量中\n",
      "security,不存在于词向量中\n",
      "passed,不存在于词向量中\n",
      "Sunrise不存在于词向量中\n",
      "rush.不存在于词向量中\n",
      "violent.不存在于词向量中\n",
      "uni,不存在于词向量中\n",
      "move...|||I不存在于词向量中\n",
      "Wheel不存在于词向量中\n",
      "logic?不存在于词向量中\n",
      "next?不存在于词向量中\n",
      "review.不存在于词向量中\n",
      "Pumpkins不存在于词向量中\n",
      "who...|||This不存在于词向量中\n",
      "posts...不存在于词向量中\n",
      "families,不存在于词向量中\n",
      "Tuesday,不存在于词向量中\n",
      "everytime.不存在于词向量中\n",
      "Eckhart不存在于词向量中\n",
      "Tolle不存在于词向量中\n",
      "Talks不存在于词向量中\n",
      "unrelated,不存在于词向量中\n",
      "Miyazaki不存在于词向量中\n",
      "Finch不存在于词向量中\n",
      "Conscientious不存在于词向量中\n",
      "Lose不存在于词向量中\n",
      "think...'不存在于词向量中\n",
      "lol'不存在于词向量中\n",
      "Father's不存在于词向量中\n",
      "stuff).不存在于词向量中\n",
      "Babies不存在于词向量中\n",
      "can...|||You不存在于词向量中\n",
      "identify.不存在于词向量中\n",
      "secrets,不存在于词向量中\n",
      "my...|||For不存在于词向量中\n",
      "block,不存在于词向量中\n",
      "down...|||I不存在于词向量中\n",
      "tee.不存在于词向量中\n",
      "and...|||So,不存在于词向量中\n",
      "intellectually.不存在于词向量中\n",
      "Barney不存在于词向量中\n",
      "Name?不存在于词向量中\n",
      "toys.不存在于词向量中\n",
      "creature.不存在于词向量中\n",
      "life'不存在于词向量中\n",
      "belong.不存在于词向量中\n",
      "zombie.不存在于词向量中\n",
      "structured.不存在于词向量中\n",
      "flame.不存在于词向量中\n",
      "time.'不存在于词向量中\n",
      "ENTP...|||I不存在于词向量中\n",
      "Left/Right:不存在于词向量中\n",
      "Libertarian/Authoritarian:不存在于词向量中\n",
      "midnight.不存在于词向量中\n",
      "spirituality.不存在于词向量中\n",
      "regret,不存在于词向量中\n",
      "Scholar不存在于词向量中\n",
      "Orchestra不存在于词向量中\n",
      "Kyle不存在于词向量中\n",
      "Compassion不存在于词向量中\n",
      "respectful.不存在于词向量中\n",
      "specifics.不存在于词向量中\n",
      "miss,不存在于词向量中\n",
      "Four:不存在于词向量中\n",
      "dom/aux不存在于词向量中\n",
      "tip,不存在于词向量中\n",
      "contribute,不存在于词向量中\n",
      "Expect不存在于词向量中\n",
      "possible.|||I不存在于词向量中\n",
      "Dany不存在于词向量中\n",
      "Littlefinger不存在于词向量中\n",
      "trips,不存在于词向量中\n",
      "sink.不存在于词向量中\n",
      "off)不存在于词向量中\n",
      "another...|||I不存在于词向量中\n",
      "Yeah...不存在于词向量中\n",
      "is...|||So不存在于词向量中\n",
      "Log不存在于词向量中\n",
      "Baldur's不存在于词向量中\n",
      "Depression,不存在于词向量中\n",
      "White,不存在于词向量中\n",
      "PersonalityCafe.不存在于词向量中\n",
      "patients.不存在于词向量中\n",
      "Communist,不存在于词向量中\n",
      "Majority不存在于词向量中\n",
      "...|||One不存在于词向量中\n",
      "Unknown不存在于词向量中\n",
      "Games.不存在于词向量中\n",
      "(yeah不存在于词向量中\n",
      "radar,不存在于词向量中\n",
      "for...|||When不存在于词向量中\n",
      "textbooks.不存在于词向量中\n",
      "ISFP...不存在于词向量中\n",
      "Auto不存在于词向量中\n",
      "Quest不存在于词向量中\n",
      "passions,不存在于词向量中\n",
      "encouraging,不存在于词向量中\n",
      "Asperger's,不存在于词向量中\n",
      "...)不存在于词向量中\n",
      "into?不存在于词向量中\n",
      "and...|||From不存在于词向量中\n",
      "bed?不存在于词向量中\n",
      "networking.不存在于词向量中\n",
      "positions.不存在于词向量中\n",
      "Wes不存在于词向量中\n",
      "abused.不存在于词向量中\n",
      "nightmare,不存在于词向量中\n",
      "DA不存在于词向量中\n",
      "snap.不存在于词向量中\n",
      "tiny,不存在于词向量中\n",
      "Thinking.不存在于词向量中\n",
      "Corinthians不存在于词向量中\n",
      "Translation不存在于词向量中\n",
      "Laws不存在于词向量中\n",
      "...|||So,不存在于词向量中\n",
      "Rainy不存在于词向量中\n",
      "rough,不存在于词向量中\n",
      "an...|||So不存在于词向量中\n",
      "expect,不存在于词向量中\n",
      "abnormal.不存在于词向量中\n",
      "mistake?不存在于词向量中\n",
      "Dreaming不存在于词向量中\n",
      "Sigh.不存在于词向量中\n",
      "allowed,不存在于词向量中\n",
      "suicidal.不存在于词向量中\n",
      "Lupin不存在于词向量中\n",
      "DVDs不存在于词向量中\n",
      "Maturity不存在于词向量中\n",
      "April.不存在于词向量中\n",
      "cocky,不存在于词向量中\n",
      "harmless.不存在于词向量中\n",
      "shift.不存在于词向量中\n",
      "Cell不存在于词向量中\n",
      "psychic.不存在于词向量中\n",
      "it...|||In不存在于词向量中\n",
      "negativity.不存在于词向量中\n",
      "rewarding.不存在于词向量中\n",
      "Records不存在于词向量中\n",
      "Battlestar不存在于词向量中\n",
      "Honda不存在于词向量中\n",
      "stressed?不存在于词向量中\n",
      "here...|||I不存在于词向量中\n",
      "sad?不存在于词向量中\n",
      "about...|||I've不存在于词向量中\n",
      "bossy.不存在于词向量中\n",
      "that...|||To不存在于词向量中\n",
      "2010.不存在于词向量中\n",
      "Scenario不存在于词向量中\n",
      "ways...不存在于词向量中\n",
      "skeptical.不存在于词向量中\n",
      "guessing,不存在于词向量中\n",
      "fitting,不存在于词向量中\n",
      "February.不存在于词向量中\n",
      "labels.不存在于词向量中\n",
      "Finger不存在于词向量中\n",
      "guns.不存在于词向量中\n",
      "ISTP!不存在于词向量中\n",
      "(go不存在于词向量中\n",
      "adolescence,不存在于词向量中\n",
      "Joke不存在于词向量中\n",
      "you'll...|||I不存在于词向量中\n",
      "Taco不存在于词向量中\n",
      "OCPD不存在于词向量中\n",
      "couch,不存在于词向量中\n",
      "discomfort,不存在于词向量中\n",
      "bits,不存在于词向量中\n",
      "STs不存在于词向量中\n",
      "hiding.不存在于词向量中\n",
      "worthless,不存在于词向量中\n",
      "BTW.不存在于词向量中\n",
      "omg,不存在于词向量中\n",
      "Especially,不存在于词向量中\n",
      "a...|||Maybe不存在于词向量中\n",
      "STRONG不存在于词向量中\n",
      "contradiction.不存在于词向量中\n",
      "Barbie不存在于词向量中\n",
      "Right.不存在于词向量中\n",
      "Director不存在于词向量中\n",
      "aesthetics.不存在于词向量中\n",
      "pen,不存在于词向量中\n",
      ":P|||My不存在于词向量中\n",
      "Perc不存在于词向量中\n",
      "Thanks.|||I不存在于词向量中\n",
      "GB不存在于词向量中\n",
      "format,不存在于词向量中\n",
      "Buddhist,不存在于词向量中\n",
      "Holland不存在于词向量中\n",
      "impulsive.不存在于词向量中\n",
      "ENFP=Ne,不存在于词向量中\n",
      "often...不存在于词向量中\n",
      "Belief不存在于词向量中\n",
      "themselves.|||I不存在于词向量中\n",
      "Hicks不存在于词向量中\n",
      "ISFPs!不存在于词向量中\n",
      "other...|||You不存在于词向量中\n",
      "ENTx不存在于词向量中\n",
      "Niss不存在于词向量中\n",
      "puzzle,不存在于词向量中\n",
      "stands,不存在于词向量中\n",
      "straightforward,不存在于词向量中\n",
      "Huxley不存在于词向量中\n",
      "Aldous不存在于词向量中\n",
      "heck.不存在于词向量中\n",
      "(work不存在于词向量中\n",
      "Circus不存在于词向量中\n",
      "actors,不存在于词向量中\n",
      "subtype.不存在于词向量中\n",
      "absolute,不存在于词向量中\n",
      "handy.不存在于词向量中\n",
      "xNTP,不存在于词向量中\n",
      "Congratulations!不存在于词向量中\n",
      "ISFJ!不存在于词向量中\n",
      "of...|||People不存在于词向量中\n",
      "onions,不存在于词向量中\n",
      "(Oh不存在于词向量中\n",
      "toxic.不存在于词向量中\n",
      "Gabriel不存在于词向量中\n",
      "Clash不存在于词向量中\n",
      "Guild不存在于词向量中\n",
      "Nietzsche,不存在于词向量中\n",
      "priority,不存在于词向量中\n",
      "with...|||It不存在于词向量中\n",
      "meet?不存在于词向量中\n",
      "one'不存在于词向量中\n",
      "Cao不存在于词向量中\n",
      "sword.不存在于词向量中\n",
      "Johns不存在于词向量中\n",
      "owl,不存在于词向量中\n",
      "policy,不存在于词向量中\n",
      "Not...|||I不存在于词向量中\n",
      "Chandler不存在于词向量中\n",
      "GT-I9195不存在于词向量中\n",
      "a...|||We不存在于词向量中\n",
      "cleaning.不存在于词向量中\n",
      "mythology,不存在于词向量中\n",
      "illegal.不存在于词向量中\n",
      "me...|||The不存在于词向量中\n",
      "sociology,不存在于词向量中\n",
      "perceiving.不存在于词向量中\n",
      "processing.不存在于词向量中\n",
      "prepared.不存在于词向量中\n",
      "internally,不存在于词向量中\n",
      "Sometimes...|||I不存在于词向量中\n",
      "MSN不存在于词向量中\n",
      "family...不存在于词向量中\n",
      "pity,不存在于词向量中\n",
      "...|||No不存在于词向量中\n",
      "Fi-Ne不存在于词向量中\n",
      "YEAH不存在于词向量中\n",
      "TBH,不存在于词向量中\n",
      "Weird,不存在于词向量中\n",
      "ambient,不存在于词向量中\n",
      "acts,不存在于词向量中\n",
      "civilization.不存在于词向量中\n",
      "actors.不存在于词向量中\n",
      "colorful,不存在于词向量中\n",
      "coworker,不存在于词向量中\n",
      "Awww不存在于词向量中\n",
      "conflicts.不存在于词向量中\n",
      "bastard.不存在于词向量中\n",
      "enthusiasm,不存在于词向量中\n",
      "rejected.不存在于词向量中\n",
      "Frankenstein不存在于词向量中\n",
      "INF不存在于词向量中\n",
      "detailed,不存在于词向量中\n",
      "difficulties.不存在于词向量中\n",
      "creating,不存在于词向量中\n",
      "emptiness.不存在于词向量中\n",
      "Feelers,不存在于词向量中\n",
      "Sorry!不存在于词向量中\n",
      "applications,不存在于词向量中\n",
      "Jersey不存在于词向量中\n",
      "Catholicism不存在于词向量中\n",
      "Forensic不存在于词向量中\n",
      "lawyer,不存在于词向量中\n",
      "Minor不存在于词向量中\n",
      "toys,不存在于词向量中\n",
      "J.K.不存在于词向量中\n",
      "addressed.不存在于词向量中\n",
      "blogs,不存在于词向量中\n",
      "Plath不存在于词向量中\n",
      "architecture,不存在于词向量中\n",
      "END不存在于词向量中\n",
      "were/are不存在于词向量中\n",
      "Report不存在于词向量中\n",
      "sometimes?不存在于词向量中\n",
      "spoken.不存在于词向量中\n",
      "DONT不存在于词向量中\n",
      "perceiver,不存在于词向量中\n",
      "avatars.不存在于词向量中\n",
      "saying?不存在于词向量中\n",
      "Stargate不存在于词向量中\n",
      "INFJs...不存在于词向量中\n",
      "something...'不存在于词向量中\n",
      "solutions,不存在于词向量中\n",
      "anger?不存在于词向量中\n",
      "cuddly.不存在于词向量中\n",
      "other...|||I'm不存在于词向量中\n",
      "stereotypical.不存在于词向量中\n",
      "integrity,不存在于词向量中\n",
      "August,不存在于词向量中\n",
      "to...|||Is不存在于词向量中\n",
      "Island,不存在于词向量中\n",
      "Festival不存在于词向量中\n",
      "Icy不存在于词向量中\n",
      "Fi...|||I不存在于词向量中\n",
      "of...|||Is不存在于词向量中\n",
      "Lego不存在于词向量中\n",
      "world)不存在于词向量中\n",
      "you...|||Yeah,不存在于词向量中\n",
      "to...|||They不存在于词向量中\n",
      "ISTJ...不存在于词向量中\n",
      "keep...|||I不存在于词向量中\n",
      "Idealistic不存在于词向量中\n",
      "of...|||I'll不存在于词向量中\n",
      "Finish不存在于词向量中\n",
      "Discworld不存在于词向量中\n",
      "'They不存在于词向量中\n",
      "cognitive...|||I不存在于词向量中\n",
      "visual.不存在于词向量中\n",
      "'out不存在于词向量中\n",
      "Girlfriend不存在于词向量中\n",
      "MTBI不存在于词向量中\n",
      "Patience不存在于词向量中\n",
      "Kafka不存在于词向量中\n",
      "confess,不存在于词向量中\n",
      "success?不存在于词向量中\n",
      "Ros不存在于词向量中\n",
      "cold?不存在于词向量中\n",
      "Existential不存在于词向量中\n",
      "practicality.不存在于词向量中\n",
      "tactic.不存在于词向量中\n",
      "Deja不存在于词向量中\n",
      "got,不存在于词向量中\n",
      "3...|||I不存在于词向量中\n",
      "Esfp不存在于词向量中\n",
      "spiritual.不存在于词向量中\n",
      "'Welcome不存在于词向量中\n",
      "right?!不存在于词向量中\n",
      "Wii不存在于词向量中\n",
      "denial,不存在于词向量中\n",
      "Individuals不存在于词向量中\n",
      "I)不存在于词向量中\n",
      "Ne-Te不存在于词向量中\n",
      "with...|||In不存在于词向量中\n",
      "Ne-Fi不存在于词向量中\n",
      "(75%)不存在于词向量中\n",
      "(s)he不存在于词向量中\n",
      "24/7,不存在于词向量中\n",
      "42)不存在于词向量中\n",
      "idealism,不存在于词向量中\n",
      "Mutual不存在于词向量中\n",
      "def.不存在于词向量中\n",
      "that....|||I不存在于词向量中\n",
      "Alternative不存在于词向量中\n",
      "90s.不存在于词向量中\n",
      "case?不存在于词向量中\n",
      "HIGHLY不存在于词向量中\n",
      "introspection.不存在于词向量中\n",
      "I...|||Maybe不存在于词向量中\n",
      "gaming.不存在于词向量中\n",
      "totally,不存在于词向量中\n",
      "Nardi不存在于词向量中\n",
      "hmm..不存在于词向量中\n",
      "Maker不存在于词向量中\n",
      "they...|||My不存在于词向量中\n",
      "Soft不存在于词向量中\n",
      "responsibilities,不存在于词向量中\n",
      ":kitteh:|||I'm不存在于词向量中\n",
      "election.不存在于词向量中\n",
      "enjoyable,不存在于词向量中\n",
      "otherwise)不存在于词向量中\n",
      "4/5不存在于词向量中\n",
      "to...|||Sorry不存在于词向量中\n",
      "Pony:不存在于词向量中\n",
      "broad,不存在于词向量中\n",
      "Avatar,不存在于词向量中\n",
      "which.不存在于词向量中\n",
      "motorcycle,不存在于词向量中\n",
      "grasp.不存在于词向量中\n",
      "sentiment,不存在于词向量中\n",
      "pasta.不存在于词向量中\n",
      "pragmatic,不存在于词向量中\n",
      "Perfection不存在于词向量中\n",
      "objectivity.不存在于词向量中\n",
      "marijuana.不存在于词向量中\n",
      "flattered.不存在于词向量中\n",
      "bro?不存在于词向量中\n",
      "radio,不存在于词向量中\n",
      "was/am不存在于词向量中\n",
      "paintings,不存在于词向量中\n",
      "fingers.不存在于词向量中\n",
      "searching,不存在于词向量中\n",
      "Everyday不存在于词向量中\n",
      "two)不存在于词向量中\n",
      "(Especially不存在于词向量中\n",
      "gentle.不存在于词向量中\n",
      "Scary不存在于词向量中\n",
      "Wave不存在于词向量中\n",
      "'being不存在于词向量中\n",
      "authentic,不存在于词向量中\n",
      "Nuclear不存在于词向量中\n",
      "Advanced不存在于词向量中\n",
      "Poem不存在于词向量中\n",
      "Photography不存在于词向量中\n",
      "'Yes.不存在于词向量中\n",
      "important?不存在于词向量中\n",
      "function...不存在于词向量中\n",
      "Friend,不存在于词向量中\n",
      "consistency.不存在于词向量中\n",
      "Stability不存在于词向量中\n",
      "Trek:不存在于词向量中\n",
      "trends,不存在于词向量中\n",
      "search,不存在于词向量中\n",
      "truths.不存在于词向量中\n",
      "list)不存在于词向量中\n",
      "Lydia不存在于词向量中\n",
      "a...|||Is不存在于词向量中\n",
      "lips,不存在于词向量中\n",
      "observed.不存在于词向量中\n",
      "rising.不存在于词向量中\n",
      "Kiersey不存在于词向量中\n",
      "developer.不存在于词向量中\n",
      "Theft不存在于词向量中\n",
      "douche.不存在于词向量中\n",
      "Tea?不存在于词向量中\n",
      "operate.不存在于词向量中\n",
      "before.|||I不存在于词向量中\n",
      "gets,不存在于词向量中\n",
      "insight?不存在于词向量中\n",
      "confused...不存在于词向量中\n",
      "class)不存在于词向量中\n",
      "question..不存在于词向量中\n",
      "right)不存在于词向量中\n",
      "Just...|||I不存在于词向量中\n",
      "Various不存在于词向量中\n",
      "Entps不存在于词向量中\n",
      "Visual:不存在于词向量中\n",
      "Tactile:不存在于词向量中\n",
      "@.@不存在于词向量中\n",
      "Quinn不存在于词向量中\n",
      "Son不存在于词向量中\n",
      "foods.不存在于词向量中\n",
      "once...|||I不存在于词向量中\n",
      "INFPs:不存在于词向量中\n",
      "(How不存在于词向量中\n",
      "Source不存在于词向量中\n",
      "(ESTP)不存在于词向量中\n",
      "Context不存在于词向量中\n",
      "...|||Is不存在于词向量中\n",
      "Activities不存在于词向量中\n",
      "beautifully.不存在于词向量中\n",
      "collected,不存在于词向量中\n",
      "nutshell,不存在于词向量中\n",
      "other.|||I不存在于词向量中\n",
      "you...|||1.不存在于词向量中\n",
      "deeper.不存在于词向量中\n",
      "INXJ不存在于词向量中\n",
      "(4不存在于词向量中\n",
      "Statistics不存在于词向量中\n",
      "certainty.不存在于词向量中\n",
      "AKA不存在于词向量中\n",
      "since...|||I不存在于词向量中\n",
      "(Because不存在于词向量中\n",
      "way..不存在于词向量中\n",
      "function)不存在于词向量中\n",
      "buttons,不存在于词向量中\n",
      "strong...|||I不存在于词向量中\n",
      "time'不存在于词向量中\n",
      "XNTJs不存在于词向量中\n",
      "intensely,不存在于词向量中\n",
      "*Sigh*不存在于词向量中\n",
      "Geek不存在于词向量中\n",
      "destiny.不存在于词向量中\n",
      "...|||Good不存在于词向量中\n",
      "road?不存在于词向量中\n",
      "Yuri不存在于词向量中\n",
      "Wears不存在于词向量中\n",
      "sales.不存在于词向量中\n",
      "Streaming不存在于词向量中\n",
      "Tinder不存在于词向量中\n",
      "Situation不存在于词向量中\n",
      "thin.不存在于词向量中\n",
      "worded.不存在于词向量中\n",
      ":)|||Can不存在于词向量中\n",
      "Lynch不存在于词向量中\n",
      "year),不存在于词向量中\n",
      "beneficial,不存在于词向量中\n",
      "profiles.不存在于词向量中\n",
      "Cersei不存在于词向量中\n",
      "1,000不存在于词向量中\n",
      "Feeling.不存在于词向量中\n",
      "Bj枚rk不存在于词向量中\n",
      "Sanders不存在于词向量中\n",
      "tick.不存在于词向量中\n",
      "Mine's不存在于词向量中\n",
      "Nines不存在于词向量中\n",
      "Mulder不存在于词向量中\n",
      "xNFJ.不存在于词向量中\n",
      "superiority.不存在于词向量中\n",
      "Pitt不存在于词向量中\n",
      "GT-S5300不存在于词向量中\n",
      "(ISTP)不存在于词向量中\n",
      "ones).不存在于词向量中\n",
      "Important不存在于词向量中\n",
      "Graham不存在于词向量中\n",
      "as...|||If不存在于词向量中\n",
      "Lucifer不存在于词向量中\n",
      "Fe-doms不存在于词向量中\n",
      "Yuki不存在于词向量中\n",
      "Zooey不存在于词向量中\n",
      "(^.^)不存在于词向量中\n",
      "GT-I9515不存在于词向量中\n",
      "Paulo不存在于词向量中\n",
      "forever...不存在于词向量中\n",
      "your...|||The不存在于词向量中\n",
      "ours,不存在于词向量中\n",
      "other...不存在于词向量中\n",
      "INTP...|||I不存在于词向量中\n",
      "talks.不存在于词向量中\n",
      "found...|||I不存在于词向量中\n",
      "She...|||I不存在于词向量中\n",
      "movements.不存在于词向量中\n",
      "fluid,不存在于词向量中\n",
      "issues?不存在于词向量中\n",
      "Anxiety,不存在于词向量中\n",
      "How?不存在于词向量中\n",
      "threat,不存在于词向量中\n",
      "meme.不存在于词向量中\n",
      "Humanity不存在于词向量中\n",
      "Carbon不存在于词向量中\n",
      "Barnes不存在于词向量中\n",
      "all...|||You不存在于词向量中\n",
      "it...|||Just不存在于词向量中\n",
      "others),不存在于词向量中\n",
      "passion?不存在于词向量中\n",
      "ya?不存在于词向量中\n",
      "consciously.不存在于词向量中\n",
      "CDs不存在于词向量中\n",
      "horror,不存在于词向量中\n",
      "ATM不存在于词向量中\n",
      "male?不存在于词向量中\n",
      "Thoreau不存在于词向量中\n",
      "withdraw,不存在于词向量中\n",
      "Fortress不存在于词向量中\n",
      "(God不存在于词向量中\n",
      "Neutral,不存在于词向量中\n",
      "with).不存在于词向量中\n",
      "responded,不存在于词向量中\n",
      "there).不存在于词向量中\n",
      "(minus不存在于词向量中\n",
      "tactics.不存在于词向量中\n",
      "Citizen不存在于词向量中\n",
      "army,不存在于词向量中\n",
      "innocence,不存在于词向量中\n",
      "Von不存在于词向量中\n",
      "brief.不存在于词向量中\n",
      "Pass不存在于词向量中\n",
      "me.|||It不存在于词向量中\n",
      "misunderstanding,不存在于词向量中\n",
      "on...|||1.不存在于词向量中\n",
      "sensitivity,不存在于词向量中\n",
      "clicked.不存在于词向量中\n",
      "2D不存在于词向量中\n",
      "defense.不存在于词向量中\n",
      "smaller,不存在于词向量中\n",
      "rug.不存在于词向量中\n",
      "incident,不存在于词向量中\n",
      "mountain,不存在于词向量中\n",
      "insulting,不存在于词向量中\n",
      "Orleans不存在于词向量中\n",
      "harm,不存在于词向量中\n",
      "Tolkien,不存在于词向量中\n",
      "effectively,不存在于词向量中\n",
      "cheesy.不存在于词向量中\n",
      "chat?不存在于词向量中\n",
      "Nevermind不存在于词向量中\n",
      "Favourite不存在于词向量中\n",
      "phobia.不存在于词向量中\n",
      "dependent.不存在于词向量中\n",
      "Te-dom不存在于词向量中\n",
      "unlikely.不存在于词向量中\n",
      "Hufflepuff!不存在于词向量中\n",
      "government?不存在于词向量中\n",
      "INs不存在于词向量中\n",
      "Bernard不存在于词向量中\n",
      "socks.不存在于词向量中\n",
      "twist.不存在于词向量中\n",
      "yo,不存在于词向量中\n",
      "hit.不存在于词向量中\n",
      "at...|||You不存在于词向量中\n",
      "Tea.不存在于词向量中\n",
      "Scout不存在于词向量中\n",
      "compromise.不存在于词向量中\n",
      "so...|||It's不存在于词向量中\n",
      "SE不存在于词向量中\n",
      "shy?不存在于词向量中\n",
      "Cameron不存在于词向量中\n",
      "it.|||Your不存在于词向量中\n",
      "Wearing不存在于词向量中\n",
      "too.|||My不存在于词向量中\n",
      "I...|||Good不存在于词向量中\n",
      "Uncle不存在于词向量中\n",
      "discussed.不存在于词向量中\n",
      "Monopoly不存在于词向量中\n",
      "Serial不存在于词向量中\n",
      "Moved不存在于词向量中\n",
      "cost.不存在于词向量中\n",
      ":wink:'不存在于词向量中\n",
      "and...|||Being不存在于词向量中\n",
      "MBTI...|||I不存在于词向量中\n",
      "title?不存在于词向量中\n",
      "Fi.|||I不存在于词向量中\n",
      "calendar.不存在于词向量中\n",
      "(oh,不存在于词向量中\n",
      "(esp不存在于词向量中\n",
      "Interesting!不存在于词向量中\n",
      "(second不存在于词向量中\n",
      "Meyer不存在于词向量中\n",
      "pics.不存在于词向量中\n",
      "are...|||How不存在于词向量中\n",
      "years...|||I不存在于词向量中\n",
      "at...|||My不存在于词向量中\n",
      "mentor.不存在于词向量中\n",
      "identify,不存在于词向量中\n",
      "guts.不存在于词向量中\n",
      "Yesterday,不存在于词向量中\n",
      ":tongue:|||My不存在于词向量中\n",
      "study?不存在于词向量中\n",
      "triad,不存在于词向量中\n",
      "ENxJ不存在于词向量中\n",
      "Applying不存在于词向量中\n",
      "first..不存在于词向量中\n",
      "beast.不存在于词向量中\n",
      "Bean不存在于词向量中\n",
      "Ruby不存在于词向量中\n",
      "Matthew不存在于词向量中\n",
      "recharge,不存在于词向量中\n",
      "butterfly,不存在于词向量中\n",
      "Rapunzel不存在于词向量中\n",
      "'what's不存在于词向量中\n",
      "Whole不存在于词向量中\n",
      "Lecter不存在于词向量中\n",
      "Suddenly,不存在于词向量中\n",
      "...|||Yes不存在于词向量中\n",
      "Led不存在于词向量中\n",
      "describing,不存在于词向量中\n",
      "Engineer不存在于词向量中\n",
      "Light,不存在于词向量中\n",
      "(MBTI不存在于词向量中\n",
      "OT不存在于词向量中\n",
      "fun...|||I不存在于词向量中\n",
      "GAD不存在于词向量中\n",
      "played,不存在于词向量中\n",
      "comics.不存在于词向量中\n",
      "now.|||You不存在于词向量中\n",
      "Prefer不存在于词向量中\n",
      "Mormon不存在于词向量中\n",
      "police,不存在于词向量中\n",
      "type.'不存在于词向量中\n",
      "gas.不存在于词向量中\n",
      "mustard,不存在于词向量中\n",
      "off-topic,不存在于词向量中\n",
      "human?不存在于词向量中\n",
      "infj?不存在于词向量中\n",
      "Betty不存在于词向量中\n",
      "for...|||It不存在于词向量中\n",
      "narcissism,不存在于词向量中\n",
      "camp.不存在于词向量中\n",
      "medication,不存在于词向量中\n",
      "time,...|||I不存在于词向量中\n",
      "HS.不存在于词向量中\n",
      "sci-fi.不存在于词向量中\n",
      "a...|||To不存在于词向量中\n",
      "Degrees不存在于词向量中\n",
      ":)|||Hello,不存在于词向量中\n",
      "OBVIOUSLY不存在于词向量中\n",
      "storms,不存在于词向量中\n",
      "Dad,不存在于词向量中\n",
      "yourself)不存在于词向量中\n",
      "obsessive.不存在于词向量中\n",
      "finest.不存在于词向量中\n",
      "y'know,不存在于词向量中\n",
      "Sophomore不存在于词向量中\n",
      "clarification,不存在于词向量中\n",
      "xNFP.不存在于词向量中\n",
      "CRAZY不存在于词向量中\n",
      "flaw.不存在于词向量中\n",
      "that?|||I'm不存在于词向量中\n",
      "amusement,不存在于词向量中\n",
      "judging,不存在于词向量中\n",
      "again...|||I不存在于词向量中\n",
      "uncle's不存在于词向量中\n",
      "pounds,不存在于词向量中\n",
      "Well..不存在于词向量中\n",
      "Freaking不存在于词向量中\n",
      "best.|||I不存在于词向量中\n",
      "merit.不存在于词向量中\n",
      "so...|||My不存在于词向量中\n",
      "Groups不存在于词向量中\n",
      "Wagner不存在于词向量中\n",
      "aren't,不存在于词向量中\n",
      "Emperor不存在于词向量中\n",
      "clip.不存在于词向量中\n",
      "succeeding.不存在于词向量中\n",
      "point)不存在于词向量中\n",
      "pursue,不存在于词向量中\n",
      "Powerful不存在于词向量中\n",
      "confrontational.不存在于词向量中\n",
      "back).不存在于词向量中\n",
      "well?|||I不存在于词向量中\n",
      "out.|||I'm不存在于词向量中\n",
      "have...|||This不存在于词向量中\n",
      "outbursts,不存在于词向量中\n",
      ":)|||Do不存在于词向量中\n",
      "maintenance.不存在于词向量中\n",
      "rules?不存在于词向量中\n",
      "agenda,不存在于词向量中\n",
      "convention.不存在于词向量中\n",
      "Gimme不存在于词向量中\n",
      "Longest不存在于词向量中\n",
      "remember?不存在于词向量中\n",
      "Inventor不存在于词向量中\n",
      ":happy:|||It不存在于词向量中\n",
      "is...|||Hey不存在于词向量中\n",
      "Ti...|||I不存在于词向量中\n",
      "starts,不存在于词向量中\n",
      "opinion...不存在于词向量中\n",
      "hers.不存在于词向量中\n",
      "Autistic不存在于词向量中\n",
      "Museum不存在于词向量中\n",
      "Darn不存在于词向量中\n",
      ":/|||I'm不存在于词向量中\n",
      "y'all,不存在于词向量中\n",
      "observer,不存在于词向量中\n",
      "philosophies.不存在于词向量中\n",
      "Fourth不存在于词向量中\n",
      "psyche.不存在于词向量中\n",
      ":laughing:|||What不存在于词向量中\n",
      "and...|||Don't不存在于词向量中\n",
      "Draper不存在于词向量中\n",
      "horse.不存在于词向量中\n",
      "Bukowski不存在于词向量中\n",
      "(male不存在于词向量中\n",
      "Da不存在于词向量中\n",
      "EVERYTHING,不存在于词向量中\n",
      "Marcus不存在于词向量中\n",
      "really...|||My不存在于词向量中\n",
      "respectful,不存在于词向量中\n",
      "but...|||It不存在于词向量中\n",
      "metaphor,不存在于词向量中\n",
      "had...不存在于词向量中\n",
      "lately?不存在于词向量中\n",
      "messy?不存在于词向量中\n",
      "Y,不存在于词向量中\n",
      "junkie.不存在于词向量中\n",
      "of...|||I'd不存在于词向量中\n",
      "hiding?不存在于词向量中\n",
      "attachment,不存在于词向量中\n",
      "attachment.不存在于词向量中\n",
      "horror.不存在于词向量中\n",
      "I...|||Sounds不存在于词向量中\n",
      "virtue,不存在于词向量中\n",
      "internal.不存在于词向量中\n",
      "(back不存在于词向量中\n",
      "much...|||I'm不存在于词向量中\n",
      "IMHO,不存在于词向量中\n",
      "date...不存在于词向量中\n",
      "Opeth不存在于词向量中\n",
      "Essay不存在于词向量中\n",
      "sad.|||I不存在于词向量中\n",
      "dinner?不存在于词向量中\n",
      "Rape不存在于词向量中\n",
      ":laughing:|||I've不存在于词向量中\n",
      "Oooh,不存在于词向量中\n",
      "Paranoid:不存在于词向量中\n",
      "afterward.不存在于词向量中\n",
      "bars.不存在于词向量中\n",
      "suits.不存在于词向量中\n",
      "immoral.不存在于词向量中\n",
      "Soldier不存在于词向量中\n",
      "Cousin:不存在于词向量中\n",
      "divorced,不存在于词向量中\n",
      "Bs不存在于词向量中\n",
      "comfortable...|||I不存在于词向量中\n",
      "Angry不存在于词向量中\n",
      "constant,不存在于词向量中\n",
      "ENTJ).不存在于词向量中\n",
      "<----不存在于词向量中\n",
      "observing.不存在于词向量中\n",
      "I...|||Yes.不存在于词向量中\n",
      "Anymore不存在于词向量中\n",
      "Literally,不存在于词向量中\n",
      "three?不存在于词向量中\n",
      "tested.不存在于词向量中\n",
      "Twice不存在于词向量中\n",
      "boards.不存在于词向量中\n",
      "Accepting不存在于词向量中\n",
      "have...|||As不存在于词向量中\n",
      "to...|||All不存在于词向量中\n",
      "but...|||It's不存在于词向量中\n",
      "INTP-ish不存在于词向量中\n",
      ":)|||Oh,不存在于词向量中\n",
      "pity.不存在于词向量中\n",
      "Walmart不存在于词向量中\n",
      "Chi不存在于词向量中\n",
      "heavily.不存在于词向量中\n",
      "accomplished,不存在于词向量中\n",
      "Greetings不存在于词向量中\n",
      "2,000不存在于词向量中\n",
      "ENTJ's.不存在于词向量中\n",
      "I'm...|||It不存在于词向量中\n",
      "hardcore.不存在于词向量中\n",
      "tension,不存在于词向量中\n",
      "hate?不存在于词向量中\n",
      "ENFJ's,不存在于词向量中\n",
      "Mentally不存在于词向量中\n",
      "WRONG不存在于词向量中\n",
      "touching,不存在于词向量中\n",
      "Artemis不存在于词向量中\n",
      "IXTP不存在于词向量中\n",
      "defined,不存在于词向量中\n",
      "Teacher:不存在于词向量中\n",
      "nothing...不存在于词向量中\n",
      "Aunt不存在于词向量中\n",
      "Whoa!不存在于词向量中\n",
      "the...|||I'll不存在于词向量中\n",
      "engineers.不存在于词向量中\n",
      "Show.不存在于词向量中\n",
      "essence.不存在于词向量中\n",
      "Korea,不存在于词向量中\n",
      "English/Language不存在于词向量中\n",
      "cut,不存在于词向量中\n",
      "damage,不存在于词向量中\n",
      "Porn不存在于词向量中\n",
      "this?!不存在于词向量中\n",
      "instantly,不存在于词向量中\n",
      "Analysis不存在于词向量中\n",
      "similarly.不存在于词向量中\n",
      "topic...不存在于词向量中\n",
      "optimism,不存在于词向量中\n",
      "Awesome,不存在于词向量中\n",
      "too.|||The不存在于词向量中\n",
      "a...|||Do不存在于词向量中\n",
      "nation.不存在于词向量中\n",
      "hence,不存在于词向量中\n",
      "hugging.不存在于词向量中\n",
      "twins.不存在于词向量中\n",
      "'make不存在于词向量中\n",
      "xSTPs不存在于词向量中\n",
      "'Lol不存在于词向量中\n",
      "what...|||My不存在于词向量中\n",
      "Lol|||I不存在于词向量中\n",
      "amazing...不存在于词向量中\n",
      "Alien不存在于词向量中\n",
      "Guns不存在于词向量中\n",
      "Problems不存在于词向量中\n",
      "Si:不存在于词向量中\n",
      "Strangers不存在于词向量中\n",
      "sandwich.不存在于词向量中\n",
      "really...|||This不存在于词向量中\n",
      "Flirting不存在于词向量中\n",
      "Geez,不存在于词向量中\n",
      "cannot,不存在于词向量中\n",
      "weapons.不存在于词向量中\n",
      "sounds...不存在于词向量中\n",
      "(ENTP不存在于词向量中\n",
      "judgments.不存在于词向量中\n",
      "standing,不存在于词向量中\n",
      "it.|||You're不存在于词向量中\n",
      "Jealousy不存在于词向量中\n",
      "Horses不存在于词向量中\n",
      "Heads不存在于词向量中\n",
      "Morrison不存在于词向量中\n",
      "Cars不存在于词向量中\n",
      "colleague,不存在于词向量中\n",
      "SJ's.不存在于词向量中\n",
      "was)不存在于词向量中\n",
      "Bran不存在于词向量中\n",
      "convinced.不存在于词向量中\n",
      "Grant不存在于词向量中\n",
      "Bravo!不存在于词向量中\n",
      "place...不存在于词向量中\n",
      "Peanut不存在于词向量中\n",
      "T/F,不存在于词向量中\n",
      "a...|||Are不存在于词向量中\n",
      "Mama不存在于词向量中\n",
      "to...|||Welcome不存在于词向量中\n",
      "here.|||The不存在于词向量中\n",
      "Fate不存在于词向量中\n",
      "adulthood.不存在于词向量中\n",
      "Roll不存在于词向量中\n",
      "Mission不存在于词向量中\n",
      "relations,不存在于词向量中\n",
      "ESFJ's.不存在于词向量中\n",
      "Pinterest不存在于词向量中\n",
      "plane.不存在于词向量中\n",
      "surgery,不存在于词向量中\n",
      "titles.不存在于词向量中\n",
      "companies.不存在于词向量中\n",
      "tolerate.不存在于词向量中\n",
      "Attachment不存在于词向量中\n",
      "fullest.不存在于词向量中\n",
      "(3)不存在于词向量中\n",
      "my...|||i不存在于词向量中\n",
      "馃拵G3M不存在于词向量中\n",
      "number?不存在于词向量中\n",
      "bit..不存在于词向量中\n",
      "Tapatalk|||Why不存在于词向量中\n",
      "show)不存在于词向量中\n",
      "premise.不存在于词向量中\n",
      "Pardon不存在于词向量中\n",
      "controlled.不存在于词向量中\n",
      "ZERO不存在于词向量中\n",
      "THREAD不存在于词向量中\n",
      "Anonymous不存在于词向量中\n",
      "Confused不存在于词向量中\n",
      "from...|||I'm不存在于词向量中\n",
      "warfare,不存在于词向量中\n",
      "principle,不存在于词向量中\n",
      "happen...不存在于词向量中\n",
      "it...|||Oh不存在于词向量中\n",
      "Chains不存在于词向量中\n",
      "well.'不存在于词向量中\n",
      "50,不存在于词向量中\n",
      "roommates,不存在于词向量中\n",
      "Grey,不存在于词向量中\n",
      "generations.不存在于词向量中\n",
      "bored?不存在于词向量中\n",
      "Social:不存在于词向量中\n",
      "Aang不存在于词向量中\n",
      "management.不存在于词向量中\n",
      "to...|||Sounds不存在于词向量中\n",
      "meanings,不存在于词向量中\n",
      "Asperger's.不存在于词向量中\n",
      "Admit不存在于词向量中\n",
      "healthy?不存在于词向量中\n",
      "have...|||It不存在于词向量中\n",
      "Wine不存在于词向量中\n",
      "energetic.不存在于词向量中\n",
      "cool..不存在于词向量中\n",
      "'tis不存在于词向量中\n",
      "Seattle,不存在于词向量中\n",
      "concerts.不存在于词向量中\n",
      "poet,不存在于词向量中\n",
      "the...|||Yes不存在于词向量中\n",
      ":kitteh:'不存在于词向量中\n",
      "legit.不存在于词向量中\n",
      "session,不存在于词向量中\n",
      "Hardly不存在于词向量中\n",
      "alone..不存在于词向量中\n",
      "emotions...|||I不存在于词向量中\n",
      "killed.不存在于词向量中\n",
      "don't...|||I've不存在于词向量中\n",
      "THINKING不存在于词向量中\n",
      "wars.不存在于词向量中\n",
      ":)|||Maybe不存在于词向量中\n",
      "Hispanic不存在于词向量中\n",
      "causes,不存在于词向量中\n",
      "December,不存在于词向量中\n",
      "pencil,不存在于词向量中\n",
      "know...|||I've不存在于词向量中\n",
      "so...|||Well,不存在于词向量中\n",
      "Nails不存在于词向量中\n",
      "naked,不存在于词向量中\n",
      "how...|||You不存在于词向量中\n",
      "as...|||When不存在于词向量中\n",
      "Universe,不存在于词向量中\n",
      "Dalai不存在于词向量中\n",
      "profound,不存在于词向量中\n",
      "Meyers-Briggs不存在于词向量中\n",
      "weird.|||I不存在于词向量中\n",
      "impulse.不存在于词向量中\n",
      ":happy:|||Thanks不存在于词向量中\n",
      "museums.不存在于词向量中\n",
      "co-workers.不存在于词向量中\n",
      "year..不存在于词向量中\n",
      "Smile不存在于词向量中\n",
      "Enneatype不存在于词向量中\n",
      "been...|||I'm不存在于词向量中\n",
      "as...|||i不存在于词向量中\n",
      "vegan.不存在于词向量中\n",
      "Doug不存在于词向量中\n",
      "irritated.不存在于词向量中\n",
      "having.不存在于词向量中\n",
      "counseling,不存在于词向量中\n",
      "techniques.不存在于词向量中\n",
      "Repent不存在于词向量中\n",
      "(quite不存在于词向量中\n",
      "pot.不存在于词向量中\n",
      "failures.不存在于词向量中\n",
      "Ni's不存在于词向量中\n",
      "XSTP不存在于词向量中\n",
      "though.|||The不存在于词向量中\n",
      "inclined.不存在于词向量中\n",
      "interpretations.不存在于词向量中\n",
      "inspiring.不存在于词向量中\n",
      "cuddling.不存在于词向量中\n",
      "Woke不存在于词向量中\n",
      "6.)不存在于词向量中\n",
      "precisely,不存在于词向量中\n",
      "matter...|||I不存在于词向量中\n",
      "(See不存在于词向量中\n",
      "impatient,不存在于词向量中\n",
      "libraries,不存在于词向量中\n",
      "equation.不存在于词向量中\n",
      "Categories:不存在于词向量中\n",
      "(Slight,不存在于词向量中\n",
      "Clear,不存在于词向量中\n",
      "Clear)不存在于词向量中\n",
      "forgiveness,不存在于词向量中\n",
      "downs,不存在于词向量中\n",
      "hated.不存在于词向量中\n",
      "opportunities,不存在于词向量中\n",
      "I...|||Did不存在于词向量中\n",
      "Steel不存在于词向量中\n",
      "Toronto,不存在于词向量中\n",
      "NOT.不存在于词向量中\n",
      "STPs不存在于词向量中\n",
      "Forest不存在于词向量中\n",
      "graphics,不存在于词向量中\n",
      "hell.|||I不存在于词向量中\n",
      "Britain不存在于词向量中\n",
      "Mexico,不存在于词向量中\n",
      "cynicism.不存在于词向量中\n",
      "mirrors,不存在于词向量中\n",
      "6'不存在于词向量中\n",
      "searching.不存在于词向量中\n",
      "Sexy不存在于词向量中\n",
      "journal,不存在于词向量中\n",
      "folk,不存在于词向量中\n",
      "Gee,不存在于词向量中\n",
      "for...|||As不存在于词向量中\n",
      "sensation.不存在于词向量中\n",
      "romantic...|||I不存在于词向量中\n",
      "domination.不存在于词向量中\n",
      "RL不存在于词向量中\n",
      "laughs,不存在于词向量中\n",
      "effect?不存在于词向量中\n",
      "INT不存在于词向量中\n",
      "baby's不存在于词向量中\n",
      "line?不存在于词向量中\n",
      "libraries.不存在于词向量中\n",
      "a...|||No,不存在于词向量中\n",
      "HD不存在于词向量中\n",
      "Intel不存在于词向量中\n",
      "Liberals不存在于词向量中\n",
      "century,不存在于词向量中\n",
      "Afraid不存在于词向量中\n",
      "agree.|||I不存在于词向量中\n",
      "cold...|||I不存在于词向量中\n",
      "alright?不存在于词向量中\n",
      "30s,不存在于词向量中\n",
      "instrument.不存在于词向量中\n",
      "4.5不存在于词向量中\n",
      "INTP....不存在于词向量中\n",
      "people...|||This不存在于词向量中\n",
      "Nature,不存在于词向量中\n",
      "categories,不存在于词向量中\n",
      "the...|||They不存在于词向量中\n",
      "(among不存在于词向量中\n",
      "Notes不存在于词向量中\n",
      "realized.不存在于词向量中\n",
      "ISTP-不存在于词向量中\n",
      "essentially,不存在于词向量中\n",
      "songs...不存在于词向量中\n",
      "Rammstein不存在于词向量中\n",
      "INTPs!不存在于词向量中\n",
      "Abbey不存在于词向量中\n",
      "impact.不存在于词向量中\n",
      "values?不存在于词向量中\n",
      "to...|||Very不存在于词向量中\n",
      "IMHO不存在于词向量中\n",
      "One's不存在于词向量中\n",
      "reverse.不存在于词向量中\n",
      "Fried不存在于词向量中\n",
      "Uh...不存在于词向量中\n",
      "profound.不存在于词向量中\n",
      "or...|||That不存在于词向量中\n",
      "later.|||I不存在于词向量中\n",
      "gal.不存在于词向量中\n",
      "going...|||I'm不存在于词向量中\n",
      "cup,不存在于词向量中\n",
      "Standing不存在于词向量中\n",
      "thing),不存在于词向量中\n",
      "Fun.不存在于词向量中\n",
      "not...|||You不存在于词向量中\n",
      "lot's不存在于词向量中\n",
      "elements.不存在于词向量中\n",
      "MD不存在于词向量中\n",
      "ideas...不存在于词向量中\n",
      "Flat不存在于词向量中\n",
      "Written不存在于词向量中\n",
      "bad..不存在于词向量中\n",
      "'People不存在于词向量中\n",
      "duties.不存在于词向量中\n",
      "reaction?不存在于词向量中\n",
      "Distance不存在于词向量中\n",
      "praise.不存在于词向量中\n",
      "Hetalia不存在于词向量中\n",
      "(during不存在于词向量中\n",
      "the...|||Yes.不存在于词向量中\n",
      "(usually)不存在于词向量中\n",
      "it.|||That's不存在于词向量中\n",
      "Seasonal不存在于词向量中\n",
      "lonely?不存在于词向量中\n",
      "friend..不存在于词向量中\n",
      "he...|||The不存在于词向量中\n",
      "hidden.不存在于词向量中\n",
      "5/10不存在于词向量中\n",
      "synesthesia.不存在于词向量中\n",
      "it's...|||The不存在于词向量中\n",
      "Mulan不存在于词向量中\n",
      "covered,不存在于词向量中\n",
      "random...|||I不存在于词向量中\n",
      "Below不存在于词向量中\n",
      "hardcore,不存在于词向量中\n",
      "laughter,不存在于词向量中\n",
      "(Harry不存在于词向量中\n",
      "Club.不存在于词向量中\n",
      "Sticking不存在于词向量中\n",
      "Christina不存在于词向量中\n",
      "HAHA不存在于词向量中\n",
      "judgment,不存在于词向量中\n",
      "Ha...不存在于词向量中\n",
      "drives,不存在于词向量中\n",
      "temperaments,不存在于词向量中\n",
      "Alaska.不存在于词向量中\n",
      "Angeles,不存在于词向量中\n",
      "Role不存在于词向量中\n",
      "1/10不存在于词向量中\n",
      "Searching不存在于词向量中\n",
      "Self:不存在于词向量中\n",
      "taught.不存在于词向量中\n",
      "however...不存在于词向量中\n",
      ":wink:|||The不存在于词向量中\n",
      "Trigun不存在于词向量中\n",
      "individually,不存在于词向量中\n",
      "a...|||Because不存在于词向量中\n",
      "windows.不存在于词向量中\n",
      "THING不存在于词向量中\n",
      ">:D不存在于词向量中\n",
      "ENF不存在于词向量中\n",
      "talkin'不存在于词向量中\n",
      "Tbh,不存在于词向量中\n",
      "Craig不存在于词向量中\n",
      "NOW!不存在于词向量中\n",
      "Katherine不存在于词向量中\n",
      "Sci不存在于词向量中\n",
      "BAM!不存在于词向量中\n",
      "Hobbies:不存在于词向量中\n",
      "it's...|||My不存在于词向量中\n",
      "artist's不存在于词向量中\n",
      "Secondly不存在于词向量中\n",
      "soon...不存在于词向量中\n",
      "Mediterranean不存在于词向量中\n",
      "bank.不存在于词向量中\n",
      "sociopaths.不存在于词向量中\n",
      "Engineering.不存在于词向量中\n",
      "tables,不存在于词向量中\n",
      "extent)不存在于词向量中\n",
      "saying...|||I不存在于词向量中\n",
      "mine.|||I不存在于词向量中\n",
      "shake.不存在于词向量中\n",
      "Todd不存在于词向量中\n",
      "Behavior不存在于词向量中\n",
      "Likewise,不存在于词向量中\n",
      "Radiohead,不存在于词向量中\n",
      "reciprocated.不存在于词向量中\n",
      "prefer...|||I不存在于词向量中\n",
      "we...|||I'm不存在于词向量中\n",
      "very...'不存在于词向量中\n",
      ":('不存在于词向量中\n",
      "humor...不存在于词向量中\n",
      "spelling,不存在于词向量中\n",
      "thick,不存在于词向量中\n",
      "PerCafe不存在于词向量中\n",
      "your'e不存在于词向量中\n",
      "Antisocial:不存在于词向量中\n",
      "Histrionic:不存在于词向量中\n",
      "Jimi不存在于词向量中\n",
      "Folk不存在于词向量中\n",
      "(7不存在于词向量中\n",
      "btw),不存在于词向量中\n",
      "(typically不存在于词向量中\n",
      "(b)不存在于词向量中\n",
      "Archetypes不存在于词向量中\n",
      "(Ne不存在于词向量中\n",
      "nights.不存在于词向量中\n",
      "flexible,不存在于词向量中\n",
      "Willy不存在于词向量中\n",
      "psychiatrist,不存在于词向量中\n",
      "me...|||If不存在于词向量中\n",
      "Longer不存在于词向量中\n",
      "Spider不存在于词向量中\n",
      "to...|||But不存在于词向量中\n",
      "not...|||When不存在于词向量中\n",
      "steam.不存在于词向量中\n",
      "people?|||I不存在于词向量中\n",
      "ENTP-不存在于词向量中\n",
      "socks,不存在于词向量中\n",
      "so...|||i不存在于词向量中\n",
      "no..不存在于词向量中\n",
      "max.不存在于词向量中\n",
      "Entj不存在于词向量中\n",
      "Si/Ne不存在于词向量中\n",
      "Bow不存在于词向量中\n",
      "introduction.不存在于词向量中\n",
      "NYC,不存在于词向量中\n",
      "Narnia不存在于词向量中\n",
      "bush,不存在于词向量中\n",
      "BS,不存在于词向量中\n",
      "works.|||I不存在于词向量中\n",
      "ring.不存在于词向量中\n",
      "but...|||When不存在于词向量中\n",
      "to...|||So,不存在于词向量中\n",
      "Estp不存在于词向量中\n",
      "Notebook不存在于词向量中\n",
      "talking?不存在于词向量中\n",
      "You鈥檙e不存在于词向量中\n",
      "says...|||I不存在于词向量中\n",
      "estj,不存在于词向量中\n",
      "isfj,不存在于词向量中\n",
      "demanding.不存在于词向量中\n",
      "...I'm不存在于词向量中\n",
      "like/dislike不存在于词向量中\n",
      "not...|||Thanks不存在于词向量中\n",
      "read.|||I不存在于词向量中\n",
      "stairs.不存在于词向量中\n",
      "outcomes.不存在于词向量中\n",
      "end...不存在于词向量中\n",
      "basics.不存在于词向量中\n",
      "blind.不存在于词向量中\n",
      "Dad.不存在于词向量中\n",
      "(To不存在于词向量中\n",
      "are...|||Oh不存在于词向量中\n",
      "existing.不存在于词向量中\n",
      "what...|||That's不存在于词向量中\n",
      "mold.不存在于词向量中\n",
      "click.不存在于词向量中\n",
      "and...|||You're不存在于词向量中\n",
      "...|||Haha不存在于词向量中\n",
      "Practically不存在于词向量中\n",
      "quirks,不存在于词向量中\n",
      "em,不存在于词向量中\n",
      "gorgeous,不存在于词向量中\n",
      "you.|||If不存在于词向量中\n",
      "it...|||A不存在于词向量中\n",
      "wallet.不存在于词向量中\n",
      "beer?不存在于词向量中\n",
      "giving.不存在于词向量中\n",
      "civil.不存在于词向量中\n",
      "leg.不存在于词向量中\n",
      "plant,不存在于词向量中\n",
      "time...|||It不存在于词向量中\n",
      "so...|||You不存在于词向量中\n",
      "explained,不存在于词向量中\n",
      "anywhere?不存在于词向量中\n",
      "D:|||I不存在于词向量中\n",
      "Sheen不存在于词向量中\n",
      "nature's不存在于词向量中\n",
      "3.0不存在于词向量中\n",
      "...|||I'll不存在于词向量中\n",
      "V,不存在于词向量中\n",
      "juice,不存在于词向量中\n",
      "Brown,不存在于词向量中\n",
      "consistent,不存在于词向量中\n",
      "other...|||This不存在于词向量中\n",
      "unbearable.不存在于词向量中\n",
      "right?).不存在于词向量中\n",
      "own.|||I不存在于词向量中\n",
      "Harvest不存在于词向量中\n",
      "aren't...|||I不存在于词向量中\n",
      "X-Men不存在于词向量中\n",
      "memes,不存在于词向量中\n",
      "psyche,不存在于词向量中\n",
      "Ohh不存在于词向量中\n",
      "Troy不存在于词向量中\n",
      "acts.不存在于词向量中\n",
      "geek.不存在于词向量中\n",
      "bubble.不存在于词向量中\n",
      "Features不存在于词向量中\n",
      "don't...|||Oh不存在于词向量中\n",
      "INTJ...|||I不存在于词向量中\n",
      "Anthem不存在于词向量中\n",
      "general...不存在于词向量中\n",
      "ENFJ...不存在于词向量中\n",
      "attention...不存在于词向量中\n",
      "receive.不存在于词向量中\n",
      "(literally不存在于词向量中\n",
      "8.5不存在于词向量中\n",
      "ready?不存在于词向量中\n",
      "...|||1)不存在于词向量中\n",
      "precious.不存在于词向量中\n",
      "punishment.不存在于词向量中\n",
      "3.00不存在于词向量中\n",
      "in...|||Oh不存在于词向量中\n",
      "Soooo不存在于词向量中\n",
      "no...|||I'm不存在于词向量中\n",
      "powers,不存在于词向量中\n",
      "retarded,不存在于词向量中\n",
      "behaviours.不存在于词向量中\n",
      "bored...不存在于词向量中\n",
      "Possible不存在于词向量中\n",
      "<.<不存在于词向量中\n",
      "fruit,不存在于词向量中\n",
      "Troll不存在于词向量中\n",
      "Caesar不存在于词向量中\n",
      "PersonalityCafe不存在于词向量中\n",
      "FB.不存在于词向量中\n",
      "protective,不存在于词向量中\n",
      "Two.不存在于词向量中\n",
      "Pity不存在于词向量中\n",
      "Diana不存在于词向量中\n",
      "Hour不存在于词向量中\n",
      "entails.不存在于词向量中\n",
      "NTP.不存在于词向量中\n",
      "satisfying.不存在于词向量中\n",
      "Apply不存在于词向量中\n",
      "May.不存在于词向量中\n",
      "Skyrim,不存在于词向量中\n",
      "them.'不存在于词向量中\n",
      "u,不存在于词向量中\n",
      "young?不存在于词向量中\n",
      "struggles.不存在于词向量中\n",
      "Descartes不存在于词向量中\n",
      "I'm...|||When不存在于词向量中\n",
      "'Sounds不存在于词向量中\n",
      "is...|||A不存在于词向量中\n",
      "glance.不存在于词向量中\n",
      "mr.Kedi不存在于词向量中\n",
      "Yellowstone不存在于词向量中\n",
      "butt.不存在于词向量中\n",
      "Edge不存在于词向量中\n",
      "discovered,不存在于词向量中\n",
      "notifications.不存在于词向量中\n",
      "amused,不存在于词向量中\n",
      "Mother,不存在于词向量中\n",
      "Jackie不存在于词向量中\n",
      "sandwich,不存在于词向量中\n",
      "world...|||I不存在于词向量中\n",
      "sideways.不存在于词向量中\n",
      "Buddhism,不存在于词向量中\n",
      "Bacon不存在于词向量中\n",
      "era,不存在于词向量中\n",
      "typing?不存在于词向量中\n",
      "Dragonball不存在于词向量中\n",
      "Safe不存在于词向量中\n",
      "9)不存在于词向量中\n",
      "there....不存在于词向量中\n",
      "eg.不存在于词向量中\n",
      "Brother-不存在于词向量中\n",
      "Mother-不存在于词向量中\n",
      "believe)不存在于词向量中\n",
      "Theory.不存在于词向量中\n",
      "you...|||I've不存在于词向量中\n",
      "alive.|||I不存在于词向量中\n",
      "=P|||I不存在于词向量中\n",
      "such)不存在于词向量中\n",
      "was...|||You不存在于词向量中\n",
      "couldn't.不存在于词向量中\n",
      "round,不存在于词向量中\n",
      "(does不存在于词向量中\n",
      "it...|||So不存在于词向量中\n",
      "Seventh不存在于词向量中\n",
      "Smashing不存在于词向量中\n",
      "ADORE不存在于词向量中\n",
      "Mandela不存在于词向量中\n",
      "commitments,不存在于词向量中\n",
      "kinds,不存在于词向量中\n",
      "Exorcist不存在于词向量中\n",
      "UN不存在于词向量中\n",
      "presented.不存在于词向量中\n",
      "spots,不存在于词向量中\n",
      "Or...|||I不存在于词向量中\n",
      "...|||After不存在于词向量中\n",
      "reliable.不存在于词向量中\n",
      "truly,不存在于词向量中\n",
      "just...|||The不存在于词向量中\n",
      "Hyde不存在于词向量中\n",
      "museum,不存在于词向量中\n",
      "Meetup不存在于词向量中\n",
      "chase.不存在于词向量中\n",
      "ST's不存在于词向量中\n",
      "Depends.不存在于词向量中\n",
      "Medical不存在于词向量中\n",
      "an...|||My不存在于词向量中\n",
      "river,不存在于词向量中\n",
      "Vs.不存在于词向量中\n",
      "uptight.不存在于词向量中\n",
      "Lesson不存在于词向量中\n",
      "Morality不存在于词向量中\n",
      "alternatives.不存在于词向量中\n",
      "Handsome不存在于词向量中\n",
      "BITCH不存在于词向量中\n",
      "angst.不存在于词向量中\n",
      "skirts,不存在于词向量中\n",
      "=(不存在于词向量中\n",
      "sympathy,不存在于词向量中\n",
      "trying...|||I不存在于词向量中\n",
      "...|||what不存在于词向量中\n",
      "Gate不存在于词向量中\n",
      "Surprising不存在于词向量中\n",
      "Poets不存在于词向量中\n",
      "whatever...|||I不存在于词向量中\n",
      "possible)不存在于词向量中\n",
      "(Also不存在于词向量中\n",
      "U.S.,不存在于词向量中\n",
      "theoretical,不存在于词向量中\n",
      "Reality:不存在于词向量中\n",
      "actuality,不存在于词向量中\n",
      "electronic,不存在于词向量中\n",
      "Tinder.不存在于词向量中\n",
      "reproduce.不存在于词向量中\n",
      "synesthesia,不存在于词向量中\n",
      "black/white不存在于词向量中\n",
      "edge,不存在于词向量中\n",
      "Frost不存在于词向量中\n",
      "So/Sx不存在于词向量中\n",
      "MsBossyPants不存在于词向量中\n",
      "(Me不存在于词向量中\n",
      "about)不存在于词向量中\n",
      "respected,不存在于词向量中\n",
      "and...|||Very不存在于词向量中\n",
      "don't.|||I不存在于词向量中\n",
      "why.|||I不存在于词向量中\n",
      "oops.不存在于词向量中\n",
      "Smith,不存在于词向量中\n",
      "Ellie不存在于词向量中\n",
      "Cornell不存在于词向量中\n",
      "Chin不存在于词向量中\n",
      "Woods不存在于词向量中\n",
      "in...|||In不存在于词向量中\n",
      "insects.不存在于词向量中\n",
      "book)不存在于词向量中\n",
      "Hades不存在于词向量中\n",
      "Aunt:不存在于词向量中\n",
      "Uncle:不存在于词向量中\n",
      "revelation.不存在于词向量中\n",
      "yo.不存在于词向量中\n",
      "Ubuntu不存在于词向量中\n",
      "Kane不存在于词向量中\n",
      "Marxist不存在于词向量中\n",
      "Ne's不存在于词向量中\n",
      "not...|||It's不存在于词向量中\n",
      "convenience.不存在于词向量中\n",
      "respected.不存在于词向量中\n",
      "afterlife,不存在于词向量中\n",
      "Intentions不存在于词向量中\n",
      "tact,不存在于词向量中\n",
      "this...|||I've不存在于词向量中\n",
      "same...不存在于词向量中\n",
      "celebrities,不存在于词向量中\n",
      "about...|||Thanks不存在于词向量中\n",
      "Stevie不存在于词向量中\n",
      "Differences不存在于词向量中\n",
      "Nationality:不存在于词向量中\n",
      "Languages:不存在于词向量中\n",
      "Person,不存在于词向量中\n",
      "...|||Any不存在于词向量中\n",
      "I...|||No.不存在于词向量中\n",
      "have...|||I've不存在于词向量中\n",
      "Cate不存在于词向量中\n",
      "stages,不存在于词向量中\n",
      "...|||But不存在于词向量中\n",
      "Training不存在于词向量中\n",
      "Style/Manner不存在于词向量中\n",
      "INFJ's!不存在于词向量中\n",
      "exploring.不存在于词向量中\n",
      "Playstation不存在于词向量中\n",
      "delusional.不存在于词向量中\n",
      "yrs.不存在于词向量中\n",
      "tattoo.不存在于词向量中\n",
      "Krav不存在于词向量中\n",
      "Tapatalk|||Thanks不存在于词向量中\n",
      "ideology.不存在于词向量中\n",
      "helped,不存在于词向量中\n",
      "dunno...不存在于词向量中\n",
      "your...|||It's不存在于词向量中\n",
      "is...|||He不存在于词向量中\n",
      "again)不存在于词向量中\n",
      "cities.不存在于词向量中\n",
      "Keenan不存在于词向量中\n",
      "Salvation不存在于词向量中\n",
      "you...|||Not不存在于词向量中\n",
      "themselves...不存在于词向量中\n",
      "USB不存在于词向量中\n",
      "the...|||Thanks,不存在于词向量中\n",
      "I...|||Have不存在于词向量中\n",
      "CARE不存在于词向量中\n",
      "skinny.不存在于词向量中\n",
      "Wallace不存在于词向量中\n",
      "six,不存在于词向量中\n",
      "xNTPs不存在于词向量中\n",
      "instead...|||I不存在于词向量中\n",
      "deadline,不存在于词向量中\n",
      "at...|||This不存在于词向量中\n",
      "Ne/Ni不存在于词向量中\n",
      "dont.不存在于词向量中\n",
      "proven.不存在于词向量中\n",
      "6/7不存在于词向量中\n",
      "ESTP)不存在于词向量中\n",
      "despair,不存在于词向量中\n",
      "in...|||How不存在于词向量中\n",
      "Authority:不存在于词向量中\n",
      "Jack's不存在于词向量中\n",
      "wheel,不存在于词向量中\n",
      "Catholic.不存在于词向量中\n",
      "impulses.不存在于词向量中\n",
      "instructions,不存在于词向量中\n",
      "Supreme不存在于词向量中\n",
      "perfection,不存在于词向量中\n",
      "reassurance.不存在于词向量中\n",
      "commercials,不存在于词向量中\n",
      "buildings,不存在于词向量中\n",
      "tremendously.不存在于词向量中\n",
      "moderation.不存在于词向量中\n",
      "web.不存在于词向量中\n",
      "tune.不存在于词向量中\n",
      "angles.不存在于词向量中\n",
      "to...|||Good不存在于词向量中\n",
      "become...|||I不存在于词向量中\n",
      "benefits,不存在于词向量中\n",
      "intentionally.不存在于词向量中\n",
      "Fritz不存在于词向量中\n",
      "toes,不存在于词向量中\n",
      "quoted,不存在于词向量中\n",
      "Forces不存在于词向量中\n",
      "believer.不存在于词向量中\n",
      "reflective,不存在于词向量中\n",
      "one-on-one.不存在于词向量中\n",
      "desktop.不存在于词向量中\n",
      "idealists.不存在于词向量中\n",
      "Kindle不存在于词向量中\n",
      "Bitch不存在于词向量中\n",
      "I...|||Some不存在于词向量中\n",
      "entity.不存在于词向量中\n",
      "embarrassing,不存在于词向量中\n",
      "necessity.不存在于词向量中\n",
      "occurs,不存在于词向量中\n",
      "deleted.不存在于词向量中\n",
      "'cool'不存在于词向量中\n",
      "Zealand.不存在于词向量中\n",
      "and...|||Its不存在于词向量中\n",
      "-Don't不存在于词向量中\n",
      "genders,不存在于词向量中\n",
      "Frustration不存在于词向量中\n",
      "challenging.不存在于词向量中\n",
      ":happy:|||I've不存在于词向量中\n",
      "diary,不存在于词向量中\n",
      "flaw,不存在于词向量中\n",
      "who?不存在于词向量中\n",
      "clock.不存在于词向量中\n",
      "is...|||Not不存在于词向量中\n",
      "tonight?不存在于词向量中\n",
      "twisted,不存在于词向量中\n",
      "that...|||In不存在于词向量中\n",
      "villian.不存在于词向量中\n",
      "lights.不存在于词向量中\n",
      "I...|||And不存在于词向量中\n",
      "JD不存在于词向量中\n",
      "something|||I不存在于词向量中\n",
      "Hug不存在于词向量中\n",
      "on...|||Well,不存在于词向量中\n",
      "bit)不存在于词向量中\n",
      "musicians.不存在于词向量中\n",
      "Descriptions不存在于词向量中\n",
      "aura,不存在于词向量中\n",
      "Woman,不存在于词向量中\n",
      "Granger不存在于词向量中\n",
      "Potter.不存在于词向量中\n",
      "socialization.不存在于词向量中\n",
      "Christians,不存在于词向量中\n",
      "a...|||Yes不存在于词向量中\n",
      "particularly.不存在于词向量中\n",
      "grandmother's不存在于词向量中\n",
      "Magnificent不存在于词向量中\n",
      "license.不存在于词向量中\n",
      "Spirituality不存在于词向量中\n",
      "Aquarian不存在于词向量中\n",
      "month?不存在于词向量中\n",
      "FEELS不存在于词向量中\n",
      "Lucas不存在于词向量中\n",
      "these...不存在于词向量中\n",
      "Spaghetti不存在于词向量中\n",
      "Achilles不存在于词向量中\n",
      "told...|||I不存在于词向量中\n",
      "County不存在于词向量中\n",
      "university?不存在于词向量中\n",
      "get...|||The不存在于词向量中\n",
      "extraverts,不存在于词向量中\n",
      "picture...不存在于词向量中\n",
      "be...|||How不存在于词向量中\n",
      "pedestal.不存在于词向量中\n",
      "tight.不存在于词向量中\n",
      "Grief不存在于词向量中\n",
      "enlightened.不存在于词向量中\n",
      "Facts不存在于词向量中\n",
      "TJ.不存在于词向量中\n",
      "titles,不存在于词向量中\n",
      "...|||Your不存在于词向量中\n",
      "videogames.不存在于词向量中\n",
      "inconsistencies.不存在于词向量中\n",
      "YT不存在于词向量中\n",
      "shit...不存在于词向量中\n",
      "Traveling不存在于词向量中\n",
      "all....不存在于词向量中\n",
      "questionnaires,不存在于词向量中\n",
      "pounds.不存在于词向量中\n",
      "masculine,不存在于词向量中\n",
      "aux.不存在于词向量中\n",
      "Quadra不存在于词向量中\n",
      "texting,不存在于词向量中\n",
      "jewelry,不存在于词向量中\n",
      "brave.不存在于词向量中\n",
      "then..不存在于词向量中\n",
      "related?不存在于词向量中\n",
      "attract.不存在于词向量中\n",
      "want...|||I'm不存在于词向量中\n",
      "Enjoy!不存在于词向量中\n",
      "Rings,不存在于词向量中\n",
      "Price不存在于词向量中\n",
      ":wink:.不存在于词向量中\n",
      "solving.不存在于词向量中\n",
      "ESTJ's,不存在于词向量中\n",
      "ESFP)不存在于词向量中\n",
      "inspirational,不存在于词向量中\n",
      "'normal'不存在于词向量中\n",
      "carrots,不存在于词向量中\n",
      "guy...|||I不存在于词向量中\n",
      "firstly,不存在于词向量中\n",
      "(outside不存在于词向量中\n",
      ":proud:|||You不存在于词向量中\n",
      "is.)不存在于词向量中\n",
      "(Of不存在于词向量中\n",
      "Mel不存在于词向量中\n",
      "else's.不存在于词向量中\n",
      "Lolita不存在于词向量中\n",
      "move...不存在于词向量中\n",
      "delicious,不存在于词向量中\n",
      "freeing.不存在于词向量中\n",
      "Philosophical不存在于词向量中\n",
      "finger.不存在于词向量中\n",
      "Crying不存在于词向量中\n",
      "nod,不存在于词向量中\n",
      "Floyd,不存在于词向量中\n",
      "Harry's不存在于词向量中\n",
      "Congress不存在于词向量中\n",
      "in...|||That不存在于词向量中\n",
      "NBA不存在于词向量中\n",
      "bones.不存在于词向量中\n",
      "don't?不存在于词向量中\n",
      "~I不存在于词向量中\n",
      "falling.不存在于词向量中\n",
      "meaningless,不存在于词向量中\n",
      "yup,不存在于词向量中\n",
      "xDD不存在于词向量中\n",
      "Cohen不存在于词向量中\n",
      "assumption,不存在于词向量中\n",
      "together.|||I不存在于词向量中\n",
      "mankind.不存在于词向量中\n",
      "it|||I'm不存在于词向量中\n",
      "Fe!不存在于词向量中\n",
      "Obama's不存在于词向量中\n",
      "ISTP|||I不存在于词向量中\n",
      "overload.不存在于词向量中\n",
      "smirk,不存在于词向量中\n",
      "Appearance不存在于词向量中\n",
      "say....不存在于词向量中\n",
      "Ronald不存在于词向量中\n",
      "Conflict不存在于词向量中\n",
      "XSFJ不存在于词向量中\n",
      "though.|||You不存在于词向量中\n",
      "music.|||I不存在于词向量中\n",
      "unconventional,不存在于词向量中\n",
      "seem,不存在于词向量中\n",
      "neighborhood.不存在于词向量中\n",
      "Tarot不存在于词向量中\n",
      "Bundy不存在于词向量中\n",
      "rebellious,不存在于词向量中\n",
      "C)不存在于词向量中\n",
      "Sinatra不存在于词向量中\n",
      "Ride不存在于词向量中\n",
      "proof,不存在于词向量中\n",
      "IXFJ不存在于词向量中\n",
      "bits.不存在于词向量中\n",
      ":P,不存在于词向量中\n",
      "heartbreaking.不存在于词向量中\n",
      "achievements,不存在于词向量中\n",
      "Changed不存在于词向量中\n",
      "(big不存在于词向量中\n",
      "chameleon,不存在于词向量中\n",
      "relationships...不存在于词向量中\n",
      "Creepy不存在于词向量中\n",
      ":wink:|||My不存在于词向量中\n",
      "goodbye.不存在于词向量中\n",
      "the...|||Like不存在于词向量中\n",
      "approachable,不存在于词向量中\n",
      "I...|||Welcome不存在于词向量中\n",
      "Lambert不存在于词向量中\n",
      "tips.不存在于词向量中\n",
      "Vinci不存在于词向量中\n",
      "'Tis不存在于词向量中\n",
      "poorly,不存在于词向量中\n",
      "sexually,不存在于词向量中\n",
      "City.不存在于词向量中\n",
      "Target不存在于词向量中\n",
      "Sociopath不存在于词向量中\n",
      "like...|||Well,不存在于词向量中\n",
      "restaurants,不存在于词向量中\n",
      "communities.不存在于词向量中\n",
      "Willis不存在于词向量中\n",
      "war?不存在于词向量中\n",
      "done.|||I不存在于词向量中\n",
      "Khan不存在于词向量中\n",
      "Dirk不存在于词向量中\n",
      "joined.不存在于词向量中\n",
      "sort?不存在于词向量中\n",
      "provided.不存在于词向量中\n",
      "vulnerable?不存在于词向量中\n",
      "soothing.不存在于词向量中\n",
      "autism,不存在于词向量中\n",
      "inches,不存在于词向量中\n",
      "Blunt不存在于词向量中\n",
      "Bird不存在于词向量中\n",
      "Nightwish不存在于词向量中\n",
      "Redemption不存在于词向量中\n",
      "Sir,不存在于词向量中\n",
      "Jam不存在于词向量中\n",
      "OkCupid不存在于词向量中\n",
      "tops,不存在于词向量中\n",
      ":laughing:)不存在于词向量中\n",
      "fantasies.不存在于词向量中\n",
      "soundtrack.不存在于词向量中\n",
      "Karenina不存在于词向量中\n",
      "suspect.不存在于词向量中\n",
      "knees,不存在于词向量中\n",
      "explained.不存在于词向量中\n",
      "room?不存在于词向量中\n",
      "kisses,不存在于词向量中\n",
      "match?不存在于词向量中\n",
      "Yay,不存在于词向量中\n",
      "in)不存在于词向量中\n",
      "Cthulhu不存在于词向量中\n",
      "who'll不存在于词向量中\n",
      "Te)不存在于词向量中\n",
      "(Te不存在于词向量中\n",
      "Always.不存在于词向量中\n",
      "Lorde不存在于词向量中\n",
      "while?不存在于词向量中\n",
      "Empty不存在于词向量中\n",
      "Ignorance不存在于词向量中\n",
      "travelling,不存在于词向量中\n",
      "Ti/Ne不存在于词向量中\n",
      "hehe,不存在于词向量中\n",
      "girlfriends.不存在于词向量中\n",
      "I...|||An不存在于词向量中\n",
      "gifted,不存在于词向量中\n",
      "rainbows.不存在于词向量中\n",
      "realm.不存在于词向量中\n",
      "technically,不存在于词向量中\n",
      "B.S.不存在于词向量中\n",
      "?!不存在于词向量中\n",
      "with...|||That不存在于词向量中\n",
      "functioning.不存在于词向量中\n",
      "first)不存在于词向量中\n",
      "exercises,不存在于词向量中\n",
      "Yagami不存在于词向量中\n",
      "arts?不存在于词向量中\n",
      "puppy.不存在于词向量中\n",
      "it.|||For不存在于词向量中\n",
      "attempt.不存在于词向量中\n",
      "glory.不存在于词向量中\n",
      "obvious?不存在于词向量中\n",
      "breaks.不存在于词向量中\n",
      "ROLE:不存在于词向量中\n",
      "sleepy.不存在于词向量中\n",
      "(90%)不存在于词向量中\n",
      "the...|||Haha,不存在于词向量中\n",
      "some...|||My不存在于词向量中\n",
      "breathe.不存在于词向量中\n",
      "trips.不存在于词向量中\n",
      "the...|||Sometimes不存在于词向量中\n",
      "ESTP.|||I不存在于词向量中\n",
      "Collective不存在于词向量中\n",
      "VII不存在于词向量中\n",
      "N's.不存在于词向量中\n",
      "TPs不存在于词向量中\n",
      "I...|||You're不存在于词向量中\n",
      "memorization.不存在于词向量中\n",
      ":tongue:|||Not不存在于词向量中\n",
      "prison,不存在于词向量中\n",
      "do/say不存在于词向量中\n",
      "._.|||I不存在于词向量中\n",
      "can...|||I've不存在于词向量中\n",
      "Sometime不存在于词向量中\n",
      "'Actually,不存在于词向量中\n",
      "Akira不存在于词向量中\n",
      "shit.|||I不存在于词向量中\n",
      "spider.不存在于词向量中\n",
      "budget.不存在于词向量中\n",
      "psychopaths.不存在于词向量中\n",
      "people|||I不存在于词向量中\n",
      "Stare不存在于词向量中\n",
      "Teenage不存在于词向量中\n",
      "Background:不存在于词向量中\n",
      "notebook,不存在于词向量中\n",
      "view?不存在于词向量中\n",
      "business?不存在于词向量中\n",
      "if...|||The不存在于词向量中\n",
      "face...不存在于词向量中\n",
      "Miami不存在于词向量中\n",
      "but...|||If不存在于词向量中\n",
      "want/need不存在于词向量中\n",
      "close-minded,不存在于词向量中\n",
      "fails.不存在于词向量中\n",
      "Funny.不存在于词向量中\n",
      "fighter,不存在于词向量中\n",
      "Atheist.不存在于词向量中\n",
      "Ok...不存在于词向量中\n",
      "How...|||I不存在于词向量中\n",
      "believer,不存在于词向量中\n",
      "Interests不存在于词向量中\n",
      "huge...|||I不存在于词向量中\n",
      "Stan不存在于词向量中\n",
      "replying,不存在于词向量中\n",
      "hear?不存在于词向量中\n",
      "hypocrisy,不存在于词向量中\n",
      "vomit.不存在于词向量中\n",
      "'friend'不存在于词向量中\n",
      "truck,不存在于词向量中\n",
      "me.|||What不存在于词向量中\n",
      "oneself,不存在于词向量中\n",
      "[/QUOTE]不存在于词向量中\n",
      "against,不存在于词向量中\n",
      "encounter,不存在于词向量中\n",
      "Vodka!不存在于词向量中\n",
      "Rob不存在于词向量中\n",
      "in...|||Yeah,不存在于词向量中\n",
      "worthless.不存在于词向量中\n",
      "pics,不存在于词向量中\n",
      "other...|||My不存在于词向量中\n",
      "DOWN不存在于词向量中\n",
      "with),不存在于词向量中\n",
      "Thousand不存在于词向量中\n",
      "works...|||I不存在于词向量中\n",
      "Venting不存在于词向量中\n",
      "hers,不存在于词向量中\n",
      "However,...|||I不存在于词向量中\n",
      "limiting.不存在于词向量中\n",
      "heartless.不存在于词向量中\n",
      "few...|||I'm不存在于词向量中\n",
      "case.|||I不存在于词向量中\n",
      "ENTPs)不存在于词向量中\n",
      "basketball.不存在于词向量中\n",
      "achievement,不存在于词向量中\n",
      "checked.不存在于词向量中\n",
      "Heh不存在于词向量中\n",
      "interesting...|||I不存在于词向量中\n",
      "like)不存在于词向量中\n",
      "Sensing:不存在于词向量中\n",
      "stacks.不存在于词向量中\n",
      "Dated不存在于词向量中\n",
      "faults,不存在于词向量中\n",
      "crash.不存在于词向量中\n",
      "struggles,不存在于词向量中\n",
      "next...|||I不存在于词向量中\n",
      "Portland不存在于词向量中\n",
      "Who.不存在于词向量中\n",
      "Institute不存在于词向量中\n",
      "RIP不存在于词向量中\n",
      "lot..不存在于词向量中\n",
      "December.不存在于词向量中\n",
      "Awareness不存在于词向量中\n",
      "Impossible不存在于词向量中\n",
      "Esfj不存在于词向量中\n",
      "a...|||First不存在于词向量中\n",
      "one?|||I不存在于词向量中\n",
      "Perfect.不存在于词向量中\n",
      "Sarcastic不存在于词向量中\n",
      "college)不存在于词向量中\n",
      "o_O不存在于词向量中\n",
      "Cruz不存在于词向量中\n",
      "sweetie,不存在于词向量中\n",
      "difficult?不存在于词向量中\n",
      "Surprisingly不存在于词向量中\n",
      "alley.不存在于词向量中\n",
      "fired.不存在于词向量中\n",
      "can't...|||I'm不存在于词向量中\n",
      "intro,不存在于词向量中\n",
      "extraversion.不存在于词向量中\n",
      ";(不存在于词向量中\n",
      "Animated不存在于词向量中\n",
      "applicable.不存在于词向量中\n",
      "move?不存在于词向量中\n",
      "Yahoo不存在于词向量中\n",
      "up?|||I不存在于词向量中\n",
      "majors,不存在于词向量中\n",
      "official.不存在于词向量中\n",
      "Teddy不存在于词向量中\n",
      "sister)不存在于词向量中\n",
      "Shit,不存在于词向量中\n",
      "Mitchell不存在于词向量中\n",
      "axis.不存在于词向量中\n",
      "Characters不存在于词向量中\n",
      "common...|||I不存在于词向量中\n",
      "hate...|||I不存在于词向量中\n",
      "'Im不存在于词向量中\n",
      "underneath.不存在于词向量中\n",
      "for...|||That's不存在于词向量中\n",
      "PoLR不存在于词向量中\n",
      "Entp,不存在于词向量中\n",
      ":laughing:|||Oh不存在于词向量中\n",
      "SD,不存在于词向量中\n",
      "symptoms,不存在于词向量中\n",
      "Interests:不存在于词向量中\n",
      "Female,不存在于词向量中\n",
      "Scroll不存在于词向量中\n",
      "dislikes,不存在于词向量中\n",
      "Prada不存在于词向量中\n",
      "down.|||I不存在于词向量中\n",
      "do...|||The不存在于词向量中\n",
      "Drum不存在于词向量中\n",
      "(4)不存在于词向量中\n",
      "and...|||Hey不存在于词向量中\n",
      "Cinderella不存在于词向量中\n",
      "closet,不存在于词向量中\n",
      "Kidding.不存在于词向量中\n",
      "epic,不存在于词向量中\n",
      "ISTJ!不存在于词向量中\n",
      "B12不存在于词向量中\n",
      "Generator不存在于词向量中\n",
      "happier,不存在于词向量中\n",
      "reply...不存在于词向量中\n",
      "External不存在于词向量中\n",
      "tickets,不存在于词向量中\n",
      ":]|||I不存在于词向量中\n",
      "funny.|||I不存在于词向量中\n",
      "atheists,不存在于词向量中\n",
      "bullies,不存在于词向量中\n",
      "Germany.不存在于词向量中\n",
      "is...|||How不存在于词向量中\n",
      "OrangeAppled不存在于词向量中\n",
      "weapon,不存在于词向量中\n",
      "It麓s不存在于词向量中\n",
      "Villain不存在于词向量中\n",
      "EXFP不存在于词向量中\n",
      "Clementine不存在于词向量中\n",
      "finally,不存在于词向量中\n",
      "jail.不存在于词向量中\n",
      "Anyways.不存在于词向量中\n",
      "anyway..不存在于词向量中\n",
      "January,不存在于词向量中\n",
      "yell,不存在于词向量中\n",
      "session.不存在于词向量中\n",
      "bread,不存在于词向量中\n",
      "argument?不存在于词向量中\n",
      "he's...|||I'm不存在于词向量中\n",
      "cannot...|||I不存在于词向量中\n",
      "to...|||Ok不存在于词向量中\n",
      "Ne-dom.不存在于词向量中\n",
      "blind,不存在于词向量中\n",
      "one...|||I'm不存在于词向量中\n",
      "Fields不存在于词向量中\n",
      "Sociology不存在于词向量中\n",
      "Bennett不存在于词向量中\n",
      "proud,不存在于词向量中\n",
      "lots.不存在于词向量中\n",
      "tight,不存在于词向量中\n",
      "at...'不存在于词向量中\n",
      "rape,不存在于词向量中\n",
      "visionary.不存在于词向量中\n",
      "Personality:不存在于词向量中\n",
      "Version不存在于词向量中\n",
      "ENTIRE不存在于词向量中\n",
      "here|||I不存在于词向量中\n",
      "IP不存在于词向量中\n",
      "trustworthy.不存在于词向量中\n",
      "Vagina不存在于词向量中\n",
      "Minecraft,不存在于词向量中\n",
      "and...|||To不存在于词向量中\n",
      "ISTj不存在于词向量中\n",
      "flexibility,不存在于词向量中\n",
      "analytical.不存在于词向量中\n",
      "addictive,不存在于词向量中\n",
      "sub-forum.不存在于词向量中\n",
      "-Not不存在于词向量中\n",
      "site's不存在于词向量中\n",
      "Phoebe不存在于词向量中\n",
      "mine?不存在于词向量中\n",
      "somewhat,不存在于词向量中\n",
      "Mom-不存在于词向量中\n",
      "feelin'不存在于词向量中\n",
      "Itachi不存在于词向量中\n",
      "Designer不存在于词向量中\n",
      "Chrono不存在于词向量中\n",
      "moron.不存在于词向量中\n",
      "deadlines.不存在于词向量中\n",
      "Thief不存在于词向量中\n",
      "reputation.不存在于词向量中\n",
      "(Part不存在于词向量中\n",
      "persons.不存在于词向量中\n",
      ",and不存在于词向量中\n",
      "intimacy,不存在于词向量中\n",
      ":crazy:|||Welcome不存在于词向量中\n",
      "Strawberry不存在于词向量中\n",
      "blanket,不存在于词向量中\n",
      "Strength-不存在于词向量中\n",
      "company?不存在于词向量中\n",
      "Danger不存在于词向量中\n",
      "Jo不存在于词向量中\n",
      ":o)|||Hi不存在于词向量中\n",
      "of...|||Haha,不存在于词向量中\n",
      "demeanor.不存在于词向量中\n",
      "the...|||He不存在于词向量中\n",
      "dust.不存在于词向量中\n",
      "humility,不存在于词向量中\n",
      "stuck,不存在于词向量中\n",
      "SM-G920T不存在于词向量中\n",
      "poster's不存在于词向量中\n",
      "tab,不存在于词向量中\n",
      "MEAN不存在于词向量中\n",
      "PERC不存在于词向量中\n",
      "Buying不存在于词向量中\n",
      "priorities,不存在于词向量中\n",
      "answered.不存在于词向量中\n",
      "anyhow.不存在于词向量中\n",
      "EXFJ不存在于词向量中\n",
      "Vietnam不存在于词向量中\n",
      "impractical,不存在于词向量中\n",
      "Psychopath不存在于词向量中\n",
      ":wink:|||It不存在于词向量中\n",
      "Panda不存在于词向量中\n",
      "subtypes.不存在于词向量中\n",
      "Dracula不存在于词向量中\n",
      "Ooh,不存在于词向量中\n",
      "Congrats!不存在于词向量中\n",
      "SLI不存在于词向量中\n",
      "condescending,不存在于词向量中\n",
      "Funnily不存在于词向量中\n",
      "Dostoevsky不存在于词向量中\n",
      "Vice不存在于词向量中\n",
      "Sixes不存在于词向量中\n",
      "sp/sx,不存在于词向量中\n",
      "(having不存在于词向量中\n",
      "Imagining不存在于词向量中\n",
      ":laughing:|||That不存在于词向量中\n",
      "SOOO不存在于词向量中\n",
      "View不存在于词向量中\n",
      "sunlight,不存在于词向量中\n",
      "Honey,不存在于词向量中\n",
      "companion.不存在于词向量中\n",
      "the...|||you不存在于词向量中\n",
      "'Haha不存在于词向量中\n",
      "graduate,不存在于词向量中\n",
      ";P|||I不存在于词向量中\n",
      "Ironically不存在于词向量中\n",
      "healing.不存在于词向量中\n",
      "have...|||There不存在于词向量中\n",
      "report,不存在于词向量中\n",
      "by...|||This不存在于词向量中\n",
      "recommendation.不存在于词向量中\n",
      "suggestions?不存在于词向量中\n",
      "close)不存在于词向量中\n",
      "fact...|||I不存在于词向量中\n",
      "WPM不存在于词向量中\n",
      "Sora不存在于词向量中\n",
      "Avoidant不存在于词向量中\n",
      "well...I不存在于词向量中\n",
      "Yourself不存在于词向量中\n",
      "Translation:不存在于词向量中\n",
      "and...|||Haha,不存在于词向量中\n",
      "Tech不存在于词向量中\n",
      "September.不存在于词向量中\n",
      "degree?不存在于词向量中\n",
      "it.|||So不存在于词向量中\n",
      "a...|||Very不存在于词向量中\n",
      "Rorschach不存在于词向量中\n",
      "(regardless不存在于词向量中\n",
      "Kick不存在于词向量中\n",
      "Ass不存在于词向量中\n",
      "ties.不存在于词向量中\n",
      "care.|||I不存在于词向量中\n",
      "smooth,不存在于词向量中\n",
      "had...'不存在于词向量中\n",
      "complete,不存在于词向量中\n",
      "Panic不存在于词向量中\n",
      "tho)不存在于词向量中\n",
      "trusted.不存在于词向量中\n",
      "potatoes,不存在于词向量中\n",
      "Member不存在于词向量中\n",
      "slavery,不存在于词向量中\n",
      "excuses,不存在于词向量中\n",
      "garbage,不存在于词向量中\n",
      "marijuana,不存在于词向量中\n",
      "Liking不存在于词向量中\n",
      "survival,不存在于词向量中\n",
      "sound?不存在于词向量中\n",
      "Dislike不存在于词向量中\n",
      "thereof.不存在于词向量中\n",
      "map,不存在于词向量中\n",
      "or...|||i不存在于词向量中\n",
      "Bullying不存在于词向量中\n",
      "are...|||Not不存在于词向量中\n",
      "the...|||Im不存在于词向量中\n",
      "order?不存在于词向量中\n",
      "POV,不存在于词向量中\n",
      "meals,不存在于词向量中\n",
      "of...|||One不存在于词向量中\n",
      "Martha不存在于词向量中\n",
      "for.|||I不存在于词向量中\n",
      "selves,不存在于词向量中\n",
      "PerC?不存在于词向量中\n",
      "cheeks.不存在于词向量中\n",
      "2013.不存在于词向量中\n",
      "Enjolras不存在于词向量中\n",
      "BUT.不存在于词向量中\n",
      "O'Brien不存在于词向量中\n",
      "answers...不存在于词向量中\n",
      "Fi's不存在于词向量中\n",
      "Si-Ne.不存在于词向量中\n",
      "challenge?不存在于词向量中\n",
      "Interaction不存在于词向量中\n",
      "(several不存在于词向量中\n",
      "Female:不存在于词向量中\n",
      "constant.不存在于词向量中\n",
      "Harris,不存在于词向量中\n",
      "Parsons不存在于词向量中\n",
      "3.14不存在于词向量中\n",
      "energies,不存在于词向量中\n",
      "(everything不存在于词向量中\n",
      "ENxPs不存在于词向量中\n",
      "atheists.不存在于词向量中\n",
      "do...'不存在于词向量中\n",
      "apathetic,不存在于词向量中\n",
      "Sartre不存在于词向量中\n",
      "someone.|||I不存在于词向量中\n",
      "of...|||Why不存在于词向量中\n",
      "fancy,不存在于词向量中\n",
      "reciprocate.不存在于词向量中\n",
      "Progressive不存在于词向量中\n",
      "cuddling,不存在于词向量中\n",
      "your's不存在于词向量中\n",
      "ketchup,不存在于词向量中\n",
      "it!)不存在于词向量中\n",
      "trivial,不存在于词向量中\n",
      "what...|||The不存在于词向量中\n",
      "stability.不存在于词向量中\n",
      "up...|||You不存在于词向量中\n",
      "Styles不存在于词向量中\n",
      "INTP;不存在于词向量中\n",
      "bubbly.不存在于词向量中\n",
      "cheerful,不存在于词向量中\n",
      "requirements,不存在于词向量中\n",
      "TRULY不存在于词向量中\n",
      "Doctors不存在于词向量中\n",
      "musicals.不存在于词向量中\n",
      "accounting,不存在于词向量中\n",
      "I...|||We不存在于词向量中\n",
      "members?不存在于词向量中\n",
      "Avett不存在于词向量中\n",
      "Animation不存在于词向量中\n",
      "quo,不存在于词向量中\n",
      "to...|||What's不存在于词向量中\n",
      "too?|||I不存在于词向量中\n",
      "Gaiman不存在于词向量中\n",
      "pills.不存在于词向量中\n",
      "AWESOME!不存在于词向量中\n",
      "Optimistic不存在于词向量中\n",
      "princess.不存在于词向量中\n",
      "on...|||It's不存在于词向量中\n",
      "Myer不存在于词向量中\n",
      "mine..不存在于词向量中\n",
      "the...|||Haha不存在于词向量中\n",
      "outcomes,不存在于词向量中\n",
      ":)|||And不存在于词向量中\n",
      "assistance,不存在于词向量中\n",
      "INTO不存在于词向量中\n",
      "shadows,不存在于词向量中\n",
      "and...|||But不存在于词向量中\n",
      "crimes,不存在于词向量中\n",
      "Cristo不存在于词向量中\n",
      "SJ's,不存在于词向量中\n",
      "5...|||I不存在于词向量中\n",
      "inside.|||I不存在于词向量中\n",
      "too...|||I'm不存在于词向量中\n",
      "I've...|||The不存在于词向量中\n",
      "driven.不存在于词向量中\n",
      "manipulate,不存在于词向量中\n",
      ";)|||It不存在于词向量中\n",
      "idea.|||I不存在于词向量中\n",
      "skeptical,不存在于词向量中\n",
      "Intelligence.不存在于词向量中\n",
      "knowing,不存在于词向量中\n",
      "can.|||I不存在于词向量中\n",
      "solve,不存在于词向量中\n",
      "Ends不存在于词向量中\n",
      "Ghandi不存在于词向量中\n",
      "Toast不存在于词向量中\n",
      "crowded,不存在于词向量中\n",
      "Weekend不存在于词向量中\n",
      "something...|||I'm不存在于词向量中\n",
      "favourites,不存在于词向量中\n",
      "India.不存在于词向量中\n",
      "Grandpa不存在于词向量中\n",
      "traditions.不存在于词向量中\n",
      "other...|||It's不存在于词向量中\n",
      "Thin不存在于词向量中\n",
      "Molly不存在于词向量中\n",
      "Disco不存在于词向量中\n",
      "Secrets不存在于词向量中\n",
      "vu.不存在于词向量中\n",
      "'that's不存在于词向量中\n",
      "fulfilling,不存在于词向量中\n",
      "command,不存在于词向量中\n",
      "HOLY不存在于词向量中\n",
      "pick,不存在于词向量中\n",
      "Unity不存在于词向量中\n",
      "Esp.不存在于词向量中\n",
      "Global5/SLOAN不存在于词向量中\n",
      "anthropology,不存在于词向量中\n",
      "you...|||Just不存在于词向量中\n",
      "ideology,不存在于词向量中\n",
      "are...|||So不存在于词向量中\n",
      "dream...不存在于词向量中\n",
      "TI不存在于词向量中\n",
      "an...|||Well,不存在于词向量中\n",
      "just....不存在于词向量中\n",
      "KILL不存在于词向量中\n",
      "horses,不存在于词向量中\n",
      "Fly不存在于词向量中\n",
      "kids...不存在于词向量中\n",
      "wisely.不存在于词向量中\n",
      "Beasts不存在于词向量中\n",
      "sorta.不存在于词向量中\n",
      "without,不存在于词向量中\n",
      "reflect,不存在于词向量中\n",
      "You!不存在于词向量中\n",
      "Lavender不存在于词向量中\n",
      "threat.不存在于词向量中\n",
      "Rising:不存在于词向量中\n",
      "WARNING:不存在于词向量中\n",
      "Actions不存在于词向量中\n",
      "TON不存在于词向量中\n",
      "COME不存在于词向量中\n",
      "that...|||So不存在于词向量中\n",
      "Controlling不存在于词向量中\n",
      "with...|||As不存在于词向量中\n",
      "actual...|||I不存在于词向量中\n",
      "UV不存在于词向量中\n",
      "advantage,不存在于词向量中\n",
      "away)不存在于词向量中\n",
      "||||||||||||||||||不存在于词向量中\n",
      "Perceivers不存在于词向量中\n",
      "Introvert.不存在于词向量中\n",
      "trolls,不存在于词向量中\n",
      "Rating不存在于词向量中\n",
      "unnecessary,不存在于词向量中\n",
      "contradictory,不存在于词向量中\n",
      "invisible,不存在于词向量中\n",
      "Tier不存在于词向量中\n",
      "wardrobe.不存在于词向量中\n",
      "convention,不存在于词向量中\n",
      "pretty...|||I'm不存在于词向量中\n",
      "tell).不存在于词向量中\n",
      "Age,不存在于词向量中\n",
      "nerdy.不存在于词向量中\n",
      "traffic,不存在于词向量中\n",
      "Florida,不存在于词向量中\n",
      "luck!|||I不存在于词向量中\n",
      "(He's不存在于词向量中\n",
      "speakers,不存在于词向量中\n",
      "Hitler.不存在于词向量中\n",
      "Reflective不存在于词向量中\n",
      "twin.不存在于词向量中\n",
      "now...|||I'm不存在于词向量中\n",
      "vehicle.不存在于词向量中\n",
      "Seeker,不存在于词向量中\n",
      "description.|||I不存在于词向量中\n",
      "food.|||I不存在于词向量中\n",
      "Plain不存在于词向量中\n",
      "previously.不存在于词向量中\n",
      "colleges,不存在于词向量中\n",
      "flirty.不存在于词向量中\n",
      "version)不存在于词向量中\n",
      "Sci-fi不存在于词向量中\n",
      "Mayer不存在于词向量中\n",
      "(Actually,不存在于词向量中\n",
      "Dexter,不存在于词向量中\n",
      "things...|||My不存在于词向量中\n",
      "draining,不存在于词向量中\n",
      "INFJ).不存在于词向量中\n",
      "seek,不存在于词向量中\n",
      "mold,不存在于词向量中\n",
      "IxFP.不存在于词向量中\n",
      "few)不存在于词向量中\n",
      "like...|||That's不存在于词向量中\n",
      "weekend?不存在于词向量中\n",
      "please?|||I不存在于词向量中\n",
      "5/6不存在于词向量中\n",
      "-...|||My不存在于词向量中\n",
      "so...|||Thank不存在于词向量中\n",
      "exclusively.不存在于词向量中\n",
      "Hmm...I不存在于词向量中\n",
      "Horrible不存在于词向量中\n",
      "Insert不存在于词向量中\n",
      "Kidding不存在于词向量中\n",
      "general.|||I不存在于词向量中\n",
      "normally?不存在于词向量中\n",
      "Delta不存在于词向量中\n",
      "good...|||I've不存在于词向量中\n",
      "hypocritical,不存在于词向量中\n",
      "left)不存在于词向量中\n",
      "Dutch,不存在于词向量中\n",
      "loved?不存在于词向量中\n",
      "Wednesday.不存在于词向量中\n",
      "shift,不存在于词向量中\n",
      "addict.不存在于词向量中\n",
      "elected.不存在于词向量中\n",
      "MAY不存在于词向量中\n",
      "Falls不存在于词向量中\n",
      "eyes.|||I不存在于词向量中\n",
      "Labyrinth不存在于词向量中\n",
      "wow...不存在于词向量中\n",
      "funeral,不存在于词向量中\n",
      "philosophies,不存在于词向量中\n",
      "Latin.不存在于词向量中\n",
      ":)|||Welcome!不存在于词向量中\n",
      "Gohan不存在于词向量中\n",
      "Trunks不存在于词向量中\n",
      "infatuation.不存在于词向量中\n",
      "accurately,不存在于词向量中\n",
      "safety,不存在于词向量中\n",
      "Answering不存在于词向量中\n",
      "strategies.不存在于词向量中\n",
      ":laughing:|||Thank不存在于词向量中\n",
      "Swedish.不存在于词向量中\n",
      "Rihanna不存在于词向量中\n",
      "shots.不存在于词向量中\n",
      "die.|||I不存在于词向量中\n",
      "brat.不存在于词向量中\n",
      "that...|||1.不存在于词向量中\n",
      "Accounting不存在于词向量中\n",
      "That's...|||I不存在于词向量中\n",
      "documentary.不存在于词向量中\n",
      "know...I不存在于词向量中\n",
      "several.不存在于词向量中\n",
      "question)不存在于词向量中\n",
      "..I不存在于词向量中\n",
      "near,不存在于词向量中\n",
      "graduate.不存在于词向量中\n",
      "presentation.不存在于词向量中\n",
      "Fuck.不存在于词向量中\n",
      "closure.不存在于词向量中\n",
      "'N'不存在于词向量中\n",
      "high?不存在于词向量中\n",
      "time.|||The不存在于词向量中\n",
      "lately...不存在于词向量中\n",
      "PM,不存在于词向量中\n",
      "Surprisingly,不存在于词向量中\n",
      "relatives,不存在于词向量中\n",
      "trainer,不存在于词向量中\n",
      "this|||I不存在于词向量中\n",
      "Julie不存在于词向量中\n",
      "adventures.不存在于词向量中\n",
      "nurse,不存在于词向量中\n",
      "...|||Are不存在于词向量中\n",
      "word...不存在于词向量中\n",
      "Movies,不存在于词向量中\n",
      "Mariah不存在于词向量中\n",
      "presentation,不存在于词向量中\n",
      "Martian不存在于词向量中\n",
      "rambling,不存在于词向量中\n",
      "down)不存在于词向量中\n",
      "label.不存在于词向量中\n",
      "frequent.不存在于词向量中\n",
      "Magi不存在于词向量中\n",
      "Magica不存在于词向量中\n",
      "a...|||Some不存在于词向量中\n",
      "Indonesia不存在于词向量中\n",
      "salad,不存在于词向量中\n",
      "unnatural.不存在于词向量中\n",
      "mellow,不存在于词向量中\n",
      "Focused不存在于词向量中\n",
      "Y.不存在于词向量中\n",
      "foremost,不存在于词向量中\n",
      ":P|||Well,不存在于词向量中\n",
      "google,不存在于词向量中\n",
      "(however不存在于词向量中\n",
      "Observant不存在于词向量中\n",
      "Spontaneous不存在于词向量中\n",
      "Fi!不存在于词向量中\n",
      "impatient.不存在于词向量中\n",
      "Figuring不存在于词向量中\n",
      "Robb不存在于词向量中\n",
      "Andrea不存在于词向量中\n",
      "perfectionism.不存在于词向量中\n",
      "Sans不存在于词向量中\n",
      "nerve.不存在于词向量中\n",
      "results?不存在于词向量中\n",
      "cope,不存在于词向量中\n",
      "broke,不存在于词向量中\n",
      "Judgement不存在于词向量中\n",
      "JW不存在于词向量中\n",
      "Turkish不存在于词向量中\n",
      "lovers.不存在于词向量中\n",
      "value?不存在于词向量中\n",
      "(took不存在于词向量中\n",
      "functions...|||I不存在于词向量中\n",
      "Costa不存在于词向量中\n",
      "HIS不存在于词向量中\n",
      "much),不存在于词向量中\n",
      "5.5不存在于词向量中\n",
      "an...不存在于词向量中\n",
      "moment)不存在于词向量中\n",
      "worrying,不存在于词向量中\n",
      "Overly不存在于词向量中\n",
      "Arrogance不存在于词向量中\n",
      "will)不存在于词向量中\n",
      "Linguistics不存在于词向量中\n",
      "kitchen.不存在于词向量中\n",
      "as...|||You不存在于词向量中\n",
      "capacity.不存在于词向量中\n",
      "Cambridge不存在于词向量中\n",
      "Violin不存在于词向量中\n",
      "geniuses.不存在于词向量中\n",
      "coke,不存在于词向量中\n",
      "much|||I不存在于词向量中\n",
      "of...|||Are不存在于词向量中\n",
      "off..不存在于词向量中\n",
      "'right'不存在于词向量中\n",
      "Return不存在于词向量中\n",
      "SM-G920W8不存在于词向量中\n",
      "destructive,不存在于词向量中\n",
      "Lauren不存在于词向量中\n",
      "complaining.不存在于词向量中\n",
      "emotionless.不存在于词向量中\n",
      "in...|||I'll不存在于词向量中\n",
      "criteria.不存在于词向量中\n",
      "chances.不存在于词向量中\n",
      "through.|||I不存在于词向量中\n",
      "marketing,不存在于词向量中\n",
      "queen.不存在于词向量中\n",
      "be).不存在于词向量中\n",
      "overweight,不存在于词向量中\n",
      "Muse,不存在于词向量中\n",
      "inside?不存在于词向量中\n",
      "a...|||Oh,不存在于词向量中\n",
      "suggest,不存在于词向量中\n",
      "understandable,不存在于词向量中\n",
      "permanent.不存在于词向量中\n",
      "the...|||-不存在于词向量中\n",
      "Caf茅不存在于词向量中\n",
      "Bonham不存在于词向量中\n",
      "Carter不存在于词向量中\n",
      "(get不存在于词向量中\n",
      "theater.不存在于词向量中\n",
      "INTPs)不存在于词向量中\n",
      "desired.不存在于词向量中\n",
      "characteristic)不存在于词向量中\n",
      "composition.不存在于词向量中\n",
      "HER不存在于词向量中\n",
      "Holly不存在于词向量中\n",
      "Healer不存在于词向量中\n",
      "lighting,不存在于词向量中\n",
      "miles.不存在于词向量中\n",
      "Values不存在于词向量中\n",
      "hair...不存在于词向量中\n",
      "whatever's不存在于词向量中\n",
      "sin.不存在于词向量中\n",
      "nonfiction,不存在于词向量中\n",
      "reactive,不存在于词向量中\n",
      "scenery,不存在于词向量中\n",
      "triad.不存在于词向量中\n",
      "troubles,不存在于词向量中\n",
      "seeking.不存在于词向量中\n",
      "Cancer,不存在于词向量中\n",
      "job...|||I不存在于词向量中\n",
      "naps.不存在于词向量中\n",
      "during...|||I不存在于词向量中\n",
      "dishonest,不存在于词向量中\n",
      "INTP-ness不存在于词向量中\n",
      "Brit不存在于词向量中\n",
      ":)|||Some不存在于词向量中\n",
      "Matilda不存在于词向量中\n",
      "observant.不存在于词向量中\n",
      "Gun不存在于词向量中\n",
      "ESFP.|||I不存在于词向量中\n",
      "die...不存在于词向量中\n",
      "though.|||My不存在于词向量中\n",
      "sharp,不存在于词向量中\n",
      "people.|||When不存在于词向量中\n",
      "flirting?不存在于词向量中\n",
      "Mirror不存在于词向量中\n",
      "languages?不存在于词向量中\n",
      "Destiny不存在于词向量中\n",
      "prefer?不存在于词向量中\n",
      "apparent,不存在于词向量中\n",
      "process?不存在于词向量中\n",
      "growing.不存在于词向量中\n",
      "a...|||Hmm不存在于词向量中\n",
      "stimulating,不存在于词向量中\n",
      "people...'不存在于词向量中\n",
      "clarify.不存在于词向量中\n",
      "advocate,不存在于词向量中\n",
      "Nikola不存在于词向量中\n",
      "X-men不存在于词向量中\n",
      "whining.不存在于词向量中\n",
      "this.)不存在于词向量中\n",
      "was...|||It不存在于词向量中\n",
      "them...|||I'm不存在于词向量中\n",
      "strict.不存在于词向量中\n",
      "Legal不存在于词向量中\n",
      "PDF不存在于词向量中\n",
      "orientation?不存在于词向量中\n",
      "in.|||I'm不存在于词向量中\n",
      "Benedict不存在于词向量中\n",
      "taking.不存在于词向量中\n",
      "Mood:不存在于词向量中\n",
      "Texas,不存在于词向量中\n",
      "cry...不存在于词向量中\n",
      "jealousy.不存在于词向量中\n",
      "Baron不存在于词向量中\n",
      "Ti-Se不存在于词向量中\n",
      "Feeler,不存在于词向量中\n",
      "crazy?不存在于词向量中\n",
      "ASMR不存在于词向量中\n",
      "Morty不存在于词向量中\n",
      "show...不存在于词向量中\n",
      "to...|||From不存在于词向量中\n",
      "F's.不存在于词向量中\n",
      "station,不存在于词向量中\n",
      "request,不存在于词向量中\n",
      "ignore,不存在于词向量中\n",
      "alpha,不存在于词向量中\n",
      "'Yes!不存在于词向量中\n",
      "an...|||Yeah,不存在于词向量中\n",
      "self-confidence,不存在于词向量中\n",
      "inspired.不存在于词向量中\n",
      "serious..不存在于词向量中\n",
      "recover.不存在于词向量中\n",
      "discovered.不存在于词向量中\n",
      "designer.不存在于词向量中\n",
      "stimulation,不存在于词向量中\n",
      "alternative.不存在于词向量中\n",
      "procrastinate,不存在于词向量中\n",
      "addictive.不存在于词向量中\n",
      "in...|||Just不存在于词向量中\n",
      ";)|||I've不存在于词向量中\n",
      "even...|||I'm不存在于词向量中\n",
      "a...|||One不存在于词向量中\n",
      "worthy,不存在于词向量中\n",
      ":O|||I不存在于词向量中\n",
      "(someone不存在于词向量中\n",
      "chasing,不存在于词向量中\n",
      "Netflix,不存在于词向量中\n",
      "Quiet,不存在于词向量中\n",
      "Dune不存在于词向量中\n",
      "landscapes,不存在于词向量中\n",
      "Highschool不存在于词向量中\n",
      "selection.不存在于词向量中\n",
      "language),不存在于词向量中\n",
      "ISFJ-不存在于词向量中\n",
      "ago),不存在于词向量中\n",
      "Prejudice,不存在于词向量中\n",
      "gather,不存在于词向量中\n",
      "briefly,不存在于词向量中\n",
      "unreliable.不存在于词向量中\n",
      "reader.不存在于词向量中\n",
      "objectively,不存在于词向量中\n",
      "Bennet不存在于词向量中\n",
      "Fe...不存在于词向量中\n",
      "chances,不存在于词向量中\n",
      "life),不存在于词向量中\n",
      "(few不存在于词向量中\n",
      "gentlemen,不存在于词向量中\n",
      "Gorillaz不存在于词向量中\n",
      "some...'不存在于词向量中\n",
      "Smallville不存在于词向量中\n",
      "Allison不存在于词向量中\n",
      "Nevermind.不存在于词向量中\n",
      "software.不存在于词向量中\n",
      "Best.不存在于词向量中\n",
      "Killer不存在于词向量中\n",
      "regardless,不存在于词向量中\n",
      "eternity.不存在于词向量中\n",
      "trolls.不存在于词向量中\n",
      "Samsung不存在于词向量中\n",
      "Ohh,不存在于词向量中\n",
      "Giga不存在于词向量中\n",
      "Blender:不存在于词向量中\n",
      "Garbanzo:不存在于词向量中\n",
      "together...不存在于词向量中\n",
      "too.'不存在于词向量中\n",
      "Down,不存在于词向量中\n",
      "Defense不存在于词向量中\n",
      "types...|||I不存在于词向量中\n",
      "leaders.不存在于词向量中\n",
      "on...|||Well不存在于词向量中\n",
      "the...|||Okay不存在于词向量中\n",
      "P's.不存在于词向量中\n",
      "that|||I不存在于词向量中\n",
      "NZ不存在于词向量中\n",
      "movie...不存在于词向量中\n",
      "Cam不存在于词向量中\n",
      "Curse不存在于词向量中\n",
      "INTP/INTJ不存在于词向量中\n",
      "over.|||I不存在于词向量中\n",
      "XNFP.不存在于词向量中\n",
      "XIII不存在于词向量中\n",
      "disappoint.不存在于词向量中\n",
      "song..不存在于词向量中\n",
      "Garfunkel不存在于词向量中\n",
      "up...|||My不存在于词向量中\n",
      "I...|||Hmm...不存在于词向量中\n",
      "they...|||Thanks不存在于词向量中\n",
      "...|||you不存在于词向量中\n",
      "some...|||If不存在于词向量中\n",
      ":)|||Yeah不存在于词向量中\n",
      "definitely...|||I不存在于词向量中\n",
      "Math.不存在于词向量中\n",
      "companionship.不存在于词向量中\n",
      "of...|||We不存在于词向量中\n",
      "phenomena,不存在于词向量中\n",
      "text?不存在于词向量中\n",
      "(ok,不存在于词向量中\n",
      "it's...不存在于词向量中\n",
      "of...|||i不存在于词向量中\n",
      "Method不存在于词向量中\n",
      "at...|||i不存在于词向量中\n",
      "dichotomies.不存在于词向量中\n",
      "harmful.不存在于词向量中\n",
      "puzzles,不存在于词向量中\n",
      "procrastinator,不存在于词向量中\n",
      "magical,不存在于词向量中\n",
      "Cute,不存在于词向量中\n",
      "'it's不存在于词向量中\n",
      "Instantly不存在于词向量中\n",
      "report.不存在于词向量中\n",
      "calming,不存在于词向量中\n",
      "Buddhism.不存在于词向量中\n",
      "atm,不存在于词向量中\n",
      "edges,不存在于词向量中\n",
      "Meetups不存在于词向量中\n",
      "function),不存在于词向量中\n",
      "weights.不存在于词向量中\n",
      "Teresa不存在于词向量中\n",
      "commit,不存在于词向量中\n",
      "Actual不存在于词向量中\n",
      "honey,不存在于词向量中\n",
      "beard.不存在于词向量中\n",
      "d)不存在于词向量中\n",
      "then)不存在于词向量中\n",
      "Letter不存在于词向量中\n",
      "Fictional不存在于词向量中\n",
      "Leader不存在于词向量中\n",
      "Effective不存在于词向量中\n",
      "Olympic不存在于词向量中\n",
      "Clare不存在于词向量中\n",
      "Irrational不存在于词向量中\n",
      "Followed不存在于词向量中\n",
      "numbers?不存在于词向量中\n",
      "hair?不存在于词向量中\n",
      "blonde,不存在于词向量中\n",
      "porn?不存在于词向量中\n",
      "way,...|||I不存在于词向量中\n",
      "INFP-不存在于词向量中\n",
      "Moral不存在于词向量中\n",
      "(1st不存在于词向量中\n",
      "steal.不存在于词向量中\n",
      "nine,不存在于词向量中\n",
      "not....不存在于词向量中\n",
      "openly,不存在于词向量中\n",
      "Pe不存在于词向量中\n",
      "my...|||Yeah不存在于词向量中\n",
      ":)|||Hey,不存在于词向量中\n",
      ":angry:|||I不存在于词向量中\n",
      "stalking.不存在于词向量中\n",
      ":bored:|||I不存在于词向量中\n",
      ":tongue:,不存在于词向量中\n",
      "originally.不存在于词向量中\n",
      "idea)不存在于词向量中\n",
      "attracted,不存在于词向量中\n",
      "disturbing,不存在于词向量中\n",
      "Z.不存在于词向量中\n",
      "Bioshock不存在于词向量中\n",
      "babe.不存在于词向量中\n",
      "Hannah不存在于词向量中\n",
      "ISTJs?不存在于词向量中\n",
      "Aubrey不存在于词向量中\n",
      "more...|||This不存在于词向量中\n",
      ">:(不存在于词向量中\n",
      "frankly.不存在于词向量中\n",
      "begin?不存在于词向量中\n",
      "particularly,不存在于词向量中\n",
      "worried,不存在于词向量中\n",
      "not...|||So不存在于词向量中\n",
      "ball,不存在于词向量中\n",
      "Fe-Ni不存在于词向量中\n",
      "xSFJs不存在于词向量中\n",
      "that.|||The不存在于词向量中\n",
      "and...|||Do不存在于词向量中\n",
      "Borderline:不存在于词向量中\n",
      "Narcissistic:不存在于词向量中\n",
      "Avoidant:不存在于词向量中\n",
      "smile.|||I不存在于词向量中\n",
      "Spider-Man不存在于词向量中\n",
      "Night,不存在于词向量中\n",
      "Bones不存在于词向量中\n",
      "Winter.不存在于词向量中\n",
      "me!)不存在于词向量中\n",
      "(considering不存在于词向量中\n",
      "it...|||Sorry不存在于词向量中\n",
      "(Very不存在于词向量中\n",
      "exams.不存在于词向量中\n",
      "Cassandra不存在于词向量中\n",
      "for...|||A不存在于词向量中\n",
      "weddings,不存在于词向量中\n",
      "graduation.不存在于词向量中\n",
      "that...|||Yes.不存在于词向量中\n",
      "Daydreaming不存在于词向量中\n",
      "her...|||This不存在于词向量中\n",
      "possibly.不存在于词向量中\n",
      "freely.不存在于词向量中\n",
      "May,不存在于词向量中\n",
      "communism.不存在于词向量中\n",
      "academically.不存在于词向量中\n",
      "inevitable,不存在于词向量中\n",
      "steps,不存在于词向量中\n",
      "ENFJ-不存在于词向量中\n",
      "not...|||Yes,不存在于词向量中\n",
      "UNTIL不存在于词向量中\n",
      "Population不存在于词向量中\n",
      "Colors不存在于词向量中\n",
      "Neko不存在于词向量中\n",
      "Ti/Fe,不存在于词向量中\n",
      "Hop不存在于词向量中\n",
      "the...|||Ah,不存在于词向量中\n",
      "tense.不存在于词向量中\n",
      "ASAP.不存在于词向量中\n",
      "Rei不存在于词向量中\n",
      "Erik不存在于词向量中\n",
      "^^'不存在于词向量中\n",
      "Strangely不存在于词向量中\n",
      "Italian.不存在于词向量中\n",
      "xNFP,不存在于词向量中\n",
      "streets,不存在于词向量中\n",
      "Forcing不存在于词向量中\n",
      "FOCUS不存在于词向量中\n",
      "you...|||No不存在于词向量中\n",
      "Barry不存在于词向量中\n",
      "weirdo.不存在于词向量中\n",
      "flavor.不存在于词向量中\n",
      "-They不存在于词向量中\n",
      "INTP-不存在于词向量中\n",
      "x.x不存在于词向量中\n",
      "be...|||Yeah不存在于词向量中\n",
      "you.|||It不存在于词向量中\n",
      "'Nuff不存在于词向量中\n",
      "Visit不存在于词向量中\n",
      "Hm不存在于词向量中\n",
      "Whoops,不存在于词向量中\n",
      "decision?不存在于词向量中\n",
      "pushover.不存在于词向量中\n",
      "Starry不存在于词向量中\n",
      "yeah?不存在于词向量中\n",
      "roommate's不存在于词向量中\n",
      "Sensitivity不存在于词向量中\n",
      "happens.|||I不存在于词向量中\n",
      "be...|||Well不存在于词向量中\n",
      "result?不存在于词向量中\n",
      "randomness.不存在于词向量中\n",
      "Moby不存在于词向量中\n",
      "bottle.不存在于词向量中\n",
      "buddies,不存在于词向量中\n",
      "wonders.不存在于词向量中\n",
      "of...|||He不存在于词向量中\n",
      "and...|||Also不存在于词向量中\n",
      "IXTJ不存在于词向量中\n",
      "fun|||I不存在于词向量中\n",
      "ENTP|||I不存在于词向量中\n",
      "made?不存在于词向量中\n",
      "instructions.不存在于词向量中\n",
      "element.不存在于词向量中\n",
      "stressful.不存在于词向量中\n",
      "attentive,不存在于词向量中\n",
      "spark,不存在于词向量中\n",
      "afar,不存在于词向量中\n",
      "tease.不存在于词向量中\n",
      "timing.不存在于词向量中\n",
      "Yup.不存在于词向量中\n",
      "MBTIs不存在于词向量中\n",
      "a...|||Sometimes不存在于词向量中\n",
      "&...|||I不存在于词向量中\n",
      "gardening,不存在于词向量中\n",
      "Patient不存在于词向量中\n",
      "Peterson不存在于词向量中\n",
      "Oracle不存在于词向量中\n",
      "Selfish不存在于词向量中\n",
      "diving,不存在于词向量中\n",
      ":)|||Dear不存在于词向量中\n",
      "Peach不存在于词向量中\n",
      "yet..不存在于词向量中\n",
      "2's不存在于词向量中\n",
      "Trance不存在于词向量中\n",
      "Armin不存在于词向量中\n",
      "nostalgia,不存在于词向量中\n",
      "Paint不存在于词向量中\n",
      "what...|||You不存在于词向量中\n",
      "suspect,不存在于词向量中\n",
      "Passionate不存在于词向量中\n",
      "incorrect,不存在于词向量中\n",
      "six.不存在于词向量中\n",
      "Js.不存在于词向量中\n",
      "self-awareness.不存在于词向量中\n",
      "SO's不存在于词向量中\n",
      "Judaism不存在于词向量中\n",
      ":tongue:|||What不存在于词向量中\n",
      "the...|||Does不存在于词向量中\n",
      "Expressing不存在于词向量中\n",
      "edgy,不存在于词向量中\n",
      "embrace.不存在于词向量中\n",
      "courses,不存在于词向量中\n",
      "Korean,不存在于词向量中\n",
      "Parrot,不存在于词向量中\n",
      "Sport不存在于词向量中\n",
      "Pepsi?)不存在于词向量中\n",
      "Hollow不存在于词向量中\n",
      "her).不存在于词向量中\n",
      "jest.不存在于词向量中\n",
      "there!|||I不存在于词向量中\n",
      "coherent.不存在于词向量中\n",
      "president.不存在于词向量中\n",
      "PA不存在于词向量中\n",
      "Hah!不存在于词向量中\n",
      "problem)不存在于词向量中\n",
      "AM,不存在于词向量中\n",
      "too....不存在于词向量中\n",
      "INTPness不存在于词向量中\n",
      "Invite不存在于词向量中\n",
      "people...|||It不存在于词向量中\n",
      "Weight:不存在于词向量中\n",
      "butterfly.不存在于词向量中\n",
      "'we不存在于词向量中\n",
      "Meg不存在于词向量中\n",
      "Finished不存在于词向量中\n",
      "Relax不存在于词向量中\n",
      "streets.不存在于词向量中\n",
      "unhealthy?不存在于词向量中\n",
      "Schindler's不存在于词向量中\n",
      "her..不存在于词向量中\n",
      "rest?不存在于词向量中\n",
      "2.00不存在于词向量中\n",
      "Sis:不存在于词向量中\n",
      "bowl.不存在于词向量中\n",
      "Next,不存在于词向量中\n",
      "headache,不存在于词向量中\n",
      "incompetence.不存在于词向量中\n",
      "below)不存在于词向量中\n",
      "spam.不存在于词向量中\n",
      "flower,不存在于词向量中\n",
      "Thinker.不存在于词向量中\n",
      ":D|||How不存在于词向量中\n",
      "is...|||Yeah不存在于词向量中\n",
      "Italy.不存在于词向量中\n",
      "Listen,不存在于词向量中\n",
      "almost...|||I'm不存在于词向量中\n",
      "react?不存在于词向量中\n",
      "heights,不存在于词向量中\n",
      "observed,不存在于词向量中\n",
      "Go,不存在于词向量中\n",
      "perfect.|||I不存在于词向量中\n",
      "keys.不存在于词向量中\n",
      "Inspector不存在于词向量中\n",
      "to...|||Can不存在于词向量中\n",
      "judgemental,不存在于词向量中\n",
      "'Someone不存在于词向量中\n",
      "broad.不存在于词向量中\n",
      "Today's不存在于词向量中\n",
      "tomorrow's不存在于词向量中\n",
      "this.|||This不存在于词向量中\n",
      "rides,不存在于词向量中\n",
      "does...不存在于词向量中\n",
      "projecting.不存在于词向量中\n",
      "both)不存在于词向量中\n",
      "(strong不存在于词向量中\n",
      "Julius不存在于词向量中\n",
      "Argentina不存在于词向量中\n",
      "Martial不存在于词向量中\n",
      "always...|||I'm不存在于词向量中\n",
      "curious.|||I不存在于词向量中\n",
      "ISFP|||I不存在于词向量中\n",
      "site?不存在于词向量中\n",
      "spanish,不存在于词向量中\n",
      "Ghetto不存在于词向量中\n",
      "highly...|||I不存在于词向量中\n",
      "(great不存在于词向量中\n",
      "Bringing不存在于词向量中\n",
      "proactive,不存在于词向量中\n",
      "risks.不存在于词向量中\n",
      "60/40不存在于词向量中\n",
      "2013,不存在于词向量中\n",
      "GOD,不存在于词向量中\n",
      "Danse不存在于词向量中\n",
      "self...|||I不存在于词向量中\n",
      ":)|||Thanks,不存在于词向量中\n",
      "Enthusiast不存在于词向量中\n",
      "INxJ.不存在于词向量中\n",
      "Popular不存在于词向量中\n",
      "LMAO不存在于词向量中\n",
      "Barely不存在于词向量中\n",
      "Nightmare不存在于词向量中\n",
      "Grimm不存在于词向量中\n",
      "Nostalgia不存在于词向量中\n",
      "free?不存在于词向量中\n",
      "sucked,不存在于词向量中\n",
      "Cheer不存在于词向量中\n",
      "how...|||My不存在于词向量中\n",
      "Twilight.不存在于词向量中\n",
      "Asia,不存在于词向量中\n",
      "solo.不存在于词向量中\n",
      "Orange,不存在于词向量中\n",
      "statement?不存在于词向量中\n",
      "Immediate不存在于词向量中\n",
      "Classics不存在于词向量中\n",
      "Pillars不存在于词向量中\n",
      "gives,不存在于词向量中\n",
      "Nelson不存在于词向量中\n",
      "Mixed不存在于词向量中\n",
      "contract.不存在于词向量中\n",
      "b,不存在于词向量中\n",
      "intimate.不存在于词向量中\n",
      "INFJness不存在于词向量中\n",
      ":D|||Just不存在于词向量中\n",
      "that...|||Hello不存在于词向量中\n",
      "PR不存在于词向量中\n",
      "concentration,不存在于词向量中\n",
      "Considerate不存在于词向量中\n",
      "Fairness不存在于词向量中\n",
      "Purity不存在于词向量中\n",
      "HTCONE不存在于词向量中\n",
      "them,...|||I不存在于词向量中\n",
      "way...|||I'm不存在于词向量中\n",
      "Gosling不存在于词向量中\n",
      "life).不存在于词向量中\n",
      "be...|||It不存在于词向量中\n",
      "good...|||My不存在于词向量中\n",
      "10)不存在于词向量中\n",
      "Together不存在于词向量中\n",
      "harshly.不存在于词向量中\n",
      "minimal.不存在于词向量中\n",
      "Interested不存在于词向量中\n",
      "reincarnation.不存在于词向量中\n",
      "penis,不存在于词向量中\n",
      "Nazis不存在于词向量中\n",
      "Chinese.不存在于词向量中\n",
      "Birds不存在于词向量中\n",
      "talker,不存在于词向量中\n",
      "narrative,不存在于词向量中\n",
      "Monkeys不存在于词向量中\n",
      "culture?不存在于词向量中\n",
      "have...|||Hi不存在于词向量中\n",
      "Job:不存在于词向量中\n",
      "consciousness?不存在于词向量中\n",
      ":)|||We不存在于词向量中\n",
      "either...|||I不存在于词向量中\n",
      "yes.|||I不存在于词向量中\n",
      "Truth.不存在于词向量中\n",
      "Arnold不存在于词向量中\n",
      "choose?不存在于词向量中\n",
      "...|||Very不存在于词向量中\n",
      "Cracked.com不存在于词向量中\n",
      "bubble,不存在于词向量中\n",
      "academia,不存在于词向量中\n",
      "thankful.不存在于词向量中\n",
      "snap,不存在于词向量中\n",
      "night.|||I不存在于词向量中\n",
      "nasty.不存在于词向量中\n",
      "ESTJ...不存在于词向量中\n",
      "get...'不存在于词向量中\n",
      "Bed不存在于词向量中\n",
      "day).不存在于词向量中\n",
      "unemployed.不存在于词向量中\n",
      "you...|||No,不存在于词向量中\n",
      "...|||Never不存在于词向量中\n",
      "butterflies.不存在于词向量中\n",
      "Geniuses不存在于词向量中\n",
      "intuitive?不存在于词向量中\n",
      "the...|||Here不存在于词向量中\n",
      "time...'不存在于词向量中\n",
      "My.不存在于词向量中\n",
      "need...|||I'm不存在于词向量中\n",
      "(obviously)不存在于词向量中\n",
      "(AKA不存在于词向量中\n",
      "hidden,不存在于词向量中\n",
      "Picked不存在于词向量中\n",
      "Er,不存在于词向量中\n",
      "mother)不存在于词向量中\n",
      "cafes,不存在于词向量中\n",
      "disorganized.不存在于词向量中\n",
      "Drug不存在于词向量中\n",
      "seven.不存在于词向量中\n",
      "Five:不存在于词向量中\n",
      "NFP's不存在于词向量中\n",
      "as...|||It不存在于词向量中\n",
      "tolerance.不存在于词向量中\n",
      "Catching不存在于词向量中\n",
      "(Oh,不存在于词向量中\n",
      "(Please不存在于词向量中\n",
      "Update:不存在于词向量中\n",
      "melancholy.不存在于词向量中\n",
      "Loss不存在于词向量中\n",
      "Ireland,不存在于词向量中\n",
      "Definite不存在于词向量中\n",
      "Fe-不存在于词向量中\n",
      "Asked不存在于词向量中\n",
      "Women's不存在于词向量中\n",
      "is...|||Why不存在于词向量中\n",
      "illegal,不存在于词向量中\n",
      "dragon.不存在于词向量中\n",
      "liars.不存在于词向量中\n",
      "german,不存在于词向量中\n",
      "wonder...不存在于词向量中\n",
      "ISTP)不存在于词向量中\n",
      "cultures,不存在于词向量中\n",
      "worse...不存在于词向量中\n",
      "(maybe)不存在于词向量中\n",
      "(introverted不存在于词向量中\n",
      "tracks.不存在于词向量中\n",
      "scientist.不存在于词向量中\n",
      "Stubborn不存在于词向量中\n",
      "angel.不存在于词向量中\n",
      "soon.|||I不存在于词向量中\n",
      "painter.不存在于词向量中\n",
      "spoon.不存在于词向量中\n",
      "Swiss不存在于词向量中\n",
      "...|||He不存在于词向量中\n",
      "Tapatalk|||Hello不存在于词向量中\n",
      "passive-aggressive.不存在于词向量中\n",
      "MDMA不存在于词向量中\n",
      "bug,不存在于词向量中\n",
      "Lunar不存在于词向量中\n",
      "INTx,不存在于词向量中\n",
      "I...|||Sometimes不存在于词向量中\n",
      "unethical.不存在于词向量中\n",
      "stability,不存在于词向量中\n",
      "bonding.不存在于词向量中\n",
      "AMD不存在于词向量中\n",
      "Neighbor不存在于词向量中\n",
      "Shoot不存在于词向量中\n",
      "that.|||This不存在于词向量中\n",
      "ENFP/INTJ不存在于词向量中\n",
      "incorrectly,不存在于词向量中\n",
      "are...|||It不存在于词向量中\n",
      "Mao不存在于词向量中\n",
      "SoundCloud不存在于词向量中\n",
      "Beating不存在于词向量中\n",
      "Vonnegut不存在于词向量中\n",
      "Murakami不存在于词向量中\n",
      "at...|||Yes,不存在于词向量中\n",
      "Marlon不存在于词向量中\n",
      "ENTJ.|||I不存在于词向量中\n",
      "understand...不存在于词向量中\n",
      "to...|||He不存在于词向量中\n",
      ":tongue:|||Yeah,不存在于词向量中\n",
      "question.|||I不存在于词向量中\n",
      "Maga不存在于词向量中\n",
      "Myth不存在于词向量中\n",
      "Type.不存在于词向量中\n",
      "Sensor,不存在于词向量中\n",
      "economics.不存在于词向量中\n",
      "PUA不存在于词向量中\n",
      "Anarchy不存在于词向量中\n",
      "slaves.不存在于词向量中\n",
      "emotional...|||I不存在于词向量中\n",
      "thinking/feeling不存在于词向量中\n",
      "futile.不存在于词向量中\n",
      "yay,不存在于词向量中\n",
      "compassion.不存在于词向量中\n",
      "pole,不存在于词向量中\n",
      "want...'不存在于词向量中\n",
      "candles,不存在于词向量中\n",
      "(live不存在于词向量中\n",
      "rebel.不存在于词向量中\n",
      "Grew不存在于词向量中\n",
      "musicians,不存在于词向量中\n",
      "Ghoul不存在于词向量中\n",
      "continues.不存在于词向量中\n",
      "CSI不存在于词向量中\n",
      "cow,不存在于词向量中\n",
      "I'm...|||The不存在于词向量中\n",
      "glass,不存在于词向量中\n",
      "Maze不存在于词向量中\n",
      "Vegan不存在于词向量中\n",
      "has...|||My不存在于词向量中\n",
      "it.|||I'd不存在于词向量中\n",
      "Bless不存在于词向量中\n",
      "writing?不存在于词向量中\n",
      "less?不存在于词向量中\n",
      "Wolves不存在于词向量中\n",
      "and...|||We不存在于词向量中\n",
      "personality...|||I不存在于词向量中\n",
      "justified,不存在于词向量中\n",
      "legit,不存在于词向量中\n",
      "was...|||Oh不存在于词向量中\n",
      "victim,不存在于词向量中\n",
      "Pisces.不存在于词向量中\n",
      "2?不存在于词向量中\n",
      "childlike,不存在于词向量中\n",
      "roots.不存在于词向量中\n",
      "Lmao不存在于词向量中\n",
      "killing.不存在于词向量中\n",
      "certainty,不存在于词向量中\n",
      "repetition,不存在于词向量中\n",
      "That...|||I不存在于词向量中\n",
      "Bells不存在于词向量中\n",
      "Pness不存在于词向量中\n",
      "Kefka不存在于词向量中\n",
      "conflicted.不存在于词向量中\n",
      "||||||||||不存在于词向量中\n",
      "moral.不存在于词向量中\n",
      "Orwell,不存在于词向量中\n",
      "gas,不存在于词向量中\n",
      "Shahada不存在于词向量中\n",
      "illnesses.不存在于词向量中\n",
      "individually.不存在于词向量中\n",
      "orders,不存在于词向量中\n",
      "Yeah!不存在于词向量中\n",
      "projection.不存在于词向量中\n",
      "History.不存在于词向量中\n",
      "Desert不存在于词向量中\n",
      "club?不存在于词向量中\n",
      "blush,不存在于词向量中\n",
      "pay.不存在于词向量中\n",
      "English?不存在于词向量中\n",
      "2009,不存在于词向量中\n",
      "you.|||Thank不存在于词向量中\n",
      "bugs,不存在于词向量中\n",
      "earned.不存在于词向量中\n",
      "C'est不存在于词向量中\n",
      "inadequate.不存在于词向量中\n",
      "same...|||I'm不存在于词向量中\n",
      "-In不存在于词向量中\n",
      "fridge.不存在于词向量中\n",
      "easy.|||I不存在于词向量中\n",
      "talker.不存在于词向量中\n",
      "Discovering不存在于词向量中\n",
      "Bang,不存在于词向量中\n",
      "same.|||I不存在于词向量中\n",
      "from...|||My不存在于词向量中\n",
      "ENFJs?不存在于词向量中\n",
      "America:不存在于词向量中\n",
      "MAD不存在于词向量中\n",
      ":P|||Well不存在于词向量中\n",
      "Java,不存在于词向量中\n",
      "Sally不存在于词向量中\n",
      "Chasing不存在于词向量中\n",
      "blank,不存在于词向量中\n",
      "Further,不存在于词向量中\n",
      "Feet不存在于词向量中\n",
      "cat...不存在于词向量中\n",
      "Bull不存在于词向量中\n",
      "Bach,不存在于词向量中\n",
      "did)不存在于词向量中\n",
      "Y'know,不存在于词向量中\n",
      "40.不存在于词向量中\n",
      "teenagers.不存在于词向量中\n",
      "any)不存在于词向量中\n",
      "controversial,不存在于词向量中\n",
      "Joel不存在于词向量中\n",
      "assertion.不存在于词向量中\n",
      "genes,不存在于词向量中\n",
      "Fruit不存在于词向量中\n",
      "Mandarin不存在于词向量中\n",
      "court.不存在于词向量中\n",
      "Levi不存在于词向量中\n",
      "your...|||What不存在于词向量中\n",
      "that...|||How不存在于词向量中\n",
      "Hamlet不存在于词向量中\n",
      "candidates.不存在于词向量中\n",
      "pun,不存在于词向量中\n",
      "cure,不存在于词向量中\n",
      "either)不存在于词向量中\n",
      "out....不存在于词向量中\n",
      "Symphony不存在于词向量中\n",
      "months...不存在于词向量中\n",
      "paragraphs,不存在于词向量中\n",
      "I...|||Ah,不存在于词向量中\n",
      "don't...|||The不存在于词向量中\n",
      ":)|||Sometimes不存在于词向量中\n",
      "Benefits不存在于词向量中\n",
      "I!不存在于词向量中\n",
      "Raising不存在于词向量中\n",
      "human's不存在于词向量中\n",
      "gif,不存在于词向量中\n",
      "'Okay,不存在于词向量中\n",
      "be...|||In不存在于词向量中\n",
      "kisses.不存在于词向量中\n",
      "separated.不存在于词向量中\n",
      "lasts.不存在于词向量中\n",
      "manage.不存在于词向量中\n",
      "shapes,不存在于词向量中\n",
      "Rogers不存在于词向量中\n",
      "Luck不存在于词向量中\n",
      "(known不存在于词向量中\n",
      "several...|||I不存在于词向量中\n",
      "conditioning,不存在于词向量中\n",
      "shucks.不存在于词向量中\n",
      "Aha!不存在于词向量中\n",
      "5?不存在于词向量中\n",
      "similarities,不存在于词向量中\n",
      "aux,不存在于词向量中\n",
      "ESL不存在于词向量中\n",
      "I...|||Okay,不存在于词向量中\n",
      "else..不存在于词向量中\n",
      "forum|||Hey不存在于词向量中\n",
      "However...不存在于词向量中\n",
      "stretch,不存在于词向量中\n",
      "Ways不存在于词向量中\n",
      "drug.不存在于词向量中\n",
      "ENTJ!不存在于词向量中\n",
      "Trolling不存在于词向量中\n",
      "Noam不存在于词向量中\n",
      "Yellow,不存在于词向量中\n",
      "motto.不存在于词向量中\n",
      "(When不存在于词向量中\n",
      "listen?不存在于词向量中\n",
      "Madison不存在于词向量中\n",
      "Adele不存在于词向量中\n",
      "would...'不存在于词向量中\n",
      "uncomfortable?不存在于词向量中\n",
      "counseling.不存在于词向量中\n",
      "Norway,不存在于词向量中\n",
      "love.|||I不存在于词向量中\n",
      "brooding,不存在于词向量中\n",
      "years),不存在于词向量中\n",
      "rooms,不存在于词向量中\n",
      "planets.不存在于词向量中\n",
      "saint.不存在于词向量中\n",
      "Ferris不存在于词向量中\n",
      "Gemini,不存在于词向量中\n",
      "Architect不存在于词向量中\n",
      "philosophical,不存在于词向量中\n",
      "goodness...不存在于词向量中\n",
      "Fire.不存在于词向量中\n",
      "my...|||In不存在于词向量中\n",
      "unpleasant.不存在于词向量中\n",
      "them....不存在于词向量中\n",
      "recognition,不存在于词向量中\n",
      "saw,不存在于词向量中\n",
      "Eldest不存在于词向量中\n",
      "Philosopher不存在于词向量中\n",
      "tritypes.不存在于词向量中\n",
      "(another不存在于词向量中\n",
      "product.不存在于词向量中\n",
      "girlfriends,不存在于词向量中\n",
      "explain...不存在于词向量中\n",
      "interrupted.不存在于词向量中\n",
      "loser,不存在于词向量中\n",
      "great...不存在于词向量中\n",
      "ENTJ's,不存在于词向量中\n",
      "Puts不存在于词向量中\n",
      "uncommon,不存在于词向量中\n",
      "a...|||Lol不存在于词向量中\n",
      "'So,不存在于词向量中\n",
      "'Hello,不存在于词向量中\n",
      "home)不存在于词向量中\n",
      "ExFP.不存在于词向量中\n",
      "the...|||Have不存在于词向量中\n",
      "hurtful.不存在于词向量中\n",
      "chips,不存在于词向量中\n",
      "Age?不存在于词向量中\n",
      "SHIT不存在于词向量中\n",
      "ai.tran.75不存在于词向量中\n",
      "debt.不存在于词向量中\n",
      "likes,不存在于词向量中\n",
      "build,不存在于词向量中\n",
      "into...|||You不存在于词向量中\n",
      "(otherwise不存在于词向量中\n",
      "Matter不存在于词向量中\n",
      "Allan不存在于词向量中\n",
      "fine...不存在于词向量中\n",
      "would...|||So不存在于词向量中\n",
      "Mountains不存在于词向量中\n",
      "(Why不存在于词向量中\n",
      ":kitteh:|||My不存在于词向量中\n",
      "possibly,不存在于词向量中\n",
      "Putin不存在于词向量中\n",
      "of...|||But不存在于词向量中\n",
      "bothered,不存在于词向量中\n",
      "Nature.不存在于词向量中\n",
      "Prozac不存在于词向量中\n",
      "Arrested不存在于词向量中\n",
      "instincts,不存在于词向量中\n",
      "vivid.不存在于词向量中\n",
      "head...|||I不存在于词向量中\n",
      "everyone)不存在于词向量中\n",
      "3w2.不存在于词向量中\n",
      "Uploaded不存在于词向量中\n",
      "it.|||One不存在于词向量中\n",
      "Junkie不存在于词向量中\n",
      "ethic.不存在于词向量中\n",
      "Green.不存在于词向量中\n",
      "people...|||The不存在于词向量中\n",
      "never...|||This不存在于词向量中\n",
      "moral,不存在于词向量中\n",
      "above)不存在于词向量中\n",
      "rape.不存在于词向量中\n",
      "maybe)不存在于词向量中\n",
      "Timothy不存在于词向量中\n",
      "level)不存在于词向量中\n",
      "trap,不存在于词向量中\n",
      "Answers不存在于词向量中\n",
      "Closer不存在于词向量中\n",
      "Ahh不存在于词向量中\n",
      ":D|||Well,不存在于词向量中\n",
      "(By不存在于词向量中\n",
      "athletic.不存在于词向量中\n",
      "duh.不存在于词向量中\n",
      "made...|||I不存在于词向量中\n",
      "Maggie不存在于词向量中\n",
      "Ne/Ti不存在于词向量中\n",
      "represent.不存在于词向量中\n",
      "IMDb不存在于词向量中\n",
      "rep.不存在于词向量中\n",
      "raised,不存在于词向量中\n",
      "all...'不存在于词向量中\n",
      "are....不存在于词向量中\n",
      "wear?不存在于词向量中\n",
      "Flower不存在于词向量中\n",
      "advocate.不存在于词向量中\n",
      "ladder.不存在于词向量中\n",
      "Norton不存在于词向量中\n",
      "lil'不存在于词向量中\n",
      "Hitch不存在于词向量中\n",
      "honest.|||I不存在于词向量中\n",
      "'it不存在于词向量中\n",
      "philosophers,不存在于词向量中\n",
      "excuses.不存在于词向量中\n",
      "English:不存在于词向量中\n",
      "he...'不存在于词向量中\n",
      "words.|||I不存在于词向量中\n",
      "typo.不存在于词向量中\n",
      "not.|||I'm不存在于词向量中\n",
      "plans?不存在于词向量中\n",
      "scientific.不存在于词向量中\n",
      "lack.不存在于词向量中\n",
      "Lips不存在于词向量中\n",
      "to...|||Some不存在于词向量中\n",
      "bounds.不存在于词向量中\n",
      "arise,不存在于词向量中\n",
      "Definition不存在于词向量中\n",
      "THEM.不存在于词向量中\n",
      "visit,不存在于词向量中\n",
      "valentine's不存在于词向量中\n",
      "Wire不存在于词向量中\n",
      "area?不存在于词向量中\n",
      "enfj.不存在于词向量中\n",
      "Futurama不存在于词向量中\n",
      "video's不存在于词向量中\n",
      "handsome,不存在于词向量中\n",
      "errors.不存在于词向量中\n",
      "I'm,不存在于词向量中\n",
      "Ethan不存在于词向量中\n",
      "couldn't...|||I不存在于词向量中\n",
      "also...|||The不存在于词向量中\n",
      "separately.不存在于词向量中\n",
      "There鈥檚不存在于词向量中\n",
      "Dad-不存在于词向量中\n",
      ":D|||That's不存在于词向量中\n",
      "employees.不存在于词向量中\n",
      "arn't不存在于词向量中\n",
      "Tho不存在于词向量中\n",
      ":tongue:|||The不存在于词向量中\n",
      "rebel,不存在于词向量中\n",
      "Funniest不存在于词向量中\n",
      "OD不存在于词向量中\n",
      "paradise.不存在于词向量中\n",
      "math?不存在于词向量中\n",
      "YO不存在于词向量中\n",
      "autonomy,不存在于词向量中\n",
      "treatment,不存在于词向量中\n",
      "home..不存在于词向量中\n",
      "'to不存在于词向量中\n",
      "movies...不存在于词向量中\n",
      "judgements,不存在于词向量中\n",
      "forgot,不存在于词向量中\n",
      "function...|||I不存在于词向量中\n",
      "environment...|||I不存在于词向量中\n",
      "Cool.不存在于词向量中\n",
      "more...|||Why不存在于词向量中\n",
      "variety,不存在于词向量中\n",
      "like...|||What不存在于词向量中\n",
      "Extreme不存在于词向量中\n",
      "MAYBE不存在于词向量中\n",
      "Repeat不存在于词向量中\n",
      "1's不存在于词向量中\n",
      "from...|||It不存在于词向量中\n",
      "many...|||I'm不存在于词向量中\n",
      "Dir不存在于词向量中\n",
      ":D|||A不存在于词向量中\n",
      "hahaha...不存在于词向量中\n",
      "across,不存在于词向量中\n",
      "that...|||Just不存在于词向量中\n",
      "(really不存在于词向量中\n",
      "Jack:不存在于词向量中\n",
      "(normally不存在于词向量中\n",
      "work),不存在于词向量中\n",
      "it...|||Thank不存在于词向量中\n",
      "teasing.不存在于词向量中\n",
      "(did不存在于词向量中\n",
      "Lara不存在于词向量中\n",
      "Philosophy.不存在于词向量中\n",
      "ISFJ's,不存在于词向量中\n",
      "outspoken,不存在于词向量中\n",
      "this!|||I不存在于词向量中\n",
      "and...|||Im不存在于词向量中\n",
      "also...|||I'm不存在于词向量中\n",
      "Solar不存在于词向量中\n",
      "Foxes不存在于词向量中\n",
      "suggests,不存在于词向量中\n",
      "speeches,不存在于词向量中\n",
      "for...|||Well,不存在于词向量中\n",
      "sorry..不存在于词向量中\n",
      "Shore不存在于词向量中\n",
      "28,不存在于词向量中\n",
      "Tons不存在于词向量中\n",
      "err,不存在于词向量中\n",
      "Touch.不存在于词向量中\n",
      "Heart:不存在于词向量中\n",
      "Gibson不存在于词向量中\n",
      "nonetheless,不存在于词向量中\n",
      "4/10不存在于词向量中\n",
      "Balance不存在于词向量中\n",
      "Jar不存在于词向量中\n",
      "abnormal,不存在于词向量中\n",
      "whoa,不存在于词向量中\n",
      "Eastwood不存在于词向量中\n",
      "bit?不存在于词向量中\n",
      "Forced不存在于词向量中\n",
      "arrogant?不存在于词向量中\n",
      "enjoyment.不存在于词向量中\n",
      "explanations,不存在于词向量中\n",
      "so...|||So不存在于词向量中\n",
      "particular?不存在于词向量中\n",
      "it.|||Yes,不存在于词向量中\n",
      "nutrition,不存在于词向量中\n",
      "Nice!不存在于词向量中\n",
      ":P|||This不存在于词向量中\n",
      "Hahah不存在于词向量中\n",
      "Ni/Fe不存在于词向量中\n",
      "too.|||I've不存在于词向量中\n",
      "a...|||People不存在于词向量中\n",
      "thoroughly.不存在于词向量中\n",
      "*sigh*|||I不存在于词向量中\n",
      "banned,不存在于词向量中\n",
      "pill.不存在于词向量中\n",
      "documentaries.不存在于词向量中\n",
      "Laden不存在于词向量中\n",
      "of.|||I不存在于词向量中\n",
      "ENFPs:不存在于词向量中\n",
      "pickles,不存在于词向量中\n",
      "heartless,不存在于词向量中\n",
      "xNFJs不存在于词向量中\n",
      "sense).不存在于词向量中\n",
      "cycles,不存在于词向量中\n",
      "Previous不存在于词向量中\n",
      "CA不存在于词向量中\n",
      "tones,不存在于词向量中\n",
      "slavery.不存在于词向量中\n",
      "Vigilant不存在于词向量中\n",
      "diary.不存在于词向量中\n",
      "J's.不存在于词向量中\n",
      "DSM不存在于词向量中\n",
      "decades,不存在于词向量中\n",
      "lightly,不存在于词向量中\n",
      "antisocial,不存在于词向量中\n",
      "haven't...|||I不存在于词向量中\n",
      "one|||I不存在于词向量中\n",
      "journals,不存在于词向量中\n",
      "blank.不存在于词向量中\n",
      "Manipulative不存在于词向量中\n",
      "enjoyed.不存在于词向量中\n",
      "LP不存在于词向量中\n",
      "ESFJ)不存在于词向量中\n",
      "Enter不存在于词向量中\n",
      "using,不存在于词向量中\n",
      "sessions.不存在于词向量中\n",
      "for...|||What不存在于词向量中\n",
      "Alone,不存在于词向量中\n",
      "that...|||A不存在于词向量中\n",
      "us)不存在于词向量中\n",
      "someone...|||This不存在于词向量中\n",
      "...|||From不存在于词向量中\n",
      "combo,不存在于词向量中\n",
      "confirm,不存在于词向量中\n",
      "intentional,不存在于词向量中\n",
      "Ender不存在于词向量中\n",
      "paradox.不存在于词向量中\n",
      "as...不存在于词向量中\n",
      "SSRI不存在于词向量中\n",
      "(INTP不存在于词向量中\n",
      "Drew不存在于词向量中\n",
      "just...|||Yeah不存在于词向量中\n",
      "I...|||Because不存在于词向量中\n",
      "xD).不存在于词向量中\n",
      "inspiring,不存在于词向量中\n",
      "speak...|||I不存在于词向量中\n",
      "Merchant不存在于词向量中\n",
      "Elephant不存在于词向量中\n",
      "Barack不存在于词向量中\n",
      "Zelda:不存在于词向量中\n",
      "1994,不存在于词向量中\n",
      "Winston不存在于词向量中\n",
      "Rich不存在于词向量中\n",
      "me...|||When不存在于词向量中\n",
      "behind...|||I不存在于词向量中\n",
      ":X不存在于词向量中\n",
      "wing)不存在于词向量中\n",
      "Radical不存在于词向量中\n",
      "Twisted不存在于词向量中\n",
      "exclusive,不存在于词向量中\n",
      "review,不存在于词向量中\n",
      "more...|||It不存在于词向量中\n",
      "Security不存在于词向量中\n",
      "Nurse不存在于词向量中\n",
      "Fire,不存在于词向量中\n",
      "November.不存在于词向量中\n",
      "H.P.不存在于词向量中\n",
      "Green,不存在于词向量中\n",
      "you....|||I不存在于词向量中\n",
      "stupidity?不存在于词向量中\n",
      "BMI不存在于词向量中\n",
      "(25%)不存在于词向量中\n",
      "Neurotic不存在于词向量中\n",
      "Gryffindor.不存在于词向量中\n",
      "agree?不存在于词向量中\n",
      "None.不存在于词向量中\n",
      "unacceptable.不存在于词向量中\n",
      "Horse不存在于词向量中\n",
      "varies,不存在于词向量中\n",
      "taught,不存在于词向量中\n",
      "Palmer不存在于词向量中\n",
      "boots.不存在于词向量中\n",
      "Hathaway不存在于词向量中\n",
      "Rim不存在于词向量中\n",
      "this...|||Yeah,不存在于词向量中\n",
      "2010,不存在于词向量中\n",
      "bags.不存在于词向量中\n",
      "really...|||When不存在于词向量中\n",
      "upfront.不存在于词向量中\n",
      "Fine.不存在于词向量中\n",
      "'He's不存在于词向量中\n",
      "Holden不存在于词向量中\n",
      "bears.不存在于词向量中\n",
      "needs?不存在于词向量中\n",
      "Beats不存在于词向量中\n",
      "HATES不存在于词向量中\n",
      "INJs不存在于词向量中\n",
      "Fiction,不存在于词向量中\n",
      "EXTP不存在于词向量中\n",
      "pockets.不存在于词向量中\n",
      "Cast不存在于词向量中\n",
      "thanks...不存在于词向量中\n",
      "time...|||I've不存在于词向量中\n",
      "Nickelback不存在于词向量中\n",
      "you...|||Do不存在于词向量中\n",
      "cautious?不存在于词向量中\n",
      "know....不存在于词向量中\n",
      "esfp,不存在于词向量中\n",
      "leadership,不存在于词向量中\n",
      "means)不存在于词向量中\n",
      "Jeans不存在于词向量中\n",
      "Revolution不存在于词向量中\n",
      "2006.不存在于词向量中\n",
      "Personality,不存在于词向量中\n",
      "Facebook?不存在于词向量中\n",
      "(different不存在于词向量中\n",
      "29.不存在于词向量中\n",
      "SM-G935F不存在于词向量中\n",
      "Euro不存在于词向量中\n",
      "tree?不存在于词向量中\n",
      "Scratch不存在于词向量中\n",
      "Maps不存在于词向量中\n",
      "annoying.|||I不存在于词向量中\n",
      "Arrow不存在于词向量中\n",
      "Democrats不存在于词向量中\n",
      "excellent,不存在于词向量中\n",
      "Pok茅mon不存在于词向量中\n",
      "Marijuana不存在于词向量中\n",
      "Hunchback不存在于词向量中\n",
      "graduation,不存在于词向量中\n",
      "remembered,不存在于词向量中\n",
      "Identity不存在于词向量中\n",
      "voices,不存在于词向量中\n",
      "Babylon不存在于词向量中\n",
      "list...不存在于词向量中\n",
      "Cats?不存在于词向量中\n",
      "series?不存在于词向量中\n",
      "though.|||It's不存在于词向量中\n",
      "Throwing不存在于词向量中\n",
      "allowed.不存在于词向量中\n",
      "'be不存在于词向量中\n",
      "Gucci不存在于词向量中\n",
      "charisma.不存在于词向量中\n",
      "Clannad不存在于词向量中\n",
      "tell?不存在于词向量中\n",
      "fix?不存在于词向量中\n",
      "Banned不存在于词向量中\n",
      "tiresome.不存在于词向量中\n",
      "really.|||I不存在于词向量中\n",
      "something..不存在于词向量中\n",
      "rigid,不存在于词向量中\n",
      "lol|||If不存在于词向量中\n",
      "Fe-dom.不存在于词向量中\n",
      "to...|||Sometimes不存在于词向量中\n",
      ":)|||welcome不存在于词向量中\n",
      "delicate,不存在于词向量中\n",
      "Te/Fi.不存在于词向量中\n",
      "meditate.不存在于词向量中\n",
      "architecture.不存在于词向量中\n",
      "Hobbit,不存在于词向量中\n",
      "cheap.不存在于词向量中\n",
      "vein,不存在于词向量中\n",
      "Scale不存在于词向量中\n",
      "Enneagram?不存在于词向量中\n",
      "me.|||That不存在于词向量中\n",
      "Auditory:不存在于词向量中\n",
      "II:不存在于词向量中\n",
      "Tolstoy不存在于词向量中\n",
      "Shepard不存在于词向量中\n",
      "sitting,不存在于词向量中\n",
      "substances,不存在于词向量中\n",
      "and...|||No,不存在于词向量中\n",
      "secure.不存在于词向量中\n",
      "I've...|||My不存在于词向量中\n",
      "Witnesses不存在于词向量中\n",
      "Grandma:不存在于词向量中\n",
      "phone...不存在于词向量中\n",
      "it...|||Yeah,不存在于词向量中\n",
      "the...|||So,不存在于词向量中\n",
      "rare?不存在于词向量中\n",
      "rabbit,不存在于词向量中\n",
      "tall.不存在于词向量中\n",
      "*Type不存在于词向量中\n",
      "him/her,不存在于词向量中\n",
      "Criticism不存在于词向量中\n",
      "difficulties,不存在于词向量中\n",
      "moved.不存在于词向量中\n",
      "India,不存在于词向量中\n",
      "my...|||Hey不存在于词向量中\n",
      "Tap不存在于词向量中\n",
      "Millennium不存在于词向量中\n",
      "Clay不存在于词向量中\n",
      "Friends:不存在于词向量中\n",
      "start...不存在于词向量中\n",
      "CPA不存在于词向量中\n",
      "alcoholic.不存在于词向量中\n",
      "cycle,不存在于词向量中\n",
      "(possibly)不存在于词向量中\n",
      "'Now不存在于词向量中\n",
      "Bjork不存在于词向量中\n",
      "confirmed,不存在于词向量中\n",
      "disappear,不存在于词向量中\n",
      "Lower不存在于词向量中\n",
      "Dickens不存在于词向量中\n",
      "self-centered.不存在于词向量中\n",
      "Sixteen不存在于词向量中\n",
      "regulations,不存在于词向量中\n",
      "Lol.|||I不存在于词向量中\n",
      "MGMT不存在于词向量中\n",
      "Twitter,不存在于词向量中\n",
      "Roommate不存在于词向量中\n",
      "INTJ.|||I'm不存在于词向量中\n",
      "Dead.不存在于词向量中\n",
      "about..不存在于词向量中\n",
      "(15不存在于词向量中\n",
      "stereotype?不存在于词向量中\n",
      "kind...|||I不存在于词向量中\n",
      "when.不存在于词向量中\n",
      "university's不存在于词向量中\n",
      "Artist,不存在于词向量中\n",
      "Carolina不存在于词向量中\n",
      "I...|||Any不存在于词向量中\n",
      "Bourne不存在于词向量中\n",
      "appetite.不存在于词向量中\n",
      "Szubrasznikarazar不存在于词向量中\n",
      "Sadness不存在于词向量中\n",
      "monster.不存在于词向量中\n",
      "Machiavellianism不存在于词向量中\n",
      "Psychopathy不存在于词向量中\n",
      "train,不存在于词向量中\n",
      "with...|||Well不存在于词向量中\n",
      "collective.不存在于词向量中\n",
      "rather...不存在于词向量中\n",
      "Metallica,不存在于词向量中\n",
      "Def不存在于词向量中\n",
      "Perfectionism不存在于词向量中\n",
      "so).不存在于词向量中\n",
      "...|||What's不存在于词向量中\n",
      "lens.不存在于词向量中\n",
      "if...|||You不存在于词向量中\n",
      "buddies.不存在于词向量中\n",
      "enjoy?不存在于词向量中\n",
      "spouse,不存在于词向量中\n",
      "sheep.不存在于词向量中\n",
      "Tarantino不存在于词向量中\n",
      "farm,不存在于词向量中\n",
      "Watership不存在于词向量中\n",
      "less...不存在于词向量中\n",
      "clown,不存在于词向量中\n",
      "Rebirth不存在于词向量中\n",
      "from.|||I不存在于词向量中\n",
      "museums,不存在于词向量中\n",
      "connected,不存在于词向量中\n",
      "encouragement,不存在于词向量中\n",
      "Texting不存在于词向量中\n",
      "losers.不存在于词向量中\n",
      "growing,不存在于词向量中\n",
      "Details不存在于词向量中\n",
      "mundane,不存在于词向量中\n",
      "likely)不存在于词向量中\n",
      "Stein不存在于词向量中\n",
      "obviously)不存在于词向量中\n",
      "Truthfully,不存在于词向量中\n",
      "assistant.不存在于词向量中\n",
      "that.'不存在于词向量中\n",
      "Ex.不存在于词向量中\n",
      "Threes不存在于词向量中\n",
      "Protestant不存在于词向量中\n",
      "Everyone!不存在于词向量中\n",
      "Academy不存在于词向量中\n",
      "heat,不存在于词向量中\n",
      "plants.不存在于词向量中\n",
      "dictionary,不存在于词向量中\n",
      "frightening.不存在于词向量中\n",
      "cartoons.不存在于词向量中\n",
      "you...|||As不存在于词向量中\n",
      "to...|||Perhaps不存在于词向量中\n",
      "bills.不存在于词向量中\n",
      "and...|||One不存在于词向量中\n",
      "MBTI庐不存在于词向量中\n",
      "self-absorbed.不存在于词向量中\n",
      "what...|||I've不存在于词向量中\n",
      "Dramatic不存在于词向量中\n",
      "and...|||Hi,不存在于词向量中\n",
      "bible.不存在于词向量中\n",
      "Quotes不存在于词向量中\n",
      "conventional,不存在于词向量中\n",
      "abroad,不存在于词向量中\n",
      "fav.不存在于词向量中\n",
      "Androgynous不存在于词向量中\n",
      "Marshall不存在于词向量中\n",
      "Imaginative不存在于词向量中\n",
      "馃尮|||Welcome不存在于词向量中\n",
      "Extravert不存在于词向量中\n",
      "swim.不存在于词向量中\n",
      "Porcupine不存在于词向量中\n",
      "that...|||There不存在于词向量中\n",
      "laziness.不存在于词向量中\n",
      "more...|||Well,不存在于词向量中\n",
      "....|||I不存在于词向量中\n",
      "bait.不存在于词向量中\n",
      "I...|||There's不存在于词向量中\n",
      "wine.不存在于词向量中\n",
      "Sufjan不存在于词向量中\n",
      "I...|||People不存在于词向量中\n",
      "thing...I不存在于词向量中\n",
      "Trigger不存在于词向量中\n",
      "Jurassic不存在于词向量中\n",
      "HTML不存在于词向量中\n",
      "ship,不存在于词向量中\n",
      "Judge不存在于词向量中\n",
      "SO?不存在于词向量中\n",
      "Buried不存在于词向量中\n",
      "Field不存在于词向量中\n",
      "Compatibility不存在于词向量中\n",
      "hill.不存在于词向量中\n",
      "Dexterity-不存在于词向量中\n",
      "Constitution-不存在于词向量中\n",
      "Intelligence-不存在于词向量中\n",
      "Wisdom-不存在于词向量中\n",
      "Sun18|||Hi不存在于词向量中\n",
      "school).不存在于词向量中\n",
      "Music:不存在于词向量中\n",
      "Chance不存在于词向量中\n",
      "PS2不存在于词向量中\n",
      "why)不存在于词向量中\n",
      "barbecue...|||Fast不存在于词向量中\n",
      "times),不存在于词向量中\n",
      "TARDIS不存在于词向量中\n",
      "Friends,不存在于词向量中\n",
      "SGH-T999不存在于词向量中\n",
      "estj's不存在于词向量中\n",
      "AM:不存在于词向量中\n",
      "Charlie:不存在于词向量中\n",
      "Hamilton不存在于词向量中\n",
      "meal(and不存在于词向量中\n",
      "infps,不存在于词向量中\n",
      "ways.|||I不存在于词向量中\n",
      "XNTP.不存在于词向量中\n",
      "priorities.不存在于词向量中\n",
      "Experiences不存在于词向量中\n",
      "I'm...|||Thank不存在于词向量中\n",
      "(Fe),不存在于词向量中\n",
      "bad.|||I不存在于词向量中\n",
      "bad)不存在于词向量中\n",
      "creator.不存在于词向量中\n",
      "Review不存在于词向量中\n",
      "Geometry不存在于词向量中\n",
      "INFPs'不存在于词向量中\n",
      "mistyping.不存在于词向量中\n",
      "Strength:不存在于词向量中\n",
      "wearing.不存在于词向量中\n",
      "base,不存在于词向量中\n",
      "dude's不存在于词向量中\n",
      "OST不存在于词向量中\n",
      "Gin不存在于词向量中\n",
      "charged.不存在于词向量中\n",
      "linked.不存在于词向量中\n",
      "Like:不存在于词向量中\n",
      "creative?不存在于词向量中\n",
      "smartest,不存在于词向量中\n",
      "fairly...|||I不存在于词向量中\n",
      "expressed.不存在于词向量中\n",
      "Ne-Fe不存在于词向量中\n",
      "(between不存在于词向量中\n",
      "gotcha.不存在于词向量中\n",
      "maintenance,不存在于词向量中\n",
      "-...|||I'm不存在于词向量中\n",
      "Si-Fi不存在于词向量中\n",
      "how...|||I've不存在于词向量中\n",
      "tangible,不存在于词向量中\n",
      "Forum,不存在于词向量中\n",
      "Welcome!|||Welcome不存在于词向量中\n",
      "many...|||The不存在于词向量中\n",
      "the...|||After不存在于词向量中\n",
      "Fine,不存在于词向量中\n",
      "Subtle不存在于词向量中\n",
      "satisfied,不存在于词向量中\n",
      "developing.不存在于词向量中\n",
      "bark,不存在于词向量中\n",
      "Lizard不存在于词向量中\n",
      "advanced,不存在于词向量中\n",
      "I...|||On不存在于词向量中\n",
      "to...|||She不存在于词向量中\n",
      "-She不存在于词向量中\n",
      "situation.|||I不存在于词向量中\n",
      "it....|||I'm不存在于词向量中\n",
      "Underground不存在于词向量中\n",
      "professionally.不存在于词向量中\n",
      "Alabama不存在于词向量中\n",
      "is...|||No不存在于词向量中\n",
      "typical,不存在于词向量中\n",
      "Augustine不存在于词向量中\n",
      ":o)不存在于词向量中\n",
      "inconsistent,不存在于词向量中\n",
      "literal.不存在于词向量中\n",
      "Finnish.不存在于词向量中\n",
      "relatives.不存在于词向量中\n",
      "thrive.不存在于词向量中\n",
      "Growth不存在于词向量中\n",
      "figures.不存在于词向量中\n",
      "Aristotle,不存在于词向量中\n",
      "all.|||I've不存在于词向量中\n",
      "Xavier不存在于词向量中\n",
      "Lisbeth不存在于词向量中\n",
      "actually?不存在于词向量中\n",
      "feelings.|||I不存在于词向量中\n",
      "so...|||For不存在于词向量中\n",
      "was...|||Thank不存在于词向量中\n",
      "hockey,不存在于词向量中\n",
      "possible).不存在于词向量中\n",
      "bull.不存在于词向量中\n",
      "Supervisor不存在于词向量中\n",
      "Journalism不存在于词向量中\n",
      "only...|||I'm不存在于词向量中\n",
      "Sales不存在于词向量中\n",
      "now...I不存在于词向量中\n",
      "Tumblr,不存在于词向量中\n",
      "Express不存在于词向量中\n",
      "Crowd不存在于词向量中\n",
      "Atlanta不存在于词向量中\n",
      "dishes.不存在于词向量中\n",
      "wealthy,不存在于词向量中\n",
      "something),不存在于词向量中\n",
      "tiring,不存在于词向量中\n",
      "assignments.不存在于词向量中\n",
      "cloud,不存在于词向量中\n",
      "Wait!不存在于词向量中\n",
      "Lacking不存在于词向量中\n",
      "copy,不存在于词向量中\n",
      "Dx不存在于词向量中\n",
      "hall,不存在于词向量中\n",
      "days).不存在于词向量中\n",
      "senior,不存在于词向量中\n",
      "Camus,不存在于词向量中\n",
      "relationship)不存在于词向量中\n",
      "tabs.不存在于词向量中\n",
      "retrospect.不存在于词向量中\n",
      "garden.不存在于词向量中\n",
      "Lived不存在于词向量中\n",
      "matter.|||I不存在于词向量中\n",
      "trade.不存在于词向量中\n",
      "Bohemian不存在于词向量中\n",
      "(nice不存在于词向量中\n",
      ":D|||There's不存在于词向量中\n",
      "pill,不存在于词向量中\n",
      "SO:不存在于词向量中\n",
      "toy,不存在于词向量中\n",
      "disguise.不存在于词向量中\n",
      "motivator.不存在于词向量中\n",
      "NT's.不存在于词向量中\n",
      "comedies.不存在于词向量中\n",
      "xSxP不存在于词向量中\n",
      "Eva不存在于词向量中\n",
      "past...不存在于词向量中\n",
      "politician,不存在于词向量中\n",
      "IxFx.不存在于词向量中\n",
      "Bj枚rk,不存在于词向量中\n",
      "Vertigo不存在于词向量中\n",
      "Behold不存在于词向量中\n",
      "literal,不存在于词向量中\n",
      "collar,不存在于词向量中\n",
      "whenever.不存在于词向量中\n",
      "Lil不存在于词向量中\n",
      "year).不存在于词向量中\n",
      "handsome.不存在于词向量中\n",
      "Jazz,不存在于词向量中\n",
      "Introversion,不存在于词向量中\n",
      "is...|||You're不存在于词向量中\n",
      "Fe).不存在于词向量中\n",
      "Ambitious,不存在于词向量中\n",
      "Deeply不存在于词向量中\n",
      "version?不存在于词向量中\n",
      "candles.不存在于词向量中\n",
      "masks,不存在于词向量中\n",
      "pilot.不存在于词向量中\n",
      "LSI不存在于词向量中\n",
      "ExxJ不存在于词向量中\n",
      "Surely,不存在于词向量中\n",
      "there...|||The不存在于词向量中\n",
      "xNTx不存在于词向量中\n",
      "theatre.不存在于词向量中\n",
      "'At不存在于词向量中\n",
      "Ni/Te不存在于词向量中\n",
      "extremely,不存在于词向量中\n",
      "yup.不存在于词向量中\n",
      "8s,不存在于词向量中\n",
      "password,不存在于词向量中\n",
      "father)不存在于词向量中\n",
      "your...|||Well,不存在于词向量中\n",
      "I'm...|||That's不存在于词向量中\n",
      "hit,不存在于词向量中\n",
      "intentional.不存在于词向量中\n",
      "Offer不存在于词向量中\n",
      "tricks.不存在于词向量中\n",
      "think/feel不存在于词向量中\n",
      "suddenly.不存在于词向量中\n",
      "if...|||This不存在于词向量中\n",
      "99.99%不存在于词向量中\n",
      "heterosexual,不存在于词向量中\n",
      "Theatre不存在于词向量中\n",
      "hills.不存在于词向量中\n",
      "Cyrus不存在于词向量中\n",
      "(every不存在于词向量中\n",
      "tertiary,不存在于词向量中\n",
      "submissive,不存在于词向量中\n",
      "Googling不存在于词向量中\n",
      "Tropes不存在于词向量中\n",
      "capabilities,不存在于词向量中\n",
      "Beebe不存在于词向量中\n",
      "cage,不存在于词向量中\n",
      "Kindergarten不存在于词向量中\n",
      "finish,不存在于词向量中\n",
      "ties,不存在于词向量中\n",
      "Darker不存在于词向量中\n",
      "in...|||1.不存在于词向量中\n",
      "amounts.不存在于词向量中\n",
      "Echo不存在于词向量中\n",
      "favorite...|||I不存在于词向量中\n",
      ":)|||Is不存在于词向量中\n",
      "me...|||Well不存在于词向量中\n",
      "Inglorious不存在于词向量中\n",
      "hired.不存在于词向量中\n",
      "INFxs不存在于词向量中\n",
      "repeatedly.不存在于词向量中\n",
      "structured,不存在于词向量中\n",
      "quite,不存在于词向量中\n",
      "Titans不存在于词向量中\n",
      "much...and不存在于词向量中\n",
      "will?不存在于词向量中\n",
      "Mothers不存在于词向量中\n",
      "not...|||Oh不存在于词向量中\n",
      "inquisitive,不存在于词向量中\n",
      "about...|||What不存在于词向量中\n",
      "Kristen不存在于词向量中\n",
      "Ne-不存在于词向量中\n",
      "agree..不存在于词向量中\n",
      "when...|||This不存在于词向量中\n",
      "Vanessa不存在于词向量中\n",
      "Nietzsche.不存在于词向量中\n",
      "boot.不存在于词向量中\n",
      "Disturbed不存在于词向量中\n",
      "n.不存在于词向量中\n",
      "injury,不存在于词向量中\n",
      "endearing.不存在于词向量中\n",
      "feature,不存在于词向量中\n",
      "tried?不存在于词向量中\n",
      "heroin,不存在于词向量中\n",
      "LSD,不存在于词向量中\n",
      "2).不存在于词向量中\n",
      "aunt,不存在于词向量中\n",
      "Virgin不存在于词向量中\n",
      "AM.不存在于词向量中\n",
      "easygoing,不存在于词向量中\n",
      "poetic.不存在于词向量中\n",
      "Analyst不存在于词向量中\n",
      "what...|||Yes,不存在于词向量中\n",
      "perceptive,不存在于词向量中\n",
      "equation,不存在于词向量中\n",
      "This!不存在于词向量中\n",
      "duty,不存在于词向量中\n",
      "campus.不存在于词向量中\n",
      "Me-不存在于词向量中\n",
      "phenomena.不存在于词向量中\n",
      "Satan.不存在于词向量中\n",
      "visible.不存在于词向量中\n",
      "restless,不存在于词向量中\n",
      "the...|||Sorry,不存在于词向量中\n",
      "TOO!不存在于词向量中\n",
      "Composer不存在于词向量中\n",
      "Galactic不存在于词向量中\n",
      "SPOILER不存在于词向量中\n",
      "sweetheart,不存在于词向量中\n",
      "Nardi's不存在于词向量中\n",
      "to...|||Actually,不存在于词向量中\n",
      "with...|||Just不存在于词向量中\n",
      "Lullaby不存在于词向量中\n",
      "confirmed.不存在于词向量中\n",
      "pig,不存在于词向量中\n",
      "apt.不存在于词向量中\n",
      "if...|||I've不存在于词向量中\n",
      "is...|||lol不存在于词向量中\n",
      "skype.不存在于词向量中\n",
      "in...|||But不存在于词向量中\n",
      "answers?不存在于词向量中\n",
      "Map不存在于词向量中\n",
      "a...|||No不存在于词向量中\n",
      "disclaimer,不存在于词向量中\n",
      "covered.不存在于词向量中\n",
      "LOADS不存在于词向量中\n",
      "points?不存在于词向量中\n",
      "Knew不存在于词向量中\n",
      "(Note:不存在于词向量中\n",
      "apples,不存在于词向量中\n",
      "Jill不存在于词向量中\n",
      "crushed.不存在于词向量中\n",
      "mental,不存在于词向量中\n",
      "dislike?不存在于词向量中\n",
      "it...|||As不存在于词向量中\n",
      "overnight.不存在于词向量中\n",
      "hypocrisy.不存在于词向量中\n",
      "minority,不存在于词向量中\n",
      "xNFx不存在于词向量中\n",
      "rise,不存在于词向量中\n",
      "OPs不存在于词向量中\n",
      "favorite?不存在于词向量中\n",
      "Claiming不存在于词向量中\n",
      "my...|||A不存在于词向量中\n",
      "infatuated,不存在于词向量中\n",
      "Smith's不存在于词向量中\n",
      "by.|||I不存在于词向量中\n",
      "everything..不存在于词向量中\n",
      "Foods不存在于词向量中\n",
      "sloth.不存在于词向量中\n",
      "are...|||A不存在于词向量中\n",
      "Pine不存在于词向量中\n",
      "Mis不存在于词向量中\n",
      "Advocate不存在于词向量中\n",
      "autumn,不存在于词向量中\n",
      "like...|||This不存在于词向量中\n",
      "Jonas不存在于词向量中\n",
      "black;不存在于词向量中\n",
      "was...|||That不存在于词向量中\n",
      "kittens.不存在于词向量中\n",
      "/end不存在于词向量中\n",
      "emotions.|||I不存在于词向量中\n",
      "I'VE不存在于词向量中\n",
      "single...|||I不存在于词向量中\n",
      "Title不存在于词向量中\n",
      "test).不存在于词向量中\n",
      "in...|||That's不存在于词向量中\n",
      "IT!!!不存在于词向量中\n",
      "Virginia,不存在于词向量中\n",
      "Wallflower不存在于词向量中\n",
      "practicing,不存在于词向量中\n",
      "judged,不存在于词向量中\n",
      "(INTJ).不存在于词向量中\n",
      "opinion).不存在于词向量中\n",
      "nostalgia?不存在于词向量中\n",
      "was...|||When不存在于词向量中\n",
      "frequent,不存在于词向量中\n",
      "I'm...|||Yeah,不存在于词向量中\n",
      "supernatural.不存在于词向量中\n",
      "and...|||No.不存在于词向量中\n",
      "Han不存在于词向量中\n",
      "just...|||It's不存在于词向量中\n",
      "Staff不存在于词向量中\n",
      "muscle.不存在于词向量中\n",
      "sleeve.不存在于词向量中\n",
      "license,不存在于词向量中\n",
      "sacred.不存在于词向量中\n",
      "(lack不存在于词向量中\n",
      "construct,不存在于词向量中\n",
      "Television不存在于词向量中\n",
      "Overthinking不存在于词向量中\n",
      "#2.不存在于词向量中\n",
      "conflict?不存在于词向量中\n",
      "that.|||It's不存在于词向量中\n",
      "Ironic不存在于词向量中\n",
      "(From不存在于词向量中\n",
      "xxTJ不存在于词向量中\n",
      "decade,不存在于词向量中\n",
      ":(|||The不存在于词向量中\n",
      "plenty.不存在于词向量中\n",
      "with...|||It's不存在于词向量中\n",
      "Viva不存在于词向量中\n",
      "workaholic.不存在于词向量中\n",
      "Ni/Ti不存在于词向量中\n",
      "generally...|||I不存在于词向量中\n",
      "ENPs不存在于词向量中\n",
      "themselves)不存在于词向量中\n",
      "errors,不存在于词向量中\n",
      "puzzle.不存在于词向量中\n",
      "stone,不存在于词向量中\n",
      "touchy,不存在于词向量中\n",
      "million,不存在于词向量中\n",
      "bookstores,不存在于词向量中\n",
      "a...|||Good不存在于词向量中\n",
      "(e.g.,不存在于词向量中\n",
      "Fs.不存在于词向量中\n",
      "worked...|||I不存在于词向量中\n",
      "grandparents.不存在于词向量中\n",
      "vivid,不存在于词向量中\n",
      "it...and不存在于词向量中\n",
      "predictable,不存在于词向量中\n",
      "each...|||I've不存在于词向量中\n",
      "you.|||What不存在于词向量中\n",
      "vampires.不存在于词向量中\n",
      "win.|||I不存在于词向量中\n",
      "Seeker.不存在于词向量中\n",
      "Du不存在于词向量中\n",
      "pants?不存在于词向量中\n",
      "hunting.不存在于词向量中\n",
      "habitat.不存在于词向量中\n",
      "bisexual,不存在于词向量中\n",
      "Ti-Se-Ni-Fe不存在于词向量中\n",
      ":proud:|||My不存在于词向量中\n",
      "being.|||I不存在于词向量中\n",
      "wide.不存在于词向量中\n",
      "exterior.不存在于词向量中\n",
      "this...|||It不存在于词向量中\n",
      "...|||Thanks,不存在于词向量中\n",
      "Goofy不存在于词向量中\n",
      "encounter.不存在于词向量中\n",
      "S-types不存在于词向量中\n",
      "sunshine.不存在于词向量中\n",
      "pay,不存在于词向量中\n",
      "Halloween,不存在于词向量中\n",
      "middle/high不存在于词向量中\n",
      "childhood?不存在于词向量中\n",
      "or...|||Thanks不存在于词向量中\n",
      "him/her.不存在于词向量中\n",
      "(forgot不存在于词向量中\n",
      "recent,不存在于词向量中\n",
      ":P|||What不存在于词向量中\n",
      "spaces,不存在于词向量中\n",
      "salad.不存在于词向量中\n",
      "S.O.不存在于词向量中\n",
      "smoked,不存在于词向量中\n",
      "bugs.不存在于词向量中\n",
      "players,不存在于词向量中\n",
      "Pinocchio不存在于词向量中\n",
      "bulb?不存在于词向量中\n",
      "Cheshire不存在于词向量中\n",
      "her...'不存在于词向量中\n",
      "politicians.不存在于词向量中\n",
      "ExTPs不存在于词向量中\n",
      "gentleman.不存在于词向量中\n",
      "work).不存在于词向量中\n",
      "eggs.不存在于词向量中\n",
      "their...|||Yeah,不存在于词向量中\n",
      "passionate.不存在于词向量中\n",
      "travelling.不存在于词向量中\n",
      "devices,不存在于词向量中\n",
      "Layton不存在于词向量中\n",
      "chain.不存在于词向量中\n",
      "Critical不存在于词向量中\n",
      "but...|||Well,不存在于词向量中\n",
      "Detroit不存在于词向量中\n",
      "sincerity,不存在于词向量中\n",
      "bit.|||I不存在于词向量中\n",
      "Simpson不存在于词向量中\n",
      "'On不存在于词向量中\n",
      "'Any不存在于词向量中\n",
      "brah.不存在于词向量中\n",
      "it...|||Thanks不存在于词向量中\n",
      "as...|||So不存在于词向量中\n",
      "Partially不存在于词向量中\n",
      "Daylight不存在于词向量中\n",
      "Ista不存在于词向量中\n",
      "also..不存在于词向量中\n",
      "creatively,不存在于词向量中\n",
      "intimidated.不存在于词向量中\n",
      "sets.不存在于词向量中\n",
      "requirement.不存在于词向量中\n",
      "potato.不存在于词向量中\n",
      "philosophy?不存在于词向量中\n",
      "relate?不存在于词向量中\n",
      "Infj.不存在于词向量中\n",
      "Bulma不存在于词向量中\n",
      "have...|||Just不存在于词向量中\n",
      "3?不存在于词向量中\n",
      "(via不存在于词向量中\n",
      "you...|||In不存在于词向量中\n",
      "tactics,不存在于词向量中\n",
      "(please不存在于词向量中\n",
      "rationally.不存在于词向量中\n",
      "initiative.不存在于词向量中\n",
      "special?不存在于词向量中\n",
      "that's...|||I'm不存在于词向量中\n",
      "resentment.不存在于词向量中\n",
      "unfair,不存在于词向量中\n",
      "collage.不存在于词向量中\n",
      "eat...|||I不存在于词向量中\n",
      "but...|||Thanks不存在于词向量中\n",
      ":smile:|||I不存在于词向量中\n",
      "Tangled不存在于词向量中\n",
      "dollars.不存在于词向量中\n",
      "MTV不存在于词向量中\n",
      "Yang不存在于词向量中\n",
      "Grey's不存在于词向量中\n",
      "Dreamers不存在于词向量中\n",
      "Added不存在于词向量中\n",
      "gettin'不存在于词向量中\n",
      "cuteness.不存在于词向量中\n",
      "listeners.不存在于词向量中\n",
      "''I不存在于词向量中\n",
      "taking...|||I不存在于词向量中\n",
      "'hard不存在于词向量中\n",
      "pretend.不存在于词向量中\n",
      "Kite不存在于词向量中\n",
      "Combat不存在于词向量中\n",
      "Needed不存在于词向量中\n",
      "high),不存在于词向量中\n",
      "'no'不存在于词向量中\n",
      "ever)不存在于词向量中\n",
      "that...|||One不存在于词向量中\n",
      "love...|||I'm不存在于词向量中\n",
      "Similarly,不存在于词向量中\n",
      "Fe-dominant不存在于词向量中\n",
      "Orphan不存在于词向量中\n",
      "convincing,不存在于词向量中\n",
      "Murakami.不存在于词向量中\n",
      "Mostly,不存在于词向量中\n",
      "pussy.不存在于词向量中\n",
      "tune,不存在于词向量中\n",
      "Butter不存在于词向量中\n",
      "2...不存在于词向量中\n",
      "1...不存在于词向量中\n",
      "recommendations.不存在于词向量中\n",
      "sucks...不存在于词向量中\n",
      "parks.不存在于词向量中\n",
      "Hiding不存在于词向量中\n",
      "would...|||The不存在于词向量中\n",
      "Damon不存在于词向量中\n",
      "strict,不存在于词向量中\n",
      "Forum.不存在于词向量中\n",
      "as...|||What不存在于词向量中\n",
      "and...|||Okay,不存在于词向量中\n",
      "extensively,不存在于词向量中\n",
      "extraversion,不存在于词向量中\n",
      "Puella不存在于词向量中\n",
      "moment's不存在于词向量中\n",
      "Jolie不存在于词向量中\n",
      "affairs.不存在于词向量中\n",
      "troll?不存在于词向量中\n",
      "way.|||If不存在于词向量中\n",
      "implied.不存在于词向量中\n",
      "classification.不存在于词向量中\n",
      "Setting不存在于词向量中\n",
      "Station不存在于词向量中\n",
      "on...|||What不存在于词向量中\n",
      "ugh,不存在于词向量中\n",
      "apathetic.不存在于词向量中\n",
      "boy?不存在于词向量中\n",
      "verbally,不存在于词向量中\n",
      "'Very不存在于词向量中\n",
      "wolves.不存在于词向量中\n",
      "suitable.不存在于词向量中\n",
      "Physically不存在于词向量中\n",
      "be...|||As不存在于词向量中\n",
      "xxFP不存在于词向量中\n",
      "run?不存在于词向量中\n",
      "A.M.不存在于词向量中\n",
      "bursts.不存在于词向量中\n",
      "the...|||Sorry不存在于词向量中\n",
      ":P|||The不存在于词向量中\n",
      "Lou不存在于词向量中\n",
      "appear.不存在于词向量中\n",
      "and...|||Most不存在于词向量中\n",
      "Marley不存在于词向量中\n",
      "in...|||One不存在于词向量中\n",
      "anarchy.不存在于词向量中\n",
      "diplomatic,不存在于词向量中\n",
      "externally,不存在于词向量中\n",
      "analyze.不存在于词向量中\n",
      "Husband不存在于词向量中\n",
      "can...|||That不存在于词向量中\n",
      "ass.|||I不存在于词向量中\n",
      "Building不存在于词向量中\n",
      "to...|||Since不存在于词向量中\n",
      "one....不存在于词向量中\n",
      "All.不存在于词向量中\n",
      "again.|||I'm不存在于词向量中\n",
      "Infp.不存在于词向量中\n",
      "Fist不存在于词向量中\n",
      "kind?不存在于词向量中\n",
      "freely,不存在于词向量中\n",
      "wave,不存在于词向量中\n",
      "psychologists,不存在于词向量中\n",
      "Surprise不存在于词向量中\n",
      "ENFp不存在于词向量中\n",
      "Nancy不存在于词向量中\n",
      "Towards不存在于词向量中\n",
      "I...|||Here不存在于词向量中\n",
      "highest.不存在于词向量中\n",
      "T/F.不存在于词向量中\n",
      "Town不存在于词向量中\n",
      "in'不存在于词向量中\n",
      "Perfectionist不存在于词向量中\n",
      "Icelandic不存在于词向量中\n",
      "battles.不存在于词向量中\n",
      "anime?不存在于词向量中\n",
      "adventurous.不存在于词向量中\n",
      "Francisco.不存在于词向量中\n",
      "INFs不存在于词向量中\n",
      "INTs不存在于词向量中\n",
      "you...|||A不存在于词向量中\n",
      "sticks.不存在于词向量中\n",
      "........不存在于词向量中\n",
      "Vintage不存在于词向量中\n",
      "WORK不存在于词向量中\n",
      "gf's不存在于词向量中\n",
      "Slowly不存在于词向量中\n",
      "'Would不存在于词向量中\n",
      "was...|||It's不存在于词向量中\n",
      "definitely...不存在于词向量中\n",
      "are...|||If不存在于词向量中\n",
      "lol...|||I不存在于词向量中\n",
      "thanks.|||I不存在于词向量中\n",
      "reward.不存在于词向量中\n",
      "the...|||An不存在于词向量中\n",
      "outlook.不存在于词向量中\n",
      "Account不存在于词向量中\n",
      "Sarcasm不存在于词向量中\n",
      "was..不存在于词向量中\n",
      "he...|||Thank不存在于词向量中\n",
      "fence.不存在于词向量中\n",
      "selfish?不存在于词向量中\n",
      "I'v不存在于词向量中\n",
      "explosion.不存在于词向量中\n",
      "'Wow!不存在于词向量中\n",
      "Enjoying不存在于词向量中\n",
      "don't...|||Well,不存在于词向量中\n",
      "talk.|||I不存在于词向量中\n",
      "questions)不存在于词向量中\n",
      "Netherlands,不存在于词向量中\n",
      "Second:不存在于词向量中\n",
      "Liars不存在于词向量中\n",
      "40,不存在于词向量中\n",
      "horses.不存在于词向量中\n",
      "tangent.不存在于词向量中\n",
      "expect...|||I不存在于词向量中\n",
      "IB不存在于词向量中\n",
      "Collins不存在于词向量中\n",
      "QUOTE不存在于词向量中\n",
      "it?)不存在于词向量中\n",
      "Keirsey.不存在于词向量中\n",
      "anything)不存在于词向量中\n",
      "poll?不存在于词向量中\n",
      "Hugo不存在于词向量中\n",
      "November,不存在于词向量中\n",
      "certain...|||I'm不存在于词向量中\n",
      "Type,不存在于词向量中\n",
      "AC不存在于词向量中\n",
      "Treasure不存在于词向量中\n",
      "theoretical.不存在于词向量中\n",
      "laugh.|||I不存在于词向量中\n",
      "trusted,不存在于词向量中\n",
      "Keira不存在于词向量中\n",
      "late?不存在于词向量中\n",
      "Beautiful,不存在于词向量中\n",
      "outdoors,不存在于词向量中\n",
      "Jules不存在于词向量中\n",
      "Insomnia不存在于词向量中\n",
      "much...'不存在于词向量中\n",
      "fluently,不存在于词向量中\n",
      "Harry,不存在于词向量中\n",
      "it?'不存在于词向量中\n",
      "terribly.不存在于词向量中\n",
      "pleasing,不存在于词向量中\n",
      "Pixel不存在于词向量中\n",
      "Moment不存在于词向量中\n",
      "Boat不存在于词向量中\n",
      "Sky,不存在于词向量中\n",
      "speaks,不存在于词向量中\n",
      "with...|||Thank不存在于词向量中\n",
      "socialism,不存在于词向量中\n",
      "intro.不存在于词向量中\n",
      "Temptation不存在于词向量中\n",
      "Judging:不存在于词向量中\n",
      "Aha不存在于词向量中\n",
      "cash.不存在于词向量中\n",
      "pen.不存在于词向量中\n",
      "living...|||I不存在于词向量中\n",
      "uptight,不存在于词向量中\n",
      "Orson不存在于词向量中\n",
      "continue,不存在于词向量中\n",
      "(lots不存在于词向量中\n",
      "little?不存在于词向量中\n",
      "scores,不存在于词向量中\n",
      "mellow.不存在于词向量中\n",
      "#1,不存在于词向量中\n",
      "Gavin不存在于词向量中\n",
      "outcast.不存在于词向量中\n",
      "Sacred不存在于词向量中\n",
      "Blade不存在于词向量中\n",
      "know.|||I'm不存在于词向量中\n",
      "Responsibility不存在于词向量中\n",
      "genetics.不存在于词向量中\n",
      "Believing不存在于词向量中\n",
      "escapism.不存在于词向量中\n",
      "choice.|||I不存在于词向量中\n",
      "Baroque不存在于词向量中\n",
      "to...|||Did不存在于词向量中\n",
      "Kaku不存在于词向量中\n",
      "movie.|||I不存在于词向量中\n",
      "factual.不存在于词向量中\n",
      "bizarre,不存在于词向量中\n",
      "CPU不存在于词向量中\n",
      "Exploring不存在于词向量中\n",
      "HORRIBLE不存在于词向量中\n",
      "surprises.不存在于词向量中\n",
      "modest,不存在于词向量中\n",
      "sweets.不存在于词向量中\n",
      "Pan's不存在于词向量中\n",
      "Nikki不存在于词向量中\n",
      "OrangeAppled,不存在于词向量中\n",
      "Burning不存在于词向量中\n",
      "wolf,不存在于词向量中\n",
      "I麓ve不存在于词向量中\n",
      "Sirius不存在于词向量中\n",
      "suggests.不存在于词向量中\n",
      "inefficient,不存在于词向量中\n",
      "Fail不存在于词向量中\n",
      "saving,不存在于词向量中\n",
      "Kierkegaard不存在于词向量中\n",
      "mbti?不存在于词向量中\n",
      "best...|||I'm不存在于词向量中\n",
      "it.|||Thank不存在于词向量中\n",
      "grudges,不存在于词向量中\n",
      "abandoned.不存在于词向量中\n",
      "annoyance.不存在于词向量中\n",
      "skepticism.不存在于词向量中\n",
      "Hide不存在于词向量中\n",
      "yourselves,不存在于词向量中\n",
      "subconscious.不存在于词向量中\n",
      "insanity,不存在于词向量中\n",
      "Cool!不存在于词向量中\n",
      "Mercy不存在于词向量中\n",
      "Lestat不存在于词向量中\n",
      "Tooth不存在于词向量中\n",
      "birthday?不存在于词向量中\n",
      "stopped,不存在于词向量中\n",
      "Queen.不存在于词向量中\n",
      "Do...|||I不存在于词向量中\n",
      "eater.不存在于词向量中\n",
      "Goo不存在于词向量中\n",
      "Einstein's不存在于词向量中\n",
      "Credit不存在于词向量中\n",
      "Union不存在于词向量中\n",
      "falling,不存在于词向量中\n",
      "risk?不存在于词向量中\n",
      "property.不存在于词向量中\n",
      "BBC's不存在于词向量中\n",
      "kiss?不存在于词向量中\n",
      "digital,不存在于词向量中\n",
      "ever.|||I不存在于词向量中\n",
      "me....I不存在于词向量中\n",
      "way'不存在于词向量中\n",
      "area...|||I不存在于词向量中\n",
      "jk,不存在于词向量中\n",
      "failing,不存在于词向量中\n",
      "Cain不存在于词向量中\n",
      "Prolonged不存在于词向量中\n",
      "Bryan不存在于词向量中\n",
      "amusement.不存在于词向量中\n",
      "leaf,不存在于词向量中\n",
      "FIGHT不存在于词向量中\n",
      "network.不存在于词向量中\n",
      "Ennegram不存在于词向量中\n",
      "esfj,不存在于词向量中\n",
      "essential.不存在于词向量中\n",
      "Ahhh,不存在于词向量中\n",
      "then...|||I've不存在于词向量中\n",
      "pessimism,不存在于词向量中\n",
      "UFO不存在于词向量中\n",
      "humility.不存在于词向量中\n",
      "meetings.不存在于词向量中\n",
      "parenting,不存在于词向量中\n",
      "final.不存在于词向量中\n",
      "Germans不存在于词向量中\n",
      "TF2不存在于词向量中\n",
      "Python,不存在于词向量中\n",
      "possess.不存在于词向量中\n",
      "he...|||That不存在于词向量中\n",
      "It.不存在于词向量中\n",
      "ISFP)不存在于词向量中\n",
      "6...不存在于词向量中\n",
      "places...不存在于词向量中\n",
      "Tv不存在于词向量中\n",
      "above...不存在于词向量中\n",
      "laugh?不存在于词向量中\n",
      "digress.不存在于词向量中\n",
      "forgetful.不存在于词向量中\n",
      "Fahrenheit不存在于词向量中\n",
      "(apart不存在于词向量中\n",
      "Lone不存在于词向量中\n",
      "Felix不存在于词向量中\n",
      "sex)不存在于词向量中\n",
      "issues.|||I不存在于词向量中\n",
      "Stark,不存在于词向量中\n",
      "ESTP-不存在于词向量中\n",
      "Vikings不存在于词向量中\n",
      "ISFP-不存在于词向量中\n",
      "people.|||I'm不存在于词向量中\n",
      "briefly.不存在于词向量中\n",
      "trusting.不存在于词向量中\n",
      "doctors.不存在于词向量中\n",
      "Hazel不存在于词向量中\n",
      "Si-dom不存在于词向量中\n",
      "Lewis,不存在于词向量中\n",
      "heh,不存在于词向量中\n",
      "copy/paste不存在于词向量中\n",
      "Demon不存在于词向量中\n",
      "Initial不存在于词向量中\n",
      "(Se不存在于词向量中\n",
      "genes.不存在于词向量中\n",
      "(85%)不存在于词向量中\n",
      "btw).不存在于词向量中\n",
      "repeatedly,不存在于词向量中\n",
      "slam.不存在于词向量中\n",
      "Plato's不存在于词向量中\n",
      "Agreed不存在于词向量中\n",
      "Strategic不存在于词向量中\n",
      "flavor,不存在于词向量中\n",
      "5'2不存在于词向量中\n",
      "Seemingly不存在于词向量中\n",
      "in...|||Well不存在于词向量中\n",
      "insincere,不存在于词向量中\n",
      "exterior,不存在于词向量中\n",
      "gain,不存在于词向量中\n",
      "doctors,不存在于词向量中\n",
      "mistype.不存在于词向量中\n",
      "mercy.不存在于词向量中\n",
      "Humility不存在于词向量中\n",
      "modesty.不存在于词向量中\n",
      "FANTASTIC不存在于词向量中\n",
      "GUYS不存在于词向量中\n",
      "Named不存在于词向量中\n",
      "Charming不存在于词向量中\n",
      "Thompson不存在于词向量中\n",
      "said...|||I'm不存在于词向量中\n",
      "motion,不存在于词向量中\n",
      "exists?不存在于词向量中\n",
      "highway.不存在于词向量中\n",
      "...|||Actually,不存在于词向量中\n",
      "authors.不存在于词向量中\n",
      "Scene不存在于词向量中\n",
      "Snowflake不存在于词向量中\n",
      "Shaun不存在于词向量中\n",
      "post).不存在于词向量中\n",
      "heartbeat.不存在于词向量中\n",
      "and...|||Good不存在于词向量中\n",
      "me...|||Do不存在于词向量中\n",
      "(Do不存在于词向量中\n",
      ";)|||This不存在于词向量中\n",
      "cousins.不存在于词向量中\n",
      "manipulated.不存在于词向量中\n",
      "Master,不存在于词向量中\n",
      ":D|||Thanks不存在于词向量中\n",
      "wait?不存在于词向量中\n",
      "me.)不存在于词向量中\n",
      "becomes,不存在于词向量中\n",
      "responsible.不存在于词向量中\n",
      "MMORPG不存在于词向量中\n",
      "prejudice.不存在于词向量中\n",
      "Affective不存在于词向量中\n",
      "math...|||I不存在于词向量中\n",
      "'INFP不存在于词向量中\n",
      "description?不存在于词向量中\n",
      "contact?不存在于词向量中\n",
      "Site不存在于词向量中\n",
      "moved,不存在于词向量中\n",
      "Belgian不存在于词向量中\n",
      "TALK不存在于词向量中\n",
      "confession.不存在于词向量中\n",
      "Lola不存在于词向量中\n",
      "F/T,不存在于词向量中\n",
      "self.|||I不存在于词向量中\n",
      "wealth.不存在于词向量中\n",
      "assertiveness.不存在于词向量中\n",
      "rudeness,不存在于词向量中\n",
      "genders.不存在于词向量中\n",
      "Mello不存在于词向量中\n",
      "Sandra不存在于词向量中\n",
      "Clock不存在于词向量中\n",
      "Potter)不存在于词向量中\n",
      "sports?不存在于词向量中\n",
      "downhill.不存在于词向量中\n",
      "'fun'不存在于词向量中\n",
      "jacket.不存在于词向量中\n",
      "WAIT不存在于词向量中\n",
      "Law.不存在于词向量中\n",
      "say...|||I'm不存在于词向量中\n",
      "flying,不存在于词向量中\n",
      "villains.不存在于词向量中\n",
      "lbs,不存在于词向量中\n",
      "Aizar不存在于词向量中\n",
      "Dangerous不存在于词向量中\n",
      "self-aware.不存在于词向量中\n",
      "...for不存在于词向量中\n",
      "Chicago.不存在于词向量中\n",
      "See?不存在于词向量中\n",
      "e)不存在于词向量中\n",
      "Bye不存在于词向量中\n",
      "Anywhere不存在于词向量中\n",
      "Lenovo不存在于词向量中\n",
      "same)不存在于词向量中\n",
      "Tail不存在于词向量中\n",
      "programs.不存在于词向量中\n",
      "Wise不存在于词向量中\n",
      "Harlem不存在于词向量中\n",
      "transportation.不存在于词向量中\n",
      "Eh不存在于词向量中\n",
      "Answer:不存在于词向量中\n",
      "Comp不存在于词向量中\n",
      "phone?不存在于词向量中\n",
      "Scorpio.不存在于词向量中\n",
      "deal...|||I不存在于词向量中\n",
      "routines,不存在于词向量中\n",
      "oldest,不存在于词向量中\n",
      "assuming.不存在于词向量中\n",
      "Strip不存在于词向量中\n",
      "Vampires不存在于词向量中\n",
      "twins,不存在于词向量中\n",
      "definately.不存在于词向量中\n",
      "Mechanic不存在于词向量中\n",
      "later?不存在于词向量中\n",
      "Stopped不存在于词向量中\n",
      "back!|||I不存在于词向量中\n",
      "officer,不存在于词向量中\n",
      "Skies不存在于词向量中\n",
      "included).不存在于词向量中\n",
      "dishonest.不存在于词向量中\n",
      "was...|||As不存在于词向量中\n",
      "Ti/Fe.不存在于词向量中\n",
      "Natalie不存在于词向量中\n",
      "ISFP's.不存在于词向量中\n",
      "bill,不存在于词向量中\n",
      "OLD不存在于词向量中\n",
      "Yes...不存在于词向量中\n",
      "much...|||You不存在于词向量中\n",
      "...|||Of不存在于词向量中\n",
      "see...'不存在于词向量中\n",
      "Lindsey不存在于词向量中\n",
      "she...|||This不存在于词向量中\n",
      "part...|||I不存在于词向量中\n",
      "Don't...|||I不存在于词向量中\n",
      "(again)不存在于词向量中\n",
      "WANTS不存在于词向量中\n",
      "heights.不存在于词向量中\n",
      "Bradley不存在于词向量中\n",
      "Attempting不存在于词向量中\n",
      "interesting)不存在于词向量中\n",
      "choir.不存在于词向量中\n",
      "professionally,不存在于词向量中\n",
      "Track:不存在于词向量中\n",
      "ONE,不存在于词向量中\n",
      "tale.不存在于词向量中\n",
      "(namely不存在于词向量中\n",
      "ISFJs?不存在于词向量中\n",
      "gratification.不存在于词向量中\n",
      "fast?不存在于词向量中\n",
      "mutual,不存在于词向量中\n",
      "funeral.不存在于词向量中\n",
      "Scored不存在于词向量中\n",
      "it...|||i不存在于词向量中\n",
      "bragging,不存在于词向量中\n",
      "tomatoes.不存在于词向量中\n",
      "sauce,不存在于词向量中\n",
      "Months不存在于词向量中\n",
      "day),不存在于词向量中\n",
      "Jeans,不存在于词向量中\n",
      "(physical不存在于词向量中\n",
      "ordered.不存在于词向量中\n",
      "Coincidentally,不存在于词向量中\n",
      "square,不存在于词向量中\n",
      "understatement.不存在于词向量中\n",
      "punk,不存在于词向量中\n",
      "nasty,不存在于词向量中\n",
      "Joining不存在于词向量中\n",
      "Baseball不存在于词向量中\n",
      "SPs,不存在于词向量中\n",
      "my...|||Just不存在于词向量中\n",
      "Lessons不存在于词向量中\n",
      "desert.不存在于词向量中\n",
      "sand,不存在于词向量中\n",
      "Very,不存在于词向量中\n",
      "RP不存在于词向量中\n",
      "(Mostly不存在于词向量中\n",
      "inept.不存在于词向量中\n",
      "cost,不存在于词向量中\n",
      "hypothetically,不存在于词向量中\n",
      "GOD!不存在于词向量中\n",
      "will...|||You不存在于词向量中\n",
      "dorm,不存在于词向量中\n",
      "Eleanor不存在于词向量中\n",
      "blast,不存在于词向量中\n",
      "also...|||This不存在于词向量中\n",
      "up.|||I'm不存在于词向量中\n",
      "Jacob不存在于词向量中\n",
      "Intp.不存在于词向量中\n",
      "reasoning?不存在于词向量中\n",
      "dances,不存在于词向量中\n",
      "long-term,不存在于词向量中\n",
      "psychedelics,不存在于词向量中\n",
      "Madonna不存在于词向量中\n",
      "Month不存在于词向量中\n",
      "BLAH不存在于词向量中\n",
      "Greg不存在于词向量中\n",
      "one...'不存在于词向量中\n",
      "owner.不存在于词向量中\n",
      "noticeable.不存在于词向量中\n",
      "Pointless不存在于词向量中\n",
      "ashamed.不存在于词向量中\n",
      "consistency,不存在于词向量中\n",
      "fruit.不存在于词向量中\n",
      "most...'不存在于词向量中\n",
      "me.|||Well不存在于词向量中\n",
      "NJs不存在于词向量中\n",
      "Willow不存在于词向量中\n",
      "stuff.|||I'm不存在于词向量中\n",
      "asap.不存在于词向量中\n",
      "lecture.不存在于词向量中\n",
      "even...|||My不存在于词向量中\n",
      "Fancy不存在于词向量中\n",
      "Incredible不存在于词向量中\n",
      "GPS.不存在于词向量中\n",
      "house...不存在于词向量中\n",
      "lot...|||I'm不存在于词向量中\n",
      "'something'不存在于词向量中\n",
      "(small不存在于词向量中\n",
      "bizarre.不存在于词向量中\n",
      "gear.不存在于词向量中\n",
      "rhythm.不存在于词向量中\n",
      "lectures,不存在于词向量中\n",
      "surreal.不存在于词向量中\n",
      "Manual不存在于词向量中\n",
      "state...|||I不存在于词向量中\n",
      "(hope不存在于词向量中\n",
      "Hulk不存在于词向量中\n",
      "FREE不存在于词向量中\n",
      "LITTLE不存在于词向量中\n",
      "so...I不存在于词向量中\n",
      "(half不存在于词向量中\n",
      "narrow.不存在于词向量中\n",
      "(out不存在于词向量中\n",
      "consolation,不存在于词向量中\n",
      "ENFJ..不存在于词向量中\n",
      "obsessed.不存在于词向量中\n",
      "adaptation.不存在于词向量中\n",
      "MENSA不存在于词向量中\n",
      "blame,不存在于词向量中\n",
      "Board不存在于词向量中\n",
      "O,不存在于词向量中\n",
      "person.|||I'm不存在于词向量中\n",
      "myself|||I不存在于词向量中\n",
      "appreciation,不存在于词向量中\n",
      "notification.不存在于词向量中\n",
      "my...|||One不存在于词向量中\n",
      "'Or不存在于词向量中\n",
      "favourite,不存在于词向量中\n",
      "fact...不存在于词向量中\n",
      "some...|||This不存在于词向量中\n",
      "extraverts.不存在于词向量中\n",
      "hurt...|||I不存在于词向量中\n",
      "backgrounds.不存在于词向量中\n",
      "Ignorant不存在于词向量中\n",
      "Fact不存在于词向量中\n",
      "Extraversion:不存在于词向量中\n",
      "FYI不存在于词向量中\n",
      "machines,不存在于词向量中\n",
      "solid.不存在于词向量中\n",
      "guy/girl不存在于词向量中\n",
      "HI不存在于词向量中\n",
      "somewhere?不存在于词向量中\n",
      "Rex不存在于词向量中\n",
      "impersonal.不存在于词向量中\n",
      "Engage不存在于词向量中\n",
      "from...|||I've不存在于词向量中\n",
      "I...|||Lol不存在于词向量中\n",
      "o'clock不存在于词向量中\n",
      "with...|||Hello不存在于词向量中\n",
      "Fool不存在于词向量中\n",
      "INFJ;不存在于词向量中\n",
      "skewed.不存在于词向量中\n",
      "reminder,不存在于词向量中\n",
      "Attracted不存在于词向量中\n",
      "Marv不存在于词向量中\n",
      "Behavioral不存在于词向量中\n",
      "you.|||When不存在于词向量中\n",
      "indifferent,不存在于词向量中\n",
      "question...|||I不存在于词向量中\n",
      "found?不存在于词向量中\n",
      "Hiraeth不存在于词向量中\n",
      "it...|||Because不存在于词向量中\n",
      "T-shirts不存在于词向量中\n",
      "he...|||What不存在于词向量中\n",
      "Challenge不存在于词向量中\n",
      "Washington,不存在于词向量中\n",
      "truthful.不存在于词向量中\n",
      "misunderstand.不存在于词向量中\n",
      "that...|||Oh不存在于词向量中\n",
      "Islam,不存在于词向量中\n",
      "you.|||This不存在于词向量中\n",
      "Taylor,不存在于词向量中\n",
      "See:不存在于词向量中\n",
      "it.|||People不存在于词向量中\n",
      "Talked不存在于词向量中\n",
      "Traveler不存在于词向量中\n",
      "secondary.不存在于词向量中\n",
      "heart?不存在于词向量中\n",
      "peoples.不存在于词向量中\n",
      "and...|||Are不存在于词向量中\n",
      "Convince不存在于词向量中\n",
      "framework,不存在于词向量中\n",
      "Rogue不存在于词向量中\n",
      "you...|||Yes不存在于词向量中\n",
      "fling,不存在于词向量中\n",
      "girly,不存在于词向量中\n",
      "magnet.不存在于词向量中\n",
      "Tan不存在于词向量中\n",
      "flower.不存在于词向量中\n",
      "philosophical.不存在于词向量中\n",
      "etc....不存在于词向量中\n",
      "emotion...不存在于词向量中\n",
      "too....|||I不存在于词向量中\n",
      "37.不存在于词向量中\n",
      "Woo不存在于词向量中\n",
      "(seems不存在于词向量中\n",
      "be...|||Thank不存在于词向量中\n",
      "altruistic.不存在于词向量中\n",
      "is...|||There不存在于词向量中\n",
      "Height:不存在于词向量中\n",
      "?|||What不存在于词向量中\n",
      "host,不存在于词向量中\n",
      "Meryl不存在于词向量中\n",
      "Match不存在于词向量中\n",
      "implications.不存在于词向量中\n",
      "astounding.不存在于词向量中\n",
      "(true不存在于词向量中\n",
      "Content不存在于词向量中\n",
      "0.00不存在于词向量中\n",
      "way.|||I'm不存在于词向量中\n",
      "o/不存在于词向量中\n",
      "colors?不存在于词向量中\n",
      "B's不存在于词向量中\n",
      "so/sp.不存在于词向量中\n",
      "dead?不存在于词向量中\n",
      "know|||I不存在于词向量中\n",
      "NiTe不存在于词向量中\n",
      "thinking.|||I不存在于词向量中\n",
      "Nevertheless不存在于词向量中\n",
      ";)|||Welcome不存在于词向量中\n",
      "dolls,不存在于词向量中\n",
      "and...|||Oh,不存在于词向量中\n",
      "...|||Don't不存在于词向量中\n",
      "classical.不存在于词向量中\n",
      "Ouch.不存在于词向量中\n",
      "themselves...|||I不存在于词向量中\n",
      "comic,不存在于词向量中\n",
      "Fortune不存在于词向量中\n",
      "superiority,不存在于词向量中\n",
      "way.|||You不存在于词向量中\n",
      "decisions?不存在于词向量中\n",
      "But...I不存在于词向量中\n",
      "you...I不存在于词向量中\n",
      ":happy:|||When不存在于词向量中\n",
      "I...|||These不存在于词向量中\n",
      "doms,不存在于词向量中\n",
      "and...|||First不存在于词向量中\n",
      "WANTED不存在于词向量中\n",
      "Gang不存在于词向量中\n",
      "neighborhood,不存在于词向量中\n",
      "updates.不存在于词向量中\n",
      "INFx.不存在于词向量中\n",
      "Tour不存在于词向量中\n",
      "Spectrum不存在于词向量中\n",
      "dinosaurs.不存在于词向量中\n",
      "peace?不存在于词向量中\n",
      "some?不存在于词向量中\n",
      "worse)不存在于词向量中\n",
      "mindfulness,不存在于词向量中\n",
      "of...|||Hmm,不存在于词向量中\n",
      "percentile.不存在于词向量中\n",
      "Lawful.不存在于词向量中\n",
      "tendencies?不存在于词向量中\n",
      "remarks,不存在于词向量中\n",
      "generalizations,不存在于词向量中\n",
      "People:不存在于词向量中\n",
      "sig,不存在于词向量中\n",
      "morality?不存在于词向量中\n",
      "of...|||There's不存在于词向量中\n",
      "Thanksgiving.不存在于词向量中\n",
      "ESTJ's.不存在于词向量中\n",
      "your...|||I've不存在于词向量中\n",
      "Thanks!|||I不存在于词向量中\n",
      "knitting,不存在于词向量中\n",
      "SORRY不存在于词向量中\n",
      "hyper,不存在于词向量中\n",
      "destroyed,不存在于词向量中\n",
      "Wal-Mart不存在于词向量中\n",
      "Gamer,不存在于词向量中\n",
      "Props不存在于词向量中\n",
      "truly...|||I不存在于词向量中\n",
      "while)不存在于词向量中\n",
      "tail.不存在于词向量中\n",
      "quote?不存在于词向量中\n",
      "Suffice不存在于词向量中\n",
      "House.不存在于词向量中\n",
      "barrier.不存在于词向量中\n",
      "Omegle不存在于词向量中\n",
      "just...|||i不存在于词向量中\n",
      "time's不存在于词向量中\n",
      "Seconds不存在于词向量中\n",
      "worms.不存在于词向量中\n",
      "5,000不存在于词向量中\n",
      "tan.不存在于词向量中\n",
      "Quick,不存在于词向量中\n",
      "Congrats,不存在于词向量中\n",
      ":crazy:|||My不存在于词向量中\n",
      "predicament.不存在于词向量中\n",
      "athiest,不存在于词向量中\n",
      "dreamy.不存在于词向量中\n",
      "Objective不存在于词向量中\n",
      "game)不存在于词向量中\n",
      "ISTJ;不存在于词向量中\n",
      "Scar不存在于词向量中\n",
      "HUGS不存在于词向量中\n",
      "*The不存在于词向量中\n",
      "(2013)不存在于词向量中\n",
      "was...|||So不存在于词向量中\n",
      "thread.|||The不存在于词向量中\n",
      "i'm...|||I不存在于词向量中\n",
      "bonus,不存在于词向量中\n",
      "suffice.不存在于词向量中\n",
      "comprehend.不存在于词向量中\n",
      "but...|||Just不存在于词向量中\n",
      "destructive.不存在于词向量中\n",
      "plane,不存在于词向量中\n",
      ":/|||Well,不存在于词向量中\n",
      "(thinking不存在于词向量中\n",
      "likely...|||I不存在于词向量中\n",
      "Discord不存在于词向量中\n",
      "...|||Same不存在于词向量中\n",
      "Trap不存在于词向量中\n",
      "Dubstep不存在于词向量中\n",
      ":C不存在于词向量中\n",
      "(Unless不存在于词向量中\n",
      "in...|||And不存在于词向量中\n",
      "Interesting...不存在于词向量中\n",
      "Caucasian不存在于词向量中\n",
      "address,不存在于词向量中\n",
      "distinction,不存在于词向量中\n",
      "homeless,不存在于词向量中\n",
      "problem...|||I不存在于词向量中\n",
      "fucked.不存在于词向量中\n",
      "me!|||I'm不存在于词向量中\n",
      "unreal.不存在于词向量中\n",
      "campus,不存在于词向量中\n",
      "have)不存在于词向量中\n",
      "to...|||Interesting不存在于词向量中\n",
      "Jude不存在于词向量中\n",
      "Pet不存在于词向量中\n",
      "Tapatalk|||I've不存在于词向量中\n",
      "reminder.不存在于词向量中\n",
      "moment.|||I不存在于词向量中\n",
      "She...|||I'm不存在于词向量中\n",
      "just...|||Oh不存在于词向量中\n",
      "Develop不存在于词向量中\n",
      "feminist.不存在于词向量中\n",
      "'Ah,不存在于词向量中\n",
      "'bad'不存在于词向量中\n",
      "a...|||So,不存在于词向量中\n",
      "intimate,不存在于词向量中\n",
      "accomplishments.不存在于词向量中\n",
      "bent,不存在于词向量中\n",
      "John,不存在于词向量中\n",
      "cloud.不存在于词向量中\n",
      "platonic,不存在于词向量中\n",
      "revolution,不存在于词向量中\n",
      "Niss.不存在于词向量中\n",
      "on...|||That's不存在于词向量中\n",
      "soft.不存在于词向量中\n",
      "Fell不存在于词向量中\n",
      "stages.不存在于词向量中\n",
      "me)|||I不存在于词向量中\n",
      "dreamers,不存在于词向量中\n",
      "solution?不存在于词向量中\n",
      "supernatural,不存在于词向量中\n",
      "constantly...|||I不存在于词向量中\n",
      "Serenity不存在于词向量中\n",
      "Men,不存在于词向量中\n",
      "Doors,不存在于词向量中\n",
      "apology,不存在于词向量中\n",
      "(seriously,不存在于词向量中\n",
      "matter).不存在于词向量中\n",
      "love..不存在于词向量中\n",
      "Testament不存在于词向量中\n",
      "participate,不存在于词向量中\n",
      "VIP不存在于词向量中\n",
      "cheese?不存在于词向量中\n",
      "co-workers,不存在于词向量中\n",
      "herd.不存在于词向量中\n",
      "Psychopaths不存在于词向量中\n",
      "something...|||My不存在于词向量中\n",
      ":)).不存在于词向量中\n",
      "burst.不存在于词向量中\n",
      "about...|||When不存在于词向量中\n",
      "CNN不存在于词向量中\n",
      "baby?不存在于词向量中\n",
      "people.|||My不存在于词向量中\n",
      "Ts.不存在于词向量中\n",
      "Wings不存在于词向量中\n",
      "songs)不存在于词向量中\n",
      "variables,不存在于词向量中\n",
      "my...|||Yes,不存在于词向量中\n",
      "Metal,不存在于词向量中\n",
      "financially.不存在于词向量中\n",
      "hip-hop,不存在于词向量中\n",
      "Emerald不存在于词向量中\n",
      "34,不存在于词向量中\n",
      "trust?不存在于词向量中\n",
      "Praise不存在于词向量中\n",
      "Magazine不存在于词向量中\n",
      "works...不存在于词向量中\n",
      "healing,不存在于词向量中\n",
      "Baker不存在于词向量中\n",
      "isn't?不存在于词向量中\n",
      "healthier,不存在于词向量中\n",
      "is...|||Dear不存在于词向量中\n",
      "Sigmund不存在于词向量中\n",
      "must...|||I不存在于词向量中\n",
      "envious,不存在于词向量中\n",
      "human...|||I不存在于词向量中\n",
      "(2012)不存在于词向量中\n",
      "(2009)不存在于词向量中\n",
      "Alicia不存在于词向量中\n",
      "Probably,不存在于词向量中\n",
      "Abortion不存在于词向量中\n",
      "hypocrite.不存在于词向量中\n",
      "that...|||She不存在于词向量中\n",
      "Daenerys不存在于词向量中\n",
      "FBI不存在于词向量中\n",
      "this.....不存在于词向量中\n",
      "Lasted不存在于词向量中\n",
      "REM不存在于词向量中\n",
      "Crisis不存在于词向量中\n",
      "joke...不存在于词向量中\n",
      "mood...不存在于词向量中\n",
      "people...|||What不存在于词向量中\n",
      "creating.不存在于词向量中\n",
      "teenagers,不存在于词向量中\n",
      "CG不存在于词向量中\n",
      "Norse不存在于词向量中\n",
      "Logically不存在于词向量中\n",
      "unicorns.不存在于词向量中\n",
      "applied.不存在于词向量中\n",
      "internet's不存在于词向量中\n",
      "(much不存在于词向量中\n",
      "hormones,不存在于词向量中\n",
      "Na,不存在于词向量中\n",
      "witch,不存在于词向量中\n",
      "prayer,不存在于词向量中\n",
      "Spiders不存在于词向量中\n",
      "Dictionary:不存在于词向量中\n",
      "much!|||I不存在于词向量中\n",
      ":happy:|||The不存在于词向量中\n",
      ";)|||Well,不存在于词向量中\n",
      "Friendships不存在于词向量中\n",
      "trait?不存在于词向量中\n",
      "need/want不存在于词向量中\n",
      "least),不存在于词向量中\n",
      "gamer,不存在于词向量中\n",
      "Clarke不存在于词向量中\n",
      "entry,不存在于词向量中\n",
      "return?不存在于词向量中\n",
      "seat.不存在于词向量中\n",
      "spend...|||I不存在于词向量中\n",
      "Amazing!不存在于词向量中\n",
      "aspirations,不存在于词向量中\n",
      "I...|||Hey,不存在于词向量中\n",
      "chase,不存在于词向量中\n",
      "X3不存在于词向量中\n",
      "continued...不存在于词向量中\n",
      "Nemo不存在于词向量中\n",
      "denied.不存在于词向量中\n",
      "especially...|||I不存在于词向量中\n",
      "Fi/Te,不存在于词向量中\n",
      "super...|||I不存在于词向量中\n",
      "))不存在于词向量中\n",
      "kryptonite.不存在于词向量中\n",
      ":)|||So,不存在于词向量中\n",
      "...|||...不存在于词向量中\n",
      "Concentration不存在于词向量中\n",
      "Geography不存在于词向量中\n",
      "Economics.不存在于词向量中\n",
      "Sweden.不存在于词向量中\n",
      "stereotypes?不存在于词向量中\n",
      "somehow?不存在于词向量中\n",
      "dimension.不存在于词向量中\n",
      "Downton不存在于词向量中\n",
      "Dress不存在于词向量中\n",
      "it.|||1.不存在于词向量中\n",
      "Drake不存在于词向量中\n",
      "demand.不存在于词向量中\n",
      "boring...不存在于词向量中\n",
      "my...|||Yes.不存在于词向量中\n",
      "counter,不存在于词向量中\n",
      "requirements.不存在于词向量中\n",
      "sickness.不存在于词向量中\n",
      "Dress:不存在于词向量中\n",
      "struggling,不存在于词向量中\n",
      "Russia,不存在于词向量中\n",
      "atheism.不存在于词向量中\n",
      "techniques,不存在于词向量中\n",
      "tedious.不存在于词向量中\n",
      "subjective?不存在于词向量中\n",
      "overtime,不存在于词向量中\n",
      "beans,不存在于词向量中\n",
      ":L不存在于词向量中\n",
      "while.|||I不存在于词向量中\n",
      "the...|||Only不存在于词向量中\n",
      "Nordic不存在于词向量中\n",
      "Disclaimer:不存在于词向量中\n",
      "diseases,不存在于词向量中\n",
      "matches,不存在于词向量中\n",
      "RAM不存在于词向量中\n",
      "protection,不存在于词向量中\n",
      "senior.不存在于词向量中\n",
      "comment?不存在于词向量中\n",
      "insignificant.不存在于词向量中\n",
      "sandwiches,不存在于词向量中\n",
      "Re:不存在于词向量中\n",
      "Mega不存在于词向量中\n",
      "Papa不存在于词向量中\n",
      "contrast.不存在于词向量中\n",
      "Catalog不存在于词向量中\n",
      "like...|||A不存在于词向量中\n",
      "time.|||I've不存在于词向量中\n",
      "Office,不存在于词向量中\n",
      "mountain.不存在于词向量中\n",
      "imagery,不存在于词向量中\n",
      "bomb.不存在于词向量中\n",
      "Store不存在于词向量中\n",
      "reach,不存在于词向量中\n",
      "hands?不存在于词向量中\n",
      "for...|||Hello不存在于词向量中\n",
      "Never.不存在于词向量中\n",
      "KIND不存在于词向量中\n",
      "support?不存在于词向量中\n",
      "Standard不存在于词向量中\n",
      "isolated,不存在于词向量中\n",
      "chickens.不存在于词向量中\n",
      "Leon不存在于词向量中\n",
      "waves.不存在于词向量中\n",
      "showing.不存在于词向量中\n",
      "Think.不存在于词向量中\n",
      "AIM不存在于词向量中\n",
      "worker,不存在于词向量中\n",
      "bigger,不存在于词向量中\n",
      "(hate不存在于词向量中\n",
      "X.不存在于词向量中\n",
      "you...|||Oh不存在于词向量中\n",
      "DSLR不存在于词向量中\n",
      "algebra.不存在于词向量中\n",
      "slightly.不存在于词向量中\n",
      "she...|||My不存在于词向量中\n",
      "see)不存在于词向量中\n",
      "opinions?不存在于词向量中\n",
      "honestly...不存在于词向量中\n",
      "leading,不存在于词向量中\n",
      "suggestions...不存在于词向量中\n",
      "happy...不存在于词向量中\n",
      "Strike不存在于词向量中\n",
      "boobs,不存在于词向量中\n",
      "Pablo不存在于词向量中\n",
      "criminal,不存在于词向量中\n",
      "comes...|||I不存在于词向量中\n",
      "ESFP...不存在于词向量中\n",
      "Mastermind.不存在于词向量中\n",
      "bosses.不存在于词向量中\n",
      "SUPPOSED不存在于词向量中\n",
      "Ne).不存在于词向量中\n",
      "of...|||All不存在于词向量中\n",
      "Two,不存在于词向量中\n",
      "44.不存在于词向量中\n",
      "Cos不存在于词向量中\n",
      "guess).不存在于词向量中\n",
      "Ne-Si.不存在于词向量中\n",
      "to...|||Have不存在于词向量中\n",
      "'perfect'不存在于词向量中\n",
      "T_T不存在于词向量中\n",
      "victory.不存在于词向量中\n",
      "Spain.不存在于词向量中\n",
      "programmer,不存在于词向量中\n",
      "expect?不存在于词向量中\n",
      "Oooh不存在于词向量中\n",
      "hopes,不存在于词向量中\n",
      "several,不存在于词向量中\n",
      "CEOs不存在于词向量中\n",
      "ENTJs?不存在于词向量中\n",
      "them.|||You不存在于词向量中\n",
      "internet)不存在于词向量中\n",
      "Hacker不存在于词向量中\n",
      "forums?不存在于词向量中\n",
      "Wow...不存在于词向量中\n",
      "umm...不存在于词向量中\n",
      "blown.不存在于词向量中\n",
      "your...|||When不存在于词向量中\n",
      "is...|||For不存在于词向量中\n",
      "Zeitgeist不存在于词向量中\n",
      "Dilbert不存在于词向量中\n",
      "Zealand,不存在于词向量中\n",
      "Adventurous不存在于词向量中\n",
      "EMT不存在于词向量中\n",
      "speaking?不存在于词向量中\n",
      "premise,不存在于词向量中\n",
      "debatable.不存在于词向量中\n",
      "their...'不存在于词向量中\n",
      "relationship...|||I'm不存在于词向量中\n",
      "documentaries,不存在于词向量中\n",
      "Tuesday.不存在于词向量中\n",
      "Universal不存在于词向量中\n",
      "Egyptian不存在于词向量中\n",
      "intervals,不存在于词向量中\n",
      "thankfully,不存在于词向量中\n",
      "Saving不存在于词向量中\n",
      "lesbian.不存在于词向量中\n",
      "in-depth,不存在于词向量中\n",
      "satisfying,不存在于词向量中\n",
      "(18不存在于词向量中\n",
      "threatened.不存在于词向量中\n",
      "Ah!不存在于词向量中\n",
      "scenes.不存在于词向量中\n",
      "5s.不存在于词向量中\n",
      "guesses,不存在于词向量中\n",
      "please...不存在于词向量中\n",
      "hill,不存在于词向量中\n",
      "with...|||Well,不存在于词向量中\n",
      "irritable,不存在于词向量中\n",
      "noun.不存在于词向量中\n",
      "with...|||Yeah,不存在于词向量中\n",
      "Transformers不存在于词向量中\n",
      "sig.不存在于词向量中\n",
      "traits...不存在于词向量中\n",
      "hehe...不存在于词向量中\n",
      "Beckett不存在于词向量中\n",
      "weeks...不存在于词向量中\n",
      "ENFJ=Fe,不存在于词向量中\n",
      "Kiss:不存在于词向量中\n",
      "Lead不存在于词向量中\n",
      "an...|||If不存在于词向量中\n",
      "towards...|||I不存在于词向量中\n",
      "pilot,不存在于词向量中\n",
      "really...|||The不存在于词向量中\n",
      "...|||There's不存在于词向量中\n",
      "ENXP.不存在于词向量中\n",
      "restless.不存在于词向量中\n",
      "walks.不存在于词向量中\n",
      "mentor,不存在于词向量中\n",
      "nap,不存在于词向量中\n",
      "Si-dom,不存在于词向量中\n",
      "Nova不存在于词向量中\n",
      "devil,不存在于词向量中\n",
      "wonderfully.不存在于词向量中\n",
      "partner)不存在于词向量中\n",
      "me...|||Yeah,不存在于词向量中\n",
      "do...|||Oh不存在于词向量中\n",
      "Example,不存在于词向量中\n",
      "frame.不存在于词向量中\n",
      "motive,不存在于词向量中\n",
      "effective,不存在于词向量中\n",
      "i...'不存在于词向量中\n",
      "sanity,不存在于词向量中\n",
      "outsiders,不存在于词向量中\n",
      "bodies,不存在于词向量中\n",
      "is...|||Your不存在于词向量中\n",
      "to...|||An不存在于词向量中\n",
      "M.D.不存在于词向量中\n",
      "algebra,不存在于词向量中\n",
      "INTJ;不存在于词向量中\n",
      "much).不存在于词向量中\n",
      "going...不存在于词向量中\n",
      "particular...|||I不存在于词向量中\n",
      "MySpace不存在于词向量中\n",
      "Roy不存在于词向量中\n",
      "Prof.不存在于词向量中\n",
      "sick?不存在于词向量中\n",
      "of...|||Hey不存在于词向量中\n",
      "crash,不存在于词向量中\n",
      "Ergo不存在于词向量中\n",
      "Mononoke不存在于词向量中\n",
      "Strategy不存在于词向量中\n",
      "ENERGY不存在于词向量中\n",
      "Deus不存在于词向量中\n",
      "autonomy.不存在于词向量中\n",
      "Arkendale:不存在于词向量中\n",
      "R&B不存在于词向量中\n",
      "Machine,不存在于词向量中\n",
      "Elvis不存在于词向量中\n",
      "or...|||How不存在于词向量中\n",
      "myself.|||I'm不存在于词向量中\n",
      "smoker,不存在于词向量中\n",
      "server.不存在于词向量中\n",
      "RPG's不存在于词向量中\n",
      "Rouge不存在于词向量中\n",
      "SSD不存在于词向量中\n",
      "after...|||I'm不存在于词向量中\n",
      "Fridays不存在于词向量中\n",
      "even...不存在于词向量中\n",
      "Yours,不存在于词向量中\n",
      "children)不存在于词向量中\n",
      "Base不存在于词向量中\n",
      "studies?不存在于词向量中\n",
      "buy,不存在于词向量中\n",
      "Reading,不存在于词向量中\n",
      "STOP.不存在于词向量中\n",
      "JB不存在于词向量中\n",
      "willing,不存在于词向量中\n",
      "Friends.不存在于词向量中\n",
      "join,不存在于词向量中\n",
      "me??不存在于词向量中\n",
      "Researcher不存在于词向量中\n",
      "Focusing不存在于词向量中\n",
      "Says不存在于词向量中\n",
      "frame,不存在于词向量中\n",
      "prospects.不存在于词向量中\n",
      "Pam不存在于词向量中\n",
      "year.|||I不存在于词向量中\n",
      "it's...|||Well,不存在于词向量中\n",
      "has...'不存在于词向量中\n",
      "Rejection不存在于词向量中\n",
      "Stoic不存在于词向量中\n",
      "Regards,不存在于词向量中\n",
      "Every.不存在于词向量中\n",
      "'let不存在于词向量中\n",
      "J?不存在于词向量中\n",
      "hahaha|||I不存在于词向量中\n",
      "COURSE不存在于词向量中\n",
      "discuss,不存在于词向量中\n",
      "Mistakes不存在于词向量中\n",
      "Mind.不存在于词向量中\n",
      "about),不存在于词向量中\n",
      "Year.不存在于词向量中\n",
      "PS.不存在于词向量中\n",
      "on...|||Yes,不存在于词向量中\n",
      "Thinkers.不存在于词向量中\n",
      "RL.不存在于词向量中\n",
      "limitations.不存在于词向量中\n",
      "contemplative,不存在于词向量中\n",
      "apathy,不存在于词向量中\n",
      "Colorado,不存在于词向量中\n",
      "and...|||the不存在于词向量中\n",
      "Vulcans不存在于词向量中\n",
      "script,不存在于词向量中\n",
      "and...|||They不存在于词向量中\n",
      "Weird.不存在于词向量中\n",
      "Needy不存在于词向量中\n",
      "randomly.不存在于词向量中\n",
      "dearly,不存在于词向量中\n",
      "path?不存在于词向量中\n",
      "and...|||While不存在于词向量中\n",
      "blessing.不存在于词向量中\n",
      "disconnected.不存在于词向量中\n",
      "Latvian不存在于词向量中\n",
      "dictator,不存在于词向量中\n",
      "accepting.不存在于词向量中\n",
      "(going不存在于词向量中\n",
      "videos?不存在于词向量中\n",
      "Ji不存在于词向量中\n",
      "south,不存在于词向量中\n",
      "March,不存在于词向量中\n",
      "headed,不存在于词向量中\n",
      "Cole不存在于词向量中\n",
      "fired,不存在于词向量中\n",
      "Suck不存在于词向量中\n",
      "CLEARLY不存在于词向量中\n",
      "raped,不存在于词向量中\n",
      "learn...|||I不存在于词向量中\n",
      "impressions,不存在于词向量中\n",
      "exaggerated.不存在于词向量中\n",
      "(say,不存在于词向量中\n",
      "acquaintance,不存在于词向量中\n",
      "wife?不存在于词向量中\n",
      "shadows.不存在于词向量中\n",
      "XNFJ不存在于词向量中\n",
      "temporary,不存在于词向量中\n",
      "kill,不存在于词向量中\n",
      "seat,不存在于词向量中\n",
      "interpretation,不存在于词向量中\n",
      "for...|||Well不存在于词向量中\n",
      "Welsh不存在于词向量中\n",
      "a...|||Sounds不存在于词向量中\n",
      "Violet不存在于词向量中\n",
      "ILE不存在于词向量中\n",
      "fit?不存在于词向量中\n",
      "Se-Ti不存在于词向量中\n",
      "Dom.不存在于词向量中\n",
      "would...|||It's不存在于词向量中\n",
      "(older不存在于词向量中\n",
      "strings.不存在于词向量中\n",
      "dilemma,不存在于词向量中\n",
      "Extra不存在于词向量中\n",
      "insanity.不存在于词向量中\n",
      "Theories不存在于词向量中\n",
      "soldier,不存在于词向量中\n",
      "do...|||i不存在于词向量中\n",
      "Pilot不存在于词向量中\n",
      "the...|||Those不存在于词向量中\n",
      "except,不存在于词向量中\n",
      "monotonous,不存在于词向量中\n",
      "favorite)不存在于词向量中\n",
      "(5)不存在于词向量中\n",
      "80.不存在于词向量中\n",
      "libertarian,不存在于词向量中\n",
      "it...|||1.不存在于词向量中\n",
      "I...|||Alright,不存在于词向量中\n",
      "tangent,不存在于词向量中\n",
      "Thom不存在于词向量中\n",
      "wan't不存在于词向量中\n",
      "dont,不存在于词向量中\n",
      "Chronic不存在于词向量中\n",
      "Armstrong不存在于词向量中\n",
      "classmates,不存在于词向量中\n",
      "rapidly.不存在于词向量中\n",
      "extroverts?不存在于词向量中\n",
      "grace.不存在于词向量中\n",
      "Oftentimes不存在于词向量中\n",
      ":D|||Yes不存在于词向量中\n",
      "Beatles,不存在于词向量中\n",
      "closest.不存在于词向量中\n",
      "Significant不存在于词向量中\n",
      "seeking,不存在于词向量中\n",
      "Five,不存在于词向量中\n",
      "quizzes.不存在于词向量中\n",
      "GPA.不存在于词向量中\n",
      "cousins,不存在于词向量中\n",
      "seeing...|||I不存在于词向量中\n",
      "Posting不存在于词向量中\n",
      "as...|||Well,不存在于词向量中\n",
      "hunter,不存在于词向量中\n",
      "Colin不存在于词向量中\n",
      "we...|||You不存在于词向量中\n",
      "heartache.不存在于词向量中\n",
      "memorable.不存在于词向量中\n",
      "banana,不存在于词向量中\n",
      "Sister-不存在于词向量中\n",
      "Friendly不存在于词向量中\n",
      "age.|||I不存在于词向量中\n",
      "approval,不存在于词向量中\n",
      "clowns,不存在于词向量中\n",
      "monsters.不存在于词向量中\n",
      "jumping/skydiving?不存在于词向量中\n",
      "airport.不存在于词向量中\n",
      "party's不存在于词向量中\n",
      "Stuart不存在于词向量中\n",
      "you.|||It's不存在于词向量中\n",
      "ESFJ's,不存在于词向量中\n",
      "have...|||That's不存在于词向量中\n",
      "this???不存在于词向量中\n",
      "it's...|||I've不存在于词向量中\n",
      "master.不存在于词向量中\n",
      "Manhattan不存在于词向量中\n",
      "5'9不存在于词向量中\n",
      "clues.不存在于词向量中\n",
      "tomorrow?不存在于词向量中\n",
      "goofy.不存在于词向量中\n",
      "front,不存在于词向量中\n",
      "you?'不存在于词向量中\n",
      "comforting,不存在于词向量中\n",
      "moderation,不存在于词向量中\n",
      "very...|||I've不存在于词向量中\n",
      "Andrei不存在于词向量中\n",
      "negatively.不存在于词向量中\n",
      "MMORPGs不存在于词向量中\n",
      "Hermann不存在于词向量中\n",
      "cafe?不存在于词向量中\n",
      "knew?不存在于词向量中\n",
      "Analyze不存在于词向量中\n",
      "pessimist,不存在于词向量中\n",
      "things....不存在于词向量中\n",
      "rings.不存在于词向量中\n",
      "be...|||For不存在于词向量中\n",
      "Online,不存在于词向量中\n",
      "Hiddleston不存在于词向量中\n",
      "quirky.不存在于词向量中\n",
      "UFC不存在于词向量中\n",
      "Unconventionality不存在于词向量中\n",
      "absorbed.不存在于词向量中\n",
      "bill.不存在于词向量中\n",
      "nerds.不存在于词向量中\n",
      "Joking不存在于词向量中\n",
      "elementary,不存在于词向量中\n",
      "a...|||Does不存在于词向量中\n",
      "uncaring,不存在于词向量中\n",
      "kicks.不存在于词向量中\n",
      "romance?不存在于词向量中\n",
      "to...|||Because不存在于词向量中\n",
      "I...|||First不存在于词向量中\n",
      "Utah不存在于词向量中\n",
      "tendency.不存在于词向量中\n",
      "pleasing.不存在于词向量中\n",
      "coat,不存在于词向量中\n",
      "hoped.不存在于词向量中\n",
      "fence,不存在于词向量中\n",
      "Smoke不存在于词向量中\n",
      "garage.不存在于词向量中\n",
      "y.o.不存在于词向量中\n",
      "river.不存在于词向量中\n",
      "dat.不存在于词向量中\n",
      "people...|||Yeah,不存在于词向量中\n",
      "nickname,不存在于词向量中\n",
      "Revealed不存在于词向量中\n",
      "Se).不存在于词向量中\n",
      "get...|||It不存在于词向量中\n",
      "myself),不存在于词向量中\n",
      "deadline.不存在于词向量中\n",
      "it??不存在于词向量中\n",
      "so.....不存在于词向量中\n",
      "jewelry.不存在于词向量中\n",
      "honor,不存在于词向量中\n",
      "twelve.不存在于词向量中\n",
      "would...|||I've不存在于词向量中\n",
      "mornings.不存在于词向量中\n",
      "Mulholland不存在于词向量中\n",
      "bruh.不存在于词向量中\n",
      "actually..不存在于词向量中\n",
      "appointment.不存在于词向量中\n",
      "good..不存在于词向量中\n",
      "relationships..不存在于词向量中\n",
      "comprehension.不存在于词向量中\n",
      "books...不存在于词向量中\n",
      "criticized.不存在于词向量中\n",
      "another.|||I不存在于词向量中\n",
      "not,...|||I不存在于词向量中\n",
      "Denver,不存在于词向量中\n",
      "'An不存在于词向量中\n",
      "combat,不存在于词向量中\n",
      "Reaper不存在于词向量中\n",
      "ENFJ.|||I不存在于词向量中\n",
      "Corps不存在于词向量中\n",
      "presents,不存在于词向量中\n",
      "Anton不存在于词向量中\n",
      "ENTJs!不存在于词向量中\n",
      ":P),不存在于词向量中\n",
      "greed,不存在于词向量中\n",
      "deception,不存在于词向量中\n",
      "syndrome,不存在于词向量中\n",
      "Wonderland.不存在于词向量中\n",
      "fart.不存在于词向量中\n",
      "Eyed不存在于词向量中\n",
      ":I不存在于词向量中\n",
      "it's...|||This不存在于词向量中\n",
      "doll,不存在于词向量中\n",
      "Pottermore.不存在于词向量中\n",
      "Arch不存在于词向量中\n",
      "stop...|||I不存在于词向量中\n",
      "Yardiff不存在于词向量中\n",
      "Taxes不存在于词向量中\n",
      "wet.不存在于词向量中\n",
      "slam,不存在于词向量中\n",
      "Release不存在于词向量中\n",
      "Gore不存在于词向量中\n",
      "(love不存在于词向量中\n",
      "observing,不存在于词向量中\n",
      "lovin'不存在于词向量中\n",
      "https://uquiz.com/GnIoID不存在于词向量中\n",
      ":laughing:|||It不存在于词向量中\n",
      "eater,不存在于词向量中\n",
      "Organization不存在于词向量中\n",
      "time.|||My不存在于词向量中\n",
      "Fe-users不存在于词向量中\n",
      "Oh?不存在于词向量中\n",
      "Artificial不存在于词向量中\n",
      "Sunset不存在于词向量中\n",
      "J/P,不存在于词向量中\n",
      "puns.不存在于词向量中\n",
      "Aragorn不存在于词向量中\n",
      "laughed,不存在于词向量中\n",
      "very...|||This不存在于词向量中\n",
      "Cher不存在于词向量中\n",
      "Skyrim.不存在于词向量中\n",
      "the...|||Actually不存在于词向量中\n",
      "Wales不存在于词向量中\n",
      "Aspergers.不存在于词向量中\n",
      "Dunning-Kruger不存在于词向量中\n",
      "and...|||Haha不存在于词向量中\n",
      "ENTJ-不存在于词向量中\n",
      "SPs.不存在于词向量中\n",
      "equals.不存在于词向量中\n",
      "about...|||If不存在于词向量中\n",
      "Shining不存在于词向量中\n",
      "ESFJ-不存在于词向量中\n",
      "Writer,不存在于词向量中\n",
      "Tie不存在于词向量中\n",
      "Heather不存在于词向量中\n",
      "ghosts,不存在于词向量中\n",
      "intense?不存在于词向量中\n",
      "its'不存在于词向量中\n",
      "perfectionism,不存在于词向量中\n",
      "Eyre,不存在于词向量中\n",
      "Go!不存在于词向量中\n",
      "Alex,不存在于词向量中\n",
      "Signs不存在于词向量中\n",
      "acquaintance.不存在于词向量中\n",
      "outside...|||I不存在于词向量中\n",
      "such...不存在于词向量中\n",
      "otherwise.|||I不存在于词向量中\n",
      "updated.不存在于词向量中\n",
      "participating.不存在于词向量中\n",
      "'Has不存在于词向量中\n",
      "(ie,不存在于词向量中\n",
      "earth?不存在于词向量中\n",
      "shit's不存在于词向量中\n",
      "Plastic不存在于词向量中\n",
      "cross.不存在于词向量中\n",
      "...|||This.不存在于词向量中\n",
      "Cooking不存在于词向量中\n",
      "(inferior不存在于词向量中\n",
      "say/do不存在于词向量中\n",
      "xDDD不存在于词向量中\n",
      "photographs,不存在于词向量中\n",
      "Hat不存在于词向量中\n",
      "^^|||You不存在于词向量中\n",
      "Judaism,不存在于词向量中\n",
      ":proud:'不存在于词向量中\n",
      "fruits,不存在于词向量中\n",
      "reach.不存在于词向量中\n",
      "Fluttershy不存在于词向量中\n",
      "Sociology,不存在于词向量中\n",
      "ENFj不存在于词向量中\n",
      "Origins不存在于词向量中\n",
      "Judger不存在于词向量中\n",
      "materials.不存在于词向量中\n",
      "Mt.不存在于词向量中\n",
      "yard.不存在于词向量中\n",
      "easygoing.不存在于词向量中\n",
      "ESTP's.不存在于词向量中\n",
      "=P)不存在于词向量中\n",
      "hospital.不存在于词向量中\n",
      "Nerd不存在于词向量中\n",
      "crimes.不存在于词向量中\n",
      "waste,不存在于词向量中\n",
      "1?不存在于词向量中\n",
      "LED不存在于词向量中\n",
      "work...|||I'm不存在于词向量中\n",
      "Quiz不存在于词向量中\n",
      "hmmm...不存在于词向量中\n",
      "fiction?不存在于词向量中\n",
      "overrated,不存在于词向量中\n",
      ";D.不存在于词向量中\n",
      "geography,不存在于词向量中\n",
      "Gilly不存在于词向量中\n",
      "Google,不存在于词向量中\n",
      "I.Q.不存在于词向量中\n",
      "Brick不存在于词向量中\n",
      "^.^|||I不存在于词向量中\n",
      "easily...不存在于词向量中\n",
      "impulse,不存在于词向量中\n",
      ":kitteh:.不存在于词向量中\n",
      ":wink:|||This不存在于词向量中\n",
      "homosexual.不存在于词向量中\n",
      "sibling,不存在于词向量中\n",
      "bush.不存在于词向量中\n",
      "'thank不存在于词向量中\n",
      "have).不存在于词向量中\n",
      "extroversion,不存在于词向量中\n",
      "insulted.不存在于词向量中\n",
      "Orthodox不存在于词向量中\n",
      "Grimes不存在于词向量中\n",
      "Painting不存在于词向量中\n",
      "Victorian不存在于词向量中\n",
      "INTP).不存在于词向量中\n",
      "Tapatalk|||No不存在于词向量中\n",
      "Hitchhikers不存在于词向量中\n",
      "seek...|||I不存在于词向量中\n",
      ":laughing:|||i不存在于词向量中\n",
      "stuff..不存在于词向量中\n",
      "Dash不存在于词向量中\n",
      "POV.不存在于词向量中\n",
      "Seem不存在于词向量中\n",
      "1-10,不存在于词向量中\n",
      "turmoil.不存在于词向量中\n",
      "Lorelai不存在于词向量中\n",
      "Celebrity不存在于词向量中\n",
      "Hrrm.不存在于词向量中\n",
      "typed?不存在于词向量中\n",
      "Beck不存在于词向量中\n",
      "better.'不存在于词向量中\n",
      "my...|||Wow,不存在于词向量中\n",
      "form?不存在于词向量中\n",
      "...But不存在于词向量中\n",
      "Waits不存在于词向量中\n",
      "ISTP's.不存在于词向量中\n",
      "intuitively.不存在于词向量中\n",
      "equality.不存在于词向量中\n",
      "responsibilities.不存在于词向量中\n",
      "to...|||Right不存在于词向量中\n",
      "closer.不存在于词向量中\n",
      "indifference.不存在于词向量中\n",
      "classes?不存在于词向量中\n",
      "Interest不存在于词向量中\n",
      "Mae不存在于词向量中\n",
      "stick,不存在于词向量中\n",
      "WOW.不存在于词向量中\n",
      "ahah.不存在于词向量中\n",
      "mission,不存在于词向量中\n",
      "Laurie不存在于词向量中\n",
      "colleagues,不存在于词向量中\n",
      "casually.不存在于词向量中\n",
      "INFJ|||Dear不存在于词向量中\n",
      "spiral.不存在于词向量中\n",
      "j/k不存在于词向量中\n",
      "Everything's不存在于词向量中\n",
      "Away.不存在于词向量中\n",
      "Lol...不存在于词向量中\n",
      "Hallows不存在于词向量中\n",
      "opinion.|||I不存在于词向量中\n",
      "'More不存在于词向量中\n",
      "(2nd不存在于词向量中\n",
      "playground.不存在于词向量中\n",
      "Oregon.不存在于词向量中\n",
      "Failed不存在于词向量中\n",
      "Murakami,不存在于词向量中\n",
      "electronics,不存在于词向量中\n",
      "Language,不存在于词向量中\n",
      "agreement,不存在于词向量中\n",
      "Empiricism不存在于词向量中\n",
      "relation.不存在于词向量中\n",
      "enjoyed,不存在于词向量中\n",
      "soulmate,不存在于词向量中\n",
      "Ham不存在于词向量中\n",
      "hide?不存在于词向量中\n",
      "Diego不存在于词向量中\n",
      "am...'不存在于词向量中\n",
      "of...|||They不存在于词向量中\n",
      "the...|||Of不存在于词向量中\n",
      "generation,不存在于词向量中\n",
      "real...不存在于词向量中\n",
      "think...|||This不存在于词向量中\n",
      "in...|||Hey不存在于词向量中\n",
      "DS不存在于词向量中\n",
      "<_<不存在于词向量中\n",
      "OBVIOUS不存在于词向量中\n",
      "Gables不存在于词向量中\n",
      "Badalandabad不存在于词向量中\n",
      "...|||While不存在于词向量中\n",
      "Sensing.不存在于词向量中\n",
      "Potatoes不存在于词向量中\n",
      ":crazy:|||I'm不存在于词向量中\n",
      "Chili不存在于词向量中\n",
      "older)不存在于词向量中\n",
      "-Do不存在于词向量中\n",
      "intuition?不存在于词向量中\n",
      "Freak不存在于词向量中\n",
      "Bernadette不存在于词向量中\n",
      "sentence?不存在于词向量中\n",
      "(had不存在于词向量中\n",
      "bitch?不存在于词向量中\n",
      "to...|||Yes不存在于词向量中\n",
      "what...|||What不存在于词向量中\n",
      "INFJs'不存在于词向量中\n",
      "(!)不存在于词向量中\n",
      "existence?不存在于词向量中\n",
      "ABBA?不存在于词向量中\n",
      "that??不存在于词向量中\n",
      "asses,不存在于词向量中\n",
      "esfj.不存在于词向量中\n",
      "removed.不存在于词向量中\n",
      "be...|||When不存在于词向量中\n",
      "ghost.不存在于词向量中\n",
      "tech.不存在于词向量中\n",
      "Aspergers,不存在于词向量中\n",
      "Dumb不存在于词向量中\n",
      "Cookie不存在于词向量中\n",
      "doin'不存在于词向量中\n",
      "chatty,不存在于词向量中\n",
      "Swing不存在于词向量中\n",
      "plus.不存在于词向量中\n",
      "...|||First不存在于词向量中\n",
      "Talent不存在于词向量中\n",
      ":)|||Good不存在于词向量中\n",
      "remarkable,不存在于词向量中\n",
      "2011,不存在于词向量中\n",
      "Copper不存在于词向量中\n",
      "functions).不存在于词向量中\n",
      "Own不存在于词向量中\n",
      "you...|||Thanks不存在于词向量中\n",
      "TRYING不存在于词向量中\n",
      "take...|||I'm不存在于词向量中\n",
      ":D|||Yeah,不存在于词向量中\n",
      ",so不存在于词向量中\n",
      "Miserables不存在于词向量中\n",
      "Jag不存在于词向量中\n",
      "'nice不存在于词向量中\n",
      "bread.不存在于词向量中\n",
      "PC!不存在于词向量中\n",
      "cookie,不存在于词向量中\n",
      "plan...|||I不存在于词向量中\n",
      "swimmingly.不存在于词向量中\n",
      "Survival不存在于词向量中\n",
      "sacrifice.不存在于词向量中\n",
      "will...|||The不存在于词向量中\n",
      "'social不存在于词向量中\n",
      "cringe.不存在于词向量中\n",
      "archetype,不存在于词向量中\n",
      "snakes,不存在于词向量中\n",
      "Why'd不存在于词向量中\n",
      "Boyfriend:不存在于词向量中\n",
      "to).不存在于词向量中\n",
      "empowering.不存在于词向量中\n",
      "c'mon不存在于词向量中\n",
      ";)|||So不存在于词向量中\n",
      "disaster,不存在于词向量中\n",
      "facebook?不存在于词向量中\n",
      "Commander不存在于词向量中\n",
      ":)|||Okay,不存在于词向量中\n",
      "apple,不存在于词向量中\n",
      "Anakin不存在于词向量中\n",
      "Leo,不存在于词向量中\n",
      "Steampunk不存在于词向量中\n",
      "Cafebot不存在于词向量中\n",
      "celebrities.不存在于词向量中\n",
      "9s.不存在于词向量中\n",
      "j/p不存在于词向量中\n",
      "posts.|||I不存在于词向量中\n",
      "Gloria不存在于词向量中\n",
      "influences.不存在于词向量中\n",
      "studying?不存在于词向量中\n",
      "..I'm不存在于词向量中\n",
      "Guy,不存在于词向量中\n",
      "calculated,不存在于词向量中\n",
      "(haha不存在于词向量中\n",
      "poetry?不存在于词向量中\n",
      "TALKING不存在于词向量中\n",
      "you?!不存在于词向量中\n",
      "sword,不存在于词向量中\n",
      "Therapist不存在于词向量中\n",
      "Gemini.不存在于词向量中\n",
      "Etc.不存在于词向量中\n",
      "nurture.不存在于词向量中\n",
      "ENFPS不存在于词向量中\n",
      "Tapatalk|||If不存在于词向量中\n",
      "pursuits,不存在于词向量中\n",
      "or...|||In不存在于词向量中\n",
      "INTJ/ENTJ不存在于词向量中\n",
      "windows,不存在于词向量中\n",
      "Realize不存在于词向量中\n",
      "Fingers不存在于词向量中\n",
      "It,不存在于词向量中\n",
      "others).不存在于词向量中\n",
      "practices.不存在于词向量中\n",
      "SI不存在于词向量中\n",
      "converse,不存在于词向量中\n",
      "unless...|||I不存在于词向量中\n",
      "illnesses,不存在于词向量中\n",
      "effectively.不存在于词向量中\n",
      "eachother's不存在于词向量中\n",
      "Tall不存在于词向量中\n",
      "'Love不存在于词向量中\n",
      "package.不存在于词向量中\n",
      "Dark,不存在于词向量中\n",
      "harshly,不存在于词向量中\n",
      "passive-aggressive,不存在于词向量中\n",
      "Hardcore不存在于词向量中\n",
      "(leaning不存在于词向量中\n",
      "Mainly,不存在于词向量中\n",
      "giggles.不存在于词向量中\n",
      "freshman,不存在于词向量中\n",
      "Appreciation不存在于词向量中\n",
      "engaging.不存在于词向量中\n",
      "solving,不存在于词向量中\n",
      "Fe-dom,不存在于词向量中\n",
      "Paula不存在于词向量中\n",
      "Fyodor不存在于词向量中\n",
      "weeks)不存在于词向量中\n",
      "sleeping?不存在于词向量中\n",
      "likeable.不存在于词向量中\n",
      "Infp,不存在于词向量中\n",
      "make-up,不存在于词向量中\n",
      "Tri不存在于词向量中\n",
      "speaking)不存在于词向量中\n",
      "...|||And不存在于词向量中\n",
      "meHate不存在于词向量中\n",
      "Perfectly不存在于词向量中\n",
      "Pewdiepie不存在于词向量中\n",
      "WWII不存在于词向量中\n",
      "Socionics:不存在于词向量中\n",
      "yet).不存在于词向量中\n",
      "All...|||I不存在于词向量中\n",
      "life....不存在于词向量中\n",
      "collection,不存在于词向量中\n",
      "husband?不存在于词向量中\n",
      "cute...不存在于词向量中\n",
      "hours?不存在于词向量中\n",
      "INTJ-INFP不存在于词向量中\n",
      "ENFP-INTJ不存在于词向量中\n",
      "quickly?不存在于词向量中\n",
      "teams.不存在于词向量中\n",
      "find...|||I'm不存在于词向量中\n",
      "warmth,不存在于词向量中\n",
      "them|||I不存在于词向量中\n",
      "Venture不存在于词向量中\n",
      "bath,不存在于词向量中\n",
      "that...|||Dear不存在于词向量中\n",
      "Chicago,不存在于词向量中\n",
      "Satoshi不存在于词向量中\n",
      "XD|||You不存在于词向量中\n",
      "horribly.不存在于词向量中\n",
      "nurturing.不存在于词向量中\n",
      "WATCH不存在于词向量中\n",
      "egg.不存在于词向量中\n",
      "Mar不存在于词向量中\n",
      "existed,不存在于词向量中\n",
      "from..不存在于词向量中\n",
      "delivery.不存在于词向量中\n",
      "Bars不存在于词向量中\n",
      "reasons)不存在于词向量中\n",
      "tape.不存在于词向量中\n",
      "why?|||I不存在于词向量中\n",
      "Bugs不存在于词向量中\n",
      "o'不存在于词向量中\n",
      "America?不存在于词向量中\n",
      "Transgender不存在于词向量中\n",
      "when...|||If不存在于词向量中\n",
      "can...|||As不存在于词向量中\n",
      "Saitama不存在于词向量中\n",
      "France.不存在于词向量中\n",
      "cynicism,不存在于词向量中\n",
      "Smell不存在于词向量中\n",
      "one.)不存在于词向量中\n",
      "Penn不存在于词向量中\n",
      "Initially,不存在于词向量中\n",
      "God...不存在于词向量中\n",
      "Bet不存在于词向量中\n",
      "NO,不存在于词向量中\n",
      "SHUT不存在于词向量中\n",
      "Failure不存在于词向量中\n",
      "ability?不存在于词向量中\n",
      "Note.不存在于词向量中\n",
      "Chill不存在于词向量中\n",
      ":(|||Yeah,不存在于词向量中\n",
      "you??不存在于词向量中\n",
      "world'不存在于词向量中\n",
      "MOM不存在于词向量中\n",
      "Origin不存在于词向量中\n",
      "AC/DC不存在于词向量中\n",
      "typical.不存在于词向量中\n",
      "Terence不存在于词向量中\n",
      "Provided不存在于词向量中\n",
      "NJ不存在于词向量中\n",
      "Monsieur不存在于词向量中\n",
      "face?不存在于词向量中\n",
      "essentially.不存在于词向量中\n",
      "Yin不存在于词向量中\n",
      "intentionally,不存在于词向量中\n",
      "(looking不存在于词向量中\n",
      "for...|||Thanks不存在于词向量中\n",
      "bipolar.不存在于词向量中\n",
      "apple.不存在于词向量中\n",
      "Desktop不存在于词向量中\n",
      ":D,不存在于词向量中\n",
      "title)不存在于词向量中\n",
      "'on不存在于词向量中\n",
      "Man:不存在于词向量中\n",
      "theoretically,不存在于词向量中\n",
      "(INFJ),不存在于词向量中\n",
      "September,不存在于词向量中\n",
      "iNtuitive.不存在于词向量中\n",
      "winning.不存在于词向量中\n",
      "Failing不存在于词向量中\n",
      "Guessing不存在于词向量中\n",
      "nearby.不存在于词向量中\n",
      "loaded.不存在于词向量中\n",
      "Salt不存在于词向量中\n",
      "Very.不存在于词向量中\n",
      "Guilty不存在于词向量中\n",
      "determined.不存在于词向量中\n",
      "Council不存在于词向量中\n",
      "Jungle不存在于词向量中\n",
      "Types,不存在于词向量中\n",
      "trail,不存在于词向量中\n",
      "'your不存在于词向量中\n",
      "plan?不存在于词向量中\n",
      "goin'不存在于词向量中\n",
      "a...|||At不存在于词向量中\n",
      "avoidance.不存在于词向量中\n",
      "ambitious.不存在于词向量中\n",
      "'who不存在于词向量中\n",
      "speakers.不存在于词向量中\n",
      "Eden不存在于词向量中\n",
      "Bubbles不存在于词向量中\n",
      "Ms不存在于词向量中\n",
      "Perspective不存在于词向量中\n",
      "Wizards不存在于词向量中\n",
      "Jungs不存在于词向量中\n",
      "reassuring.不存在于词向量中\n",
      "animal?不存在于词向量中\n",
      "IJs不存在于词向量中\n",
      "manipulate.不存在于词向量中\n",
      "Luffy不存在于词向量中\n",
      "Explosions不存在于词向量中\n",
      "hehe|||I不存在于词向量中\n",
      "encyclopedia|||I不存在于词向量中\n",
      "Comment不存在于词向量中\n",
      "wrong..不存在于词向量中\n",
      "Si)不存在于词向量中\n",
      "programs,不存在于词向量中\n",
      "masculinity.不存在于词向量中\n",
      "mankind,不存在于词向量中\n",
      "underdeveloped.不存在于词向量中\n",
      "borderline.不存在于词向量中\n",
      "POST不存在于词向量中\n",
      "Confident不存在于词向量中\n",
      "electronica,不存在于词向量中\n",
      ":happy:|||Thank不存在于词向量中\n",
      "open...|||I不存在于词向量中\n",
      "sweetness,不存在于词向量中\n",
      "-...'不存在于词向量中\n",
      "artwork,不存在于词向量中\n",
      "Niles不存在于词向量中\n",
      "I...|||Wow,不存在于词向量中\n",
      "remember...不存在于词向量中\n",
      "one...|||That's不存在于词向量中\n",
      "I'm...|||So不存在于词向量中\n",
      "it.|||i不存在于词向量中\n",
      "holiday.不存在于词向量中\n",
      "educated,不存在于词向量中\n",
      "autumn.不存在于词向量中\n",
      "behold,不存在于词向量中\n",
      "or...|||So不存在于词向量中\n",
      "elements,不存在于词向量中\n",
      "(Thanks不存在于词向量中\n",
      "I麓ll不存在于词向量中\n",
      "knife.不存在于词向量中\n",
      "stuff),不存在于词向量中\n",
      "'About不存在于词向量中\n",
      "introverted...|||I不存在于词向量中\n",
      "Minus不存在于词向量中\n",
      "So:不存在于词向量中\n",
      "spots.不存在于词向量中\n",
      "Tool,不存在于词向量中\n",
      "workers.不存在于词向量中\n",
      "a.k.a.不存在于词向量中\n",
      "Engineering,不存在于词向量中\n",
      "do....不存在于词向量中\n",
      "body...|||I不存在于词向量中\n",
      "Bane不存在于词向量中\n",
      "system.|||I不存在于词向量中\n",
      "-Anna|||I不存在于词向量中\n",
      "Sparks不存在于词向量中\n",
      "Nathan不存在于词向量中\n",
      "Generous不存在于词向量中\n",
      "mate?不存在于词向量中\n",
      "their...|||This不存在于词向量中\n",
      "this...|||This不存在于词向量中\n",
      "be...|||That不存在于词向量中\n",
      "product,不存在于词向量中\n",
      "Wars)不存在于词向量中\n",
      "shine.不存在于词向量中\n",
      "Ahem.不存在于词向量中\n",
      "spirits.不存在于词向量中\n",
      "diagnosis,不存在于词向量中\n",
      "efforts.不存在于词向量中\n",
      "estp's不存在于词向量中\n",
      "Calculate不存在于词向量中\n",
      "I...|||While不存在于词向量中\n",
      "Club,不存在于词向量中\n",
      "(...|||I不存在于词向量中\n",
      "Laughter不存在于词向量中\n",
      "Judgers不存在于词向量中\n",
      "(doing不存在于词向量中\n",
      "trilogy.不存在于词向量中\n",
      "posts?不存在于词向量中\n",
      "Cold.不存在于词向量中\n",
      "Economic不存在于词向量中\n",
      "TMI,不存在于词向量中\n",
      "Lightning不存在于词向量中\n",
      "Historical不存在于词向量中\n",
      "jumping,不存在于词向量中\n",
      "-To不存在于词向量中\n",
      "about...|||You不存在于词向量中\n",
      "papers.不存在于词向量中\n",
      "John:不存在于词向量中\n",
      "2012,不存在于词向量中\n",
      "unexpected,不存在于词向量中\n",
      "to...|||Yes!不存在于词向量中\n",
      "Bloom不存在于词向量中\n",
      "masterpiece.不存在于词向量中\n",
      "Li不存在于词向量中\n",
      "tritypes,不存在于词向量中\n",
      "Dee不存在于词向量中\n",
      "undergrad,不存在于词向量中\n",
      "5054N不存在于词向量中\n",
      "Size:不存在于词向量中\n",
      "S's.不存在于词向量中\n",
      "Intps不存在于词向量中\n",
      "Jinsei不存在于词向量中\n",
      "|||||||||||||||||||||||||||不存在于词向量中\n",
      "Eagle|||I不存在于词向量中\n",
      "here.|||Greetings不存在于词向量中\n",
      "Lunar.|||I不存在于词向量中\n",
      "GT-S5830i不存在于词向量中\n",
      "are...|||She不存在于词向量中\n",
      "activities?不存在于词向量中\n",
      "thumb,不存在于词向量中\n",
      "Jet不存在于词向量中\n",
      "and...|||Have不存在于词向量中\n",
      "think...|||My不存在于词向量中\n",
      "Fun,不存在于词向量中\n",
      "fast.|||I不存在于词向量中\n",
      "ironically.不存在于词向量中\n",
      "Freelance不存在于词向量中\n",
      "here.|||You不存在于词向量中\n",
      "Cold,不存在于词向量中\n",
      "Observe不存在于词向量中\n",
      "Violent不存在于词向量中\n",
      "Guitar,不存在于词向量中\n",
      "face.|||I不存在于词向量中\n",
      "ACT,不存在于词向量中\n",
      "know...|||That's不存在于词向量中\n",
      "boys'不存在于词向量中\n",
      "God)不存在于词向量中\n",
      "been...'不存在于词向量中\n",
      "proper,不存在于词向量中\n",
      "Plans不存在于词向量中\n",
      "Fascinating.不存在于词向量中\n",
      "geometry,不存在于词向量中\n",
      "unattainable.不存在于词向量中\n",
      "Soren不存在于词向量中\n",
      "primary,不存在于词向量中\n",
      "lady's不存在于词向量中\n",
      "classics,不存在于词向量中\n",
      "Burns不存在于词向量中\n",
      "me.|||Thank不存在于词向量中\n",
      "'so不存在于词向量中\n",
      "RDJ不存在于词向量中\n",
      "Meant不存在于词向量中\n",
      "Explore不存在于词向量中\n",
      "at...|||If不存在于词向量中\n",
      "Driver不存在于词向量中\n",
      "...|||^不存在于词向量中\n",
      "Achieve不存在于词向量中\n",
      "that.|||Why不存在于词向量中\n",
      "trouble...|||I不存在于词向量中\n",
      "posture,不存在于词向量中\n",
      "well...|||I'm不存在于词向量中\n",
      "out...|||The不存在于词向量中\n",
      "meditating,不存在于词向量中\n",
      "dominant?不存在于词向量中\n",
      "INTJ-ish不存在于词向量中\n",
      "thanked,不存在于词向量中\n",
      "better)不存在于词向量中\n",
      "guide,不存在于词向量中\n",
      "cynic,不存在于词向量中\n",
      "furthermore,不存在于词向量中\n",
      "motto,不存在于词向量中\n",
      "they...|||Oh不存在于词向量中\n",
      "Manic不存在于词向量中\n",
      "of...|||Welcome不存在于词向量中\n",
      "arm,不存在于词向量中\n",
      "ant,不存在于词向量中\n",
      "Minute不存在于词向量中\n",
      "Adrian不存在于词向量中\n",
      "theft,不存在于词向量中\n",
      "domain.不存在于词向量中\n",
      "job.|||I不存在于词向量中\n",
      "comparisons.不存在于词向量中\n",
      "babies?不存在于词向量中\n",
      "excess,不存在于词向量中\n",
      "too.|||What不存在于词向量中\n",
      "the...|||Could不存在于词向量中\n",
      "reckless,不存在于词向量中\n",
      "be...|||Yes,不存在于词向量中\n",
      "Sygma不存在于词向量中\n",
      "trust...|||I不存在于词向量中\n",
      "Klein不存在于词向量中\n",
      "killing,不存在于词向量中\n",
      "homes.不存在于词向量中\n",
      "Emo不存在于词向量中\n",
      "regularly?不存在于词向量中\n",
      "Persian不存在于词向量中\n",
      "Brief不存在于词向量中\n",
      "smooth.不存在于词向量中\n",
      "discussing.不存在于词向量中\n",
      "seriousness.不存在于词向量中\n",
      "in...|||Do不存在于词向量中\n",
      "project?不存在于词向量中\n",
      "for...|||That不存在于词向量中\n",
      "lol|||That不存在于词向量中\n",
      "prayer.不存在于词向量中\n",
      "penises.不存在于词向量中\n",
      "Davis不存在于词向量中\n",
      "chills.不存在于词向量中\n",
      "obvious...不存在于词向量中\n",
      "Feast不存在于词向量中\n",
      "surprise)不存在于词向量中\n",
      "stoned.不存在于词向量中\n",
      "DMT不存在于词向量中\n",
      "sizes,不存在于词向量中\n",
      "Rhett不存在于词向量中\n",
      "my...|||Dear不存在于词向量中\n",
      "camp,不存在于词向量中\n",
      "Much.不存在于词向量中\n",
      "Walls不存在于词向量中\n",
      "predators.不存在于词向量中\n",
      "instructor,不存在于词向量中\n",
      "Mila不存在于词向量中\n",
      "Kunis不存在于词向量中\n",
      "Psychiatry不存在于词向量中\n",
      "at...|||When不存在于词向量中\n",
      "equipment,不存在于词向量中\n",
      "etc...)不存在于词向量中\n",
      "Landscape不存在于词向量中\n",
      "Communications不存在于词向量中\n",
      "Associate's不存在于词向量中\n",
      "Degree不存在于词向量中\n",
      "Wisconsin不存在于词向量中\n",
      "words)不存在于词向量中\n",
      "Extroverts,不存在于词向量中\n",
      "Banner不存在于词向量中\n",
      "(Go不存在于词向量中\n",
      "cliff.不存在于词向量中\n",
      "NAME不存在于词向量中\n",
      "lust,不存在于词向量中\n",
      "How,不存在于词向量中\n",
      "opponent's不存在于词向量中\n",
      "Articles不存在于词向量中\n",
      "is...|||We不存在于词向量中\n",
      "unbalanced,不存在于词向量中\n",
      "does)不存在于词向量中\n",
      "INTJ?|||I不存在于词向量中\n",
      "secondary,不存在于词向量中\n",
      "adult?不存在于词向量中\n",
      "(Sometimes不存在于词向量中\n",
      "often..不存在于词向量中\n",
      "issues...不存在于词向量中\n",
      "a...|||-不存在于词向量中\n",
      "rephrase.不存在于词向量中\n",
      "Kafka,不存在于词向量中\n",
      "uncertainty.不存在于词向量中\n",
      "(only)不存在于词向量中\n",
      "those.|||I不存在于词向量中\n",
      "Magnetic不存在于词向量中\n",
      "Unfortunate不存在于词向量中\n",
      "humor?不存在于词向量中\n",
      "-John不存在于词向量中\n",
      "slut.不存在于词向量中\n",
      "screwed.不存在于词向量中\n",
      "Pit不存在于词向量中\n",
      "sweaters.不存在于词向量中\n",
      "potato,不存在于词向量中\n",
      "Ummm不存在于词向量中\n",
      "N)不存在于词向量中\n",
      "ooh,不存在于词向量中\n",
      "character...不存在于词向量中\n",
      "Gamma不存在于词向量中\n",
      "a...|||Sorry不存在于词向量中\n",
      "typings,不存在于词向量中\n",
      "talk...不存在于词向量中\n",
      "Immortal不存在于词向量中\n",
      "fictional,不存在于词向量中\n",
      "girls...不存在于词向量中\n",
      "do...|||Not不存在于词向量中\n",
      "over)不存在于词向量中\n",
      "Feb不存在于词向量中\n",
      "Chart不存在于词向量中\n",
      "technical,不存在于词向量中\n",
      "lack,不存在于词向量中\n",
      "Active不存在于词向量中\n",
      "Gaming不存在于词向量中\n",
      "filter.不存在于词向量中\n",
      ")'不存在于词向量中\n",
      "superpowers,不存在于词向量中\n",
      "When,不存在于词向量中\n",
      "flying.不存在于词向量中\n",
      "flag.不存在于词向量中\n",
      "extroverted...不存在于词向量中\n",
      "spotlight.不存在于词向量中\n",
      "xNTJ,不存在于词向量中\n",
      "horrendous.不存在于词向量中\n",
      "Marius不存在于词向量中\n",
      "TiNe不存在于词向量中\n",
      "Ti's不存在于词向量中\n",
      "or...|||Oh不存在于词向量中\n",
      "Te-doms不存在于词向量中\n",
      "Eternity不存在于词向量中\n",
      "(unlike不存在于词向量中\n",
      "invention,不存在于词向量中\n",
      "I'm...|||Why不存在于词向量中\n",
      "-How不存在于词向量中\n",
      "here.|||My不存在于词向量中\n",
      "SillaSY不存在于词向量中\n",
      "BC不存在于词向量中\n",
      "crossed.不存在于词向量中\n",
      "knowledgeable,不存在于词向量中\n",
      "open-minded.不存在于词向量中\n",
      "coast.不存在于词向量中\n",
      "me...|||What不存在于词向量中\n",
      "there|||I不存在于词向量中\n",
      "NOT:不存在于词向量中\n",
      "attention..不存在于词向量中\n",
      "humans?不存在于词向量中\n",
      "problem..不存在于词向量中\n",
      "better|||I不存在于词向量中\n",
      "to...|||Hey,不存在于词向量中\n",
      "system?不存在于词向量中\n",
      "(Also,不存在于词向量中\n",
      "N's,不存在于词向量中\n",
      "variation.不存在于词向量中\n",
      "sharks,不存在于词向量中\n",
      "newbie.不存在于词向量中\n",
      "I..不存在于词向量中\n",
      "(On不存在于词向量中\n",
      "CRAP不存在于词向量中\n",
      "injustice,不存在于词向量中\n",
      "gambling.不存在于词向量中\n",
      "rewarding,不存在于词向量中\n",
      "Kinesthetic不存在于词向量中\n",
      "Cure,不存在于词向量中\n",
      "Backstreet不存在于词向量中\n",
      ";p|||I不存在于词向量中\n",
      "real)不存在于词向量中\n",
      "decided,不存在于词向量中\n",
      "Check.不存在于词向量中\n",
      "INFJ...|||I不存在于词向量中\n",
      "outfit.不存在于词向量中\n",
      "I...|||Lol,不存在于词向量中\n",
      "bf's不存在于词向量中\n",
      "channel,不存在于词向量中\n",
      "make...|||I'm不存在于词向量中\n",
      "ENFP.|||I'm不存在于词向量中\n",
      "fate?不存在于词向量中\n",
      "of...|||While不存在于词向量中\n",
      "NES不存在于词向量中\n",
      "shooting,不存在于词向量中\n",
      "cold...不存在于词向量中\n",
      "so...|||Do不存在于词向量中\n",
      "Biggest不存在于词向量中\n",
      "Gluttony不存在于词向量中\n",
      "Deadpool不存在于词向量中\n",
      "it?|||I'm不存在于词向量中\n",
      "yikes.不存在于词向量中\n",
      "actually.|||I不存在于词向量中\n",
      "Pratchett不存在于词向量中\n",
      "Cradle不存在于词向量中\n",
      "nazi.不存在于词向量中\n",
      "prank.不存在于词向量中\n",
      "myth.不存在于词向量中\n",
      "average)不存在于词向量中\n",
      "imbalance.不存在于词向量中\n",
      "definitely...|||I'm不存在于词向量中\n",
      "months.|||I不存在于词向量中\n",
      "lavender.不存在于词向量中\n",
      "Alzheimer's不存在于词向量中\n",
      "tell)不存在于词向量中\n",
      "1).不存在于词向量中\n",
      "roof.不存在于词向量中\n",
      "fine.|||I不存在于词向量中\n",
      "here.|||Welcome不存在于词向量中\n",
      "subconsciously.不存在于词向量中\n",
      "killers.不存在于词向量中\n",
      "shut.不存在于词向量中\n",
      "register.不存在于词向量中\n",
      "'Go不存在于词向量中\n",
      "...just不存在于词向量中\n",
      "Website不存在于词向量中\n",
      "Carrots不存在于词向量中\n",
      "Fi/Ne不存在于词向量中\n",
      "awesomeness.不存在于词向量中\n",
      "hotel,不存在于词向量中\n",
      "INFx,不存在于词向量中\n",
      "efforts,不存在于词向量中\n",
      "c'est不存在于词向量中\n",
      "(everyone不存在于词向量中\n",
      "relative,不存在于词向量中\n",
      "emotions)不存在于词向量中\n",
      "female...|||I不存在于词向量中\n",
      "really...|||Yeah,不存在于词向量中\n",
      "outside?不存在于词向量中\n",
      "pencil.不存在于词向量中\n",
      "Buddy不存在于词向量中\n",
      "vain.不存在于词向量中\n",
      "raise.不存在于词向量中\n",
      "Arms不存在于词向量中\n",
      "own...|||The不存在于词向量中\n",
      "thoughts.|||I不存在于词向量中\n",
      "age)不存在于词向量中\n",
      "-...|||How不存在于词向量中\n",
      "pig.不存在于词向量中\n",
      "Das不存在于词向量中\n",
      "wavy,不存在于词向量中\n",
      ">.<|||I不存在于词向量中\n",
      "Locked不存在于词向量中\n",
      "yard,不存在于词向量中\n",
      "Wrote不存在于词向量中\n",
      "cozy,不存在于词向量中\n",
      "wallpaper,不存在于词向量中\n",
      "Dwarf不存在于词向量中\n",
      "Exit不存在于词向量中\n",
      "(random不存在于词向量中\n",
      "xSFJ.不存在于词向量中\n",
      "ExFJ.不存在于词向量中\n",
      "ones'不存在于词向量中\n",
      "Push不存在于词向量中\n",
      "Guilt不存在于词向量中\n",
      "truthful,不存在于词向量中\n",
      "practice?不存在于词向量中\n",
      "different).不存在于词向量中\n",
      "me...|||Thank不存在于词向量中\n",
      ":)|||when不存在于词向量中\n",
      "share...|||I不存在于词向量中\n",
      "working...|||I不存在于词向量中\n",
      "chuckled不存在于词向量中\n",
      "bunny,不存在于词向量中\n",
      "Partners:不存在于词向量中\n",
      "rising,不存在于词向量中\n",
      "WISH不存在于词向量中\n",
      "was...|||A不存在于词向量中\n",
      "by...|||It不存在于词向量中\n",
      "YEARS不存在于词向量中\n",
      "biggest,不存在于词向量中\n",
      "stance,不存在于词向量中\n",
      "the...|||Good不存在于词向量中\n",
      "mysticism.不存在于词向量中\n",
      "them...'不存在于词向量中\n",
      "best!|||I不存在于词向量中\n",
      "style=color:不存在于词向量中\n",
      "McCartney不存在于词向量中\n",
      "space...不存在于词向量中\n",
      "Religions不存在于词向量中\n",
      "Herbert不存在于词向量中\n",
      "Salmon不存在于词向量中\n",
      "him....|||I不存在于词向量中\n",
      "this.|||Oh不存在于词向量中\n",
      "transition.不存在于词向量中\n",
      "yelling,不存在于词向量中\n",
      "the...|||^不存在于词向量中\n",
      "apology.不存在于词向量中\n",
      "ma'am.不存在于词向量中\n",
      "screaming,不存在于词向量中\n",
      "be...|||Oh,不存在于词向量中\n",
      "YOU!!!不存在于词向量中\n",
      "Trail不存在于词向量中\n",
      "kids.|||I不存在于词向量中\n",
      "touchy.不存在于词向量中\n",
      "Goat不存在于词向量中\n",
      "regular,不存在于词向量中\n",
      "visuals,不存在于词向量中\n",
      "sensations,不存在于词向量中\n",
      "you'r不存在于词向量中\n",
      "charged,不存在于词向量中\n",
      "received,不存在于词向量中\n",
      "Braveheart不存在于词向量中\n",
      "though.|||There不存在于词向量中\n",
      "emptiness,不存在于词向量中\n",
      "boss's不存在于词向量中\n",
      "Atheist,不存在于词向量中\n",
      "occurring.不存在于词向量中\n",
      "exactly...|||I不存在于词向量中\n",
      "Sun:不存在于词向量中\n",
      "rationally,不存在于词向量中\n",
      "Kamen不存在于词向量中\n",
      "patients,不存在于词向量中\n",
      "Ni-Ti.不存在于词向量中\n",
      "(All不存在于词向量中\n",
      "requests.不存在于词向量中\n",
      "doom.不存在于词向量中\n",
      "left...|||I不存在于词向量中\n",
      "YEAH!不存在于词向量中\n",
      "an...|||I'd不存在于词向量中\n",
      "and...|||Then不存在于词向量中\n",
      "is...|||I'd不存在于词向量中\n",
      "primary.不存在于词向量中\n",
      "outlook,不存在于词向量中\n",
      "it's...|||Thanks不存在于词向量中\n",
      "INTJ's?不存在于词向量中\n",
      "convey.不存在于词向量中\n",
      "this...|||Not不存在于词向量中\n",
      "popular?不存在于词向量中\n",
      "the...|||this不存在于词向量中\n",
      "stops.不存在于词向量中\n",
      "Ur不存在于词向量中\n",
      "..but不存在于词向量中\n",
      "you.|||I've不存在于词向量中\n",
      "than...|||My不存在于词向量中\n",
      "conscience,不存在于词向量中\n",
      "detachment.不存在于词向量中\n",
      "fragile,不存在于词向量中\n",
      "WHILE不存在于词向量中\n",
      "abandoned,不存在于词向量中\n",
      "suspicious,不存在于词向量中\n",
      "varies.不存在于词向量中\n",
      "I'm...|||For不存在于词向量中\n",
      "Perseus不存在于词向量中\n",
      "choir,不存在于词向量中\n",
      "Youngest不存在于词向量中\n",
      "truck.不存在于词向量中\n",
      "also)不存在于词向量中\n",
      "Hawaii,不存在于词向量中\n",
      "come...'不存在于词向量中\n",
      "minimum.不存在于词向量中\n",
      "Creating不存在于词向量中\n",
      "PerC's不存在于词向量中\n",
      "(Who不存在于词向量中\n",
      "memo.不存在于词向量中\n",
      "incident.不存在于词向量中\n",
      "enneagrams.不存在于词向量中\n",
      "extremes,不存在于词向量中\n",
      "quite...不存在于词向量中\n",
      "but...|||As不存在于词向量中\n",
      "distractions.不存在于词向量中\n",
      "Shakespeare,不存在于词向量中\n",
      "ten.不存在于词向量中\n",
      "Kept不存在于词向量中\n",
      "major?不存在于词向量中\n",
      "Boundaries不存在于词向量中\n",
      "me.|||Yeah,不存在于词向量中\n",
      "grief,不存在于词向量中\n",
      "redundant,不存在于词向量中\n",
      ":tongue:|||This不存在于词向量中\n",
      "are...|||That不存在于词向量中\n",
      "(literally)不存在于词向量中\n",
      "contribution.不存在于词向量中\n",
      "contributions.不存在于词向量中\n",
      "Recent不存在于词向量中\n",
      "YOU?不存在于词向量中\n",
      ":happy:|||Hi不存在于词向量中\n",
      "his...|||The不存在于词向量中\n",
      "ISxJ.不存在于词向量中\n",
      "Miracles不存在于词向量中\n",
      "Rory不存在于词向量中\n",
      "66.667不存在于词向量中\n",
      "this'不存在于词向量中\n",
      "Desperate不存在于词向量中\n",
      "ANd不存在于词向量中\n",
      "(lol).不存在于词向量中\n",
      "skype,不存在于词向量中\n",
      "from)不存在于词向量中\n",
      "of...|||Hi!不存在于词向量中\n",
      "Mother.不存在于词向量中\n",
      "Daughter,不存在于词向量中\n",
      "you...|||They不存在于词向量中\n",
      "are...|||That's不存在于词向量中\n",
      "offend,不存在于词向量中\n",
      "'INFJ不存在于词向量中\n",
      "Hm..不存在于词向量中\n",
      "Connery不存在于词向量中\n",
      "Developer不存在于词向量中\n",
      "AGAIN不存在于词向量中\n",
      "place...|||I不存在于词向量中\n",
      "slang.不存在于词向量中\n",
      "UR不存在于词向量中\n",
      "agency.不存在于词向量中\n",
      "Zeus不存在于词向量中\n",
      "grade)不存在于词向量中\n",
      "it...|||How不存在于词向量中\n",
      "Umm...不存在于词向量中\n",
      "woman...不存在于词向量中\n",
      "mental.不存在于词向量中\n",
      "planner,不存在于词向量中\n",
      "consensus,不存在于词向量中\n",
      "Weak不存在于词向量中\n",
      "competent.不存在于词向量中\n",
      "Assertive不存在于词向量中\n",
      "J...不存在于词向量中\n",
      "Elite不存在于词向量中\n",
      "me...|||i不存在于词向量中\n",
      "figures,不存在于词向量中\n",
      "ISIS不存在于词向量中\n",
      "Thailand不存在于词向量中\n",
      "Trinity不存在于词向量中\n",
      "Kennedy不存在于词向量中\n",
      "Miracle不存在于词向量中\n",
      "Mask,不存在于词向量中\n",
      "parents...|||I不存在于词向量中\n",
      "80s,不存在于词向量中\n",
      "snob.不存在于词向量中\n",
      "June.不存在于词向量中\n",
      "Freeman不存在于词向量中\n",
      "GIFs不存在于词向量中\n",
      "evaluation.不存在于词向量中\n",
      "Hopkins不存在于词向量中\n",
      "and...|||Sometimes不存在于词向量中\n",
      "Phoenix.不存在于词向量中\n",
      "BC,不存在于词向量中\n",
      "with..不存在于词向量中\n",
      "once..不存在于词向量中\n",
      "xxTP不存在于词向量中\n",
      "drop.不存在于词向量中\n",
      "anyways.|||I不存在于词向量中\n",
      "Dunno,不存在于词向量中\n",
      "Photoshop.不存在于词向量中\n",
      "Even...|||I不存在于词向量中\n",
      "upset?不存在于词向量中\n",
      "Au不存在于词向量中\n",
      "the...|||Lol,不存在于词向量中\n",
      "weights,不存在于词向量中\n",
      ";)|||In不存在于词向量中\n",
      "'ENTP不存在于词向量中\n",
      "unhealthy)不存在于词向量中\n",
      "scattered,不存在于词向量中\n",
      "Malkovich不存在于词向量中\n",
      "'Nice不存在于词向量中\n",
      "After...|||I不存在于词向量中\n",
      "THERE不存在于词向量中\n",
      "detrimental.不存在于词向量中\n",
      "any...|||The不存在于词向量中\n",
      "inwardly?不存在于词向量中\n",
      "outwardly?不存在于词向量中\n",
      "P?不存在于词向量中\n",
      "of...|||As不存在于词向量中\n",
      "3,000不存在于词向量中\n",
      "combination?不存在于词向量中\n",
      "Lavigne不存在于词向量中\n",
      "Traffic不存在于词向量中\n",
      "test...|||I不存在于词向量中\n",
      "labor,不存在于词向量中\n",
      "warning.不存在于词向量中\n",
      "(N不存在于词向量中\n",
      "(T不存在于词向量中\n",
      "Constant不存在于词向量中\n",
      "claims.不存在于词向量中\n",
      "example),不存在于词向量中\n",
      "brighter.不存在于词向量中\n",
      "puppies.不存在于词向量中\n",
      "pal.不存在于词向量中\n",
      "primarily.不存在于词向量中\n",
      "smartass,不存在于词向量中\n",
      "cock.不存在于词向量中\n",
      "'S'不存在于词向量中\n",
      "Limited不存在于词向量中\n",
      "xNTJ.不存在于词向量中\n",
      "often).不存在于词向量中\n",
      "story).不存在于词向量中\n",
      "(Fi).不存在于词向量中\n",
      "Excel不存在于词向量中\n",
      "Hammer不存在于词向量中\n",
      "Tapatalk|||Is不存在于词向量中\n",
      "Hole不存在于词向量中\n",
      "their...|||The不存在于词向量中\n",
      "time.|||If不存在于词向量中\n",
      "Last.fm不存在于词向量中\n",
      "Boys,不存在于词向量中\n",
      "Luna,不存在于词向量中\n",
      "(1=不存在于词向量中\n",
      "few...不存在于词向量中\n",
      "Namely不存在于词向量中\n",
      "Mac.不存在于词向量中\n",
      "professors.不存在于词向量中\n",
      "get...|||It's不存在于词向量中\n",
      "ESTJ).不存在于词向量中\n",
      "accents,不存在于词向量中\n",
      "mannerisms,不存在于词向量中\n",
      "are...|||Yes不存在于词向量中\n",
      "Also...不存在于词向量中\n",
      "unicorns,不存在于词向量中\n",
      "compassionate.不存在于词向量中\n",
      "Flirt不存在于词向量中\n",
      "mean.|||I不存在于词向量中\n",
      "Clever不存在于词向量中\n",
      "situational,不存在于词向量中\n",
      "overseas,不存在于词向量中\n",
      "dear...不存在于词向量中\n",
      "go...|||My不存在于词向量中\n",
      "E/I,不存在于词向量中\n",
      "S/N,不存在于词向量中\n",
      "(b/c不存在于词向量中\n",
      ":tongue:|||Oh不存在于词向量中\n",
      "Summer,不存在于词向量中\n",
      "Bob's不存在于词向量中\n",
      "sayin'不存在于词向量中\n",
      "figured,不存在于词向量中\n",
      "be...|||It's不存在于词向量中\n",
      "span,不存在于词向量中\n",
      "Originally,不存在于词向量中\n",
      "ExFx不存在于词向量中\n",
      "Deadly不存在于词向量中\n",
      "Alchemist:不存在于词向量中\n",
      "FJ.不存在于词向量中\n",
      "MuChApArAdOx不存在于词向量中\n",
      "belt.不存在于词向量中\n",
      "Construction不存在于词向量中\n",
      "Megan不存在于词向量中\n",
      "you...|||We不存在于词向量中\n",
      "soda,不存在于词向量中\n",
      "BRING不存在于词向量中\n",
      "ugly?不存在于词向量中\n",
      "she...|||It's不存在于词向量中\n",
      "resolution.不存在于词向量中\n",
      "Loneliness不存在于词向量中\n",
      "bull,不存在于词向量中\n",
      "I've...|||I've不存在于词向量中\n",
      "Google+不存在于词向量中\n",
      "me.|||Well,不存在于词向量中\n",
      "online...不存在于词向量中\n",
      "Uni.不存在于词向量中\n",
      "or...|||1.不存在于词向量中\n",
      "Beloved不存在于词向量中\n",
      "simpler.不存在于词向量中\n",
      "impact,不存在于词向量中\n",
      "today..不存在于词向量中\n",
      "Diligent不存在于词向量中\n",
      "perspective...不存在于词向量中\n",
      "paid,不存在于词向量中\n",
      "outdoors.不存在于词向量中\n",
      "confrontational,不存在于词向量中\n",
      "it!|||I'm不存在于词向量中\n",
      "month)不存在于词向量中\n",
      "sixteen.不存在于词向量中\n",
      "(Let's不存在于词向量中\n",
      "Stone.不存在于词向量中\n",
      "Cook不存在于词向量中\n",
      ":)|||what不存在于词向量中\n",
      "Inquisitive不存在于词向量中\n",
      "ExTx不存在于词向量中\n",
      "you!|||I'm不存在于词向量中\n",
      "Brown's不存在于词向量中\n",
      "LOST不存在于词向量中\n",
      "festivals,不存在于词向量中\n",
      "Communism不存在于词向量中\n",
      "second...|||I不存在于词向量中\n",
      "Grayson不存在于词向量中\n",
      "Mitt不存在于词向量中\n",
      "videos)不存在于词向量中\n",
      "catchy,不存在于词向量中\n",
      "Mason不存在于词向量中\n",
      "ESTJ|||I不存在于词向量中\n",
      "questioning.不存在于词向量中\n",
      "banter.不存在于词向量中\n",
      "mistypes.不存在于词向量中\n",
      "It...'不存在于词向量中\n",
      "Work?不存在于词向量中\n",
      "duality,不存在于词向量中\n",
      "'Like不存在于词向量中\n",
      "Sophia不存在于词向量中\n",
      "Milo不存在于词向量中\n",
      "psychological,不存在于词向量中\n",
      "be),不存在于词向量中\n",
      "contract,不存在于词向量中\n",
      "and...|||Yes.不存在于词向量中\n",
      "uncle,不存在于词向量中\n",
      "Edison不存在于词向量中\n",
      "social...|||I'm不存在于词向量中\n",
      "heal,不存在于词向量中\n",
      "Order:不存在于词向量中\n",
      "urge,不存在于词向量中\n",
      "to...|||Here不存在于词向量中\n",
      "Patrol不存在于词向量中\n",
      "Afterwards,不存在于词向量中\n",
      ":laughing:|||Yes不存在于词向量中\n",
      "their...|||My不存在于词向量中\n",
      "cynic.不存在于词向量中\n",
      "mind.|||My不存在于词向量中\n",
      "departments.不存在于词向量中\n",
      "boxes.不存在于词向量中\n",
      "do...|||Yes,不存在于词向量中\n",
      "dudes,不存在于词向量中\n",
      "I...|||Being不存在于词向量中\n",
      "symbols.不存在于词向量中\n",
      "attractiveness.不存在于词向量中\n",
      "hard)不存在于词向量中\n",
      "outwardly.不存在于词向量中\n",
      "Golf不存在于词向量中\n",
      "celebrity.不存在于词向量中\n",
      "waves,不存在于词向量中\n",
      "INFP-INTJ不存在于词向量中\n",
      "lefty,不存在于词向量中\n",
      "winning,不存在于词向量中\n",
      "Ritalin不存在于词向量中\n",
      "dubstep.不存在于词向量中\n",
      "(Type不存在于词向量中\n",
      "me.|||So不存在于词向量中\n",
      ":kitteh:|||I've不存在于词向量中\n",
      "we...|||If不存在于词向量中\n",
      "a...|||You've不存在于词向量中\n",
      "OMG.不存在于词向量中\n",
      "Shades不存在于词向量中\n",
      "Rat不存在于词向量中\n",
      "once.|||I不存在于词向量中\n",
      "Utterly不存在于词向量中\n",
      "Lighten不存在于词向量中\n",
      "(cuz不存在于词向量中\n",
      "treat.不存在于词向量中\n",
      "Ik不存在于词向量中\n",
      "Opposites不存在于词向量中\n",
      "anything...|||I'm不存在于词向量中\n",
      "NASA不存在于词向量中\n",
      "charismatic.不存在于词向量中\n",
      "Eleven不存在于词向量中\n",
      "Sleepy不存在于词向量中\n",
      "Elsa,不存在于词向量中\n",
      "techno,不存在于词向量中\n",
      "unemployed,不存在于词向量中\n",
      "positive?不存在于词向量中\n",
      "designs.不存在于词向量中\n",
      "second.|||I不存在于词向量中\n",
      "Likely:不存在于词向量中\n",
      "minutes)不存在于词向量中\n",
      "Tumblr.不存在于词向量中\n",
      "minutes...|||I不存在于词向量中\n",
      "it...|||Not不存在于词向量中\n",
      "crack.不存在于词向量中\n",
      "and...|||And不存在于词向量中\n",
      "Lama不存在于词向量中\n",
      "hugged,不存在于词向量中\n",
      "disrespect.不存在于词向量中\n",
      "do...|||When不存在于词向量中\n",
      "Lions不存在于词向量中\n",
      "XD|||This不存在于词向量中\n",
      "Grave不存在于词向量中\n",
      "rut,不存在于词向量中\n",
      "that...|||Oh,不存在于词向量中\n",
      "Louie不存在于词向量中\n",
      "Piece,不存在于词向量中\n",
      "get...|||I've不存在于词向量中\n",
      "Knightley不存在于词向量中\n",
      "dominant...|||I不存在于词向量中\n",
      "c,不存在于词向量中\n",
      "imagine...|||I不存在于词向量中\n",
      "'Depends不存在于词向量中\n",
      "respect...|||I不存在于词向量中\n",
      "forgiving.不存在于词向量中\n",
      "welcome!|||I不存在于词向量中\n",
      "have...|||It's不存在于词向量中\n",
      "questions.|||I不存在于词向量中\n",
      "brutal.不存在于词向量中\n",
      "determinism,不存在于词向量中\n",
      "atheism,不存在于词向量中\n",
      "'are不存在于词向量中\n",
      "pensive,不存在于词向量中\n",
      "though.|||If不存在于词向量中\n",
      "out...|||I've不存在于词向量中\n",
      "estj.不存在于词向量中\n",
      "Infp's不存在于词向量中\n",
      "fe,不存在于词向量中\n",
      "enfj's不存在于词向量中\n",
      "materialistic,不存在于词向量中\n",
      "STAND不存在于词向量中\n",
      "hesitation,不存在于词向量中\n",
      "believed,不存在于词向量中\n",
      "timeless,不存在于词向量中\n",
      "being...|||The不存在于词向量中\n",
      "FWIW,不存在于词向量中\n",
      "on...|||Yeah,不存在于词向量中\n",
      "nicer.不存在于词向量中\n",
      "body's不存在于词向量中\n",
      "feel...|||My不存在于词向量中\n",
      "Spin不存在于词向量中\n",
      "Jekyll不存在于词向量中\n",
      "Budapest不存在于词向量中\n",
      "magazines,不存在于词向量中\n",
      "manners.不存在于词向量中\n",
      "Also,...|||I不存在于词向量中\n",
      "talked.不存在于词向量中\n",
      "them.|||This不存在于词向量中\n",
      "Restitution不存在于词向量中\n",
      "Genghis不存在于词向量中\n",
      ":p|||My不存在于词向量中\n",
      "Cheers.不存在于词向量中\n",
      "get...不存在于词向量中\n",
      "horribly,不存在于词向量中\n",
      "it.|||And不存在于词向量中\n",
      "Art.不存在于词向量中\n",
      "...|||Here不存在于词向量中\n",
      ":)|||Are不存在于词向量中\n",
      "...|||Something不存在于词向量中\n",
      "think...|||You不存在于词向量中\n",
      "used?不存在于词向量中\n",
      "experiencing,不存在于词向量中\n",
      "that...|||Do不存在于词向量中\n",
      ":laughing:|||For不存在于词向量中\n",
      "enfjs,不存在于词向量中\n",
      "INFJs)不存在于词向量中\n",
      "TLC不存在于词向量中\n",
      "7.)不存在于词向量中\n",
      "to...|||Actually不存在于词向量中\n",
      "I`ve不存在于词向量中\n",
      "are).不存在于词向量中\n",
      "violated.不存在于词向量中\n",
      "admirable.不存在于词向量中\n",
      "GIVE不存在于词向量中\n",
      "Cynical不存在于词向量中\n",
      "understands,不存在于词向量中\n",
      "Hire不存在于词向量中\n",
      "Someday不存在于词向量中\n",
      "vacuum.不存在于词向量中\n",
      "(Only不存在于词向量中\n",
      "Imo,不存在于词向量中\n",
      "join?不存在于词向量中\n",
      "tank.不存在于词向量中\n",
      "vicinity.不存在于词向量中\n",
      "And...|||You不存在于词向量中\n",
      "pocket,不存在于词向量中\n",
      "Sisters不存在于词向量中\n",
      "Bunny,不存在于词向量中\n",
      "hasn't,不存在于词向量中\n",
      "daydream?不存在于词向量中\n",
      "sure).不存在于词向量中\n",
      "antidepressants.不存在于词向量中\n",
      "into...'不存在于词向量中\n",
      "well.|||The不存在于词向量中\n",
      "Samaritan不存在于词向量中\n",
      "assistance.不存在于词向量中\n",
      "Savior不存在于词向量中\n",
      "wrote?不存在于词向量中\n",
      "work!|||I不存在于词向量中\n",
      "anyways...不存在于词向量中\n",
      "Bravo.不存在于词向量中\n",
      "Poe's不存在于词向量中\n",
      "hint,不存在于词向量中\n",
      "not...|||Not不存在于词向量中\n",
      "near.不存在于词向量中\n",
      "watched,不存在于词向量中\n",
      "factual,不存在于词向量中\n",
      "over...|||I'm不存在于词向量中\n",
      "some)不存在于词向量中\n",
      "The...|||You不存在于词向量中\n",
      "subway,不存在于词向量中\n",
      "board?不存在于词向量中\n",
      "what's...|||I不存在于词向量中\n",
      "playing...|||I不存在于词向量中\n",
      "Rogan不存在于词向量中\n",
      "Fi-users不存在于词向量中\n",
      "maker,不存在于词向量中\n",
      "NF?不存在于词向量中\n",
      "essays,不存在于词向量中\n",
      "killer,不存在于词向量中\n",
      "bad'不存在于词向量中\n",
      "hiding,不存在于词向量中\n",
      "takes.不存在于词向量中\n",
      "wacky,不存在于词向量中\n",
      "wood,不存在于词向量中\n",
      "as...|||Some不存在于词向量中\n",
      "dance?不存在于词向量中\n",
      "Fill不存在于词向量中\n",
      "kitten.不存在于词向量中\n",
      "Fixing不存在于词向量中\n",
      "Guy.不存在于词向量中\n",
      "plate.不存在于词向量中\n",
      "shared,不存在于词向量中\n",
      "our...|||It不存在于词向量中\n",
      "listens.不存在于词向量中\n",
      "do...|||I've不存在于词向量中\n",
      "like...|||If不存在于词向量中\n",
      "Weren't不存在于词向量中\n",
      "masturbation.不存在于词向量中\n",
      "of...|||From不存在于词向量中\n",
      "iSTJ不存在于词向量中\n",
      "he...|||Well,不存在于词向量中\n",
      "Happily不存在于词向量中\n",
      ":P|||If不存在于词向量中\n",
      "know...|||My不存在于词向量中\n",
      "slim.不存在于词向量中\n",
      "brother?不存在于词向量中\n",
      "established,不存在于词向量中\n",
      "kids)不存在于词向量中\n",
      "forgetful,不存在于词向量中\n",
      "Beer不存在于词向量中\n",
      "it...|||Wow,不存在于词向量中\n",
      "Asians不存在于词向量中\n",
      "firm.不存在于词向量中\n",
      "2...|||I不存在于词向量中\n",
      "Salsa不存在于词向量中\n",
      "breakdown,不存在于词向量中\n",
      "joke.|||I不存在于词向量中\n",
      "one...|||The不存在于词向量中\n",
      "Sending不存在于词向量中\n",
      "you...|||Hi不存在于词向量中\n",
      "Chris,不存在于词向量中\n",
      "...|||Did不存在于词向量中\n",
      "things).不存在于词向量中\n",
      "appearances.不存在于词向量中\n",
      "Evil.不存在于词向量中\n",
      "'T'不存在于词向量中\n",
      "mornings,不存在于词向量中\n",
      "tricks,不存在于词向量中\n",
      "rabbit.不存在于词向量中\n",
      "my...|||Don't不存在于词向量中\n",
      "Janelle不存在于词向量中\n",
      "foot.不存在于词向量中\n",
      ":laughing:|||That's不存在于词向量中\n",
      ";)|||If不存在于词向量中\n",
      "of...|||To不存在于词向量中\n",
      "considerate.不存在于词向量中\n",
      "hermit.不存在于词向量中\n",
      "me|||The不存在于词向量中\n",
      "Smooth不存在于词向量中\n",
      "Snooki不存在于词向量中\n",
      "truthfully,不存在于词向量中\n",
      "racing.不存在于词向量中\n",
      "Army.不存在于词向量中\n",
      "Request不存在于词向量中\n",
      "saying.|||I不存在于词向量中\n",
      "transfer,不存在于词向量中\n",
      "act...|||I不存在于词向量中\n",
      "House:不存在于词向量中\n",
      "forum....不存在于词向量中\n",
      "Moments不存在于词向量中\n",
      "CBD不存在于词向量中\n",
      "(+不存在于词向量中\n",
      "Linda不存在于词向量中\n",
      "things...|||Not不存在于词向量中\n",
      "just...|||How不存在于词向量中\n",
      "Liam不存在于词向量中\n",
      "INFP/INTP不存在于词向量中\n",
      "than...'不存在于词向量中\n",
      "Immature不存在于词向量中\n",
      "batteries.不存在于词向量中\n",
      "Chopin,不存在于词向量中\n",
      "exercise?不存在于词向量中\n",
      "Being...|||I不存在于词向量中\n",
      "sx.不存在于词向量中\n",
      "hug...不存在于词向量中\n",
      "Perpetual不存在于词向量中\n",
      "panic,不存在于词向量中\n",
      "did/do不存在于词向量中\n",
      "inward,不存在于词向量中\n",
      "(late不存在于词向量中\n",
      "follows.不存在于词向量中\n",
      "sensible.不存在于词向量中\n",
      "unreliable,不存在于词向量中\n",
      "now.|||It不存在于词向量中\n",
      "very...|||The不存在于词向量中\n",
      "side)不存在于词向量中\n",
      "one...|||Well,不存在于词向量中\n",
      "my...|||Most不存在于词向量中\n",
      "way.)不存在于词向量中\n",
      "all.'不存在于词向量中\n",
      "18)不存在于词向量中\n",
      "Isis不存在于词向量中\n",
      "insane?不存在于词向量中\n",
      "wander.不存在于词向量中\n",
      "Belgium.不存在于词向量中\n",
      "change...|||I不存在于词向量中\n",
      "boxing.不存在于词向量中\n",
      ":wink:)不存在于词向量中\n",
      "ENTPs'不存在于词向量中\n",
      "drag.不存在于词向量中\n",
      "physics?不存在于词向量中\n",
      "could.|||I不存在于词向量中\n",
      "intjs.不存在于词向量中\n",
      "lawyer.不存在于词向量中\n",
      "(post不存在于词向量中\n",
      "back)不存在于词向量中\n",
      "Jelly不存在于词向量中\n",
      "elegant.不存在于词向量中\n",
      "Fantasia不存在于词向量中\n",
      "Genetic不存在于词向量中\n",
      ":tongue:|||It's不存在于词向量中\n",
      "poison,不存在于词向量中\n",
      ":)|||1.不存在于词向量中\n",
      ":D|||Your不存在于词向量中\n",
      "an...|||Do不存在于词向量中\n",
      "JK,不存在于词向量中\n",
      "Emotion不存在于词向量中\n",
      "being...|||It不存在于词向量中\n",
      "movie's不存在于词向量中\n",
      "worse?不存在于词向量中\n",
      "he...|||So不存在于词向量中\n",
      "Friday!不存在于词向量中\n",
      "organised.不存在于词向量中\n",
      "Wendy不存在于词向量中\n",
      "Edmund不存在于词向量中\n",
      "answer's不存在于词向量中\n",
      "helping,不存在于词向量中\n",
      "ISTJs:不存在于词向量中\n",
      "Fi-user不存在于词向量中\n",
      "(Based不存在于词向量中\n",
      "weird...|||I不存在于词向量中\n",
      "mild,不存在于词向量中\n",
      "THERE.不存在于词向量中\n",
      "procrastinating,不存在于词向量中\n",
      "Fuck,不存在于词向量中\n",
      "A5500-F不存在于词向量中\n",
      "Tapatalk|||Well不存在于词向量中\n",
      "my...|||-不存在于词向量中\n",
      "...|||-不存在于词向量中\n",
      "device.不存在于词向量中\n",
      "pursue.不存在于词向量中\n",
      "(lost不存在于词向量中\n",
      "irritable.不存在于词向量中\n",
      "Dresden不存在于词向量中\n",
      "Destroy不存在于词向量中\n",
      "Pennsylvania不存在于词向量中\n",
      "emails.不存在于词向量中\n",
      "blast.不存在于词向量中\n",
      "up,...|||I不存在于词向量中\n",
      "PERSONALITY不存在于词向量中\n",
      "changed?不存在于词向量中\n",
      "monsters,不存在于词向量中\n",
      "Concerning不存在于词向量中\n",
      "Mickey不存在于词向量中\n",
      "heated.不存在于词向量中\n",
      "of).不存在于词向量中\n",
      "bin,不存在于词向量中\n",
      "Coincidentally不存在于词向量中\n",
      "bi,不存在于词向量中\n",
      "zombies.不存在于词向量中\n",
      "an...|||Just不存在于词向量中\n",
      "analyzing.不存在于词向量中\n",
      "coincidence?不存在于词向量中\n",
      "settled.不存在于词向量中\n",
      "cigarette,不存在于词向量中\n",
      "reproduce,不存在于词向量中\n",
      "naivety.不存在于词向量中\n",
      "harassment.不存在于词向量中\n",
      "u?不存在于词向量中\n",
      "Brazil.不存在于词向量中\n",
      "carefree,不存在于词向量中\n",
      "Mask不存在于词向量中\n",
      "conversation...|||I不存在于词向量中\n",
      "composition,不存在于词向量中\n",
      "Mm.不存在于词向量中\n",
      "#2,不存在于词向量中\n",
      "flaw?不存在于词向量中\n",
      "'weird'不存在于词向量中\n",
      "political,不存在于词向量中\n",
      "conform.不存在于词向量中\n",
      "Beautifully不存在于词向量中\n",
      "the...|||Who不存在于词向量中\n",
      "college),不存在于词向量中\n",
      "helping...|||I不存在于词向量中\n",
      "guidelines,不存在于词向量中\n",
      "Can't.不存在于词向量中\n",
      "that...|||But不存在于词向量中\n",
      "stations,不存在于词向量中\n",
      "pushy.不存在于词向量中\n",
      "He's...|||I不存在于词向量中\n",
      "Wide不存在于词向量中\n",
      "um..不存在于词向量中\n",
      "Rebellious不存在于词向量中\n",
      "Genre:不存在于词向量中\n",
      "Touching不存在于词向量中\n",
      "Narcissists不存在于词向量中\n",
      "poop,不存在于词向量中\n",
      "sex...|||I不存在于词向量中\n",
      "Ne...|||I不存在于词向量中\n",
      "(close不存在于词向量中\n",
      "male...不存在于词向量中\n",
      "cartoons,不存在于词向量中\n",
      "just...|||If不存在于词向量中\n",
      "Jones,不存在于词向量中\n",
      "can't...|||The不存在于词向量中\n",
      "sx/so,不存在于词向量中\n",
      "'Please不存在于词向量中\n",
      "Suzumiya不存在于词向量中\n",
      "and...|||Welcome不存在于词向量中\n",
      "Fe.|||I不存在于词向量中\n",
      "punk.不存在于词向量中\n",
      "entrepreneur,不存在于词向量中\n",
      "(btw不存在于词向量中\n",
      "divide.不存在于词向量中\n",
      "Assassins不存在于词向量中\n",
      "king.不存在于词向量中\n",
      ":D|||Thank不存在于词向量中\n",
      "his...|||A不存在于词向量中\n",
      "dysfunctional,不存在于词向量中\n",
      "Revolutionary不存在于词向量中\n",
      "Obama,不存在于词向量中\n",
      "it.|||Well不存在于词向量中\n",
      "am),不存在于词向量中\n",
      "validated.不存在于词向量中\n",
      "Haba不存在于词向量中\n",
      "x.不存在于词向量中\n",
      "Lad.不存在于词向量中\n",
      "college...不存在于词向量中\n",
      "linear,不存在于词向量中\n",
      "Grizzly不存在于词向量中\n",
      "that.|||It不存在于词向量中\n",
      "one...|||If不存在于词向量中\n",
      "they...|||You不存在于词向量中\n",
      "fuzzy.不存在于词向量中\n",
      "Illogical不存在于词向量中\n",
      "about...|||My不存在于词向量中\n",
      "spree.不存在于词向量中\n",
      "attitudes,不存在于词向量中\n",
      "Stripes不存在于词向量中\n",
      "(try不存在于词向量中\n",
      "game...不存在于词向量中\n",
      "Remind不存在于词向量中\n",
      "Grass不存在于词向量中\n",
      "truths,不存在于词向量中\n",
      "philosophers.不存在于词向量中\n",
      "Hikaru不存在于词向量中\n",
      "SUCK不存在于词向量中\n",
      "bolded,不存在于词向量中\n",
      "heavens.不存在于词向量中\n",
      "damn...不存在于词向量中\n",
      "meat?不存在于词向量中\n",
      "PROCESS不存在于词向量中\n",
      "getting,不存在于词向量中\n",
      "device,不存在于词向量中\n",
      ":D|||Well不存在于词向量中\n",
      "characteristic.不存在于词向量中\n",
      "bs.不存在于词向量中\n",
      "Sim不存在于词向量中\n",
      "at...|||A不存在于词向量中\n",
      "WWE不存在于词向量中\n",
      "WW2不存在于词向量中\n",
      "performing,不存在于词向量中\n",
      "control...|||I不存在于词向量中\n",
      "we.不存在于词向量中\n",
      "INTx.不存在于词向量中\n",
      "newbie,不存在于词向量中\n",
      "Profession:不存在于词向量中\n",
      "Hobby不存在于词向量中\n",
      "as...|||Well不存在于词向量中\n",
      "Kenny不存在于词向量中\n",
      "Fountainhead不存在于词向量中\n",
      "young.|||I不存在于词向量中\n",
      "YOU!!不存在于词向量中\n",
      "where?不存在于词向量中\n",
      "term...|||I不存在于词向量中\n",
      "'dark不存在于词向量中\n",
      "patronizing,不存在于词向量中\n",
      "also...|||My不存在于词向量中\n",
      "the...|||Last不存在于词向量中\n",
      "touchy-feely.不存在于词向量中\n",
      "though.|||Yeah,不存在于词向量中\n",
      "-_-|||I不存在于词向量中\n",
      "hard.|||I不存在于词向量中\n",
      "toilet,不存在于词向量中\n",
      "e-mail.不存在于词向量中\n",
      "relief,不存在于词向量中\n",
      "I...|||lol不存在于词向量中\n",
      "CANT不存在于词向量中\n",
      "anything).不存在于词向量中\n",
      "generic,不存在于词向量中\n",
      "on...|||Just不存在于词向量中\n",
      "Hilarious.不存在于词向量中\n",
      "nice...|||I不存在于词向量中\n",
      "me...|||Thanks不存在于词向量中\n",
      "make...|||The不存在于词向量中\n",
      "chain,不存在于词向量中\n",
      "Toyota不存在于词向量中\n",
      "Happy,不存在于词向量中\n",
      "societies,不存在于词向量中\n",
      "you're...|||You不存在于词向量中\n",
      "Turkey不存在于词向量中\n",
      "cranky.不存在于词向量中\n",
      "you...|||Why不存在于词向量中\n",
      "Misty不存在于词向量中\n",
      "quieter,不存在于词向量中\n",
      "hobby?不存在于词向量中\n",
      "Authentic不存在于词向量中\n",
      "explaining.不存在于词向量中\n",
      "Dual不存在于词向量中\n",
      "P.S不存在于词向量中\n",
      "YOURSELF不存在于词向量中\n",
      "Remove不存在于词向量中\n",
      "Everdeen不存在于词向量中\n",
      "deSouza不存在于词向量中\n",
      "Trivial不存在于词向量中\n",
      "generalize,不存在于词向量中\n",
      "prom,不存在于词向量中\n",
      "party...不存在于词向量中\n",
      "alley,不存在于词向量中\n",
      "took...|||I不存在于词向量中\n",
      "the...|||Because不存在于词向量中\n",
      "ENTPS不存在于词向量中\n",
      "The...|||My不存在于词向量中\n",
      "sensations.不存在于词向量中\n",
      "your...|||That's不存在于词向量中\n",
      "grateful.不存在于词向量中\n",
      "whether...|||I不存在于词向量中\n",
      "to...|||At不存在于词向量中\n",
      "this...|||A不存在于词向量中\n",
      "'fake'不存在于词向量中\n",
      "TONS不存在于词向量中\n",
      "consistently.不存在于词向量中\n",
      "SOs不存在于词向量中\n",
      "Inability不存在于词向量中\n",
      "for...|||Some不存在于词向量中\n",
      "STJ's不存在于词向量中\n",
      "fatigue.不存在于词向量中\n",
      "colleges.不存在于词向量中\n",
      "cool?不存在于词向量中\n",
      "Deal不存在于词向量中\n",
      "an...|||As不存在于词向量中\n",
      "them.|||I've不存在于词向量中\n",
      "choice)不存在于词向量中\n",
      "smile...不存在于词向量中\n",
      "AB不存在于词向量中\n",
      "KC不存在于词向量中\n",
      "'feeling'不存在于词向量中\n",
      "Counting不存在于词向量中\n",
      "awesome|||I不存在于词向量中\n",
      "(hard不存在于词向量中\n",
      "meetup.com不存在于词向量中\n",
      "SciFi不存在于词向量中\n",
      "punctuation.不存在于词向量中\n",
      "overbearing.不存在于词向量中\n",
      "battles,不存在于词向量中\n",
      "(8不存在于词向量中\n",
      "6?不存在于词向量中\n",
      "(make不存在于词向量中\n",
      "nature)不存在于词向量中\n",
      "situation)不存在于词向量中\n",
      "(near不存在于词向量中\n",
      "masterpiece,不存在于词向量中\n",
      "Ashes不存在于词向量中\n",
      "bud.不存在于词向量中\n",
      "sh*t.不存在于词向量中\n",
      "judgers.不存在于词向量中\n",
      "Halloween.不存在于词向量中\n",
      "and...|||People不存在于词向量中\n",
      "don't...|||1.不存在于词向量中\n",
      "counterpart.不存在于词向量中\n",
      "Philippines不存在于词向量中\n",
      "Clothes不存在于词向量中\n",
      "Yes?不存在于词向量中\n",
      "with...|||A不存在于词向量中\n",
      "forum)不存在于词向量中\n",
      "xNTP.不存在于词向量中\n",
      "'Because不存在于词向量中\n",
      "burden,不存在于词向量中\n",
      "Robots不存在于词向量中\n",
      "Owen不存在于词向量中\n",
      "auras.不存在于词向量中\n",
      "Rachmaninoff,不存在于词向量中\n",
      "have.|||I不存在于词向量中\n",
      "resume,不存在于词向量中\n",
      "(way不存在于词向量中\n",
      "past)不存在于词向量中\n",
      "Nihilism不存在于词向量中\n",
      "creep,不存在于词向量中\n",
      "exposure.不存在于词向量中\n",
      "S/O不存在于词向量中\n",
      "it...it不存在于词向量中\n",
      "(Yeah,不存在于词向量中\n",
      "history...不存在于词向量中\n",
      "Delicious不存在于词向量中\n",
      "Intj's不存在于词向量中\n",
      "forum!|||I不存在于词向量中\n",
      "thrill.不存在于词向量中\n",
      "Ni...不存在于词向量中\n",
      "trying)不存在于词向量中\n",
      "just...|||I'd不存在于词向量中\n",
      "Portuguese,不存在于词向量中\n",
      "people's...|||I不存在于词向量中\n",
      "quoted.不存在于词向量中\n",
      "(Doctor不存在于词向量中\n",
      "respectable,不存在于词向量中\n",
      "too.|||Thank不存在于词向量中\n",
      "(or...|||I不存在于词向量中\n",
      "owners.不存在于词向量中\n",
      ":D|||No不存在于词向量中\n",
      "on...|||Yeah不存在于词向量中\n",
      "Hitchcock不存在于词向量中\n",
      "chef,不存在于词向量中\n",
      "Jolie,不存在于词向量中\n",
      "opinions...不存在于词向量中\n",
      ";)|||i不存在于词向量中\n",
      "psychiatrist.不存在于词向量中\n",
      "Fix不存在于词向量中\n",
      "my...|||To不存在于词向量中\n",
      "IE不存在于词向量中\n",
      "but...|||Your不存在于词向量中\n",
      "raining,不存在于词向量中\n",
      "Self-Sufficiency:不存在于词向量中\n",
      "mastermind,不存在于词向量中\n",
      "teams,不存在于词向量中\n",
      "Blame不存在于词向量中\n",
      "wtf?不存在于词向量中\n",
      "Mexicans不存在于词向量中\n",
      "like...|||That不存在于词向量中\n",
      "betrayed.不存在于词向量中\n",
      ">.>|||I不存在于词向量中\n",
      "inconsiderate,不存在于词向量中\n",
      "'Hey,不存在于词向量中\n",
      "And:不存在于词向量中\n",
      "panda.不存在于词向量中\n",
      "means.|||I不存在于词向量中\n",
      "complex?不存在于词向量中\n",
      "Amon不存在于词向量中\n",
      "Stereotypes不存在于词向量中\n",
      "'Being不存在于词向量中\n",
      "URL.不存在于词向量中\n",
      "Alpha,不存在于词向量中\n",
      "TiNi不存在于词向量中\n",
      "too...|||The不存在于词向量中\n",
      "Turning不存在于词向量中\n",
      "reggae,不存在于词向量中\n",
      "etc..)不存在于词向量中\n",
      "Analyzing不存在于词向量中\n",
      "Myers-Briggs,不存在于词向量中\n",
      "does),不存在于词向量中\n",
      ":proud:|||This不存在于词向量中\n",
      "sin,不存在于词向量中\n",
      "or...|||Well,不存在于词向量中\n",
      "KISS不存在于词向量中\n",
      ":)|||One不存在于词向量中\n",
      "Indifferent不存在于词向量中\n",
      "hype.不存在于词向量中\n",
      "switch,不存在于词向量中\n",
      "up...|||Well,不存在于词向量中\n",
      "guard,不存在于词向量中\n",
      "out),不存在于词向量中\n",
      "Kat不存在于词向量中\n",
      "with...|||Most不存在于词向量中\n",
      "they...|||As不存在于词向量中\n",
      "dancer,不存在于词向量中\n",
      "know...|||This不存在于词向量中\n",
      "uniqueness,不存在于词向量中\n",
      "though.)不存在于词向量中\n",
      "Users不存在于词向量中\n",
      "Volume不存在于词向量中\n",
      "the...|||There's不存在于词向量中\n",
      "contexts,不存在于词向量中\n",
      "Singer不存在于词向量中\n",
      "Continued不存在于词向量中\n",
      "Galactica不存在于词向量中\n",
      "this.'不存在于词向量中\n",
      ";)|||How不存在于词向量中\n",
      "pub,不存在于词向量中\n",
      "that'不存在于词向量中\n",
      "on...|||Maybe不存在于词向量中\n",
      "concentrate.不存在于词向量中\n",
      "Rocket不存在于词向量中\n",
      "WARNING不存在于词向量中\n",
      "it.|||Maybe不存在于词向量中\n",
      "the...|||Very不存在于词向量中\n",
      "noticing.不存在于词向量中\n",
      "Mentalist不存在于词向量中\n",
      "Everywhere不存在于词向量中\n",
      "Psychologist不存在于词向量中\n",
      "the...|||Sure,不存在于词向量中\n",
      "selfless.不存在于词向量中\n",
      "car...|||I不存在于词向量中\n",
      ":tongue:|||So不存在于词向量中\n",
      "style.|||I不存在于词向量中\n",
      "Theoretical不存在于词向量中\n",
      "Rene不存在于词向量中\n",
      "Nerd,不存在于词向量中\n",
      "recently?不存在于词向量中\n",
      "him...|||I'm不存在于词向量中\n",
      "insomnia.不存在于词向量中\n",
      "IS.不存在于词向量中\n",
      "monster,不存在于词向量中\n",
      "stumped.不存在于词向量中\n",
      "hm,不存在于词向量中\n",
      "Con不存在于词向量中\n",
      "says?不存在于词向量中\n",
      "Beginning不存在于词向量中\n",
      "Stalking不存在于词向量中\n",
      "...|||oh不存在于词向量中\n",
      ",but不存在于词向量中\n",
      "Anti不存在于词向量中\n",
      "you...|||i不存在于词向量中\n",
      "bone.不存在于词向量中\n",
      "people...|||i不存在于词向量中\n",
      "classics.不存在于词向量中\n",
      "I...|||-不存在于词向量中\n",
      "know'不存在于词向量中\n",
      "fill.不存在于词向量中\n",
      "Fame不存在于词向量中\n",
      "anticipation,不存在于词向量中\n",
      "weird)不存在于词向量中\n",
      "Nice,不存在于词向量中\n",
      "ASK不存在于词向量中\n",
      "Not.不存在于词向量中\n",
      ":D|||I'll不存在于词向量中\n",
      "Macabre不存在于词向量中\n",
      "Youtube,不存在于词向量中\n",
      "capabilities.不存在于词向量中\n",
      "ExTP,不存在于词向量中\n",
      "Contrast不存在于词向量中\n",
      "explode,不存在于词向量中\n",
      "INTPs...不存在于词向量中\n",
      "sandwiches.不存在于词向量中\n",
      "Undertale不存在于词向量中\n",
      "streak,不存在于词向量中\n",
      "then...|||Well,不存在于词向量中\n",
      "agreeable.不存在于词向量中\n",
      "doorway,不存在于词向量中\n",
      "NOPE.不存在于词向量中\n",
      "processing,不存在于词向量中\n",
      "old's不存在于词向量中\n",
      "Cinderella:不存在于词向量中\n",
      "Venus:不存在于词向量中\n",
      "=D|||I不存在于词向量中\n",
      "N64不存在于词向量中\n",
      "T?不存在于词向量中\n",
      "Pieces不存在于词向量中\n",
      "rationals,不存在于词向量中\n",
      "mainly,不存在于词向量中\n",
      "implicitly.不存在于词向量中\n",
      "any...|||You不存在于词向量中\n",
      "descriptions?不存在于词向量中\n",
      "him).不存在于词向量中\n",
      "HA.不存在于词向量中\n",
      "be...|||There不存在于词向量中\n",
      "autistic,不存在于词向量中\n",
      "opera.不存在于词向量中\n",
      "Computers不存在于词向量中\n",
      "Hah.不存在于词向量中\n",
      "Juno不存在于词向量中\n",
      "'What's不存在于词向量中\n",
      "horny.不存在于词向量中\n",
      "irony.不存在于词向量中\n",
      "FOREVER不存在于词向量中\n",
      "gathered,不存在于词向量中\n",
      "as...|||That不存在于词向量中\n",
      "tiny.不存在于词向量中\n",
      "divorced.不存在于词向量中\n",
      "superhero,不存在于词向量中\n",
      "Alternatively,不存在于词向量中\n",
      "way....不存在于词向量中\n",
      "me):不存在于词向量中\n",
      "ESTP...不存在于词向量中\n",
      "self-image.不存在于词向量中\n",
      "academia.不存在于词向量中\n",
      "stake.不存在于词向量中\n",
      "more...|||Not不存在于词向量中\n",
      "professionals.不存在于词向量中\n",
      "favour,不存在于词向量中\n",
      "INxP,不存在于词向量中\n",
      ":happy:|||Welcome不存在于词向量中\n",
      "(Perhaps不存在于词向量中\n",
      "Anarchist不存在于词向量中\n",
      "fairy.不存在于词向量中\n",
      "willpower.不存在于词向量中\n",
      "Philippines.不存在于词向量中\n",
      "Taoism不存在于词向量中\n",
      "Bio不存在于词向量中\n",
      "MP3不存在于词向量中\n",
      "wet,不存在于词向量中\n",
      "Beth不存在于词向量中\n",
      "(neither不存在于词向量中\n",
      "breed,不存在于词向量中\n",
      "Brady不存在于词向量中\n",
      "to...|||Haha不存在于词向量中\n",
      "welcome.|||I不存在于词向量中\n",
      "PDA.不存在于词向量中\n",
      "retail,不存在于词向量中\n",
      "counting.不存在于词向量中\n",
      "to|||I不存在于词向量中\n",
      "life...|||I'm不存在于词向量中\n",
      "Hatter不存在于词向量中\n",
      "formal.不存在于词向量中\n",
      "tiger,不存在于词向量中\n",
      "I'd...|||I'm不存在于词向量中\n",
      "disclosure,不存在于词向量中\n",
      "individuality.不存在于词向量中\n",
      "Si-doms不存在于词向量中\n",
      "TL;DR不存在于词向量中\n",
      "Man!不存在于词向量中\n",
      "jaded,不存在于词向量中\n",
      "probably)不存在于词向量中\n",
      "whoops,不存在于词向量中\n",
      "books.|||I不存在于词向量中\n",
      "G-d不存在于词向量中\n",
      ":dry:)不存在于词向量中\n",
      "Fives不存在于词向量中\n",
      "Completely.不存在于词向量中\n",
      "Mere不存在于词向量中\n",
      "challenged,不存在于词向量中\n",
      "Issues不存在于词向量中\n",
      "Pregnancy不存在于词向量中\n",
      "links?不存在于词向量中\n",
      "sticks,不存在于词向量中\n",
      "post's不存在于词向量中\n",
      "Speed不存在于词向量中\n",
      "tooth.不存在于词向量中\n",
      "spouse's不存在于词向量中\n",
      "E...不存在于词向量中\n",
      "vocation,不存在于词向量中\n",
      "publicly.不存在于词向量中\n",
      "Proud不存在于词向量中\n",
      "Assistant不存在于词向量中\n",
      "Unethical不存在于词向量中\n",
      "THIS!不存在于词向量中\n",
      "In,不存在于词向量中\n",
      "how...|||Well,不存在于词向量中\n",
      "I...|||Hello,不存在于词向量中\n",
      "Pants不存在于词向量中\n",
      "climate.不存在于词向量中\n",
      "station.不存在于词向量中\n",
      "mobile.不存在于词向量中\n",
      "registered.不存在于词向量中\n",
      "a...|||He不存在于词向量中\n",
      "off).不存在于词向量中\n",
      "Mal不存在于词向量中\n",
      "NTJ.不存在于词向量中\n",
      "interested.|||I不存在于词向量中\n",
      "mysterious?不存在于词向量中\n",
      "Underneath不存在于词向量中\n",
      "confirmation.不存在于词向量中\n",
      "pillows,不存在于词向量中\n",
      "above?不存在于词向量中\n",
      "they...|||When不存在于词向量中\n",
      "stalking,不存在于词向量中\n",
      "though...|||I'm不存在于词向量中\n",
      "ESFJ!不存在于词向量中\n",
      "books)不存在于词向量中\n",
      "Cup不存在于词向量中\n",
      "7's不存在于词向量中\n",
      "Beatrice不存在于词向量中\n",
      "shared...|||I不存在于词向量中\n",
      "You?不存在于词向量中\n",
      "Youx92re不存在于词向量中\n",
      "too...'不存在于词向量中\n",
      "teens/early不存在于词向量中\n",
      "Material不存在于词向量中\n",
      "Across不存在于词向量中\n",
      "pasta,不存在于词向量中\n",
      "Ireland.不存在于词向量中\n",
      "get...|||This不存在于词向量中\n",
      "Bi不存在于词向量中\n",
      "So/Sp.不存在于词向量中\n",
      "EST不存在于词向量中\n",
      "Jk,不存在于词向量中\n",
      "'logic'不存在于词向量中\n",
      "Atlantic不存在于词向量中\n",
      "Mia不存在于词向量中\n",
      "more),不存在于词向量中\n",
      "hiatus.不存在于词向量中\n",
      "I...|||Me不存在于词向量中\n",
      "passes.不存在于词向量中\n",
      "clean...|||I不存在于词向量中\n",
      "superpowers.不存在于词向量中\n",
      "kinda...不存在于词向量中\n",
      "xD|||It's不存在于词向量中\n",
      "tried...不存在于词向量中\n",
      "posting...不存在于词向量中\n",
      "uhm...不存在于词向量中\n",
      "ISTJ).不存在于词向量中\n",
      "tour.不存在于词向量中\n",
      "either).不存在于词向量中\n",
      "XD,不存在于词向量中\n",
      "PerC...不存在于词向量中\n",
      "Welcome!|||I不存在于词向量中\n",
      "00's不存在于词向量中\n",
      "website's不存在于词向量中\n",
      "months).不存在于词向量中\n",
      "country)不存在于词向量中\n",
      "Melody,不存在于词向量中\n",
      "...|||Here's不存在于词向量中\n",
      "masks.不存在于词向量中\n",
      "and...|||He不存在于词向量中\n",
      "abortion.不存在于词向量中\n",
      "academically,不存在于词向量中\n",
      "Manifesto不存在于词向量中\n",
      "followed,不存在于词向量中\n",
      "...|||She不存在于词向量中\n",
      "trial.不存在于词向量中\n",
      "an...|||Oh不存在于词向量中\n",
      "Cheers,不存在于词向量中\n",
      "Extroversion:不存在于词向量中\n",
      "Caribbean不存在于词向量中\n",
      "Cabin不存在于词向量中\n",
      "LOVES不存在于词向量中\n",
      "so/sx,不存在于词向量中\n",
      "biases,不存在于词向量中\n",
      "E:不存在于词向量中\n",
      "N:不存在于词向量中\n",
      "Kai不存在于词向量中\n",
      "anybody's不存在于词向量中\n",
      "there'不存在于词向量中\n",
      ":)!不存在于词向量中\n",
      "selective.不存在于词向量中\n",
      "devastated.不存在于词向量中\n",
      "to....不存在于词向量中\n",
      "D's不存在于词向量中\n",
      "chips.不存在于词向量中\n",
      "want's不存在于词向量中\n",
      "Boot不存在于词向量中\n",
      "lol....|||I不存在于词向量中\n",
      "(i.e不存在于词向量中\n",
      "(makes不存在于词向量中\n",
      "roles?不存在于词向量中\n",
      "weren't,不存在于词向量中\n",
      "(Besides不存在于词向量中\n",
      "Lost,不存在于词向量中\n",
      "testosterone,不存在于词向量中\n",
      "in...|||No,不存在于词向量中\n",
      "J/P.不存在于词向量中\n",
      "sensor?不存在于词向量中\n",
      "out.'不存在于词向量中\n",
      "Primus不存在于词向量中\n",
      "convinced,不存在于词向量中\n",
      "(yet)不存在于词向量中\n",
      "feminist,不存在于词向量中\n",
      "P.E.不存在于词向量中\n",
      "or...|||Yes,不存在于词向量中\n",
      "Create,不存在于词向量中\n",
      "anything..不存在于词向量中\n",
      "changes?不存在于词向量中\n",
      ":'(|||I不存在于词向量中\n",
      "spring,不存在于词向量中\n",
      "charity.不存在于词向量中\n",
      "lucid,不存在于词向量中\n",
      "list.|||I不存在于词向量中\n",
      "cuddle,不存在于词向量中\n",
      "DO,不存在于词向量中\n",
      "like),不存在于词向量中\n",
      "Sexy,不存在于词向量中\n",
      "or...|||Yeah,不存在于词向量中\n",
      "looked,不存在于词向量中\n",
      "disrespect,不存在于词向量中\n",
      "Nubb不存在于词向量中\n",
      "plausible.不存在于词向量中\n",
      "'that不存在于词向量中\n",
      "(2015)不存在于词向量中\n",
      "genocide.不存在于词向量中\n",
      "sleeves.不存在于词向量中\n",
      "are...|||1.不存在于词向量中\n",
      "Donuts不存在于词向量中\n",
      "I...|||Last不存在于词向量中\n",
      "she.不存在于词向量中\n",
      "future...不存在于词向量中\n",
      "services.不存在于词向量中\n",
      "underwear.不存在于词向量中\n",
      "I've...|||This不存在于词向量中\n",
      "mercy,不存在于词向量中\n",
      "Mmm,不存在于词向量中\n",
      "MIA不存在于词向量中\n",
      "'INTP不存在于词向量中\n",
      "Tea,不存在于词向量中\n",
      "cap?不存在于词向量中\n",
      "clueless,不存在于词向量中\n",
      "NOT...|||I不存在于词向量中\n",
      "INFJ),不存在于词向量中\n",
      "came...|||I不存在于词向量中\n",
      "'n不存在于词向量中\n",
      "Long,不存在于词向量中\n",
      "Idiot不存在于词向量中\n",
      "Laugh不存在于词向量中\n",
      "orientated.不存在于词向量中\n",
      "Wort不存在于词向量中\n",
      "'F'不存在于词向量中\n",
      "2009.不存在于词向量中\n",
      "fake?不存在于词向量中\n",
      "that...|||I'd不存在于词向量中\n",
      "fist.不存在于词向量中\n",
      "testing,不存在于词向量中\n",
      "time.....不存在于词向量中\n",
      "stale.不存在于词向量中\n",
      "guests,不存在于词向量中\n",
      "Haha.|||I不存在于词向量中\n",
      "Petty不存在于词向量中\n",
      "family/friends不存在于词向量中\n",
      "LEARN不存在于词向量中\n",
      "accent,不存在于词向量中\n",
      "Scrubs,不存在于词向量中\n",
      "Simpsons,不存在于词向量中\n",
      "paper?不存在于词向量中\n",
      "evolving.不存在于词向量中\n",
      "Later,不存在于词向量中\n",
      "Dali不存在于词向量中\n",
      "imaginable.不存在于词向量中\n",
      "they...|||I've不存在于词向量中\n",
      "Mice不存在于词向量中\n",
      "Respond不存在于词向量中\n",
      "OKC不存在于词向量中\n",
      "energy...不存在于词向量中\n",
      "'There's不存在于词向量中\n",
      "paralysis.不存在于词向量中\n",
      "ukulele,不存在于词向量中\n",
      "steel,不存在于词向量中\n",
      "facts?不存在于词向量中\n",
      "the...|||Ok不存在于词向量中\n",
      "Pour不存在于词向量中\n",
      "him/herself不存在于词向量中\n",
      "inputs.不存在于词向量中\n",
      "Se/Si不存在于词向量中\n",
      "Observing不存在于词向量中\n",
      "Rare不存在于词向量中\n",
      "on...|||When不存在于词向量中\n",
      "Executive不存在于词向量中\n",
      "monotony,不存在于词向量中\n",
      "thinkin'不存在于词向量中\n",
      "frickin'不存在于词向量中\n",
      "wreck.不存在于词向量中\n",
      "college's不存在于词向量中\n",
      "0.0不存在于词向量中\n",
      "-...|||This不存在于词向量中\n",
      "end...|||I不存在于词向量中\n",
      "UP!不存在于词向量中\n",
      "Platonic不存在于词向量中\n",
      "Daleks不存在于词向量中\n",
      "Men.不存在于词向量中\n",
      "cakes.不存在于词向量中\n",
      "Up,不存在于词向量中\n",
      "nervous?不存在于词向量中\n",
      "Pepsi不存在于词向量中\n",
      "condolences.不存在于词向量中\n",
      "wide,不存在于词向量中\n",
      "when...|||It不存在于词向量中\n",
      "Incubus不存在于词向量中\n",
      "and...|||Thanks,不存在于词向量中\n",
      "(ISTJ).不存在于词向量中\n",
      "I...|||Hey!不存在于词向量中\n",
      "Moderately不存在于词向量中\n",
      "agrees.不存在于词向量中\n",
      "Sid不存在于词向量中\n",
      "internet...不存在于词向量中\n",
      "Male,不存在于词向量中\n",
      "assignments,不存在于词向量中\n",
      "came.不存在于词向量中\n",
      "INTJs...|||I不存在于词向量中\n",
      "their...|||Well不存在于词向量中\n",
      "then...'不存在于词向量中\n",
      "mistaken,不存在于词向量中\n",
      "specifically)不存在于词向量中\n",
      "sister...不存在于词向量中\n",
      "burned,不存在于词向量中\n",
      "doing...不存在于词向量中\n",
      "around..不存在于词向量中\n",
      "touched,不存在于词向量中\n",
      "growth?不存在于词向量中\n",
      "-What不存在于词向量中\n",
      "Maya不存在于词向量中\n",
      "Amos不存在于词向量中\n",
      "experiments.不存在于词向量中\n",
      "much...|||The不存在于词向量中\n",
      "noises,不存在于词向量中\n",
      "dancer.不存在于词向量中\n",
      "P.s.不存在于词向量中\n",
      "chaotic,不存在于词向量中\n",
      "bother,不存在于词向量中\n",
      "hesitant,不存在于词向量中\n",
      "Vatican不存在于词向量中\n",
      "(She's不存在于词向量中\n",
      "2w3.不存在于词向量中\n",
      "LISTEN不存在于词向量中\n",
      "Here:不存在于词向量中\n",
      ":wink:|||You不存在于词向量中\n",
      "in...|||There不存在于词向量中\n",
      "in...|||Why不存在于词向量中\n",
      "restrictions.不存在于词向量中\n",
      "Testing不存在于词向量中\n",
      "loves.不存在于词向量中\n",
      "Libertarian.不存在于词向量中\n",
      "reality.|||I不存在于词向量中\n",
      "Peacemaker不存在于词向量中\n",
      "us...|||I'm不存在于词向量中\n",
      "whistle,不存在于词向量中\n",
      "of...|||Interesting不存在于词向量中\n",
      "maybe..不存在于词向量中\n",
      "Fluent不存在于词向量中\n",
      "static,不存在于词向量中\n",
      "MLP不存在于词向量中\n",
      ":)|||Haha,不存在于词向量中\n",
      "very...|||It不存在于词向量中\n",
      "Program不存在于词向量中\n",
      "At...|||I不存在于词向量中\n",
      "psychopathy.不存在于词向量中\n",
      "feel/think不存在于词向量中\n",
      "noodles,不存在于词向量中\n",
      "to...|||Its不存在于词向量中\n",
      "think...|||Just不存在于词向量中\n",
      "soap.不存在于词向量中\n",
      "action?不存在于词向量中\n",
      "hometown.不存在于词向量中\n",
      "suggest.不存在于词向量中\n",
      "Show,不存在于词向量中\n",
      "bags,不存在于词向量中\n",
      "boy...不存在于词向量中\n",
      "Suite不存在于词向量中\n",
      "later),不存在于词向量中\n",
      "Adams,不存在于词向量中\n",
      "Williams,不存在于词向量中\n",
      "LAST不存在于词向量中\n",
      "Exxx不存在于词向量中\n",
      "idealists,不存在于词向量中\n",
      "MLK不存在于词向量中\n",
      "Piano,不存在于词向量中\n",
      "'life不存在于词向量中\n",
      "Anger.不存在于词向量中\n",
      "Brooks不存在于词向量中\n",
      "enlisted不存在于词向量中\n",
      "your...|||And不存在于词向量中\n",
      "causes.不存在于词向量中\n",
      "Dusty不存在于词向量中\n",
      "archetypes.不存在于词向量中\n",
      "people...|||1.不存在于词向量中\n",
      "Thatx92s不存在于词向量中\n",
      "reliability,不存在于词向量中\n",
      "min.不存在于词向量中\n",
      "HATED不存在于词向量中\n",
      "bitchy,不存在于词向量中\n",
      "symbols,不存在于词向量中\n",
      "Recipes不存在于词向量中\n",
      "devices.不存在于词向量中\n",
      "NOW.不存在于词向量中\n",
      "Plath,不存在于词向量中\n",
      "affect.不存在于词向量中\n",
      "even...|||The不存在于词向量中\n",
      "even?不存在于词向量中\n",
      "Supposedly,不存在于词向量中\n",
      "murderer.不存在于词向量中\n",
      "race?不存在于词向量中\n",
      "were...|||The不存在于词向量中\n",
      "calmly,不存在于词向量中\n",
      "comedies,不存在于词向量中\n",
      "Jewish,不存在于词向量中\n",
      "situations...不存在于词向量中\n",
      "respond?不存在于词向量中\n",
      "am...|||When不存在于词向量中\n",
      "admirable,不存在于词向量中\n",
      "hunt.不存在于词向量中\n",
      "Peru不存在于词向量中\n",
      "Honest,不存在于词向量中\n",
      "initiate,不存在于词向量中\n",
      "Monsters不存在于词向量中\n",
      "appears.不存在于词向量中\n",
      "INFJ=Ni,不存在于词向量中\n",
      "Ran不存在于词向量中\n",
      "Beneath不存在于词向量中\n",
      "notifications,不存在于词向量中\n",
      "forte.不存在于词向量中\n",
      "outfits,不存在于词向量中\n",
      "Hello.不存在于词向量中\n",
      "their...|||It's不存在于词向量中\n",
      "like...|||It不存在于词向量中\n",
      "roots,不存在于词向量中\n",
      "Beethoven,不存在于词向量中\n",
      "all...I不存在于词向量中\n",
      "(somewhat不存在于词向量中\n",
      "Adelaide不存在于词向量中\n",
      "ahaha.不存在于词向量中\n",
      "Salinger不存在于词向量中\n",
      "Antiant不存在于词向量中\n",
      "(apparently)不存在于词向量中\n",
      "Amazing.不存在于词向量中\n",
      "official,不存在于词向量中\n",
      "people....|||I不存在于词向量中\n",
      "bones,不存在于词向量中\n",
      "ISXP不存在于词向量中\n",
      "being...'不存在于词向量中\n",
      "how...|||It's不存在于词向量中\n",
      "preferred.不存在于词向量中\n",
      "Black.不存在于词向量中\n",
      "simple...|||I不存在于词向量中\n",
      "pseudoscience.不存在于词向量中\n",
      "xNFJ,不存在于词向量中\n",
      "surfing,不存在于词向量中\n",
      "connection?不存在于词向量中\n",
      "belt,不存在于词向量中\n",
      "better).不存在于词向量中\n",
      "Blake.不存在于词向量中\n",
      "comfortably.不存在于词向量中\n",
      "Travis不存在于词向量中\n",
      "Hilton不存在于词向量中\n",
      "Adderall不存在于词向量中\n",
      "Paramore不存在于词向量中\n",
      "Pratt不存在于词向量中\n",
      "Differing不存在于词向量中\n",
      "total,不存在于词向量中\n",
      "Gon不存在于词向量中\n",
      "Killua不存在于词向量中\n",
      "Fabulous不存在于词向量中\n",
      "Antisocial不存在于词向量中\n",
      "hysterical.不存在于词向量中\n",
      "something...|||You不存在于词向量中\n",
      "Officer不存在于词向量中\n",
      "Austria不存在于词向量中\n",
      "Coffee,不存在于词向量中\n",
      "are...|||In不存在于词向量中\n",
      "she...|||Thanks不存在于词向量中\n",
      "and...|||Interesting不存在于词向量中\n",
      "same).不存在于词向量中\n",
      "cops.不存在于词向量中\n",
      "cops,不存在于词向量中\n",
      ":)|||INFP不存在于词向量中\n",
      "'Here's不存在于词向量中\n",
      "itself.|||I不存在于词向量中\n",
      "programmers,不存在于词向量中\n",
      "James,不存在于词向量中\n",
      "approaches.不存在于词向量中\n",
      "Trek.不存在于词向量中\n",
      "Doctor.不存在于词向量中\n",
      "(12不存在于词向量中\n",
      "non-stop.不存在于词向量中\n",
      "TES不存在于词向量中\n",
      "Cosmic不存在于词向量中\n",
      "Forgotten不存在于词向量中\n",
      "signature?不存在于词向量中\n",
      "Solve不存在于词向量中\n",
      "Chomsky不存在于词向量中\n",
      "aloofness.不存在于词向量中\n",
      "the...|||Are不存在于词向量中\n",
      "ups.不存在于词向量中\n",
      "adapt.不存在于词向量中\n",
      "Shark不存在于词向量中\n",
      "melody,不存在于词向量中\n",
      "know-it-all,不存在于词向量中\n",
      "are...|||Just不存在于词向量中\n",
      "all...|||That不存在于词向量中\n",
      "tangents.不存在于词向量中\n",
      "civilization,不存在于词向量中\n",
      "Brody不存在于词向量中\n",
      "Purely不存在于词向量中\n",
      "Salvador不存在于词向量中\n",
      "Bell,不存在于词向量中\n",
      "Elfen不存在于词向量中\n",
      "Spelling不存在于词向量中\n",
      "Moulin不存在于词向量中\n",
      "unrelated.不存在于词向量中\n",
      "1.1不存在于词向量中\n",
      "calculus,不存在于词向量中\n",
      "something....不存在于词向量中\n",
      "way.|||My不存在于词向量中\n",
      "TOP不存在于词向量中\n",
      "HAHAHA不存在于词向量中\n",
      "8s.不存在于词向量中\n",
      "Truly,不存在于词向量中\n",
      "I'm...|||Dear不存在于词向量中\n",
      "photographer.不存在于词向量中\n",
      "BACK不存在于词向量中\n",
      "rose,不存在于词向量中\n",
      "a...|||Of不存在于词向量中\n",
      "Umm不存在于词向量中\n",
      "Tapatalk|||Yes,不存在于词向量中\n",
      "prevalent.不存在于词向量中\n",
      "MBTI).不存在于词向量中\n",
      "lie?不存在于词向量中\n",
      "with...|||How不存在于词向量中\n",
      "Borderlands不存在于词向量中\n",
      "relevance.不存在于词向量中\n",
      "will...|||My不存在于词向量中\n",
      "Thanks|||I不存在于词向量中\n",
      "Parker不存在于词向量中\n",
      "friendships?不存在于词向量中\n",
      "competence,不存在于词向量中\n",
      "stamps,不存在于词向量中\n",
      "Analytical不存在于词向量中\n",
      "5'5不存在于词向量中\n",
      "(<20,不存在于词向量中\n",
      "20-25,不存在于词向量中\n",
      "26-30,不存在于词向量中\n",
      ">30)?不存在于词向量中\n",
      "hipster.不存在于词向量中\n",
      "Possibly.不存在于词向量中\n",
      "help)不存在于词向量中\n",
      "Hope,不存在于词向量中\n",
      "accomplish,不存在于词向量中\n",
      "so...|||Well不存在于词向量中\n",
      "ton.不存在于词向量中\n",
      "Lantern不存在于词向量中\n",
      "elitist,不存在于词向量中\n",
      "obsolete.不存在于词向量中\n",
      "but...|||Is不存在于词向量中\n",
      "but...)不存在于词向量中\n",
      "is?|||I不存在于词向量中\n",
      "go...'不存在于词向量中\n",
      "TOLD不存在于词向量中\n",
      "Passive不存在于词向量中\n",
      "honest..不存在于词向量中\n",
      "Bowl不存在于词向量中\n",
      "Swift's不存在于词向量中\n",
      "Tapatalk|||It's不存在于词向量中\n",
      "people...|||Not不存在于词向量中\n",
      "interact,不存在于词向量中\n",
      "Anyways...不存在于词向量中\n",
      "Mighty不存在于词向量中\n",
      ":p|||You不存在于词向量中\n",
      "geniuses,不存在于词向量中\n",
      "bluntly,不存在于词向量中\n",
      "Sharpe不存在于词向量中\n",
      "Prestige不存在于词向量中\n",
      "open?不存在于词向量中\n",
      "skiing,不存在于词向量中\n",
      "Bowie,不存在于词向量中\n",
      "allow...|||I不存在于词向量中\n",
      "holes,不存在于词向量中\n",
      "Joanna不存在于词向量中\n",
      "to...|||Now不存在于词向量中\n",
      "Bread不存在于词向量中\n",
      "am.|||I'm不存在于词向量中\n",
      "letters?不存在于词向量中\n",
      "karma,不存在于词向量中\n",
      "are...|||Your不存在于词向量中\n",
      "op,不存在于词向量中\n",
      "Marty不存在于词向量中\n",
      "lettuce,不存在于词向量中\n",
      "Gustav不存在于词向量中\n",
      "save?不存在于词向量中\n",
      "(would不存在于词向量中\n",
      "Bat不存在于词向量中\n",
      "can...|||The不存在于词向量中\n",
      "one-sided.不存在于词向量中\n",
      "lore,不存在于词向量中\n",
      "capable.不存在于词向量中\n",
      "Poems不存在于词向量中\n",
      "Childish不存在于词向量中\n",
      "be...|||Some不存在于词向量中\n",
      "zombies,不存在于词向量中\n",
      "of...|||Sometimes不存在于词向量中\n",
      "Suggest不存在于词向量中\n",
      "Sun.不存在于词向量中\n",
      "Sickness不存在于词向量中\n",
      "choice?不存在于词向量中\n",
      "Whereas,不存在于词向量中\n",
      "immaturity.不存在于词向量中\n",
      "Wikipedia:不存在于词向量中\n",
      "21)不存在于词向量中\n",
      "Fe-Se不存在于词向量中\n",
      "INXJ.不存在于词向量中\n",
      "Classical,不存在于词向量中\n",
      "Aurelius不存在于词向量中\n",
      "Warning不存在于词向量中\n",
      "Waves不存在于词向量中\n",
      "Apathetic不存在于词向量中\n",
      "occurred,不存在于词向量中\n",
      "Morrissey不存在于词向量中\n",
      "Seal不存在于词向量中\n",
      "(must不存在于词向量中\n",
      "neurotic.不存在于词向量中\n",
      "INXP,不存在于词向量中\n",
      "NFP,不存在于词向量中\n",
      "MBTI/Socionics不存在于词向量中\n",
      "as...|||You're不存在于词向量中\n",
      "locations.不存在于词向量中\n",
      "actress.不存在于词向量中\n",
      "Then...不存在于词向量中\n",
      "8...|||I不存在于词向量中\n",
      "mechanical.不存在于词向量中\n",
      "she/he不存在于词向量中\n",
      "for...|||How不存在于词向量中\n",
      "losing.不存在于词向量中\n",
      "ENTP).不存在于词向量中\n",
      "charity,不存在于词向量中\n",
      "from...|||If不存在于词向量中\n",
      "was...|||If不存在于词向量中\n",
      "though.|||It不存在于词向量中\n",
      "Mustang不存在于词向量中\n",
      ":/'不存在于词向量中\n",
      "the...|||See不存在于词向量中\n",
      "alien.不存在于词向量中\n",
      "why),不存在于词向量中\n",
      "Palpatine不存在于词向量中\n",
      "Shit!不存在于词向量中\n",
      "One...|||I不存在于词向量中\n",
      "o.o|||I不存在于词向量中\n",
      "Tradition不存在于词向量中\n",
      "mysticism,不存在于词向量中\n",
      "abrasive,不存在于词向量中\n",
      "Judeo-Christian不存在于词向量中\n",
      "therapeutic,不存在于词向量中\n",
      "pain...不存在于词向量中\n",
      "delivery,不存在于词向量中\n",
      "up!|||I不存在于词向量中\n",
      "99.999%不存在于词向量中\n",
      "intelligences,不存在于词向量中\n",
      "below).不存在于词向量中\n",
      "Undertaker不存在于词向量中\n",
      "socialising,不存在于词向量中\n",
      "saving.不存在于词向量中\n",
      "affair.不存在于词向量中\n",
      "B.A.不存在于词向量中\n",
      "Geonerd不存在于词向量中\n",
      "MALE不存在于词向量中\n",
      "shoot,不存在于词向量中\n",
      "Badass不存在于词向量中\n",
      "Skull不存在于词向量中\n",
      "electronics.不存在于词向量中\n",
      "telling.不存在于词向量中\n",
      "hermit,不存在于词向量中\n",
      "in...|||You're不存在于词向量中\n",
      "subway.不存在于词向量中\n",
      "whore,不存在于词向量中\n",
      "2015.不存在于词向量中\n",
      "healthier.不存在于词向量中\n",
      "initiative,不存在于词向量中\n",
      "Broadway不存在于词向量中\n",
      "jaded.不存在于词向量中\n",
      "Swede不存在于词向量中\n",
      "Se.|||I不存在于词向量中\n",
      "connections?不存在于词向量中\n",
      "Jan不存在于词向量中\n",
      "ExFPs不存在于词向量中\n",
      "Ich不存在于词向量中\n",
      "my...|||All不存在于词向量中\n",
      "me...|||That's不存在于词向量中\n",
      "smiley,不存在于词向量中\n",
      "Soda不存在于词向量中\n",
      "Katie不存在于词向量中\n",
      "what...|||When不存在于词向量中\n",
      "memes.不存在于词向量中\n",
      "distrust.不存在于词向量中\n",
      "unexpectedly.不存在于词向量中\n",
      "paranoia.不存在于词向量中\n",
      "Yorke不存在于词向量中\n",
      "Questionnaire不存在于词向量中\n",
      "lion.不存在于词向量中\n",
      "(About不存在于词向量中\n",
      "Hepburn不存在于词向量中\n",
      "(started不存在于词向量中\n",
      "Lamar不存在于词向量中\n",
      "unnerving.不存在于词向量中\n",
      "brainstorming,不存在于词向量中\n",
      "to...|||Does不存在于词向量中\n",
      "moderate,不存在于词向量中\n",
      "Catelyn不存在于词向量中\n",
      "abortion,不存在于词向量中\n",
      "a...|||There's不存在于词向量中\n",
      "masses.不存在于词向量中\n",
      "be...|||Well,不存在于词向量中\n",
      "estimation,不存在于词向量中\n",
      "similar)不存在于词向量中\n",
      "CelebrityTypes.com不存在于词向量中\n",
      "upsetting.不存在于词向量中\n",
      "nod.不存在于词向量中\n",
      "conversations?不存在于词向量中\n",
      "did.|||I不存在于词向量中\n",
      "Relating不存在于词向量中\n",
      "YES!!!不存在于词向量中\n",
      "Blood,不存在于词向量中\n",
      "advices,不存在于词向量中\n",
      "of...|||Hey,不存在于词向量中\n",
      "Pale不存在于词向量中\n",
      "reincarnation,不存在于词向量中\n",
      "infj's.不存在于词向量中\n",
      "respect?不存在于词向量中\n",
      "comes...不存在于词向量中\n",
      "Dig不存在于词向量中\n",
      "fries.不存在于词向量中\n",
      "Oops.不存在于词向量中\n",
      "relaxation.不存在于词向量中\n",
      ":))|||I不存在于词向量中\n",
      "Arguments不存在于词向量中\n",
      "A's.不存在于词向量中\n",
      "mother?不存在于词向量中\n",
      "socialism.不存在于词向量中\n",
      "in..不存在于词向量中\n",
      "hoping,不存在于词向量中\n",
      "even...|||You不存在于词向量中\n",
      "F:不存在于词向量中\n",
      "tomatoes,不存在于词向量中\n",
      "so...|||That不存在于词向量中\n",
      "self-explanatory.不存在于词向量中\n",
      "WickedQueen.不存在于词向量中\n",
      "Celine不存在于词向量中\n",
      "whatever).不存在于词向量中\n",
      "follower.不存在于词向量中\n",
      "Kansas不存在于词向量中\n",
      "Bear.不存在于词向量中\n",
      "stories?不存在于词向量中\n",
      "simplicity,不存在于词向量中\n",
      "waiting,不存在于词向量中\n",
      "manner?不存在于词向量中\n",
      "Legos不存在于词向量中\n",
      "gregarious,不存在于词向量中\n",
      "dots.不存在于词向量中\n",
      "Hello?不存在于词向量中\n",
      "Immortality不存在于词向量中\n",
      "you...|||To不存在于词向量中\n",
      "IxTJ.不存在于词向量中\n",
      "INFP?|||I不存在于词向量中\n",
      "Dallas不存在于词向量中\n",
      "sixteen,不存在于词向量中\n",
      "giant,不存在于词向量中\n",
      "Bad.不存在于词向量中\n",
      "Seemed不存在于词向量中\n",
      "like...|||i不存在于词向量中\n",
      "missed,不存在于词向量中\n",
      "'From不存在于词向量中\n",
      "Carlos不存在于词向量中\n",
      "Chaplin不存在于词向量中\n",
      "convictions.不存在于词向量中\n",
      "individuality,不存在于词向量中\n",
      "losing,不存在于词向量中\n",
      "ass?不存在于词向量中\n",
      "Finland,不存在于词向量中\n",
      "and...|||Ok不存在于词向量中\n",
      "'Did不存在于词向量中\n",
      "ESTJ)不存在于词向量中\n",
      "distinction.不存在于词向量中\n",
      "about...|||A不存在于词向量中\n",
      "Yeah..不存在于词向量中\n",
      "(been不存在于词向量中\n",
      "volleyball,不存在于词向量中\n",
      "of...|||Love不存在于词向量中\n",
      "considered...|||I不存在于词向量中\n",
      "plants,不存在于词向量中\n",
      "can't...|||You不存在于词向量中\n",
      "School:不存在于词向量中\n",
      "(got不存在于词向量中\n",
      "Alysaria不存在于词向量中\n",
      "usernames.不存在于词向量中\n",
      "Cherry不存在于词向量中\n",
      "Mystical不存在于词向量中\n",
      "of...|||And不存在于词向量中\n",
      "Concerto不存在于词向量中\n",
      "I...|||Hmm不存在于词向量中\n",
      "by...不存在于词向量中\n",
      "deviantART不存在于词向量中\n",
      "showers.不存在于词向量中\n",
      "Whisper不存在于词向量中\n",
      "to...|||Yes.不存在于词向量中\n",
      "work.|||You不存在于词向量中\n",
      "Jade不存在于词向量中\n",
      "semantics.不存在于词向量中\n",
      "'Haha,不存在于词向量中\n",
      "opposition.不存在于词向量中\n",
      "of...|||Yep,不存在于词向量中\n",
      "child...不存在于词向量中\n",
      "amused.不存在于词向量中\n",
      "threads.|||I不存在于词向量中\n",
      "bud,不存在于词向量中\n",
      "Simone不存在于词向量中\n",
      "Solving不存在于词向量中\n",
      "diarrhea.不存在于词向量中\n",
      "I...|||But不存在于词向量中\n",
      "USD不存在于词向量中\n",
      "Norris不存在于词向量中\n",
      "relationships)不存在于词向量中\n",
      "I'm...|||If不存在于词向量中\n",
      "performing.不存在于词向量中\n",
      "separate.不存在于词向量中\n",
      "lower,不存在于词向量中\n",
      "internal,不存在于词向量中\n",
      "think...|||The不存在于词向量中\n",
      "tolerance,不存在于词向量中\n",
      "People...|||I不存在于词向量中\n",
      "Lang不存在于词向量中\n",
      "improve,不存在于词向量中\n",
      "empathic,不存在于词向量中\n",
      "here.|||This不存在于词向量中\n",
      "one...|||It's不存在于词向量中\n",
      "protagonist.不存在于词向量中\n",
      "needed.|||I不存在于词向量中\n",
      "life.|||What不存在于词向量中\n",
      "a...|||this不存在于词向量中\n",
      "midnight,不存在于词向量中\n",
      "time....不存在于词向量中\n",
      "couch.不存在于词向量中\n",
      "politics?不存在于词向量中\n",
      "avatar...不存在于词向量中\n",
      "Lee,不存在于词向量中\n",
      "Zappa不存在于词向量中\n",
      "out,...|||I不存在于词向量中\n",
      "randomly,不存在于词向量中\n",
      "monogamous,不存在于词向量中\n",
      "chatting,不存在于词向量中\n",
      "surreal,不存在于词向量中\n",
      ":tongue:|||No,不存在于词向量中\n",
      "...|||By不存在于词向量中\n",
      "fellows,不存在于词向量中\n",
      "you.|||Oh不存在于词向量中\n",
      "Biological不存在于词向量中\n",
      "Materials不存在于词向量中\n",
      "C's不存在于词向量中\n",
      "game.|||I不存在于词向量中\n",
      "Your...|||I不存在于词向量中\n",
      "tact.不存在于词向量中\n",
      "for...|||Hey不存在于词向量中\n",
      "Syria不存在于词向量中\n",
      "[Insert不存在于词向量中\n",
      "she...|||The不存在于词向量中\n",
      "a...|||Sorry,不存在于词向量中\n",
      "Briggs.不存在于词向量中\n",
      "Love?不存在于词向量中\n",
      "No...不存在于词向量中\n",
      "business...不存在于词向量中\n",
      "interested?不存在于词向量中\n",
      "when...'不存在于词向量中\n",
      "about...|||Yeah,不存在于词向量中\n",
      "fearless,不存在于词向量中\n",
      "Liquid不存在于词向量中\n",
      "warmth.不存在于词向量中\n",
      "he...|||If不存在于词向量中\n",
      "of...|||Haha不存在于词向量中\n",
      "landscape,不存在于词向量中\n",
      "TEST不存在于词向量中\n",
      "committed,不存在于词向量中\n",
      "knew...|||I不存在于词向量中\n",
      "IxTJ,不存在于词向量中\n",
      "Paying不存在于词向量中\n",
      "Apple.不存在于词向量中\n",
      "feelings...|||I不存在于词向量中\n",
      "just...|||Oh,不存在于词向量中\n",
      "hummus,不存在于词向量中\n",
      "roll,不存在于词向量中\n",
      "soon?不存在于词向量中\n",
      "Acceptance不存在于词向量中\n",
      "has...|||The不存在于词向量中\n",
      "information...|||I不存在于词向量中\n",
      "watching...|||I不存在于词向量中\n",
      "them...|||So不存在于词向量中\n",
      "Writer不存在于词向量中\n",
      "Chef不存在于词向量中\n",
      "Way.不存在于词向量中\n",
      "(hell不存在于词向量中\n",
      "asocial,不存在于词向量中\n",
      "Janet不存在于词向量中\n",
      "and...|||Hey,不存在于词向量中\n",
      "Debbie不存在于词向量中\n",
      "or...|||You're不存在于词向量中\n",
      "Smiles不存在于词向量中\n",
      "peeve.不存在于词向量中\n",
      "modern,不存在于词向量中\n",
      "LotR不存在于词向量中\n",
      "(time不存在于词向量中\n",
      "...|||Sounds不存在于词向量中\n",
      "Grandmaster不存在于词向量中\n",
      "please.|||I不存在于词向量中\n",
      "partners?不存在于词向量中\n",
      "Woohoo!不存在于词向量中\n",
      "makes.不存在于词向量中\n",
      "Atleast不存在于词向量中\n",
      "(native不存在于词向量中\n",
      "eight.不存在于词向量中\n",
      "trapped,不存在于词向量中\n",
      "Christie不存在于词向量中\n",
      "Compliant-Inquirer不存在于词向量中\n",
      "Rebecca不存在于词向量中\n",
      "facade,不存在于词向量中\n",
      "T!不存在于词向量中\n",
      "writing...不存在于词向量中\n",
      "able...|||I不存在于词向量中\n",
      ":P|||Hi不存在于词向量中\n",
      "VA不存在于词向量中\n",
      "Oblivion,不存在于词向量中\n",
      "goodbye,不存在于词向量中\n",
      "Camera不存在于词向量中\n",
      "Ingalls不存在于词向量中\n",
      "jobs?不存在于词向量中\n",
      "Syndrome.不存在于词向量中\n",
      "c'mon,不存在于词向量中\n",
      "girly.不存在于词向量中\n",
      "sitting.不存在于词向量中\n",
      "men?不存在于词向量中\n",
      "love...|||My不存在于词向量中\n",
      "coat.不存在于词向量中\n",
      "go...|||I'm不存在于词向量中\n",
      "temporary.不存在于词向量中\n",
      "Worlds.不存在于词向量中\n",
      "are...|||Do不存在于词向量中\n",
      "umm..不存在于词向量中\n",
      "trance,不存在于词向量中\n",
      "fantasies,不存在于词向量中\n",
      "it.|||Not不存在于词向量中\n",
      "Comfort不存在于词向量中\n",
      "(INFJ,不存在于词向量中\n",
      "submissive?不存在于词向量中\n",
      "Siblings'不存在于词向量中\n",
      "Current/last不存在于词向量中\n",
      "bacon.不存在于词向量中\n",
      "nihilism.不存在于词向量中\n",
      ":)|||There不存在于词向量中\n",
      "re-designed.不存在于词向量中\n",
      "ads,不存在于词向量中\n",
      "animated,不存在于词向量中\n",
      "Expectations不存在于词向量中\n",
      "out.|||My不存在于词向量中\n",
      "INFP),不存在于词向量中\n",
      "mostly)不存在于词向量中\n",
      "Campbell不存在于词向量中\n",
      "(Can't不存在于词向量中\n",
      "wtf.不存在于词向量中\n",
      "discussion?不存在于词向量中\n",
      "budget,不存在于词向量中\n",
      "Swedish,不存在于词向量中\n",
      "complain,不存在于词向量中\n",
      "no....不存在于词向量中\n",
      "tease,不存在于词向量中\n",
      "unreasonable.不存在于词向量中\n",
      "aggression,不存在于词向量中\n",
      "Taste不存在于词向量中\n",
      "intolerant,不存在于词向量中\n",
      "...|||At不存在于词向量中\n",
      "desired,不存在于词向量中\n",
      "dignity,不存在于词向量中\n",
      "I/E,不存在于词向量中\n",
      "female).不存在于词向量中\n",
      "womb.不存在于词向量中\n",
      "SF.不存在于词向量中\n",
      "this...|||If不存在于词向量中\n",
      "Hooray!不存在于词向量中\n",
      "answer.|||I不存在于词向量中\n",
      "her...|||I'm不存在于词向量中\n",
      "flute.不存在于词向量中\n",
      "Gospel不存在于词向量中\n",
      "dances.不存在于词向量中\n",
      "spoiled,不存在于词向量中\n",
      "keyboard,不存在于词向量中\n",
      "Pilates不存在于词向量中\n",
      "Courage不存在于词向量中\n",
      "open-mindedness,不存在于词向量中\n",
      "SHIT.不存在于词向量中\n",
      "they...|||No不存在于词向量中\n",
      "a...|||All不存在于词向量中\n",
      "girlfriend...不存在于词向量中\n",
      "scary...不存在于词向量中\n",
      "then....不存在于词向量中\n",
      "GIRL不存在于词向量中\n",
      "teasing,不存在于词向量中\n",
      "Plague不存在于词向量中\n",
      "flaky,不存在于词向量中\n",
      "Clouds不存在于词向量中\n",
      "Hard.不存在于词向量中\n",
      "Dexter.不存在于词向量中\n",
      "ads.不存在于词向量中\n",
      "GED不存在于词向量中\n",
      "feel...|||When不存在于词向量中\n",
      "Quora不存在于词向量中\n",
      "Pot,不存在于词向量中\n",
      "very.不存在于词向量中\n",
      "HELLO不存在于词向量中\n",
      "out...|||If不存在于词向量中\n",
      "CONSTANTLY不存在于词向量中\n",
      "from...|||You不存在于词向量中\n",
      "Kubrick不存在于词向量中\n",
      "duh,不存在于词向量中\n",
      "just...|||Well不存在于词向量中\n",
      "(taken不存在于词向量中\n",
      "Tarzan不存在于词向量中\n",
      "Jesus'不存在于词向量中\n",
      "network,不存在于词向量中\n",
      "appearance?不存在于词向量中\n",
      "been...|||I've不存在于词向量中\n",
      "again....不存在于词向量中\n",
      "ISTP-ish不存在于词向量中\n",
      "and...|||1)不存在于词向量中\n",
      "Industrial不存在于词向量中\n",
      "than...|||I've不存在于词向量中\n",
      "incomplete,不存在于词向量中\n",
      "precision.不存在于词向量中\n",
      "Shepherd不存在于词向量中\n",
      "wallet,不存在于词向量中\n",
      ":D|||So不存在于词向量中\n",
      "but...|||Wow,不存在于词向量中\n",
      "dark)不存在于词向量中\n",
      "Psychedelic不存在于词向量中\n",
      "Camille不存在于词向量中\n",
      "such).不存在于词向量中\n",
      "Tapatalk|||1.不存在于词向量中\n",
      ":happy:|||This不存在于词向量中\n",
      "cigarettes,不存在于词向量中\n",
      "Martin,不存在于词向量中\n",
      "Axe不存在于词向量中\n",
      "grudge.不存在于词向量中\n",
      "hope...不存在于词向量中\n",
      "shyness.不存在于词向量中\n",
      "occurrence,不存在于词向量中\n",
      "they...|||What不存在于词向量中\n",
      "I...|||Sorry不存在于词向量中\n",
      "judge?不存在于词向量中\n",
      "few?不存在于词向量中\n",
      "anyhow,不存在于词向量中\n",
      "supply.不存在于词向量中\n",
      "petty,不存在于词向量中\n",
      "DONE不存在于词向量中\n",
      "Vs不存在于词向量中\n",
      "Improving不存在于词向量中\n",
      "you're...'不存在于词向量中\n",
      "to?|||I不存在于词向量中\n",
      "too.|||I'm不存在于词向量中\n",
      "relation,不存在于词向量中\n",
      "months...|||I不存在于词向量中\n",
      "i...|||My不存在于词向量中\n",
      "ESxJs不存在于词向量中\n",
      "pleasures.不存在于词向量中\n",
      "closeness.不存在于词向量中\n",
      "discrimination,不存在于词向量中\n",
      "Connecting不存在于词向量中\n",
      "Conceptual不存在于词向量中\n",
      "Day!不存在于词向量中\n",
      "Basket不存在于词向量中\n",
      "players.不存在于词向量中\n",
      "Arkham不存在于词向量中\n",
      "Cookies不存在于词向量中\n",
      "Country,不存在于词向量中\n",
      "Barnum不存在于词向量中\n",
      "frightening,不存在于词向量中\n",
      "1/2oz不存在于词向量中\n",
      "self-conscious.不存在于词向量中\n",
      "spoilers,不存在于词向量中\n",
      "thingy,不存在于词向量中\n",
      "experiences...不存在于词向量中\n",
      "matter...不存在于词向量中\n",
      "you.|||A不存在于词向量中\n",
      "Poison不存在于词向量中\n",
      "3's不存在于词向量中\n",
      "sold.不存在于词向量中\n",
      "Si...|||I不存在于词向量中\n",
      "probably...|||I'm不存在于词向量中\n",
      "passing.不存在于词向量中\n",
      "marketing.不存在于词向量中\n",
      "(Except不存在于词向量中\n",
      "27.不存在于词向量中\n",
      "word.|||I不存在于词向量中\n",
      "and...|||An不存在于词向量中\n",
      "theorized不存在于词向量中\n",
      "angry...不存在于词向量中\n",
      "nightmares,不存在于词向量中\n",
      "league,不存在于词向量中\n",
      "Proper不存在于词向量中\n",
      "(short不存在于词向量中\n",
      "EN不存在于词向量中\n",
      "guidance,不存在于词向量中\n",
      "rebellious.不存在于词向量中\n",
      "Canis不存在于词向量中\n",
      "drawings.不存在于词向量中\n",
      "I...|||Never不存在于词向量中\n",
      "T-T不存在于词向量中\n",
      "about...|||The不存在于词向量中\n",
      "occurs.不存在于词向量中\n",
      "orderly,不存在于词向量中\n",
      "the...|||Seems不存在于词向量中\n",
      "outlet,不存在于词向量中\n",
      "Yamaha不存在于词向量中\n",
      "...|||Ah,不存在于词向量中\n",
      "Ram不存在于词向量中\n",
      "'you're不存在于词向量中\n",
      "(damn不存在于词向量中\n",
      "Gaga.不存在于词向量中\n",
      "me...|||1.不存在于词向量中\n",
      "voice?不存在于词向量中\n",
      "ceiling,不存在于词向量中\n",
      "Difference不存在于词向量中\n",
      "ladder,不存在于词向量中\n",
      "me...|||I've不存在于词向量中\n",
      "skirt,不存在于词向量中\n",
      "sunglasses,不存在于词向量中\n",
      "Clarkson不存在于词向量中\n",
      "Deathly不存在于词向量中\n",
      "much...|||I've不存在于词向量中\n",
      "ticket.不存在于词向量中\n",
      "scientists,不存在于词向量中\n",
      "grudges.不存在于词向量中\n",
      "along...不存在于词向量中\n",
      "Owl.不存在于词向量中\n",
      "detective.不存在于词向量中\n",
      "SM-G920V不存在于词向量中\n",
      "Depressive不存在于词向量中\n",
      "like...|||Yeah,不存在于词向量中\n",
      "'true'不存在于词向量中\n",
      "Pirate不存在于词向量中\n",
      "Believer不存在于词向量中\n",
      "unemotional,不存在于词向量中\n",
      "Talk,不存在于词向量中\n",
      "nonsensical.不存在于词向量中\n",
      "lonely...不存在于词向量中\n",
      "shells,不存在于词向量中\n",
      "spoiler.不存在于词向量中\n",
      "about...|||Well不存在于词向量中\n",
      "Q.不存在于词向量中\n",
      "discrimination.不存在于词向量中\n",
      "upbeat,不存在于词向量中\n",
      "she)不存在于词向量中\n",
      "Kerouac不存在于词向量中\n",
      "discuss...|||I不存在于词向量中\n",
      "Sweet,不存在于词向量中\n",
      "more...|||Thanks不存在于词向量中\n",
      "Enterprise不存在于词向量中\n",
      "Fireflies不存在于词向量中\n",
      "him...I不存在于词向量中\n",
      "have...|||Not不存在于词向量中\n",
      "(Ne),不存在于词向量中\n",
      "pessimist.不存在于词向量中\n",
      "ummm...不存在于词向量中\n",
      "(thats不存在于词向量中\n",
      "feels...|||I不存在于词向量中\n",
      "Battlefield不存在于词向量中\n",
      "hoodie,不存在于词向量中\n",
      "ENFJ;不存在于词向量中\n",
      "offers.不存在于词向量中\n",
      "Discussion不存在于词向量中\n",
      "Prayer不存在于词向量中\n",
      "INFP-ness不存在于词向量中\n",
      "ninja'd不存在于词向量中\n",
      "Reich不存在于词向量中\n",
      "it.|||Hello不存在于词向量中\n",
      "Shelby不存在于词向量中\n",
      "Huckleberry不存在于词向量中\n",
      "Warcraft,不存在于词向量中\n",
      "(38%)不存在于词向量中\n",
      "sibling.不存在于词向量中\n",
      "(none不存在于词向量中\n",
      "Administration不存在于词向量中\n",
      "youngest,不存在于词向量中\n",
      "infp...不存在于词向量中\n",
      "2004.不存在于词向量中\n",
      "neuroscience.不存在于词向量中\n",
      "clearly...|||I不存在于词向量中\n",
      "site.|||I不存在于词向量中\n",
      "stand,不存在于词向量中\n",
      "credibility.不存在于词向量中\n",
      "identical.不存在于词向量中\n",
      "arrived,不存在于词向量中\n",
      "Legacy不存在于词向量中\n",
      "slightly,不存在于词向量中\n",
      "Traditional不存在于词向量中\n",
      "foreign.不存在于词向量中\n",
      "more...|||When不存在于词向量中\n",
      "(70%)不存在于词向量中\n",
      "can...|||When不存在于词向量中\n",
      "Carrey不存在于词向量中\n",
      "Inspired不存在于词向量中\n",
      "Four,不存在于词向量中\n",
      "psychopaths,不存在于词向量中\n",
      "Habits不存在于词向量中\n",
      "deal?不存在于词向量中\n",
      "grumpy.不存在于词向量中\n",
      "around...不存在于词向量中\n",
      "unrealistic,不存在于词向量中\n",
      "Lena不存在于词向量中\n",
      "heels,不存在于词向量中\n",
      "Poll不存在于词向量中\n",
      "xSxJ不存在于词向量中\n",
      "by...|||The不存在于词向量中\n",
      "Trapped不存在于词向量中\n",
      "inc.不存在于词向量中\n",
      "ADD/ADHD不存在于词向量中\n",
      "5'4不存在于词向量中\n",
      "VP不存在于词向量中\n",
      "Se...|||I不存在于词向量中\n",
      ";)|||It's不存在于词向量中\n",
      "INTJ..不存在于词向量中\n",
      "Yoko不存在于词向量中\n",
      "Sniper不存在于词向量中\n",
      "exploration.不存在于词向量中\n",
      "smiles.不存在于词向量中\n",
      "Ns.不存在于词向量中\n",
      "class.|||I不存在于词向量中\n",
      "(Most不存在于词向量中\n",
      "Free|||I不存在于词向量中\n",
      "DC.不存在于词向量中\n",
      "Away,不存在于词向量中\n",
      "that...|||No,不存在于词向量中\n",
      "mom?不存在于词向量中\n",
      "Manga不存在于词向量中\n",
      ";/不存在于词向量中\n",
      "INFP..不存在于词向量中\n",
      "Derren不存在于词向量中\n",
      "known?不存在于词向量中\n",
      "B1-A71不存在于词向量中\n",
      "browser,不存在于词向量中\n",
      "Romanian不存在于词向量中\n",
      "F?不存在于词向量中\n",
      "Water,不存在于词向量中\n",
      "pockets,不存在于词向量中\n",
      "Mount不存在于词向量中\n",
      "lake.不存在于词向量中\n",
      "think),不存在于词向量中\n",
      "Stephanie不存在于词向量中\n",
      "wavelength.不存在于词向量中\n",
      "intuitively,不存在于词向量中\n",
      "care)不存在于词向量中\n",
      "who/what不存在于词向量中\n",
      "like...|||Good不存在于词向量中\n",
      "there),不存在于词向量中\n",
      "'special不存在于词向量中\n",
      "not...|||How不存在于词向量中\n",
      "the...|||Hello,不存在于词向量中\n",
      "Mannequin不存在于词向量中\n",
      "Hush不存在于词向量中\n",
      "personality's不存在于词向量中\n",
      "praise,不存在于词向量中\n",
      "who...'不存在于词向量中\n",
      "Twos不存在于词向量中\n",
      "Greek.不存在于词向量中\n",
      "Download不存在于词向量中\n",
      "scheme,不存在于词向量中\n",
      "curiosity?不存在于词向量中\n",
      ":laughing:|||Thanks不存在于词向量中\n",
      "neuroscience,不存在于词向量中\n",
      "Status:不存在于词向量中\n",
      "Twins不存在于词向量中\n",
      "Nin不存在于词向量中\n",
      "MBTi不存在于词向量中\n",
      "Namely,不存在于词向量中\n",
      "vet.不存在于词向量中\n",
      "like...|||As不存在于词向量中\n",
      "Frasier不存在于词向量中\n",
      "Poet不存在于词向量中\n",
      "INTPness.不存在于词向量中\n",
      "Google's不存在于词向量中\n",
      "angels.不存在于词向量中\n",
      "...|||We不存在于词向量中\n",
      "christmas,不存在于词向量中\n",
      "travel?不存在于词向量中\n",
      "Banana不存在于词向量中\n",
      "can't...|||This不存在于词向量中\n",
      "vampires,不存在于词向量中\n",
      "much.|||I'm不存在于词向量中\n",
      "degree...不存在于词向量中\n",
      "whiny.不存在于词向量中\n",
      "don't!不存在于词向量中\n",
      "called...不存在于词向量中\n",
      "that...but不存在于词向量中\n",
      "society...|||I不存在于词向量中\n",
      "clear...|||I不存在于词向量中\n",
      "Solo不存在于词向量中\n",
      "too.|||When不存在于词向量中\n",
      "their...|||If不存在于词向量中\n",
      "Spinoza不存在于词向量中\n",
      "fall...|||I不存在于词向量中\n",
      "I'm...|||Thanks不存在于词向量中\n",
      "was.|||I不存在于词向量中\n",
      "apologized,不存在于词向量中\n",
      "short?不存在于词向量中\n",
      "RN不存在于词向量中\n",
      "to...|||Okay,不存在于词向量中\n",
      "like...|||Well不存在于词向量中\n",
      "tangents,不存在于词向量中\n",
      "brained,不存在于词向量中\n",
      "Rust不存在于词向量中\n",
      "Rinse不存在于词向量中\n",
      "Symphonic不存在于词向量中\n",
      "more....不存在于词向量中\n",
      "helps.|||I不存在于词向量中\n",
      "your...|||It不存在于词向量中\n",
      "Theme:不存在于词向量中\n",
      "with?|||I不存在于词向量中\n",
      ":tongue:|||1.不存在于词向量中\n",
      "unwanted,不存在于词向量中\n",
      "turkey,不存在于词向量中\n",
      "is,...|||I不存在于词向量中\n",
      "topic..不存在于词向量中\n",
      "Stanford不存在于词向量中\n",
      "into...|||I'm不存在于词向量中\n",
      "Eights不存在于词向量中\n",
      "Checked不存在于词向量中\n",
      "find...|||My不存在于词向量中\n",
      "thesis.不存在于词向量中\n",
      "what?!不存在于词向量中\n",
      "have...|||I'll不存在于词向量中\n",
      "H&M不存在于词向量中\n",
      "year...|||I不存在于词向量中\n",
      "(personally不存在于词向量中\n",
      "Heir不存在于词向量中\n",
      "really...|||You不存在于词向量中\n",
      "When?不存在于词向量中\n",
      "Narcissism不存在于词向量中\n",
      "to...|||Wow不存在于词向量中\n",
      "american,不存在于词向量中\n",
      "well-being,不存在于词向量中\n",
      "biases.不存在于词向量中\n",
      "creatively.不存在于词向量中\n",
      "ASAP不存在于词向量中\n",
      "replies...不存在于词向量中\n",
      "comeback.不存在于词向量中\n",
      "Talon不存在于词向量中\n",
      "water?不存在于词向量中\n",
      "have...|||Well,不存在于词向量中\n",
      "PersonalDNA不存在于词向量中\n",
      "Creator不存在于词向量中\n",
      "coin,不存在于词向量中\n",
      "JCF不存在于词向量中\n",
      "PersonalityCafe!不存在于词向量中\n",
      "Choice不存在于词向量中\n",
      "genitals.不存在于词向量中\n",
      "but...|||So不存在于词向量中\n",
      "Ti-dom.不存在于词向量中\n",
      "Toxic不存在于词向量中\n",
      "Austrian不存在于词向量中\n",
      "clearer,不存在于词向量中\n",
      "could...|||I'm不存在于词向量中\n",
      "apologise.不存在于词向量中\n",
      "the...|||Interesting.不存在于词向量中\n",
      "his...|||You不存在于词向量中\n",
      "apples.不存在于词向量中\n",
      "it.....不存在于词向量中\n",
      "grin.不存在于词向量中\n",
      "case).不存在于词向量中\n",
      "was).不存在于词向量中\n",
      ":proud:|||When不存在于词向量中\n",
      "Implying不存在于词向量中\n",
      "Intuition,不存在于词向量中\n",
      "got...|||I'm不存在于词向量中\n",
      "TV?不存在于词向量中\n",
      "Lester不存在于词向量中\n",
      "Nye不存在于词向量中\n",
      "Sorta不存在于词向量中\n",
      "Sooner不存在于词向量中\n",
      "Before,不存在于词向量中\n",
      "for...|||So不存在于词向量中\n",
      "Narcissist不存在于词向量中\n",
      "INFP/INFJ不存在于词向量中\n",
      "too...I不存在于词向量中\n",
      "threads...不存在于词向量中\n",
      "own...不存在于词向量中\n",
      "Titanic,不存在于词向量中\n",
      "Tomb不存在于词向量中\n",
      "if...|||So不存在于词向量中\n",
      "type.|||I'm不存在于词向量中\n",
      "sloppy.不存在于词向量中\n",
      "Texas.不存在于词向量中\n",
      "Total:不存在于词向量中\n",
      "my...|||Well不存在于词向量中\n",
      "Cal不存在于词向量中\n",
      "worse.|||I不存在于词向量中\n",
      "phone)不存在于词向量中\n",
      "Mondays不存在于词向量中\n",
      "Paradox不存在于词向量中\n",
      "6s,不存在于词向量中\n",
      "you...|||Hello不存在于词向量中\n",
      "signal.不存在于词向量中\n",
      "Intrapersonal不存在于词向量中\n",
      "adaptable,不存在于词向量中\n",
      "-This不存在于词向量中\n",
      "pure.不存在于词向量中\n",
      "if...|||My不存在于词向量中\n",
      "months),不存在于词向量中\n",
      "Exciting不存在于词向量中\n",
      "orders.不存在于词向量中\n",
      "Seen不存在于词向量中\n",
      "Closing不存在于词向量中\n",
      "umbrella.不存在于词向量中\n",
      "places...|||I不存在于词向量中\n",
      "zero.不存在于词向量中\n",
      "Resources不存在于词向量中\n",
      "had?不存在于词向量中\n",
      "apologise,不存在于词向量中\n",
      "Yes.|||I不存在于词向量中\n",
      "suppressed.不存在于词向量中\n",
      "Empires不存在于词向量中\n",
      "Polish,不存在于词向量中\n",
      "secret?不存在于词向量中\n",
      "communism,不存在于词向量中\n",
      "Lost.不存在于词向量中\n",
      "taller.不存在于词向量中\n",
      "threats,不存在于词向量中\n",
      "Cannibal不存在于词向量中\n",
      "Squad不存在于词向量中\n",
      "Gump不存在于词向量中\n",
      "Roses不存在于词向量中\n",
      "claims,不存在于词向量中\n",
      "Newbie不存在于词向量中\n",
      ";)|||Oh不存在于词向量中\n",
      "address.不存在于词向量中\n",
      "formula.不存在于词向量中\n",
      ":D|||Oh不存在于词向量中\n",
      "certain)不存在于词向量中\n",
      "Emotionally,不存在于词向量中\n",
      "Labour不存在于词向量中\n",
      "print.不存在于词向量中\n",
      "-Love不存在于词向量中\n",
      "endeavors.不存在于词向量中\n",
      "find...'不存在于词向量中\n",
      "grip,不存在于词向量中\n",
      "masters.不存在于词向量中\n",
      "IQ's不存在于词向量中\n",
      "Idol不存在于词向量中\n",
      "Kaneki不存在于词向量中\n",
      "aren't?不存在于词向量中\n",
      "friendship)不存在于词向量中\n",
      "olds.不存在于词向量中\n",
      "=)|||I'm不存在于词向量中\n",
      "tragic,不存在于词向量中\n",
      "EXTJ不存在于词向量中\n",
      "Ne.|||I不存在于词向量中\n",
      "disturbed.不存在于词向量中\n",
      "Linux.不存在于词向量中\n",
      "MBTI),不存在于词向量中\n",
      "tertiary.不存在于词向量中\n",
      "possessions,不存在于词向量中\n",
      "Oo不存在于词向量中\n",
      "Conspiracy不存在于词向量中\n",
      "GIF不存在于词向量中\n",
      "INTJs'不存在于词向量中\n",
      "toddler.不存在于词向量中\n",
      "muscular,不存在于词向量中\n",
      "Cons:不存在于词向量中\n",
      "Religion,不存在于词向量中\n",
      "Shoot,不存在于词向量中\n",
      "ambidextrous.不存在于词向量中\n",
      "afterward,不存在于词向量中\n",
      "disorder...不存在于词向量中\n",
      "bi-polar,不存在于词向量中\n",
      "Indicator不存在于词向量中\n",
      "Males不存在于词向量中\n",
      "mistype,不存在于词向量中\n",
      "Einstein.不存在于词向量中\n",
      "Blank不存在于词向量中\n",
      "Misa不存在于词向量中\n",
      "exaggeration,不存在于词向量中\n",
      "lol....不存在于词向量中\n",
      "THANKS不存在于词向量中\n",
      "groceries.不存在于词向量中\n",
      "monologue,不存在于词向量中\n",
      "Starbucks.不存在于词向量中\n",
      "forgiving,不存在于词向量中\n",
      "accomplish.不存在于词向量中\n",
      "infinity,不存在于词向量中\n",
      "BSc不存在于词向量中\n",
      "ISTP...|||I不存在于词向量中\n",
      "legitimate.不存在于词向量中\n",
      "like...|||Oh不存在于词向量中\n",
      "vocabulary.不存在于词向量中\n",
      "is...|||Do不存在于词向量中\n",
      "SM-G900F不存在于词向量中\n",
      "Ti-Ne.不存在于词向量中\n",
      "Polar不存在于词向量中\n",
      "members'不存在于词向量中\n",
      "'relationship'不存在于词向量中\n",
      "Fitness不存在于词向量中\n",
      "Maroon不存在于词向量中\n",
      "scarf,不存在于词向量中\n",
      "Momo不存在于词向量中\n",
      "their,不存在于词向量中\n",
      "Let鈥檚不存在于词向量中\n",
      "'evil'不存在于词向量中\n",
      "perceiving,不存在于词向量中\n",
      "ways)不存在于词向量中\n",
      "sexually.不存在于词向量中\n",
      "bond,不存在于词向量中\n",
      "GP不存在于词向量中\n",
      "'different'不存在于词向量中\n",
      "unnoticed.不存在于词向量中\n",
      "external,不存在于词向量中\n",
      "achievements.不存在于词向量中\n",
      "avatars,不存在于词向量中\n",
      "Niccolo不存在于词向量中\n",
      "tho...不存在于词向量中\n",
      "why's不存在于词向量中\n",
      "STJs.不存在于词向量中\n",
      "WoW.不存在于词向量中\n",
      "fast...不存在于词向量中\n",
      "directness,不存在于词向量中\n",
      "betrayal,不存在于词向量中\n",
      "Danganronpa不存在于词向量中\n",
      "obligations.不存在于词向量中\n",
      "homophobic,不存在于词向量中\n",
      "possibly?不存在于词向量中\n",
      "abuser.不存在于词向量中\n",
      "do...|||It不存在于词向量中\n",
      "Muppets不存在于词向量中\n",
      "Wtf不存在于词向量中\n",
      "Alphonse不存在于词向量中\n",
      "LET'S不存在于词向量中\n",
      "Holmes.不存在于词向量中\n",
      "Aquarius,不存在于词向量中\n",
      "whim,不存在于词向量中\n",
      "wolf.不存在于词向量中\n",
      "adrenaline.不存在于词向量中\n",
      "harmful,不存在于词向量中\n",
      "Careers不存在于词向量中\n",
      "theory)不存在于词向量中\n",
      "conceited,不存在于词向量中\n",
      "he...|||I'm不存在于词向量中\n",
      "saved.不存在于词向量中\n",
      "KFC不存在于词向量中\n",
      "ice,不存在于词向量中\n",
      "Flynn不存在于词向量中\n",
      "it.|||Yes不存在于词向量中\n",
      "implications,不存在于词向量中\n",
      "(4th不存在于词向量中\n",
      "puppet.不存在于词向量中\n",
      "up...|||If不存在于词向量中\n",
      "Jennywocky不存在于词向量中\n",
      "reader?不存在于词向量中\n",
      "Posts不存在于词向量中\n",
      "K-12不存在于词向量中\n",
      "Suffering不存在于词向量中\n",
      "smartphone.不存在于词向量中\n",
      "Euron不存在于词向量中\n",
      "sticky,不存在于词向量中\n",
      "Fate/Zero不存在于词向量中\n",
      "once)不存在于词向量中\n",
      "Lied不存在于词向量中\n",
      "NT:不存在于词向量中\n",
      "DOTA不存在于词向量中\n",
      ":P|||It's不存在于词向量中\n",
      "loops.不存在于词向量中\n",
      "isfj.不存在于词向量中\n",
      "one.'不存在于词向量中\n",
      ":D|||That不存在于词向量中\n",
      "^_^|||I'm不存在于词向量中\n",
      "importance,不存在于词向量中\n",
      "gravity,不存在于词向量中\n",
      "OP?不存在于词向量中\n",
      "my...|||At不存在于词向量中\n",
      "gifted.不存在于词向量中\n",
      "style)不存在于词向量中\n",
      "gravy.不存在于词向量中\n",
      "Kay不存在于词向量中\n",
      "you're...|||I'm不存在于词向量中\n",
      "Male:不存在于词向量中\n",
      "Surprised不存在于词向量中\n",
      "customers,不存在于词向量中\n",
      "Tai不存在于词向量中\n",
      "Merely不存在于词向量中\n",
      "Fe-Si不存在于词向量中\n",
      "convincing.不存在于词向量中\n",
      "Honesty,不存在于词向量中\n",
      "scholar,不存在于词向量中\n",
      "(want不存在于词向量中\n",
      "drunk?不存在于词向量中\n",
      "(Ti).不存在于词向量中\n",
      "Myself,不存在于词向量中\n",
      "P.S.:不存在于词向量中\n",
      "Tapatalk|||No,不存在于词向量中\n",
      "I...|||At不存在于词向量中\n",
      "Interstellar不存在于词向量中\n",
      "'I'不存在于词向量中\n",
      "(things不存在于词向量中\n",
      ":tongue:|||How不存在于词向量中\n",
      "doormat.不存在于词向量中\n",
      "ENFJ|||I不存在于词向量中\n",
      "Apartment不存在于词向量中\n",
      "Kirk不存在于词向量中\n",
      "and...|||Lol,不存在于词向量中\n",
      "toilet.不存在于词向量中\n",
      "details...不存在于词向量中\n",
      "Scully不存在于词向量中\n",
      "biking,不存在于词向量中\n",
      "misunderstandings,不存在于词向量中\n",
      "optimist.不存在于词向量中\n",
      "ourselves?不存在于词向量中\n",
      "INFJs...|||I不存在于词向量中\n",
      "covers,不存在于词向量中\n",
      "op.不存在于词向量中\n",
      "a...|||After不存在于词向量中\n",
      "Nation不存在于词向量中\n",
      "entj's不存在于词向量中\n",
      "Quran不存在于词向量中\n",
      "think...|||Oh不存在于词向量中\n",
      "Cities不存在于词向量中\n",
      "many)不存在于词向量中\n",
      "dead...不存在于词向量中\n",
      "Fe;不存在于词向量中\n",
      "now.)不存在于词向量中\n",
      "KKK不存在于词向量中\n",
      "Forgetting不存在于词向量中\n",
      "what...不存在于词向量中\n",
      "ASD不存在于词向量中\n",
      "cookie?不存在于词向量中\n",
      "aunt's不存在于词向量中\n",
      "plastic,不存在于词向量中\n",
      "sx,不存在于词向量中\n",
      "preparation.不存在于词向量中\n",
      "(although,不存在于词向量中\n",
      "Intuiting不存在于词向量中\n",
      "Hume不存在于词向量中\n",
      "tidy,不存在于词向量中\n",
      "represents.不存在于词向量中\n",
      "Almond不存在于词向量中\n",
      "Death.不存在于词向量中\n",
      ":tongue:|||It不存在于词向量中\n",
      "one...|||You不存在于词向量中\n",
      "inputs,不存在于词向量中\n",
      "DIE不存在于词向量中\n",
      "Gandhi,不存在于词向量中\n",
      "rides.不存在于词向量中\n",
      ":)|||Thanks.不存在于词向量中\n",
      "manifest.不存在于词向量中\n",
      "馃尮|||Hello不存在于词向量中\n",
      "NA不存在于词向量中\n",
      "close...不存在于词向量中\n",
      "Master.不存在于词向量中\n",
      "hipster,不存在于词向量中\n",
      "Loathing不存在于词向量中\n",
      "TX.不存在于词向量中\n",
      "nice'不存在于词向量中\n",
      "Flanders不存在于词向量中\n",
      "little)不存在于词向量中\n",
      "insects,不存在于词向量中\n",
      ":laughing:|||So不存在于词向量中\n",
      "(Aspie)不存在于词向量中\n",
      "(asked不存在于词向量中\n",
      "tomboy,不存在于词向量中\n",
      "Irrelevant不存在于词向量中\n",
      "LittleDreamer不存在于词向量中\n",
      "COD不存在于词向量中\n",
      "Saves不存在于词向量中\n",
      "Walked不存在于词向量中\n",
      "nephew,不存在于词向量中\n",
      "Hung不存在于词向量中\n",
      "Harsh不存在于词向量中\n",
      "Bitter不存在于词向量中\n",
      "Trevor不存在于词向量中\n",
      "depressed...不存在于词向量中\n",
      "Oreo不存在于词向量中\n",
      "stories...|||I不存在于词向量中\n",
      "myself....|||I不存在于词向量中\n",
      "'well不存在于词向量中\n",
      "Shania不存在于词向量中\n",
      ".|||My不存在于词向量中\n",
      "Don't.不存在于词向量中\n",
      ":blushed:|||I'm不存在于词向量中\n",
      "painless.不存在于词向量中\n",
      "Tchaikovsky不存在于词向量中\n",
      "point..不存在于词向量中\n",
      "sunset,不存在于词向量中\n",
      "Bleh.不存在于词向量中\n",
      "corrected.不存在于词向量中\n",
      "serious...不存在于词向量中\n",
      "Se-Te不存在于词向量中\n",
      "Ouch,不存在于词向量中\n",
      "Austin,不存在于词向量中\n",
      "a.)不存在于词向量中\n",
      "b.)不存在于词向量中\n",
      "(ex.不存在于词向量中\n",
      "Theoretically不存在于词向量中\n",
      "0,不存在于词向量中\n",
      "couldn't,不存在于词向量中\n",
      "CafeBot不存在于词向量中\n",
      "Prior不存在于词向量中\n",
      "vocals,不存在于词向量中\n",
      "precisely.不存在于词向量中\n",
      "Analysis:不存在于词向量中\n",
      "presents.不存在于词向量中\n",
      "The...'不存在于词向量中\n",
      "nickname.不存在于词向量中\n",
      "excitable,不存在于词向量中\n",
      "Skinny不存在于词向量中\n",
      "world.|||I'm不存在于词向量中\n",
      ":D|||Some不存在于词向量中\n",
      "Charisma-不存在于词向量中\n",
      "(John不存在于词向量中\n",
      "hints,不存在于词向量中\n",
      "load.不存在于词向量中\n",
      "mythology.不存在于词向量中\n",
      "distress.不存在于词向量中\n",
      "fridge,不存在于词向量中\n",
      "'Those不存在于词向量中\n",
      "(More不存在于词向量中\n",
      "Also...|||I不存在于词向量中\n",
      "goes...|||I不存在于词向量中\n",
      "Thanx不存在于词向量中\n",
      "cruelty,不存在于词向量中\n",
      "Occupy不存在于词向量中\n",
      "worthwhile,不存在于词向量中\n",
      "ladies'不存在于词向量中\n",
      "ever...不存在于词向量中\n",
      "Dummies-不存在于词向量中\n",
      "Fern不存在于词向量中\n",
      "furniture.不存在于词向量中\n",
      ":tongue:|||That不存在于词向量中\n",
      "Sophie不存在于词向量中\n",
      "somethin'不存在于词向量中\n",
      "Pretend不存在于词向量中\n",
      "then?|||I不存在于词向量中\n",
      "Canadian,不存在于词向量中\n",
      "Punjabi不存在于词向量中\n",
      "that...|||Lol不存在于词向量中\n",
      "friends|||I不存在于词向量中\n",
      "in...|||Not不存在于词向量中\n",
      "INFP/ENFP不存在于词向量中\n",
      "guy.|||I不存在于词向量中\n",
      "pretentious.不存在于词向量中\n",
      "about...|||So不存在于词向量中\n",
      "pal,不存在于词向量中\n",
      "Kakashi不存在于词向量中\n",
      "Tapatalk|||Banned不存在于词向量中\n",
      "Reese不存在于词向量中\n",
      "judger,不存在于词向量中\n",
      "Istps不存在于词向量中\n",
      "Simba不存在于词向量中\n",
      "(High不存在于词向量中\n",
      "tomorrow...不存在于词向量中\n",
      "Claude不存在于词向量中\n",
      "requirement,不存在于词向量中\n",
      "physically...|||I不存在于词向量中\n",
      "Sexuality不存在于词向量中\n",
      "BPD,不存在于词向量中\n",
      "correction.不存在于词向量中\n",
      "charts,不存在于词向量中\n",
      "helicopters不存在于词向量中\n",
      "Cho不存在于词向量中\n",
      "tip.不存在于词向量中\n",
      "years..不存在于词向量中\n",
      "X)不存在于词向量中\n",
      "it...|||Yeah不存在于词向量中\n",
      "mascara,不存在于词向量中\n",
      "Dreams,不存在于词向量中\n",
      "any...|||I've不存在于词向量中\n",
      "Out.不存在于词向量中\n",
      "Root不存在于词向量中\n",
      "my...|||And不存在于词向量中\n",
      "Jewish.不存在于词向量中\n",
      "Frieza不存在于词向量中\n",
      "turtles,不存在于词向量中\n",
      "'why'不存在于词向量中\n",
      "XNXP不存在于词向量中\n",
      "Utopian不存在于词向量中\n",
      "Swim不存在于词向量中\n",
      "Fibonacci不存在于词向量中\n",
      "coolest.不存在于词向量中\n",
      "Candles不存在于词向量中\n",
      "Morals不存在于词向量中\n",
      "sx/soc不存在于词向量中\n",
      "Caregiver不存在于词向量中\n",
      "Desk不存在于词向量中\n",
      "Characters:不存在于词向量中\n",
      "tempers.不存在于词向量中\n",
      "`不存在于词向量中\n",
      "Babylon,不存在于词向量中\n",
      "avoided.不存在于词向量中\n",
      "Che不存在于词向量中\n",
      "Depp,不存在于词向量中\n",
      "fine?不存在于词向量中\n",
      ">:)不存在于词向量中\n",
      "PERSON不存在于词向量中\n",
      "writer?不存在于词向量中\n",
      "Jane,不存在于词向量中\n",
      "Lo不存在于词向量中\n",
      "x01660|||I不存在于词向量中\n",
      "Sammy不存在于词向量中\n",
      "Utopia不存在于词向量中\n",
      "ENFJ/INFP不存在于词向量中\n",
      "law?不存在于词向量中\n",
      "Excessive不存在于词向量中\n",
      "company's不存在于词向量中\n",
      "encountered,不存在于词向量中\n",
      "though.'不存在于词向量中\n",
      "rapapbara不存在于词向量中\n",
      "(1,不存在于词向量中\n",
      "Flags不存在于词向量中\n",
      "Ay,不存在于词向量中\n",
      "Minato,不存在于词向量中\n",
      "Nagato.不存在于词向量中\n",
      "Decisions不存在于词向量中\n",
      "contact.|||I不存在于词向量中\n",
      "women)不存在于词向量中\n",
      "Faye不存在于词向量中\n",
      "as...|||A不存在于词向量中\n",
      "expressing,不存在于词向量中\n",
      "reflecting,不存在于词向量中\n",
      "it.|||Oh,不存在于词向量中\n",
      "being...|||Do不存在于词向量中\n",
      "cellphone.不存在于词向量中\n",
      "how...'不存在于词向量中\n",
      "group's不存在于词向量中\n",
      "old.|||I不存在于词向量中\n",
      "Superpower不存在于词向量中\n",
      "Relativity不存在于词向量中\n",
      "Gundam不存在于词向量中\n",
      "overthinking,不存在于词向量中\n",
      "Ops不存在于词向量中\n",
      "3.|||I不存在于词向量中\n",
      "stats,不存在于词向量中\n",
      "would...|||For不存在于词向量中\n",
      "moves.不存在于词向量中\n",
      "Authenticity不存在于词向量中\n",
      "Shared不存在于词向量中\n",
      "degree)不存在于词向量中\n",
      "component,不存在于词向量中\n",
      "right!!不存在于词向量中\n",
      "risky,不存在于词向量中\n",
      "bench,不存在于词向量中\n",
      "Innovator不存在于词向量中\n",
      "Awww,不存在于词向量中\n",
      "2007.不存在于词向量中\n",
      "gem.不存在于词向量中\n",
      "difficulty...|||I不存在于词向量中\n",
      "(New不存在于词向量中\n",
      "little).不存在于词向量中\n",
      "picture).不存在于词向量中\n",
      "drummer,不存在于词向量中\n",
      "heavily,不存在于词向量中\n",
      "Ohhh不存在于词向量中\n",
      "overthinking.不存在于词向量中\n",
      "Select不存在于词向量中\n",
      "books),不存在于词向量中\n",
      "Chronicle不存在于词向量中\n",
      "think?)不存在于词向量中\n",
      "Quebec不存在于词向量中\n",
      "noooo,不存在于词向量中\n",
      "isfj's不存在于词向量中\n",
      "because...|||It不存在于词向量中\n",
      "fanatics.不存在于词向量中\n",
      "creature,不存在于词向量中\n",
      "wreck,不存在于词向量中\n",
      "personalitycafe.不存在于词向量中\n",
      "asses.不存在于词向量中\n",
      "Morpheus不存在于词向量中\n",
      "imbalance,不存在于词向量中\n",
      "Dictionary不存在于词向量中\n",
      "Feminine:不存在于词向量中\n",
      "Only,不存在于词向量中\n",
      "just...|||Thank不存在于词向量中\n",
      "practices,不存在于词向量中\n",
      "responds.不存在于词向量中\n",
      "eerie.不存在于词向量中\n",
      "tales.不存在于词向量中\n",
      "Pig不存在于词向量中\n",
      "of...|||Now不存在于词向量中\n",
      "reviews,不存在于词向量中\n",
      "of...|||Some不存在于词向量中\n",
      "convenient,不存在于词向量中\n",
      "square.不存在于词向量中\n",
      "-|||I不存在于词向量中\n",
      "volunteering.不存在于词向量中\n",
      "SFJ.不存在于词向量中\n",
      "closed?不存在于词向量中\n",
      "intentions?不存在于词向量中\n",
      "dude?不存在于词向量中\n",
      "though.|||I've不存在于词向量中\n",
      "park)不存在于词向量中\n",
      ":tongue:|||Why不存在于词向量中\n",
      "it.|||Just不存在于词向量中\n",
      "nothingness,不存在于词向量中\n",
      "Trolls不存在于词向量中\n",
      "world..不存在于词向量中\n",
      "world...|||I'm不存在于词向量中\n",
      "Pets不存在于词向量中\n",
      "pharmacy.不存在于词向量中\n",
      "advise,不存在于词向量中\n",
      "resemblance.不存在于词向量中\n",
      "Marx,不存在于词向量中\n",
      "astronaut,不存在于词向量中\n",
      ";)|||Yes不存在于词向量中\n",
      "deer.不存在于词向量中\n",
      "applies.不存在于词向量中\n",
      "stimulants.不存在于词向量中\n",
      "Careful不存在于词向量中\n",
      "ailment不存在于词向量中\n",
      "life.|||It不存在于词向量中\n",
      "'Who不存在于词向量中\n",
      "am...|||How不存在于词向量中\n",
      "librarian,不存在于词向量中\n",
      "is...|||So,不存在于词向量中\n",
      "but...|||Yeah,不存在于词向量中\n",
      "Organizational不存在于词向量中\n",
      "careless,不存在于词向量中\n",
      "last)不存在于词向量中\n",
      "tomato,不存在于词向量中\n",
      "me.|||Yes,不存在于词向量中\n",
      "scored.不存在于词向量中\n",
      "here?|||I不存在于词向量中\n",
      "Most...|||I不存在于词向量中\n",
      "skin?不存在于词向量中\n",
      "junk.不存在于词向量中\n",
      "Churches不存在于词向量中\n",
      "Ne-dominant不存在于词向量中\n",
      "rather:不存在于词向量中\n",
      "ENFP|||I'm不存在于词向量中\n",
      "try?不存在于词向量中\n",
      "Sauron不存在于词向量中\n",
      "1950's不存在于词向量中\n",
      "Cat.不存在于词向量中\n",
      "doctor?不存在于词向量中\n",
      "R&B,不存在于词向量中\n",
      "Dissonance,不存在于词向量中\n",
      "Just.不存在于词向量中\n",
      "guess....不存在于词向量中\n",
      "INFPs)不存在于词向量中\n",
      "what...|||That不存在于词向量中\n",
      "Killers,不存在于词向量中\n",
      "Ty不存在于词向量中\n",
      "them!|||I不存在于词向量中\n",
      "Jobs,不存在于词向量中\n",
      "adjust.不存在于词向量中\n",
      "out/不存在于词向量中\n",
      "</3不存在于词向量中\n",
      "or...|||Just不存在于词向量中\n",
      "Lloyd不存在于词向量中\n",
      "Database不存在于词向量中\n",
      "distribution.不存在于词向量中\n",
      "and...|||Every不存在于词向量中\n",
      "Badlands不存在于词向量中\n",
      "Sounded不存在于词向量中\n",
      "i,不存在于词向量中\n",
      "Judging.不存在于词向量中\n",
      "modes,不存在于词向量中\n",
      "punch,不存在于词向量中\n",
      "is...|||Are不存在于词向量中\n",
      "natural...|||I不存在于词向量中\n",
      "aboard,不存在于词向量中\n",
      "xD),不存在于词向量中\n",
      ".__.不存在于词向量中\n",
      "practise,不存在于词向量中\n",
      "a...|||Great不存在于词向量中\n",
      "sexism,不存在于词向量中\n",
      "Mango不存在于词向量中\n",
      "Gothic不存在于词向量中\n",
      "...|||Pretty不存在于词向量中\n",
      "Legends,不存在于词向量中\n",
      "gospel,不存在于词向量中\n",
      "Performer,不存在于词向量中\n",
      "instrumental,不存在于词向量中\n",
      "Particularly,不存在于词向量中\n",
      "exaggeration.不存在于词向量中\n",
      "Rock.不存在于词向量中\n",
      "they...|||Not不存在于词向量中\n",
      "Extroversion,不存在于词向量中\n",
      "precision,不存在于词向量中\n",
      "something...|||This不存在于词向量中\n",
      "wording,不存在于词向量中\n",
      "(mother不存在于词向量中\n",
      "orgasm.不存在于词向量中\n",
      "french.不存在于词向量中\n",
      "bother?不存在于词向量中\n",
      ":laughing:|||Well,不存在于词向量中\n",
      "I...|||Ah不存在于词向量中\n",
      ":cool:|||You不存在于词向量中\n",
      "Chestnut不存在于词向量中\n",
      "rubbish,不存在于词向量中\n",
      "implies,不存在于词向量中\n",
      "52.94%不存在于词向量中\n",
      "(wanting不存在于词向量中\n",
      "Michael,不存在于词向量中\n",
      "shake,不存在于词向量中\n",
      "nor...|||I不存在于词向量中\n",
      "Daisy不存在于词向量中\n",
      "indifferent.不存在于词向量中\n",
      "INFP;不存在于词向量中\n",
      "a...|||Hmm...不存在于词向量中\n",
      "teacher)不存在于词向量中\n",
      "Valjean不存在于词向量中\n",
      "needs...|||I不存在于词向量中\n",
      "Riddle不存在于词向量中\n",
      "NeTi不存在于词向量中\n",
      "high...不存在于词向量中\n",
      "can)不存在于词向量中\n",
      "with...|||On不存在于词向量中\n",
      "type'不存在于词向量中\n",
      "Yup!不存在于词向量中\n",
      "any...|||My不存在于词向量中\n",
      "dont...|||I不存在于词向量中\n",
      "began.不存在于词向量中\n",
      "btw.|||I不存在于词向量中\n",
      "dot.不存在于词向量中\n",
      "coffee...|||I不存在于词向量中\n",
      "Leigh不存在于词向量中\n",
      "Waters不存在于词向量中\n",
      "blocks,不存在于词向量中\n",
      "exact)不存在于词向量中\n",
      "who)不存在于词向量中\n",
      "IME,不存在于词向量中\n",
      "about...|||Well,不存在于词向量中\n",
      "lot).不存在于词向量中\n",
      "behaved,不存在于词向量中\n",
      "contest,不存在于词向量中\n",
      "Curiosity,不存在于词向量中\n",
      "doing)不存在于词向量中\n",
      "functions.|||I不存在于词向量中\n",
      "ESFP|||I不存在于词向量中\n",
      "1|||I不存在于词向量中\n",
      "Spatial不存在于词向量中\n",
      "tag.不存在于词向量中\n",
      "Bastard不存在于词向量中\n",
      "manage,不存在于词向量中\n",
      "that...|||At不存在于词向量中\n",
      "results...不存在于词向量中\n",
      "comment)不存在于词向量中\n",
      "out).不存在于词向量中\n",
      "to...|||Please不存在于词向量中\n",
      "rational?不存在于词向量中\n",
      "Steps不存在于词向量中\n",
      "do.|||The不存在于词向量中\n",
      "snail.不存在于词向量中\n",
      "neighbor.不存在于词向量中\n",
      "Problem?不存在于词向量中\n",
      "fluid.不存在于词向量中\n",
      "bought?不存在于词向量中\n",
      "...|||Wow不存在于词向量中\n",
      "S/N.不存在于词向量中\n",
      "flash,不存在于词向量中\n",
      "editor,不存在于词向量中\n",
      "discussed,不存在于词向量中\n",
      "ILE,不存在于词向量中\n",
      "Melancholic不存在于词向量中\n",
      "it...|||That不存在于词向量中\n",
      "E)不存在于词向量中\n",
      "concerns,不存在于词向量中\n",
      "Hundred不存在于词向量中\n",
      "Republic.不存在于词向量中\n",
      "output,不存在于词向量中\n",
      "that...|||Welcome不存在于词向量中\n",
      "up.|||It不存在于词向量中\n",
      "Oprah不存在于词向量中\n",
      "Lock不存在于词向量中\n",
      "knives.不存在于词向量中\n",
      "Please?不存在于词向量中\n",
      "Matthews不存在于词向量中\n",
      "ego?不存在于词向量中\n",
      "need...不存在于词向量中\n",
      "Cop不存在于词向量中\n",
      "...|||Only不存在于词向量中\n",
      "Smiths,不存在于词向量中\n",
      "Sticky不存在于词向量中\n",
      "2000.不存在于词向量中\n",
      "drinker.不存在于词向量中\n",
      "do....|||I不存在于词向量中\n",
      "lol|||Yeah不存在于词向量中\n",
      "lighting.不存在于词向量中\n",
      "DW不存在于词向量中\n",
      "avatar).不存在于词向量中\n",
      "Fs,不存在于词向量中\n",
      "insurance,不存在于词向量中\n",
      "main...|||I不存在于词向量中\n",
      "so...|||The不存在于词向量中\n",
      "(INTJ),不存在于词向量中\n",
      "horny,不存在于词向量中\n",
      "know),不存在于词向量中\n",
      "funny..不存在于词向量中\n",
      "buff,不存在于词向量中\n",
      "outrageous,不存在于词向量中\n",
      "women...|||I不存在于词向量中\n",
      "unique...|||I不存在于词向量中\n",
      "our...'不存在于词向量中\n",
      "I...|||Okay不存在于词向量中\n",
      "News,不存在于词向量中\n",
      "Silmarillion不存在于词向量中\n",
      "good...|||What不存在于词向量中\n",
      "Existentialism不存在于词向量中\n",
      "Olsen不存在于词向量中\n",
      "Jeffrey不存在于词向量中\n",
      "Dropkick不存在于词向量中\n",
      "this...|||And不存在于词向量中\n",
      "darling,不存在于词向量中\n",
      "(?),不存在于词向量中\n",
      "the...|||Its不存在于词向量中\n",
      "congratulations.不存在于词向量中\n",
      "nonexistent.不存在于词向量中\n",
      "ISTJs!不存在于词向量中\n",
      "ofcourse.不存在于词向量中\n",
      "lately.|||I不存在于词向量中\n",
      "hypocrites,不存在于词向量中\n",
      "picture...|||I不存在于词向量中\n",
      "a...|||Too不存在于词向量中\n",
      "'smart'不存在于词向量中\n",
      "talk..不存在于词向量中\n",
      "OTL不存在于词向量中\n",
      "Charismatic不存在于词向量中\n",
      "exactly...不存在于词向量中\n",
      "vanish.不存在于词向量中\n",
      "INTJ'不存在于词向量中\n",
      "Doin?不存在于词向量中\n",
      "intimidating?不存在于词向量中\n",
      "Mick不存在于词向量中\n",
      "position?不存在于词向量中\n",
      "loops,不存在于词向量中\n",
      "Bebop,不存在于词向量中\n",
      "HAVEN'T不存在于词向量中\n",
      "me...|||So不存在于词向量中\n",
      "ambiguous,不存在于词向量中\n",
      "rest:不存在于词向量中\n",
      "Thomson's不存在于词向量中\n",
      "that.|||To不存在于词向量中\n",
      "civil,不存在于词向量中\n",
      "mentally?不存在于词向量中\n",
      "ALONE不存在于词向量中\n",
      "Author不存在于词向量中\n",
      "pry,不存在于词向量中\n",
      "lied.不存在于词向量中\n",
      ":cool:|||So不存在于词向量中\n",
      "responses...不存在于词向量中\n",
      "Million不存在于词向量中\n",
      "Today:不存在于词向量中\n",
      "car...不存在于词向量中\n",
      "hesitation.不存在于词向量中\n",
      "cons,不存在于词向量中\n",
      "With...|||I不存在于词向量中\n",
      "...|||yeah不存在于词向量中\n",
      "do...|||A不存在于词向量中\n",
      "Trek,不存在于词向量中\n",
      "Wherever不存在于词向量中\n",
      "Goose不存在于词向量中\n",
      "apologizing,不存在于词向量中\n",
      "folder.不存在于词向量中\n",
      "Promethea,不存在于词向量中\n",
      "Tactics不存在于词向量中\n",
      "raise,不存在于词向量中\n",
      "standing.不存在于词向量中\n",
      "4chan,不存在于词向量中\n",
      "possible...|||I不存在于词向量中\n",
      "Eddard不存在于词向量中\n",
      "evil.|||I不存在于词向量中\n",
      "Vancouver,不存在于词向量中\n",
      "Sympathy不存在于词向量中\n",
      "Tegan不存在于词向量中\n",
      "it.|||Does不存在于词向量中\n",
      "I'd...|||The不存在于词向量中\n",
      "Duke不存在于词向量中\n",
      "Block不存在于词向量中\n",
      "Shine不存在于词向量中\n",
      "recognize,不存在于词向量中\n",
      "they.不存在于词向量中\n",
      "when...|||It's不存在于词向量中\n",
      "outward,不存在于词向量中\n",
      "sentiments.不存在于词向量中\n",
      "self-acceptance.不存在于词向量中\n",
      "your...|||In不存在于词向量中\n",
      "centered,不存在于词向量中\n",
      "logic...不存在于词向量中\n",
      "symbolic,不存在于词向量中\n",
      "belly.不存在于词向量中\n",
      "therapists.不存在于词向量中\n",
      "here.|||I've不存在于词向量中\n",
      "filled.不存在于词向量中\n",
      ":)|||well不存在于词向量中\n",
      "of...|||Ok,不存在于词向量中\n",
      "mechanical,不存在于词向量中\n",
      "believes.不存在于词向量中\n",
      "Facets不存在于词向量中\n",
      "comment...不存在于词向量中\n",
      "book?|||I不存在于词向量中\n",
      "Hallmark不存在于词向量中\n",
      "someone),不存在于词向量中\n",
      "fashionable.不存在于词向量中\n",
      "have...|||Why不存在于词向量中\n",
      "Goal不存在于词向量中\n",
      "Springsteen不存在于词向量中\n",
      "Dun不存在于词向量中\n",
      "ask...|||You不存在于词向量中\n",
      "linguistics,不存在于词向量中\n",
      "anthropology.不存在于词向量中\n",
      "aspirations.不存在于词向量中\n",
      "@OP,不存在于词向量中\n",
      "mile.不存在于词向量中\n",
      "Candy,不存在于词向量中\n",
      "Intj.不存在于词向量中\n",
      "D:<不存在于词向量中\n",
      "mind..不存在于词向量中\n",
      "have..不存在于词向量中\n",
      "barely.不存在于词向量中\n",
      "wandering,不存在于词向量中\n",
      "INFP.|||I'm不存在于词向量中\n",
      "faves.不存在于词向量中\n",
      "how...|||This不存在于词向量中\n",
      "expanded.不存在于词向量中\n",
      "relatable,不存在于词向量中\n",
      "has...|||I'm不存在于词向量中\n",
      "Thank-you不存在于词向量中\n",
      "Avengers.不存在于词向量中\n",
      "here...I不存在于词向量中\n",
      "clicked,不存在于词向量中\n",
      ":happy:|||That's不存在于词向量中\n",
      "Sheep不存在于词向量中\n",
      "Reed不存在于词向量中\n",
      "S:不存在于词向量中\n",
      "visions,不存在于词向量中\n",
      "You...'不存在于词向量中\n",
      "and...|||Ha!不存在于词向量中\n",
      "Brutal不存在于词向量中\n",
      "Ugly不存在于词向量中\n",
      "Borg不存在于词向量中\n",
      "Mildly不存在于词向量中\n",
      "threshold.不存在于词向量中\n",
      "objectives.不存在于词向量中\n",
      "HERE.不存在于词向量中\n",
      "health?不存在于词向量中\n",
      "better,...|||I不存在于词向量中\n",
      "yours.|||I不存在于词向量中\n",
      "misunderstand,不存在于词向量中\n",
      "above...|||I不存在于词向量中\n",
      "caught,不存在于词向量中\n",
      "doses,不存在于词向量中\n",
      "respects.不存在于词向量中\n",
      "there...|||This不存在于词向量中\n",
      "if...|||It's不存在于词向量中\n",
      "Geology不存在于词向量中\n",
      "non-INTJ不存在于词向量中\n",
      "I'm...|||Hi不存在于词向量中\n",
      "more...|||Thank不存在于词向量中\n",
      "haha|||I'm不存在于词向量中\n",
      "statement.|||I不存在于词向量中\n",
      "Eh.不存在于词向量中\n",
      "understands.不存在于词向量中\n",
      "to...|||Would不存在于词向量中\n",
      "if.不存在于词向量中\n",
      "encouraged.不存在于词向量中\n",
      "I'm...|||Oh,不存在于词向量中\n",
      "elaborate?|||I不存在于词向量中\n",
      "we...'不存在于词向量中\n",
      "legacy.不存在于词向量中\n",
      "a...|||Don't不存在于词向量中\n",
      "(100%不存在于词向量中\n",
      "diverse.不存在于词向量中\n",
      "horrific,不存在于词向量中\n",
      "depression)不存在于词向量中\n",
      "4th.不存在于词向量中\n",
      "browns,不存在于词向量中\n",
      "Arclight不存在于词向量中\n",
      "Metroid不存在于词向量中\n",
      "Withdrawn,不存在于词向量中\n",
      "retiring,不存在于词向量中\n",
      "hardheaded,不存在于词向量中\n",
      "cats?不存在于词向量中\n",
      "rapists,不存在于词向量中\n",
      "Idiosyncratic不存在于词向量中\n",
      "oblivious,不存在于词向量中\n",
      "studied.不存在于词向量中\n",
      "Cs不存在于词向量中\n",
      "DEAL不存在于词向量中\n",
      "life...I不存在于词向量中\n",
      "me/my不存在于词向量中\n",
      "guarded.不存在于词向量中\n",
      "the...|||Sounds不存在于词向量中\n",
      "Expressive不存在于词向量中\n",
      "cycles.不存在于词向量中\n",
      "a...|||Actually不存在于词向量中\n",
      "WANNA不存在于词向量中\n",
      "the...|||Also,不存在于词向量中\n",
      "suspicion.不存在于词向量中\n",
      "bestie.不存在于词向量中\n",
      "Dickens,不存在于词向量中\n",
      "churches.不存在于词向量中\n",
      "tops.不存在于词向量中\n",
      "dragon,不存在于词向量中\n",
      "lookin'不存在于词向量中\n",
      "hippie.不存在于词向量中\n",
      "Kent不存在于词向量中\n",
      "mail.不存在于词向量中\n",
      "ENFJ/INFJ不存在于词向量中\n",
      "book...|||I不存在于词向量中\n",
      "locked.不存在于词向量中\n",
      "of...|||Yes不存在于词向量中\n",
      "Primarily不存在于词向量中\n",
      "sorrow.不存在于词向量中\n",
      "Flip不存在于词向量中\n",
      "like...|||Your不存在于词向量中\n",
      "imploded不存在于词向量中\n",
      "Openly不存在于词向量中\n",
      "N-types不存在于词向量中\n",
      "general).不存在于词向量中\n",
      "Martin.不存在于词向量中\n",
      "elves,不存在于词向量中\n",
      "Disney.不存在于词向量中\n",
      "Dell不存在于词向量中\n",
      "topic....不存在于词向量中\n",
      "Previously不存在于词向量中\n",
      "skirt.不存在于词向量中\n",
      "Medicine不存在于词向量中\n",
      "non-fiction.不存在于词向量中\n",
      "literally)不存在于词向量中\n",
      "through...|||I'm不存在于词向量中\n",
      "dates?不存在于词向量中\n",
      "ENFP/INFP不存在于词向量中\n",
      "Foo不存在于词向量中\n",
      "what...'不存在于词向量中\n",
      "person'不存在于词向量中\n",
      "Certified不存在于词向量中\n",
      "would...|||Oh不存在于词向量中\n",
      "bastards.不存在于词向量中\n",
      ";)|||That's不存在于词向量中\n",
      "wanted?不存在于词向量中\n",
      "astonishing不存在于词向量中\n",
      "ambivert,不存在于词向量中\n",
      ":D|||Hi不存在于词向量中\n",
      "Athena不存在于词向量中\n",
      "every...|||The不存在于词向量中\n",
      "versatile,不存在于词向量中\n",
      "journalism.不存在于词向量中\n",
      "dialogue.不存在于词向量中\n",
      "Hermoine不存在于词向量中\n",
      "Emotions,不存在于词向量中\n",
      "Amy:不存在于词向量中\n",
      "F...不存在于词向量中\n",
      "abstraction,不存在于词向量中\n",
      "claim?不存在于词向量中\n",
      "Observations不存在于词向量中\n",
      "orientated,不存在于词向量中\n",
      "I...|||She不存在于词向量中\n",
      "anonymity.不存在于词向量中\n",
      "these)不存在于词向量中\n",
      "ISTP/INTP不存在于词向量中\n",
      "Wars:不存在于词向量中\n",
      "Syrian不存在于词向量中\n",
      "nails.不存在于词向量中\n",
      "have...|||Yes,不存在于词向量中\n",
      "70s,不存在于词向量中\n",
      "time!|||I不存在于词向量中\n",
      "12)不存在于词向量中\n",
      "it,...'不存在于词向量中\n",
      "Paladin不存在于词向量中\n",
      "terrifying,不存在于词向量中\n",
      "fickle,不存在于词向量中\n",
      "Contains不存在于词向量中\n",
      "fury.不存在于词向量中\n",
      "unwittingly不存在于词向量中\n",
      "case..不存在于词向量中\n",
      "idiotic.不存在于词向量中\n",
      "about...|||i不存在于词向量中\n",
      "err...不存在于词向量中\n",
      "fortunes不存在于词向量中\n",
      "compass.不存在于词向量中\n",
      "Addiction不存在于词向量中\n",
      "Piccolo不存在于词向量中\n",
      "Krillin不存在于词向量中\n",
      "GT不存在于词向量中\n",
      "socialising.不存在于词向量中\n",
      ";)|||What不存在于词向量中\n",
      "Broadcast不存在于词向量中\n",
      "the...|||These不存在于词向量中\n",
      "root.不存在于词向量中\n",
      "variations.不存在于词向量中\n",
      "close.|||I不存在于词向量中\n",
      "(80%)不存在于词向量中\n",
      "realm,不存在于词向量中\n",
      "Missed不存在于词向量中\n",
      "buzzed,不存在于词向量中\n",
      "pray,不存在于词向量中\n",
      "Lebowski不存在于词向量中\n",
      "above).不存在于词向量中\n",
      "Syndrome,不存在于词向量中\n",
      "INTP),不存在于词向量中\n",
      "me.|||1.不存在于词向量中\n",
      "evenings.不存在于词向量中\n",
      "Short,不存在于词向量中\n",
      "Am茅lie不存在于词向量中\n",
      "at...|||Oh不存在于词向量中\n",
      "(feat.不存在于词向量中\n",
      "magazine,不存在于词向量中\n",
      "Satellite不存在于词向量中\n",
      "Arab不存在于词向量中\n",
      "dont'不存在于词向量中\n",
      "what...|||Well不存在于词向量中\n",
      "fallacy,不存在于词向量中\n",
      "rabbits.不存在于词向量中\n",
      "same..不存在于词向量中\n",
      "Like..不存在于词向量中\n",
      "flirtatious,不存在于词向量中\n",
      "Umm..不存在于词向量中\n",
      "ever..不存在于词向量中\n",
      "(ENTP,不存在于词向量中\n",
      "unkind.不存在于词向量中\n",
      "irresponsible,不存在于词向量中\n",
      "both.|||I不存在于词向量中\n",
      "to...|||you不存在于词向量中\n",
      "motive.不存在于词向量中\n",
      "Austria,不存在于词向量中\n",
      "Britannia不存在于词向量中\n",
      "Asylum不存在于词向量中\n",
      "Benefit不存在于词向量中\n",
      "Breathe不存在于词向量中\n",
      "Smooth,不存在于词向量中\n",
      "album)不存在于词向量中\n",
      "Zeppelin不存在于词向量中\n",
      "Called不存在于词向量中\n",
      "gang.不存在于词向量中\n",
      "fizzled不存在于词向量中\n",
      ":-).不存在于词向量中\n",
      "following,不存在于词向量中\n",
      "state?不存在于词向量中\n",
      "Finland.不存在于词向量中\n",
      "Vedder不存在于词向量中\n",
      "Norway.不存在于词向量中\n",
      "an...|||That's不存在于词向量中\n",
      "the...|||Lol不存在于词向量中\n",
      "there...|||I've不存在于词向量中\n",
      "the...|||Basically不存在于词向量中\n",
      "meant...|||I不存在于词向量中\n",
      "Unbreakable不存在于词向量中\n",
      "Fey不存在于词向量中\n",
      "doll.不存在于词向量中\n",
      "FOMO不存在于词向量中\n",
      "shade,不存在于词向量中\n",
      "appeal,不存在于词向量中\n",
      "vet,不存在于词向量中\n",
      "Stardust不存在于词向量中\n",
      "contribution,不存在于词向量中\n",
      "'But不存在于词向量中\n",
      "Rosetta不存在于词向量中\n",
      "Warmth不存在于词向量中\n",
      "them.|||Well不存在于词向量中\n",
      "...|||i'm不存在于词向量中\n",
      "10/10.不存在于词向量中\n",
      "spaces.不存在于词向量中\n",
      "kinda,不存在于词向量中\n",
      "Te/Ti不存在于词向量中\n",
      "didn't...'不存在于词向量中\n",
      "interested)不存在于词向量中\n",
      "edition.不存在于词向量中\n",
      "anywhere.|||I不存在于词向量中\n",
      "been...|||That不存在于词向量中\n",
      "Tick不存在于词向量中\n",
      "Cat:不存在于词向量中\n",
      "them.|||What不存在于词向量中\n",
      "Strongly不存在于词向量中\n",
      "Histrionic不存在于词向量中\n",
      "follower,不存在于词向量中\n",
      "things...'不存在于词向量中\n",
      "Bright,不存在于词向量中\n",
      ":dry:'不存在于词向量中\n",
      "INFJ!!!不存在于词向量中\n",
      "Maxim不存在于词向量中\n",
      "...except不存在于词向量中\n",
      "met...|||I不存在于词向量中\n",
      "foremost.不存在于词向量中\n",
      "Decide不存在于词向量中\n",
      "Lonely.不存在于词向量中\n",
      "Warhammer不存在于词向量中\n",
      "should...不存在于词向量中\n",
      "a...|||Hi!不存在于词向量中\n",
      "organised,不存在于词向量中\n",
      ":P|||Just不存在于词向量中\n",
      "minimalist,不存在于词向量中\n",
      "P.M.不存在于词向量中\n",
      "both...不存在于词向量中\n",
      "My...|||It不存在于词向量中\n",
      ":S|||I不存在于词向量中\n",
      "Micheal不存在于词向量中\n",
      ":P|||So不存在于词向量中\n",
      "Empathetic不存在于词向量中\n",
      "guys!|||I不存在于词向量中\n",
      "profile?不存在于词向量中\n",
      "Tapatalk|||That's不存在于词向量中\n",
      "go..不存在于词向量中\n",
      "impress.不存在于词向量中\n",
      "you.|||Just不存在于词向量中\n",
      "automatically,不存在于词向量中\n",
      "Conrad不存在于词向量中\n",
      "me.|||That's不存在于词向量中\n",
      "Gomez不存在于词向量中\n",
      "charming?不存在于词向量中\n",
      "pretend,不存在于词向量中\n",
      "More,不存在于词向量中\n",
      "to...|||No.不存在于词向量中\n",
      "cope.不存在于词向量中\n",
      "can...|||Not不存在于词向量中\n",
      "snob,不存在于词向量中\n",
      "WITHOUT不存在于词向量中\n",
      "Neptune不存在于词向量中\n",
      "specialty,不存在于词向量中\n",
      "^^|||I'm不存在于词向量中\n",
      "douche,不存在于词向量中\n",
      "-...|||If不存在于词向量中\n",
      "Wells不存在于词向量中\n",
      "stuff.)不存在于词向量中\n",
      "Slipknot不存在于词向量中\n",
      "for...|||Yes不存在于词向量中\n",
      "yourself...|||I不存在于词向量中\n",
      "slightly...|||I不存在于词向量中\n",
      "criteria,不存在于词向量中\n",
      "objectivity,不存在于词向量中\n",
      "LOVE.不存在于词向量中\n",
      "masculinity,不存在于词向量中\n",
      "as...|||Thanks不存在于词向量中\n",
      "xNxJ不存在于词向量中\n",
      "this'll不存在于词向量中\n",
      ":laughing:|||As不存在于词向量中\n",
      "more...|||The不存在于词向量中\n",
      "Amazon.不存在于词向量中\n",
      "grace,不存在于词向量中\n",
      "a...|||But不存在于词向量中\n",
      "customers.不存在于词向量中\n",
      "actually...'不存在于词向量中\n",
      "Historically不存在于词向量中\n",
      "LORD不存在于词向量中\n",
      "daydreamer,不存在于词向量中\n",
      "Co-op不存在于词向量中\n",
      "Goodness,不存在于词向量中\n",
      "perfect...不存在于词向量中\n",
      "giddy,不存在于词向量中\n",
      "my...|||Of不存在于词向量中\n",
      "provide.不存在于词向量中\n",
      "shades.不存在于词向量中\n",
      "procrastination...不存在于词向量中\n",
      "implied,不存在于词向量中\n",
      "are...|||Thank不存在于词向量中\n",
      "just...|||So不存在于词向量中\n",
      "Fixed不存在于词向量中\n",
      "all.|||So不存在于词向量中\n",
      "current,不存在于词向量中\n",
      "UX不存在于词向量中\n",
      "Tapatalk|||Thank不存在于词向量中\n",
      "Grrr.不存在于词向量中\n",
      "days..不存在于词向量中\n",
      "down..不存在于词向量中\n",
      "heart..不存在于词向量中\n",
      "most...|||Thanks不存在于词向量中\n",
      "lots,不存在于词向量中\n",
      "counts.|||I不存在于词向量中\n",
      "recipe?不存在于词向量中\n",
      "'thank'不存在于词向量中\n",
      "delightful.不存在于词向量中\n",
      "up|||I不存在于词向量中\n",
      "radical,不存在于词向量中\n",
      "jerks,不存在于词向量中\n",
      "CafeBot.不存在于词向量中\n",
      "T.V.不存在于词向量中\n",
      "Now?不存在于词向量中\n",
      "me's不存在于词向量中\n",
      "drinker,不存在于词向量中\n",
      "would...|||You不存在于词向量中\n",
      "man.|||I'm不存在于词向量中\n",
      "covers.不存在于词向量中\n",
      "Dispenser不存在于词向量中\n",
      "better),不存在于词向量中\n",
      "cabin,不存在于词向量中\n",
      "Geoff不存在于词向量中\n",
      "Rooster不存在于词向量中\n",
      "recently...|||I不存在于词向量中\n",
      "quest,不存在于词向量中\n",
      "schedules,不存在于词向量中\n",
      "tantrums,不存在于词向量中\n",
      "complacent.不存在于词向量中\n",
      "Genetics不存在于词向量中\n",
      "goal?不存在于词向量中\n",
      "ABC不存在于词向量中\n",
      "anyone...|||I'm不存在于词向量中\n",
      "This...不存在于词向量中\n",
      "That.不存在于词向量中\n",
      "triangle,不存在于词向量中\n",
      "buzz.不存在于词向量中\n",
      "f'ing不存在于词向量中\n",
      "disappointment,不存在于词向量中\n",
      "sacrifice,不存在于词向量中\n",
      "urges,不存在于词向量中\n",
      "Linear不存在于词向量中\n",
      "Reality-based不存在于词向量中\n",
      "pussy,不存在于词向量中\n",
      "(english:不存在于词向量中\n",
      "her/him不存在于词向量中\n",
      "I...|||Like不存在于词向量中\n",
      "speaker's不存在于词向量中\n",
      "be...|||She不存在于词向量中\n",
      "Calm,不存在于词向量中\n",
      "for...|||Thank不存在于词向量中\n",
      "but...|||That不存在于词向量中\n",
      "counsellor.不存在于词向量中\n",
      "no...|||If不存在于词向量中\n",
      "records.不存在于词向量中\n",
      "some...|||So不存在于词向量中\n",
      "believes,不存在于词向量中\n",
      ":)|||Yes不存在于词向量中\n",
      "city's不存在于词向量中\n",
      "wallflower,不存在于词向量中\n",
      "the...|||my不存在于词向量中\n",
      "perc.不存在于词向量中\n",
      "them...|||That不存在于词向量中\n",
      "said....不存在于词向量中\n",
      "Hubby不存在于词向量中\n",
      "(20不存在于词向量中\n",
      "auditory?不存在于词向量中\n",
      "respectively,不存在于词向量中\n",
      "make...|||When不存在于词向量中\n",
      "husband...不存在于词向量中\n",
      "si,不存在于词向量中\n",
      "term?不存在于词向量中\n",
      "Lars不存在于词向量中\n",
      "doable.不存在于词向量中\n",
      "time...I不存在于词向量中\n",
      "wave.不存在于词向量中\n",
      "caps,不存在于词向量中\n",
      "the...|||Having不存在于词向量中\n",
      "disappeared.不存在于词向量中\n",
      "dogma.不存在于词向量中\n",
      "that...|||Hmm,不存在于词向量中\n",
      "Record:不存在于词向量中\n",
      "Alaska,不存在于词向量中\n",
      "overemotional,不存在于词向量中\n",
      "I...|||INFJ不存在于词向量中\n",
      "Tycoon不存在于词向量中\n",
      "highest,不存在于词向量中\n",
      "smokers,不存在于词向量中\n",
      "Fully不存在于词向量中\n",
      "loudly.不存在于词向量中\n",
      "Exile不存在于词向量中\n",
      "Basterds不存在于词向量中\n",
      "imperfect,不存在于词向量中\n",
      "casually,不存在于词向量中\n",
      "things...and不存在于词向量中\n",
      "inventions,不存在于词向量中\n",
      "quicker.不存在于词向量中\n",
      "Patterns不存在于词向量中\n",
      "sheets.不存在于词向量中\n",
      "believe).不存在于词向量中\n",
      "mushrooms.不存在于词向量中\n",
      "kitten,不存在于词向量中\n",
      "^^|||This不存在于词向量中\n",
      "South.不存在于词向量中\n",
      "coding.不存在于词向量中\n",
      "it.|||Being不存在于词向量中\n",
      "spontaneity,不存在于词向量中\n",
      "HAHAHAHA不存在于词向量中\n",
      "crackers.不存在于词向量中\n",
      ":D?不存在于词向量中\n",
      "existing,不存在于词向量中\n",
      "attitude?不存在于词向量中\n",
      "DNA.不存在于词向量中\n",
      "Dude!不存在于词向量中\n",
      "IN.不存在于词向量中\n",
      "Thirty不存在于词向量中\n",
      "...|||An不存在于词向量中\n",
      "jump,不存在于词向量中\n",
      "am....不存在于词向量中\n",
      "Te-Ni不存在于词向量中\n",
      "immediate,不存在于词向量中\n",
      "xD|||Well,不存在于词向量中\n",
      "<3|||I've不存在于词向量中\n",
      "emphasis,不存在于词向量中\n",
      "Hasn't不存在于词向量中\n",
      "Stefan不存在于词向量中\n",
      "scenario?不存在于词向量中\n",
      "incoming.不存在于词向量中\n",
      "preferable.不存在于词向量中\n",
      "Staring不存在于词向量中\n",
      "cues.不存在于词向量中\n",
      "Manipulation不存在于词向量中\n",
      "curious?不存在于词向量中\n",
      "feely,不存在于词向量中\n",
      "sayin'.不存在于词向量中\n",
      "Santa,不存在于词向量中\n",
      "sure...|||I'm不存在于词向量中\n",
      "Costco不存在于词向量中\n",
      "garage,不存在于词向量中\n",
      "...You不存在于词向量中\n",
      "back),不存在于词向量中\n",
      "Received不存在于词向量中\n",
      "Mazda不存在于词向量中\n",
      "Vancouver.不存在于词向量中\n",
      "three...|||I不存在于词向量中\n",
      "Fort不存在于词向量中\n",
      "local,不存在于词向量中\n",
      "Horizon不存在于词向量中\n",
      "'Ya不存在于词向量中\n",
      "in...|||Sorry不存在于词向量中\n",
      "(ESTP不存在于词向量中\n",
      "experience.|||I'm不存在于词向量中\n",
      "flicker不存在于词向量中\n",
      "Lennon,不存在于词向量中\n",
      "guess.|||I'm不存在于词向量中\n",
      "very...|||1.不存在于词向量中\n",
      "disappointing,不存在于词向量中\n",
      "brunette,不存在于词向量中\n",
      "state...不存在于词向量中\n",
      "ISFj不存在于词向量中\n",
      "interested...不存在于词向量中\n",
      "wrestling,不存在于词向量中\n",
      "Egypt,不存在于词向量中\n",
      "Dylan,不存在于词向量中\n",
      "but...|||Do不存在于词向量中\n",
      ":(|||You不存在于词向量中\n",
      "universe's不存在于词向量中\n",
      "SF,不存在于词向量中\n",
      "Hostility:不存在于词向量中\n",
      "Anger:不存在于词向量中\n",
      "stuff....不存在于词向量中\n",
      "Jen不存在于词向量中\n",
      "bowling,不存在于词向量中\n",
      "Aid不存在于词向量中\n",
      "Stockholm不存在于词向量中\n",
      "too.|||You不存在于词向量中\n",
      "Tools不存在于词向量中\n",
      "Vin不存在于词向量中\n",
      "disinterest.不存在于词向量中\n",
      "apocalypse,不存在于词向量中\n",
      "UK?不存在于词向量中\n",
      "Time:不存在于词向量中\n",
      "esfp's不存在于词向量中\n",
      "totally...|||I不存在于词向量中\n",
      "unfortunately)不存在于词向量中\n",
      "completion,不存在于词向量中\n",
      "harmonious.不存在于词向量中\n",
      "(extroverted不存在于词向量中\n",
      "gathering.不存在于词向量中\n",
      "callous.不存在于词向量中\n",
      "self-improvement,不存在于词向量中\n",
      "entitlement.不存在于词向量中\n",
      "feed.不存在于词向量中\n",
      "John.不存在于词向量中\n",
      "lazy?不存在于词向量中\n",
      "presentations,不存在于词向量中\n",
      "C++,不存在于词向量中\n",
      "List:不存在于词向量中\n",
      "TRUE.不存在于词向量中\n",
      "enough).不存在于词向量中\n",
      "'good不存在于词向量中\n",
      "thread.)不存在于词向量中\n",
      "for...|||I'd不存在于词向量中\n",
      "funny;不存在于词向量中\n",
      "know...but不存在于词向量中\n",
      "...is不存在于词向量中\n",
      "caused.不存在于词向量中\n",
      "me...|||It不存在于词向量中\n",
      "I...|||He不存在于词向量中\n",
      "house...|||I不存在于词向量中\n",
      "30s.不存在于词向量中\n",
      "...|||All不存在于词向量中\n",
      "patch.不存在于词向量中\n",
      "Youre不存在于词向量中\n",
      "But!不存在于词向量中\n",
      "Since,不存在于词向量中\n",
      "(aka,不存在于词向量中\n",
      "bigotry,不存在于词向量中\n",
      "easy-going,不存在于词向量中\n",
      "Realism不存在于词向量中\n",
      "'With不存在于词向量中\n",
      "trivial.不存在于词向量中\n",
      "ex?不存在于词向量中\n",
      "Definitely!不存在于词向量中\n",
      "Competition不存在于词向量中\n",
      "Enjoyed不存在于词向量中\n",
      "'logical'不存在于词向量中\n",
      "group)不存在于词向量中\n",
      "Marge不存在于词向量中\n",
      "ESTJ-不存在于词向量中\n",
      "Constitution不存在于词向量中\n",
      "gif.不存在于词向量中\n",
      "done.'不存在于词向量中\n",
      "Tiny不存在于词向量中\n",
      "extension,不存在于词向量中\n",
      "Woodley不存在于词向量中\n",
      "casted不存在于词向量中\n",
      "rusty,不存在于词向量中\n",
      "face...|||I不存在于词向量中\n",
      "see...|||I'm不存在于词向量中\n",
      "applied,不存在于词向量中\n",
      "both).不存在于词向量中\n",
      "perfume,不存在于词向量中\n",
      "wash,不存在于词向量中\n",
      "Hindu不存在于词向量中\n",
      "Catfish不存在于词向量中\n",
      "Subway不存在于词向量中\n",
      "cereal,不存在于词向量中\n",
      "Erica不存在于词向量中\n",
      "hassle,不存在于词向量中\n",
      "Catch不存在于词向量中\n",
      "I/E.不存在于词向量中\n",
      "Yea.不存在于词向量中\n",
      "Secondary:不存在于词向量中\n",
      ":wink:|||Good不存在于词向量中\n",
      "to...|||Hi,不存在于词向量中\n",
      "not...|||I'd不存在于词向量中\n",
      "Tapatalk|||Not不存在于词向量中\n",
      "be...|||Why不存在于词向量中\n",
      "of...|||1)不存在于词向量中\n",
      "Afghanistan不存在于词向量中\n",
      "operation.不存在于词向量中\n",
      "of...|||At不存在于词向量中\n",
      "anyway?|||I不存在于词向量中\n",
      "necessities.不存在于词向量中\n",
      "(obviously).不存在于词向量中\n",
      "at...|||Hey不存在于词向量中\n",
      "instant.不存在于词向量中\n",
      "LACK不存在于词向量中\n",
      "Mid不存在于词向量中\n",
      "Scottish,不存在于词向量中\n",
      "flattering.不存在于词向量中\n",
      "Clive不存在于词向量中\n",
      "rise.不存在于词向量中\n",
      "Elizabeth,不存在于词向量中\n",
      "Sharon不存在于词向量中\n",
      "Erin不存在于词向量中\n",
      "Snape,不存在于词向量中\n",
      ":tongue:|||That's不存在于词向量中\n",
      "Debussy,不存在于词向量中\n",
      "cello,不存在于词向量中\n",
      "so...|||That's不存在于词向量中\n",
      "Stepping不存在于词向量中\n",
      "tool?不存在于词向量中\n",
      "emotionally...|||I不存在于词向量中\n",
      "Energetic不存在于词向量中\n",
      "Meh不存在于词向量中\n",
      "infp?不存在于词向量中\n",
      "target,不存在于词向量中\n",
      "friends/family.不存在于词向量中\n",
      "Good:不存在于词向量中\n",
      "2/不存在于词向量中\n",
      ">_<|||I不存在于词向量中\n",
      "antidote不存在于词向量中\n",
      "forfeit不存在于词向量中\n",
      "do,...|||I不存在于词向量中\n",
      ":)|||Honestly,不存在于词向量中\n",
      "LOL.|||I不存在于词向量中\n",
      "(Someone不存在于词向量中\n",
      "flight.不存在于词向量中\n",
      "Ground不存在于词向量中\n",
      "patronising,不存在于词向量中\n",
      "bunny.不存在于词向量中\n",
      "Scots不存在于词向量中\n",
      "Haters不存在于词向量中\n",
      "negatively,不存在于词向量中\n",
      "meet...|||I不存在于词向量中\n",
      "mentioning.不存在于词向量中\n",
      "model?不存在于词向量中\n",
      "appointment,不存在于词向量中\n",
      "pad.不存在于词向量中\n",
      "thick.不存在于词向量中\n",
      "Who?不存在于词向量中\n",
      "(Same不存在于词向量中\n",
      "an...|||i不存在于词向量中\n",
      "sorry),不存在于词向量中\n",
      "5'7不存在于词向量中\n",
      "scary?不存在于词向量中\n",
      "L.A.不存在于词向量中\n",
      "I'm...|||Well,不存在于词向量中\n",
      "insensitivity,不存在于词向量中\n",
      "with...|||i不存在于词向量中\n",
      "(hell,不存在于词向量中\n",
      "of...|||the不存在于词向量中\n",
      "'get'不存在于词向量中\n",
      "Thoughts?不存在于词向量中\n",
      "(compared不存在于词向量中\n",
      "&/or不存在于词向量中\n",
      "worst?不存在于词向量中\n",
      "Blue.不存在于词向量中\n",
      "Redemption,不存在于词向量中\n",
      "came,不存在于词向量中\n",
      "Wit不存在于词向量中\n",
      "loathsome不存在于词向量中\n",
      ";]不存在于词向量中\n",
      "cross,不存在于词向量中\n",
      "Clapton不存在于词向量中\n",
      "affable不存在于词向量中\n",
      "beyond.不存在于词向量中\n",
      "participates不存在于词向量中\n",
      "Sources:不存在于词向量中\n",
      "aha.不存在于词向量中\n",
      "Caught不存在于词向量中\n",
      ":D|||Welcome不存在于词向量中\n",
      ":P|||A不存在于词向量中\n",
      "INFPs...|||I不存在于词向量中\n",
      "taste?不存在于词向量中\n",
      "Carnegie不存在于词向量中\n",
      "jump.不存在于词向量中\n",
      "stupid)不存在于词向量中\n",
      "feel...|||You不存在于词向量中\n",
      "xxFJ不存在于词向量中\n",
      "soccer.不存在于词向量中\n",
      "lower.不存在于词向量中\n",
      "left.|||I不存在于词向量中\n",
      "out...|||My不存在于词向量中\n",
      "time...|||My不存在于词向量中\n",
      "T-Rex不存在于词向量中\n",
      "Meetup!不存在于词向量中\n",
      "MBTI-based不存在于词向量中\n",
      "function).不存在于词向量中\n",
      "5'10不存在于词向量中\n",
      "vehicle,不存在于词向量中\n",
      "ghetto,不存在于词向量中\n",
      "Tekken不存在于词向量中\n",
      "Nostalgic不存在于词向量中\n",
      "Present不存在于词向量中\n",
      "and...|||INTJ不存在于词向量中\n",
      "guess.'不存在于词向量中\n",
      "...|||Today不存在于词向量中\n",
      "always...|||The不存在于词向量中\n",
      "shouldn't,不存在于词向量中\n",
      "videos...不存在于词向量中\n",
      "quirks?不存在于词向量中\n",
      "babe,不存在于词向量中\n",
      "Linings不存在于词向量中\n",
      "'help'不存在于词向量中\n",
      "(past不存在于词向量中\n",
      "face)不存在于词向量中\n",
      "my...|||Hi不存在于词向量中\n",
      "(down不存在于词向量中\n",
      "editing,不存在于词向量中\n",
      "design)不存在于词向量中\n",
      "Production不存在于词向量中\n",
      "Files不存在于词向量中\n",
      "conversation.|||I不存在于词向量中\n",
      "bump.不存在于词向量中\n",
      "games...|||I不存在于词向量中\n",
      "it...|||And不存在于词向量中\n",
      "EEG不存在于词向量中\n",
      "scum.不存在于词向量中\n",
      "Silly,不存在于词向量中\n",
      "Mine:不存在于词向量中\n",
      "creep.不存在于词向量中\n",
      "would...|||My不存在于词向量中\n",
      "Asian,不存在于词向量中\n",
      "words...|||I不存在于词向量中\n",
      "so/sp/sx不存在于词向量中\n",
      "(guess不存在于词向量中\n",
      "reason).不存在于词向量中\n",
      "ESxPs不存在于词向量中\n",
      "cosmos.不存在于词向量中\n",
      "triggered.不存在于词向量中\n",
      "It'不存在于词向量中\n",
      "Boy,不存在于词向量中\n",
      "lands.不存在于词向量中\n",
      "blanket.不存在于词向量中\n",
      "rain?不存在于词向量中\n",
      "it?|||If不存在于词向量中\n",
      "out...|||Well不存在于词向量中\n",
      "natural?不存在于词向量中\n",
      "it|||i不存在于词向量中\n",
      "your,不存在于词向量中\n",
      "gays.不存在于词向量中\n",
      "whirl不存在于词向量中\n",
      "all's不存在于词向量中\n",
      "anatomy,不存在于词向量中\n",
      "science.|||I不存在于词向量中\n",
      "......|||I不存在于词向量中\n",
      "ni,不存在于词向量中\n",
      "Grey.不存在于词向量中\n",
      "Uhhh,不存在于词向量中\n",
      "'Anyone不存在于词向量中\n",
      "option.|||I不存在于词向量中\n",
      "film)不存在于词向量中\n",
      "Shutter不存在于词向量中\n",
      "Cruise不存在于词向量中\n",
      "anyways)不存在于词向量中\n",
      "comedian,不存在于词向量中\n",
      "here!)不存在于词向量中\n",
      "drivers.不存在于词向量中\n",
      "lying?不存在于词向量中\n",
      "out...|||You不存在于词向量中\n",
      "an...|||Thanks不存在于词向量中\n",
      "it...|||Are不存在于词向量中\n",
      "an...|||Hey不存在于词向量中\n",
      "You...|||You不存在于词向量中\n",
      "interpersonal...|||I不存在于词向量中\n",
      "Piglet不存在于词向量中\n",
      "Brain,不存在于词向量中\n",
      "kilometers不存在于词向量中\n",
      "significance.不存在于词向量中\n",
      "situation...|||I不存在于词向量中\n",
      "things|||I不存在于词向量中\n",
      "committed.不存在于词向量中\n",
      "Pokemon.不存在于词向量中\n",
      "...|||Before不存在于词向量中\n",
      "Struggling不存在于词向量中\n",
      "Dummies不存在于词向量中\n",
      "Sciences不存在于词向量中\n",
      "exhibit.不存在于词向量中\n",
      "i/e不存在于词向量中\n",
      "Rochester不存在于词向量中\n",
      "to...|||Thanks!不存在于词向量中\n",
      "want)不存在于词向量中\n",
      "~|||I不存在于词向量中\n",
      "Salad不存在于词向量中\n",
      "finding...|||I不存在于词向量中\n",
      "see...|||You不存在于词向量中\n",
      "on...|||As不存在于词向量中\n",
      "Stalin,不存在于词向量中\n",
      "Anyone,不存在于词向量中\n",
      "Ghosts不存在于词向量中\n",
      "altruistic,不存在于词向量中\n",
      "vampire,不存在于词向量中\n",
      "EVERYONE.不存在于词向量中\n",
      "correctness.不存在于词向量中\n",
      "T)不存在于词向量中\n",
      "deduced不存在于词向量中\n",
      "Dependent:不存在于词向量中\n",
      "moon...不存在于词向量中\n",
      "Mortal不存在于词向量中\n",
      "store.|||I不存在于词向量中\n",
      "beautiful...不存在于词向量中\n",
      "6'1不存在于词向量中\n",
      "Pawn不存在于词向量中\n",
      "Cat's不存在于词向量中\n",
      "Slaughterhouse不存在于词向量中\n",
      "ratio.不存在于词向量中\n",
      "Philadelphia不存在于词向量中\n",
      "awesome...|||I不存在于词向量中\n",
      "Garbage不存在于词向量中\n",
      "serious...|||I不存在于词向量中\n",
      "behalf.不存在于词向量中\n",
      "field?不存在于词向量中\n",
      "barge不存在于词向量中\n",
      "Farewell不存在于词向量中\n",
      "(up不存在于词向量中\n",
      "and...|||Some不存在于词向量中\n",
      "(granted不存在于词向量中\n",
      "energy?不存在于词向量中\n",
      "my...|||Your不存在于词向量中\n",
      "||||||||||||||||||||不存在于词向量中\n",
      "mind'不存在于词向量中\n",
      "d.不存在于词向量中\n",
      "arises,不存在于词向量中\n",
      "dumbass.不存在于词向量中\n",
      "had...|||I'm不存在于词向量中\n",
      "appreciative.不存在于词向量中\n",
      "fluff.不存在于词向量中\n",
      "xD|||I've不存在于词向量中\n",
      "calmness.不存在于词向量中\n",
      "bluntness,不存在于词向量中\n",
      "(dating不存在于词向量中\n",
      "whimsical,不存在于词向量中\n",
      "Writing.不存在于词向量中\n",
      "Composition不存在于词向量中\n",
      "Merkel不存在于词向量中\n",
      "Morfy不存在于词向量中\n",
      "demands.不存在于词向量中\n",
      "trance.不存在于词向量中\n",
      "immortality,不存在于词向量中\n",
      "an...|||Not不存在于词向量中\n",
      "pack.不存在于词向量中\n",
      "composure.不存在于词向量中\n",
      "NEXT不存在于词向量中\n",
      "sunday,不存在于词向量中\n",
      "have/had不存在于词向量中\n",
      "a...|||While不存在于词向量中\n",
      "conformity.不存在于词向量中\n",
      "PDA不存在于词向量中\n",
      "Bob.不存在于词向量中\n",
      "Castelo不存在于词向量中\n",
      "a...|||oh不存在于词向量中\n",
      "disposition.不存在于词向量中\n",
      "subtype,不存在于词向量中\n",
      "Gervais不存在于词向量中\n",
      "notion,不存在于词向量中\n",
      "Freddy不存在于词向量中\n",
      "Gilbert不存在于词向量中\n",
      "Switch不存在于词向量中\n",
      "recommend.不存在于词向量中\n",
      "as...|||Oh不存在于词向量中\n",
      "Te!不存在于词向量中\n",
      "drawers,不存在于词向量中\n",
      "and...|||He's不存在于词向量中\n",
      "is...|||1.不存在于词向量中\n",
      "Built不存在于词向量中\n",
      "crap?不存在于词向量中\n",
      "asks,不存在于词向量中\n",
      "working?不存在于词向量中\n",
      "I'll...'不存在于词向量中\n",
      "...|||Yup,不存在于词向量中\n",
      "@OP不存在于词向量中\n",
      "hardworking,不存在于词向量中\n",
      "that.|||I've不存在于词向量中\n",
      "choices?不存在于词向量中\n",
      "education?不存在于词向量中\n",
      "though.|||When不存在于词向量中\n",
      "chose.不存在于词向量中\n",
      "Librarian不存在于词向量中\n",
      "Dana不存在于词向量中\n",
      "that...|||I'll不存在于词向量中\n",
      "chart?不存在于词向量中\n",
      "54.167不存在于词向量中\n",
      "me.|||You're不存在于词向量中\n",
      "sour.不存在于词向量中\n",
      "guarded,不存在于词向量中\n",
      "Jackman不存在于词向量中\n",
      "Monroe不存在于词向量中\n",
      "exception,不存在于词向量中\n",
      "too...|||It不存在于词向量中\n",
      "with...|||That's不存在于词向量中\n",
      "view...不存在于词向量中\n",
      "sometimes...|||I'm不存在于词向量中\n",
      "this.|||I've不存在于词向量中\n",
      "D.C.不存在于词向量中\n",
      "THREAD.不存在于词向量中\n",
      "..you不存在于词向量中\n",
      "possession.不存在于词向量中\n",
      "blankets.不存在于词向量中\n",
      "Inevitable不存在于词向量中\n",
      "noob.不存在于词向量中\n",
      "lurking.不存在于词向量中\n",
      "Ethnicity:不存在于词向量中\n",
      "Rushmore不存在于词向量中\n",
      "ISTJ|||I不存在于词向量中\n",
      "ENFP!!不存在于词向量中\n",
      "PERFECT不存在于词向量中\n",
      "ALMOST不存在于词向量中\n",
      "PG不存在于词向量中\n",
      "off'不存在于词向量中\n",
      "obvious)不存在于词向量中\n",
      "BPD.不存在于词向量中\n",
      "Agnostic.不存在于词向量中\n",
      "breeze.不存在于词向量中\n",
      "w/e不存在于词向量中\n",
      "developed?不存在于词向量中\n",
      "Everyday,不存在于词向量中\n",
      "Strangelove不存在于词向量中\n",
      "(65%)不存在于词向量中\n",
      "(45%)不存在于词向量中\n",
      "you.|||Well,不存在于词向量中\n",
      "DARE不存在于词向量中\n",
      "disingenuous.不存在于词向量中\n",
      "in...|||Is不存在于词向量中\n",
      "(these不存在于词向量中\n",
      "2001.不存在于词向量中\n",
      "odds,不存在于词向量中\n",
      "misunderstood?不存在于词向量中\n",
      ":)|||Actually,不存在于词向量中\n",
      "hasn't.不存在于词向量中\n",
      "INFJ/INFP不存在于词向量中\n",
      "Ariel:不存在于词向量中\n",
      "Attractive不存在于词向量中\n",
      "...|||Even不存在于词向量中\n",
      "court,不存在于词向量中\n",
      "relevant?不存在于词向量中\n",
      "similar?不存在于词向量中\n",
      "Cautious不存在于词向量中\n",
      "Oddly,不存在于词向量中\n",
      "relieves不存在于词向量中\n",
      "34.不存在于词向量中\n",
      "phases.不存在于词向量中\n",
      "ppl,不存在于词向量中\n",
      "Busy不存在于词向量中\n",
      "clothes...不存在于词向量中\n",
      "'people不存在于词向量中\n",
      "Spring.不存在于词向量中\n",
      "quo.不存在于词向量中\n",
      "by...|||What不存在于词向量中\n",
      "sewing,不存在于词向量中\n",
      "SO!不存在于词向量中\n",
      "rushed.不存在于词向量中\n",
      "super,不存在于词向量中\n",
      "aspergers,不存在于词向量中\n",
      "Difficulty不存在于词向量中\n",
      "way.|||This不存在于词向量中\n",
      "always...|||This不存在于词向量中\n",
      "Healing不存在于词向量中\n",
      "PRETTY不存在于词向量中\n",
      "Spoken不存在于词向量中\n",
      "beats.不存在于词向量中\n",
      "new...|||This不存在于词向量中\n",
      "Norman不存在于词向量中\n",
      "top...|||I不存在于词向量中\n",
      "sale.不存在于词向量中\n",
      "IV,不存在于词向量中\n",
      "Birthday,不存在于词向量中\n",
      ":kitteh:|||It不存在于词向量中\n",
      "hindsight,不存在于词向量中\n",
      "bumper不存在于词向量中\n",
      "cartoon.不存在于词向量中\n",
      "workout,不存在于词向量中\n",
      "6).不存在于词向量中\n",
      "4's,不存在于词向量中\n",
      "ISTP).不存在于词向量中\n",
      "didn't...|||I'm不存在于词向量中\n",
      "at...|||One不存在于词向量中\n",
      "giddy.不存在于词向量中\n",
      "listening?不存在于词向量中\n",
      "2017.不存在于词向量中\n",
      "similarity.不存在于词向量中\n",
      "BrainRight不存在于词向量中\n",
      "Elaine不存在于词向量中\n",
      ":|||I不存在于词向量中\n",
      "Nobody's不存在于词向量中\n",
      "pasts不存在于词向量中\n",
      "MBIT不存在于词向量中\n",
      "sane,不存在于词向量中\n",
      "free-spirited,不存在于词向量中\n",
      "...|||well不存在于词向量中\n",
      "me|||i不存在于词向量中\n",
      "good!|||I不存在于词向量中\n",
      "Direction不存在于词向量中\n",
      "other...'不存在于词向量中\n",
      "'yeah,不存在于词向量中\n",
      "instrumentals,不存在于词向量中\n",
      "highly,不存在于词向量中\n",
      "replies?不存在于词向量中\n",
      "hardly...|||I不存在于词向量中\n",
      "loners,不存在于词向量中\n",
      "am).不存在于词向量中\n",
      "Doctor,不存在于词向量中\n",
      "Eye:不存在于词向量中\n",
      "wins.|||I不存在于词向量中\n",
      "Politicians不存在于词向量中\n",
      "amazing..不存在于词向量中\n",
      "subtitles.不存在于词向量中\n",
      "STFU不存在于词向量中\n",
      ":)|||You're不存在于词向量中\n",
      "indeed.|||I不存在于词向量中\n",
      "'Here不存在于词向量中\n",
      "involved?不存在于词向量中\n",
      "incredibly...|||I不存在于词向量中\n",
      "factory.不存在于词向量中\n",
      "signal,不存在于词向量中\n",
      "schoolwork.不存在于词向量中\n",
      "SENSE不存在于词向量中\n",
      "outfits.不存在于词向量中\n",
      "rationality,不存在于词向量中\n",
      "Discuss不存在于词向量中\n",
      "morbid,不存在于词向量中\n",
      "Fishing不存在于词向量中\n",
      "classroom,不存在于词向量中\n",
      "towns,不存在于词向量中\n",
      "Asian?不存在于词向量中\n",
      "pollution,不存在于词向量中\n",
      "twisted.不存在于词向量中\n",
      "brag,不存在于词向量中\n",
      "it....I不存在于词向量中\n",
      "'old不存在于词向量中\n",
      "thanks!|||I不存在于词向量中\n",
      "express,不存在于词向量中\n",
      "second...不存在于词向量中\n",
      "explain...|||I不存在于词向量中\n",
      "fork,不存在于词向量中\n",
      "different)不存在于词向量中\n",
      "do...|||That不存在于词向量中\n",
      "it...|||Yes,不存在于词向量中\n",
      "puppies,不存在于词向量中\n",
      "Fantasizing不存在于词向量中\n",
      "hardware,不存在于词向量中\n",
      "(anything不存在于词向量中\n",
      "INForJoking不存在于词向量中\n",
      "order...|||I不存在于词向量中\n",
      "Alfred不存在于词向量中\n",
      "are...|||I'd不存在于词向量中\n",
      "well.|||What不存在于词向量中\n",
      "that...|||Is不存在于词向量中\n",
      "bio,不存在于词向量中\n",
      "Bravo不存在于词向量中\n",
      "welcomed.不存在于词向量中\n",
      "had/have不存在于词向量中\n",
      "Gladiator不存在于词向量中\n",
      "Bates不存在于词向量中\n",
      "at...|||Well,不存在于词向量中\n",
      "Superiority:不存在于词向量中\n",
      "Exhibitionism:不存在于词向量中\n",
      "Exploitativeness:不存在于词向量中\n",
      "4.00不存在于词向量中\n",
      "Vanity:不存在于词向量中\n",
      "Entitlement:不存在于词向量中\n",
      "it?|||You不存在于词向量中\n",
      "a...|||Since不存在于词向量中\n",
      "?|||i不存在于词向量中\n",
      "^^|||i不存在于词向量中\n",
      "Taurus,不存在于词向量中\n",
      "Aries,不存在于词向量中\n",
      "Virgo,不存在于词向量中\n",
      "'oh,不存在于词向量中\n",
      "so/sp,不存在于词向量中\n",
      "cancer?不存在于词向量中\n",
      "me?'不存在于词向量中\n",
      "Whoops.不存在于词向量中\n",
      "woman)不存在于词向量中\n",
      "MAJOR不存在于词向量中\n",
      "butterflies,不存在于词向量中\n",
      "too...|||Thanks不存在于词向量中\n",
      "Fe-aux不存在于词向量中\n",
      "deal)不存在于词向量中\n",
      "elses.不存在于词向量中\n",
      "RED不存在于词向量中\n",
      "...|||They不存在于词向量中\n",
      "usefulness,不存在于词向量中\n",
      "...|||Does不存在于词向量中\n",
      "SOCIAL不存在于词向量中\n",
      "Ours不存在于词向量中\n",
      "LoL.不存在于词向量中\n",
      "fee,不存在于词向量中\n",
      "(edit:不存在于词向量中\n",
      "ya'不存在于词向量中\n",
      ":P|||Too不存在于词向量中\n",
      "INTJ's...不存在于词向量中\n",
      "Cartoon不存在于词向量中\n",
      ":D|||Haha不存在于词向量中\n",
      "Hipsters不存在于词向量中\n",
      "cat?不存在于词向量中\n",
      "KNOWS不存在于词向量中\n",
      "I...|||Very不存在于词向量中\n",
      "Cereal不存在于词向量中\n",
      "enlightenment.不存在于词向量中\n",
      "precious,不存在于词向量中\n",
      "...|||Sometimes不存在于词向量中\n",
      "pillow,不存在于词向量中\n",
      "permanent,不存在于词向量中\n",
      ":-)|||I'm不存在于词向量中\n",
      "can...|||Thanks不存在于词向量中\n",
      "tequila,不存在于词向量中\n",
      "Chappelle不存在于词向量中\n",
      "and...|||After不存在于词向量中\n",
      "one,...|||I不存在于词向量中\n",
      "value...|||I不存在于词向量中\n",
      "Close-mindedness不存在于词向量中\n",
      "me.|||In不存在于词向量中\n",
      "trousers,不存在于词向量中\n",
      "do...I不存在于词向量中\n",
      "think...|||Thank不存在于词向量中\n",
      "Sweetish不存在于词向量中\n",
      "my...|||From不存在于词向量中\n",
      "Jaws不存在于词向量中\n",
      "alienating不存在于词向量中\n",
      "back,...|||I不存在于词向量中\n",
      "The...|||I've不存在于词向量中\n",
      "twitter,不存在于词向量中\n",
      "grandfather,不存在于词向量中\n",
      "a..不存在于词向量中\n",
      "18).不存在于词向量中\n",
      "outfit,不存在于词向量中\n",
      "Me!不存在于词向量中\n",
      "chemistry?不存在于词向量中\n",
      "...|||Could不存在于词向量中\n",
      "Hall不存在于词向量中\n",
      "if...|||That不存在于词向量中\n",
      "Processing不存在于词向量中\n",
      "view)不存在于词向量中\n",
      "All!不存在于词向量中\n",
      "Tonight,不存在于词向量中\n",
      "sheep,不存在于词向量中\n",
      "Sanguine不存在于词向量中\n",
      "as)不存在于词向量中\n",
      "necessary)不存在于词向量中\n",
      "bummer,不存在于词向量中\n",
      "=]|||I不存在于词向量中\n",
      "left-brained.不存在于词向量中\n",
      "Girls,不存在于词向量中\n",
      "Streaming,不存在于词向量中\n",
      "disorder)不存在于词向量中\n",
      "Parody不存在于词向量中\n",
      "Dora不存在于词向量中\n",
      "a...|||Haha,不存在于词向量中\n",
      "Beautiful.不存在于词向量中\n",
      "INFJ/ENTP不存在于词向量中\n",
      ":laughing:|||A不存在于词向量中\n",
      "Skins不存在于词向量中\n",
      "advise.不存在于词向量中\n",
      "fulfilled.不存在于词向量中\n",
      "CV不存在于词向量中\n",
      "your...|||Not不存在于词向量中\n",
      "bath.不存在于词向量中\n",
      "idea;不存在于词向量中\n",
      "re-evaluating不存在于词向量中\n",
      "influences,不存在于词向量中\n",
      "fucked,不存在于词向量中\n",
      "Neo不存在于词向量中\n",
      "to...|||Depends不存在于词向量中\n",
      "me?)不存在于词向量中\n",
      "NF)不存在于词向量中\n",
      "motherfucker.不存在于词向量中\n",
      "Tom:不存在于词向量中\n",
      "Chris:不存在于词向量中\n",
      "theories?不存在于词向量中\n",
      "industry?不存在于词向量中\n",
      "america,不存在于词向量中\n",
      "message|||I不存在于词向量中\n",
      "LEFT不存在于词向量中\n",
      "Blow不存在于词向量中\n",
      "Jock,不存在于词向量中\n",
      "Geek,不存在于词向量中\n",
      "Prep,不存在于词向量中\n",
      "readings.不存在于词向量中\n",
      "know...|||You不存在于词向量中\n",
      "Course,不存在于词向量中\n",
      "scary.|||I不存在于词向量中\n",
      "THING.不存在于词向量中\n",
      "Four.不存在于词向量中\n",
      "late)不存在于词向量中\n",
      "...,不存在于词向量中\n",
      "about...|||Not不存在于词向量中\n",
      "textbook,不存在于词向量中\n",
      "validity,不存在于词向量中\n",
      "sci-fi/fantasy不存在于词向量中\n",
      "pay...|||I不存在于词向量中\n",
      "exploring,不存在于词向量中\n",
      "Zech不存在于词向量中\n",
      "side'不存在于词向量中\n",
      "BMW不存在于词向量中\n",
      "'right不存在于词向量中\n",
      "fabulous,不存在于词向量中\n",
      "NPR不存在于词向量中\n",
      "rolls.不存在于词向量中\n",
      "destination,不存在于词向量中\n",
      "Stroke不存在于词向量中\n",
      "Chosen不存在于词向量中\n",
      "Surreal不存在于词向量中\n",
      "Come,不存在于词向量中\n",
      "somewhere..不存在于词向量中\n",
      "'Wow不存在于词向量中\n",
      "so),不存在于词向量中\n",
      "case...|||I不存在于词向量中\n",
      "informative,不存在于词向量中\n",
      "head),不存在于词向量中\n",
      "Lisbon不存在于词向量中\n",
      "right?),不存在于词向量中\n",
      "justification.不存在于词向量中\n",
      "up....|||I不存在于词向量中\n",
      "what)不存在于词向量中\n",
      "Anastasia不存在于词向量中\n",
      "it...|||To不存在于词向量中\n",
      "Apologies.不存在于词向量中\n",
      "LIKES不存在于词向量中\n",
      "about...|||Do不存在于词向量中\n",
      ":crazy:|||You不存在于词向量中\n",
      "anything,...|||I不存在于词向量中\n",
      "remember),不存在于词向量中\n",
      "the...|||that不存在于词向量中\n",
      "i...|||I'm不存在于词向量中\n",
      "don't...|||This不存在于词向量中\n",
      "Sharp不存在于词向量中\n",
      "applicable,不存在于词向量中\n",
      "Sanders,不存在于词向量中\n",
      "gestures.不存在于词向量中\n",
      "(Did不存在于词向量中\n",
      "lean.不存在于词向量中\n",
      "Scott,不存在于词向量中\n",
      "same...|||This不存在于词向量中\n",
      "things'不存在于词向量中\n",
      "Subjective不存在于词向量中\n",
      "musical.不存在于词向量中\n",
      "WON'T不存在于词向量中\n",
      "Enneagrams不存在于词向量中\n",
      "dressed,不存在于词向量中\n",
      "lol.|||The不存在于词向量中\n",
      "grandma,不存在于词向量中\n",
      "liver,不存在于词向量中\n",
      "(see:不存在于词向量中\n",
      "...|||Ok,不存在于词向量中\n",
      "Proxy不存在于词向量中\n",
      "Panda.不存在于词向量中\n",
      "Warm,不存在于词向量中\n",
      "invasion,不存在于词向量中\n",
      "'After不存在于词向量中\n",
      "IEE不存在于词向量中\n",
      "gave,不存在于词向量中\n",
      "AWAY不存在于词向量中\n",
      "or...|||Well不存在于词向量中\n",
      "from...|||So不存在于词向量中\n",
      "Chameleon不存在于词向量中\n",
      "have...|||If不存在于词向量中\n",
      "Numb不存在于词向量中\n",
      "genocide,不存在于词向量中\n",
      "of...|||Don't不存在于词向量中\n",
      "enlist不存在于词向量中\n",
      "KTT不存在于词向量中\n",
      "funny).不存在于词向量中\n",
      "history?不存在于词向量中\n",
      "2005.不存在于词向量中\n",
      "I...|||Actually不存在于词向量中\n",
      "whatever),不存在于词向量中\n",
      "Et不存在于词向量中\n",
      "useful?不存在于词向量中\n",
      "been...|||When不存在于词向量中\n",
      "reconsider.不存在于词向量中\n",
      "fixing,不存在于词向量中\n",
      "Ariana不存在于词向量中\n",
      "wasted,不存在于词向量中\n",
      "residing不存在于词向量中\n",
      "speculation,不存在于词向量中\n",
      "only...|||You不存在于词向量中\n",
      "coaster.不存在于词向量中\n",
      "Cajun不存在于词向量中\n",
      "INFJ/ENFJ不存在于词向量中\n",
      "Ladies,不存在于词向量中\n",
      "Penguin不存在于词向量中\n",
      "proportion.不存在于词向量中\n",
      "Confession:不存在于词向量中\n",
      "Brown.不存在于词向量中\n",
      "WAY!不存在于词向量中\n",
      "Enigma不存在于词向量中\n",
      "your...|||Dear不存在于词向量中\n",
      "sure!|||I不存在于词向量中\n",
      "my...|||We不存在于词向量中\n",
      "Aikido不存在于词向量中\n",
      "generous.不存在于词向量中\n",
      "ID,不存在于词向量中\n",
      "she...|||I've不存在于词向量中\n",
      "sudden.不存在于词向量中\n",
      "graduated,不存在于词向量中\n",
      "newspaper,不存在于词向量中\n",
      "59.167不存在于词向量中\n",
      "mostly...|||I不存在于词向量中\n",
      "poet.不存在于词向量中\n",
      "CSS不存在于词向量中\n",
      "Eragon不存在于词向量中\n",
      "Burton's不存在于词向量中\n",
      "Dreamer.不存在于词向量中\n",
      "means...不存在于词向量中\n",
      "Castle,不存在于词向量中\n",
      "Megami不存在于词向量中\n",
      "Care.不存在于词向量中\n",
      "happen.|||I不存在于词向量中\n",
      "conscientious.不存在于词向量中\n",
      "'Where不存在于词向量中\n",
      "from...|||Thank不存在于词向量中\n",
      "rationality.不存在于词向量中\n",
      "zodiac,不存在于词向量中\n",
      "welfare.不存在于词向量中\n",
      "don't...|||It不存在于词向量中\n",
      "language...不存在于词向量中\n",
      "only?不存在于词向量中\n",
      "Hey.不存在于词向量中\n",
      "Tiger.不存在于词向量中\n",
      "(under不存在于词向量中\n",
      "overview.不存在于词向量中\n",
      "HAVING不存在于词向量中\n",
      "(dunno不存在于词向量中\n",
      "clash,不存在于词向量中\n",
      "it...|||Maybe不存在于词向量中\n",
      "for...|||Sounds不存在于词向量中\n",
      "needs)不存在于词向量中\n",
      "is...|||Hi不存在于词向量中\n",
      "behaviours,不存在于词向量中\n",
      "about...|||There不存在于词向量中\n",
      "intimately.不存在于词向量中\n",
      "setting?不存在于词向量中\n",
      "friend.|||I'm不存在于词向量中\n",
      "ceremony,不存在于词向量中\n",
      "calendar,不存在于词向量中\n",
      "Muhammad不存在于词向量中\n",
      "ruthlessly不存在于词向量中\n",
      "Sees不存在于词向量中\n",
      "Bravo,不存在于词向量中\n",
      "type.|||I've不存在于词向量中\n",
      "further?不存在于词向量中\n",
      "idk)不存在于词向量中\n",
      "Delivery不存在于词向量中\n",
      "fascinating...不存在于词向量中\n",
      "depends...不存在于词向量中\n",
      "pitch,不存在于词向量中\n",
      "nonfiction.不存在于词向量中\n",
      "safer.不存在于词向量中\n",
      "BUNCH不存在于词向量中\n",
      "'^不存在于词向量中\n",
      "(ISFP不存在于词向量中\n",
      "Bollywood不存在于词向量中\n",
      "Thumbs不存在于词向量中\n",
      "are...|||Yeah不存在于词向量中\n",
      "wives.不存在于词向量中\n",
      "Daydream不存在于词向量中\n",
      "feature.不存在于词向量中\n",
      "have...|||What不存在于词向量中\n",
      "cases)不存在于词向量中\n",
      "conscience?不存在于词向量中\n",
      "INTPS不存在于词向量中\n",
      "do.|||That's不存在于词向量中\n",
      "Clingy不存在于词向量中\n",
      "What.不存在于词向量中\n",
      "B.S不存在于词向量中\n",
      "FUN.不存在于词向量中\n",
      "xSFP.不存在于词向量中\n",
      "Helga不存在于词向量中\n",
      "think...|||What不存在于词向量中\n",
      "Broadly,不存在于词向量中\n",
      "(should不存在于词向量中\n",
      "just...|||What不存在于词向量中\n",
      "Spirits不存在于词向量中\n",
      "...|||Being不存在于词向量中\n",
      "Shape不存在于词向量中\n",
      "catholic)不存在于词向量中\n",
      "THIS,不存在于词向量中\n",
      "Souled不存在于词向量中\n",
      "the.不存在于词向量中\n",
      "life.|||The不存在于词向量中\n",
      "nothing)不存在于词向量中\n",
      "Facebook...不存在于词向量中\n",
      "been...不存在于词向量中\n",
      "fit...不存在于词向量中\n",
      "meditating.不存在于词向量中\n",
      "employee,不存在于词向量中\n",
      "than...|||1.不存在于词向量中\n",
      "(8)不存在于词向量中\n",
      "character...|||I不存在于词向量中\n",
      "axis,不存在于词向量中\n",
      "functionally,不存在于词向量中\n",
      "admire...|||I不存在于词向量中\n",
      "...|||Ok不存在于词向量中\n",
      ":wink:|||Maybe不存在于词向量中\n",
      "this...|||You不存在于词向量中\n",
      "Thunder不存在于词向量中\n",
      "Minesweeper不存在于词向量中\n",
      "glare.不存在于词向量中\n",
      "monitor.不存在于词向量中\n",
      "Whatever,不存在于词向量中\n",
      "Party.不存在于词向量中\n",
      "anymore).不存在于词向量中\n",
      "SW不存在于词向量中\n",
      "Sports不存在于词向量中\n",
      "alcoholic?不存在于词向量中\n",
      "intrigued,不存在于词向量中\n",
      ":)|||Of不存在于词向量中\n",
      "grass.不存在于词向量中\n",
      "anxiety...不存在于词向量中\n",
      "duck,不存在于词向量中\n",
      ".........不存在于词向量中\n",
      "redundant.不存在于词向量中\n",
      "awkward.|||I不存在于词向量中\n",
      "rarity,不存在于词向量中\n",
      "Masculinity不存在于词向量中\n",
      "nuances.不存在于词向量中\n",
      "for...|||He不存在于词向量中\n",
      "Onto不存在于词向量中\n",
      "profit,不存在于词向量中\n",
      "Liar不存在于词向量中\n",
      "Game,不存在于词向量中\n",
      "Shingeki不存在于词向量中\n",
      "ninja.不存在于词向量中\n",
      "disappointment.不存在于词向量中\n",
      "emotional.|||I不存在于词向量中\n",
      "illness?不存在于词向量中\n",
      "yeh,不存在于词向量中\n",
      "for...|||Hi不存在于词向量中\n",
      "Pop,不存在于词向量中\n",
      "ESTJ.|||I不存在于词向量中\n",
      "Six:不存在于词向量中\n",
      "otherwise),不存在于词向量中\n",
      "mental/emotional不存在于词向量中\n",
      ":cool:|||I'm不存在于词向量中\n",
      "clients,不存在于词向量中\n",
      "dessert.不存在于词向量中\n",
      "man|||I不存在于词向量中\n",
      "Bard不存在于词向量中\n",
      "Frankie不存在于词向量中\n",
      "Enchanted不存在于词向量中\n",
      "Halsey不存在于词向量中\n",
      "Alone.不存在于词向量中\n",
      "Instincts不存在于词向量中\n",
      "handful,不存在于词向量中\n",
      "level...|||I不存在于词向量中\n",
      "5am.不存在于词向量中\n",
      "Jose不存在于词向量中\n",
      "more...|||A不存在于词向量中\n",
      "variant,不存在于词向量中\n",
      "Joe's不存在于词向量中\n",
      "on.'不存在于词向量中\n",
      "RBF不存在于词向量中\n",
      "lurkers,不存在于词向量中\n",
      "a...|||LOL不存在于词向量中\n",
      "*STJ不存在于词向量中\n",
      "in...|||We不存在于词向量中\n",
      "soc/sx不存在于词向量中\n",
      "easy?不存在于词向量中\n",
      "...what不存在于词向量中\n",
      "traitor不存在于词向量中\n",
      "loophole不存在于词向量中\n",
      "becase不存在于词向量中\n",
      ":DDD不存在于词向量中\n",
      "them...but不存在于词向量中\n",
      "Game:不存在于词向量中\n",
      "Latest不存在于词向量中\n",
      "somehow...不存在于词向量中\n",
      "not),不存在于词向量中\n",
      "2014,不存在于词向量中\n",
      "it.|||No不存在于词向量中\n",
      "astrophysics,不存在于词向量中\n",
      "miscommunication.不存在于词向量中\n",
      "prose.不存在于词向量中\n",
      "Yikes!不存在于词向量中\n",
      ":)|||Sorry不存在于词向量中\n",
      "Cuddling不存在于词向量中\n",
      "Nurture不存在于词向量中\n",
      "welcomes.不存在于词向量中\n",
      ":)|||Nice不存在于词向量中\n",
      "in...|||Hello不存在于词向量中\n",
      "Grande不存在于词向量中\n",
      "Goulding不存在于词向量中\n",
      "origin.不存在于词向量中\n",
      "sentiments,不存在于词向量中\n",
      "awkward?不存在于词向量中\n",
      "deny,不存在于词向量中\n",
      "Reagan不存在于词向量中\n",
      "?|||It不存在于词向量中\n",
      "discoveries,不存在于词向量中\n",
      "Yu-Gi-Oh不存在于词向量中\n",
      "Glory不存在于词向量中\n",
      "Leather不存在于词向量中\n",
      "Enthusiasm不存在于词向量中\n",
      "cigarette.不存在于词向量中\n",
      "live.|||I不存在于词向量中\n",
      "dogs?不存在于词向量中\n",
      "...|||INTJ不存在于词向量中\n",
      "kingdom.不存在于词向量中\n",
      "Mycroft不存在于词向量中\n",
      "100,不存在于词向量中\n",
      "it's...'不存在于词向量中\n",
      "feelings/emotions不存在于词向量中\n",
      "truth...不存在于词向量中\n",
      "(;不存在于词向量中\n",
      "Grandfather:不存在于词向量中\n",
      "BTS不存在于词向量中\n",
      "sugar-coat不存在于词向量中\n",
      "performer.不存在于词向量中\n",
      "storyline,不存在于词向量中\n",
      "shot?不存在于词向量中\n",
      "(enneagram不存在于词向量中\n",
      "manipulation?不存在于词向量中\n",
      "the...|||Pretty不存在于词向量中\n",
      "understanding?不存在于词向量中\n",
      "wrong),不存在于词向量中\n",
      "pole.不存在于词向量中\n",
      "Marxism不存在于词向量中\n",
      "Indonesian不存在于词向量中\n",
      "Death,不存在于词向量中\n",
      "Angel,不存在于词向量中\n",
      "Nile不存在于词向量中\n",
      "metal?不存在于词向量中\n",
      "sociology.不存在于词向量中\n",
      "(third不存在于词向量中\n",
      "multitasking,不存在于词向量中\n",
      "chore.不存在于词向量中\n",
      "outcasts.不存在于词向量中\n",
      "analyzing?不存在于词向量中\n",
      "Sigh...不存在于词向量中\n",
      "intuition...不存在于词向量中\n",
      "online)不存在于词向量中\n",
      "Keane不存在于词向量中\n",
      "just...|||Just不存在于词向量中\n",
      "(huge不存在于词向量中\n",
      "words),不存在于词向量中\n",
      "idol.不存在于词向量中\n",
      "Duran不存在于词向量中\n",
      "Hare不存在于词向量中\n",
      "Russians不存在于词向量中\n",
      "Powell不存在于词向量中\n",
      "If...|||The不存在于词向量中\n",
      "emphasis.不存在于词向量中\n",
      "altogether,不存在于词向量中\n",
      "Buffy,不存在于词向量中\n",
      "guy),不存在于词向量中\n",
      "am...|||i不存在于词向量中\n",
      "Pissed不存在于词向量中\n",
      "Tested不存在于词向量中\n",
      "Enrique不存在于词向量中\n",
      "Inspiration不存在于词向量中\n",
      "Blanchett不存在于词向量中\n",
      "they...|||It's不存在于词向量中\n",
      "himself...|||I不存在于词向量中\n",
      "diverse,不存在于词向量中\n",
      "them.|||1.不存在于词向量中\n",
      "Westboro不存在于词向量中\n",
      "luck?不存在于词向量中\n",
      "irritation,不存在于词向量中\n",
      "Xanax不存在于词向量中\n",
      "aimless,不存在于词向量中\n",
      "favor,不存在于词向量中\n",
      "Tridentus不存在于词向量中\n",
      "entirety,不存在于词向量中\n",
      "Tank不存在于词向量中\n",
      "idiotic,不存在于词向量中\n",
      "and...|||Maybe不存在于词向量中\n",
      "Mahatma不存在于词向量中\n",
      "bolded.不存在于词向量中\n",
      "infectious.不存在于词向量中\n",
      "Kill.不存在于词向量中\n",
      "Se-不存在于词向量中\n",
      "see's不存在于词向量中\n",
      "Brisbane不存在于词向量中\n",
      "body...不存在于词向量中\n",
      "calories.不存在于词向量中\n",
      "greater,不存在于词向量中\n",
      "cognition,不存在于词向量中\n",
      "powerless.不存在于词向量中\n",
      "subjectivity,不存在于词向量中\n",
      "music).不存在于词向量中\n",
      "spontaneity.不存在于词向量中\n",
      "introvert.|||I不存在于词向量中\n",
      "follow?不存在于词向量中\n",
      "Resistance不存在于词向量中\n",
      "Screen不存在于词向量中\n",
      "Fe/Ti,不存在于词向量中\n",
      "missed?不存在于词向量中\n",
      "Moore不存在于词向量中\n",
      "are...|||INFP不存在于词向量中\n",
      "Cable不存在于词向量中\n",
      "pile,不存在于词向量中\n",
      "but...|||Not不存在于词向量中\n",
      "swallow,不存在于词向量中\n",
      "Want,不存在于词向量中\n",
      "Immediately不存在于词向量中\n",
      "HUG不存在于词向量中\n",
      ":wink:|||What不存在于词向量中\n",
      "satire,不存在于词向量中\n",
      "at...|||I've不存在于词向量中\n",
      "considering.不存在于词向量中\n",
      "Album:不存在于词向量中\n",
      "(Dad不存在于词向量中\n",
      "journalism,不存在于词向量中\n",
      "out!|||I不存在于词向量中\n",
      "Remix)不存在于词向量中\n",
      "supermarket.不存在于词向量中\n",
      ":wink:|||That's不存在于词向量中\n",
      "NT...不存在于词向量中\n",
      "Jessie不存在于词向量中\n",
      "Sie不存在于词向量中\n",
      "grandfather.不存在于词向量中\n",
      "Read.不存在于词向量中\n",
      "what?|||I不存在于词向量中\n",
      "help!|||I不存在于词向量中\n",
      "Joe.不存在于词向量中\n",
      "simplistic.不存在于词向量中\n",
      "fan?不存在于词向量中\n",
      "Ocarina不存在于词向量中\n",
      "ME!!!不存在于词向量中\n",
      "EMOTIONAL不存在于词向量中\n",
      "'Sorry,不存在于词向量中\n",
      "Moss不存在于词向量中\n",
      "feels?不存在于词向量中\n",
      "ENTP-ish不存在于词向量中\n",
      "Seinfeld,不存在于词向量中\n",
      "Restaurant不存在于词向量中\n",
      "Missy不存在于词向量中\n",
      "Hobbs不存在于词向量中\n",
      "Heat不存在于词向量中\n",
      "Days.不存在于词向量中\n",
      "then...|||The不存在于词向量中\n",
      "chemicals.不存在于词向量中\n",
      "are...|||We不存在于词向量中\n",
      "collected.不存在于词向量中\n",
      "Joshua不存在于词向量中\n",
      "from...'不存在于词向量中\n",
      "Trailer不存在于词向量中\n",
      "enlightened,不存在于词向量中\n",
      "Wife:不存在于词向量中\n",
      "humour?不存在于词向量中\n",
      "niche.不存在于词向量中\n",
      "FORGET不存在于词向量中\n",
      "Sapphire不存在于词向量中\n",
      "advices.不存在于词向量中\n",
      "people...|||Yes,不存在于词向量中\n",
      "Poland.不存在于词向量中\n",
      "softer,不存在于词向量中\n",
      "either?不存在于词向量中\n",
      "Magic:不存在于词向量中\n",
      "Florida.不存在于词向量中\n",
      "a...|||Where不存在于词向量中\n",
      "w/e.不存在于词向量中\n",
      "Great.不存在于词向量中\n",
      "Hokahey不存在于词向量中\n",
      "(we)不存在于词向量中\n",
      "it.|||I'll不存在于词向量中\n",
      "ENFP's!不存在于词向量中\n",
      "morons.不存在于词向量中\n",
      "while...|||I'm不存在于词向量中\n",
      "further...不存在于词向量中\n",
      "W,不存在于词向量中\n",
      "Seriously!不存在于词向量中\n",
      "earlier?不存在于词向量中\n",
      "X:不存在于词向量中\n",
      "cuddle.不存在于词向量中\n",
      "in...|||Sometimes不存在于词向量中\n",
      "finger,不存在于词向量中\n",
      "sections.不存在于词向量中\n",
      "Court不存在于词向量中\n",
      "(Good不存在于词向量中\n",
      "expansion.不存在于词向量中\n",
      "tiger.不存在于词向量中\n",
      "Inu不存在于词向量中\n",
      "when/if不存在于词向量中\n",
      "we've...|||I不存在于词向量中\n",
      "vice-versa.不存在于词向量中\n",
      "unemotional.不存在于词向量中\n",
      "all.|||The不存在于词向量中\n",
      "left?不存在于词向量中\n",
      "Roberts不存在于词向量中\n",
      "person...|||I'm不存在于词向量中\n",
      "tea...不存在于词向量中\n",
      "because...|||It's不存在于词向量中\n",
      "50's不存在于词向量中\n",
      "Audio不存在于词向量中\n",
      "now!|||I不存在于词向量中\n",
      "colleagues.不存在于词向量中\n",
      "brownies,不存在于词向量中\n",
      "though.|||Well,不存在于词向量中\n",
      "documents.不存在于词向量中\n",
      "recommended.不存在于词向量中\n",
      "bonus.不存在于词向量中\n",
      "outdated,不存在于词向量中\n",
      "event?不存在于词向量中\n",
      "angst,不存在于词向量中\n",
      "me...|||In不存在于词向量中\n",
      "Pills不存在于词向量中\n",
      "bleak.不存在于词向量中\n",
      "and...|||Actually不存在于词向量中\n",
      "analyst.不存在于词向量中\n",
      "to...|||Nice不存在于词向量中\n",
      "Zoom不存在于词向量中\n",
      "at...|||What不存在于词向量中\n",
      "state's不存在于词向量中\n",
      "spider,不存在于词向量中\n",
      "Benny不存在于词向量中\n",
      "carefree.不存在于词向量中\n",
      "write...|||I'm不存在于词向量中\n",
      "Rangers不存在于词向量中\n",
      "doing...'不存在于词向量中\n",
      "of...|||Can不存在于词向量中\n",
      "permissive?不存在于词向量中\n",
      "monogamous?不存在于词向量中\n",
      "mother...|||I不存在于词向量中\n",
      "Xbox.不存在于词向量中\n",
      "Saturdays不存在于词向量中\n",
      "Face,不存在于词向量中\n",
      "exISTP不存在于词向量中\n",
      "Muslim.不存在于词向量中\n",
      "Erudite不存在于词向量中\n",
      "owners,不存在于词向量中\n",
      "otherwise?不存在于词向量中\n",
      "you...|||By不存在于词向量中\n",
      "warm?不存在于词向量中\n",
      "July,不存在于词向量中\n",
      "spoilt不存在于词向量中\n",
      "colleague.不存在于词向量中\n",
      "Checks不存在于词向量中\n",
      "shorter,不存在于词向量中\n",
      "romantic?不存在于词向量中\n",
      "learnt.不存在于词向量中\n",
      "Brooklyn不存在于词向量中\n",
      "access.不存在于词向量中\n",
      "(which...|||I不存在于词向量中\n",
      "Corporations不存在于词向量中\n",
      "band?不存在于词向量中\n",
      "regular.不存在于词向量中\n",
      "uplifting.不存在于词向量中\n",
      "Thor:不存在于词向量中\n",
      "Riy不存在于词向量中\n",
      "(most)不存在于词向量中\n",
      "non-NTs不存在于词向量中\n",
      "I...|||Honestly,不存在于词向量中\n",
      "me?|||I'm不存在于词向量中\n",
      "smarter?不存在于词向量中\n",
      "intolerant.不存在于词向量中\n",
      "dots,不存在于词向量中\n",
      "inward.不存在于词向量中\n",
      "chains,不存在于词向量中\n",
      "I...|||Today不存在于词向量中\n",
      "meaning?不存在于词向量中\n",
      "me.....不存在于词向量中\n",
      "(56%)不存在于词向量中\n",
      "in...|||Hi不存在于词向量中\n",
      "Initiative不存在于词向量中\n",
      "Conversely,不存在于词向量中\n",
      "that...|||Im不存在于词向量中\n",
      "gore.不存在于词向量中\n",
      "Manson,不存在于词向量中\n",
      "assertion?不存在于词向量中\n",
      "he...不存在于词向量中\n",
      "labs.不存在于词向量中\n",
      "(moreso不存在于词向量中\n",
      "an...|||What不存在于词向量中\n",
      "about...|||Yes,不存在于词向量中\n",
      "...the不存在于词向量中\n",
      "Device|||I不存在于词向量中\n",
      "linguistic,不存在于词向量中\n",
      "Joyce不存在于词向量中\n",
      "Cory不存在于词向量中\n",
      "you!.不存在于词向量中\n",
      "Witness不存在于词向量中\n",
      "permitted不存在于词向量中\n",
      "'ok不存在于词向量中\n",
      "Methinks不存在于词向量中\n",
      "Prove不存在于词向量中\n",
      "offered.不存在于词向量中\n",
      "readily.不存在于词向量中\n",
      "Woah,不存在于词向量中\n",
      "kind.|||I不存在于词向量中\n",
      "(dark不存在于词向量中\n",
      "mole.不存在于词向量中\n",
      "PBS不存在于词向量中\n",
      "image?不存在于词向量中\n",
      "DarkBarlow不存在于词向量中\n",
      "Someday,不存在于词向量中\n",
      "animals.|||I不存在于词向量中\n",
      "concept?不存在于词向量中\n",
      "alphabet,不存在于词向量中\n",
      "Dickinson不存在于词向量中\n",
      "ramblings.不存在于词向量中\n",
      "confirm.不存在于词向量中\n",
      "not...|||Dear不存在于词向量中\n",
      ":tongue:|||When不存在于词向量中\n",
      "sorry.|||I'm不存在于词向量中\n",
      "cube.不存在于词向量中\n",
      ":happy:|||Oh不存在于词向量中\n",
      "Thomas,不存在于词向量中\n",
      "myself.|||Yes,不存在于词向量中\n",
      "PTSD.不存在于词向量中\n",
      "things),不存在于词向量中\n",
      "(heck,不存在于词向量中\n",
      "WTF?不存在于词向量中\n",
      ":dry:|||The不存在于词向量中\n",
      "Help!不存在于词向量中\n",
      "even...|||Not不存在于词向量中\n",
      "beasts,不存在于词向量中\n",
      "being...|||You不存在于词向量中\n",
      "lol)|||I不存在于词向量中\n",
      "retreat,不存在于词向量中\n",
      "cheek,不存在于词向量中\n",
      "Mirai不存在于词向量中\n",
      "Reimu不存在于词向量中\n",
      "Scotland,不存在于词向量中\n",
      "Sevens不存在于词向量中\n",
      "surprisingly.不存在于词向量中\n",
      "perhaps...|||I不存在于词向量中\n",
      "beef,不存在于词向量中\n",
      "suits,不存在于词向量中\n",
      "summary.不存在于词向量中\n",
      "Now...|||I不存在于词向量中\n",
      "Minchin不存在于词向量中\n",
      "favorites...不存在于词向量中\n",
      "Ros,不存在于词向量中\n",
      "Perry,不存在于词向量中\n",
      "Americans.不存在于词向量中\n",
      "shocking.不存在于词向量中\n",
      "dictator.不存在于词向量中\n",
      "written...|||I不存在于词向量中\n",
      "theory...不存在于词向量中\n",
      "doing...|||I'm不存在于词向量中\n",
      "joining.不存在于词向量中\n",
      "Admittedly不存在于词向量中\n",
      "Hurry不存在于词向量中\n",
      "Olive不存在于词向量中\n",
      "Bertrand不存在于词向量中\n",
      "'new不存在于词向量中\n",
      "Zumba不存在于词向量中\n",
      "Higurashi不存在于词向量中\n",
      "know...|||The不存在于词向量中\n",
      "fallacies,不存在于词向量中\n",
      "long-term.不存在于词向量中\n",
      "like...|||Do不存在于词向量中\n",
      "he...|||Hey不存在于词向量中\n",
      "time...|||Thank不存在于词向量中\n",
      "Dauntless.不存在于词向量中\n",
      "don't...|||If不存在于词向量中\n",
      "I'm...|||i不存在于词向量中\n",
      "ExFJs不存在于词向量中\n",
      "edit,不存在于词向量中\n",
      "Yay.不存在于词向量中\n",
      "successfully.不存在于词向量中\n",
      "stay?不存在于词向量中\n",
      "experiments,不存在于词向量中\n",
      "rebellion,不存在于词向量中\n",
      "It's...|||I'm不存在于词向量中\n",
      "this...|||Thank不存在于词向量中\n",
      "MAN.不存在于词向量中\n",
      "pile.不存在于词向量中\n",
      "Apollo不存在于词向量中\n",
      "fulfillment.不存在于词向量中\n",
      "overlooked,不存在于词向量中\n",
      "inconsiderate.不存在于词向量中\n",
      "opponent,不存在于词向量中\n",
      "gaze.不存在于词向量中\n",
      "Gym不存在于词向量中\n",
      "me....|||I'm不存在于词向量中\n",
      "yang.不存在于词向量中\n",
      "Peters不存在于词向量中\n",
      "monotone,不存在于词向量中\n",
      "Damned不存在于词向量中\n",
      "FTW.不存在于词向量中\n",
      "at...|||Dear不存在于词向量中\n",
      "then...|||I'm不存在于词向量中\n",
      "miraculously不存在于词向量中\n",
      "helps?不存在于词向量中\n",
      "(watched不存在于词向量中\n",
      "place),不存在于词向量中\n",
      "INJ不存在于词向量中\n",
      "1w9?不存在于词向量中\n",
      "23/26不存在于词向量中\n",
      "xSFJ,不存在于词向量中\n",
      "worst...|||I不存在于词向量中\n",
      "days),不存在于词向量中\n",
      "Widow不存在于词向量中\n",
      "Se-dom.不存在于词向量中\n",
      "basement,不存在于词向量中\n",
      "Largest不存在于词向量中\n",
      "Spirit.不存在于词向量中\n",
      "policies.不存在于词向量中\n",
      "Evil,不存在于词向量中\n",
      "31,不存在于词向量中\n",
      "articulate,不存在于词向量中\n",
      "(sounds不存在于词向量中\n",
      "of...|||Two不存在于词向量中\n",
      "LA.不存在于词向量中\n",
      "known...|||I不存在于词向量中\n",
      "person..不存在于词向量中\n",
      "'Could不存在于词向量中\n",
      "this??不存在于词向量中\n",
      "bold)不存在于词向量中\n",
      "politeness,不存在于词向量中\n",
      "cheek.不存在于词向量中\n",
      "Settings不存在于词向量中\n",
      "an...|||When不存在于词向量中\n",
      "Round不存在于词向量中\n",
      "SF's不存在于词向量中\n",
      "lol|||lol不存在于词向量中\n",
      "...|||Ah不存在于词向量中\n",
      "Many,不存在于词向量中\n",
      "fidgety,不存在于词向量中\n",
      "XDD不存在于词向量中\n",
      "analogies,不存在于词向量中\n",
      "nihilist.不存在于词向量中\n",
      "is...|||One不存在于词向量中\n",
      "supposed...|||I不存在于词向量中\n",
      "fitness.不存在于词向量中\n",
      "bicycles,不存在于词向量中\n",
      "an...|||One不存在于词向量中\n",
      "love'不存在于词向量中\n",
      "to.|||I've不存在于词向量中\n",
      "reason.|||I'm不存在于词向量中\n",
      "Morrison,不存在于词向量中\n",
      "Soup不存在于词向量中\n",
      "-Having不存在于词向量中\n",
      "woudn't不存在于词向量中\n",
      "reddit,不存在于词向量中\n",
      "Roth不存在于词向量中\n",
      "me.|||A不存在于词向量中\n",
      "throat,不存在于词向量中\n",
      "MAKES不存在于词向量中\n",
      "Suzanne不存在于词向量中\n",
      ":tongue:|||Just不存在于词向量中\n",
      "gamer.不存在于词向量中\n",
      "as...|||In不存在于词向量中\n",
      "emoticons.不存在于词向量中\n",
      "Ben,不存在于词向量中\n",
      "nihilism,不存在于词向量中\n",
      "others,...|||I不存在于词向量中\n",
      "wikipedia.不存在于词向量中\n",
      "Trayvon不存在于词向量中\n",
      "SMART不存在于词向量中\n",
      "ideally,不存在于词向量中\n",
      "and...|||Sure,不存在于词向量中\n",
      "appointments,不存在于词向量中\n",
      "Maximum不存在于词向量中\n",
      "Brings不存在于词向量中\n",
      "Tango不存在于词向量中\n",
      "face.|||My不存在于词向量中\n",
      "TYPES:不存在于词向量中\n",
      "pleased.不存在于词向量中\n",
      "Balls不存在于词向量中\n",
      "extinct,不存在于词向量中\n",
      "confine不存在于词向量中\n",
      "endless,不存在于词向量中\n",
      "...|||Can不存在于词向量中\n",
      "Writes不存在于词向量中\n",
      "ok...不存在于词向量中\n",
      "Bing不存在于词向量中\n",
      "language...|||I不存在于词向量中\n",
      "Tapatalk|||Hey不存在于词向量中\n",
      "NLD不存在于词向量中\n",
      "Kathleen不存在于词向量中\n",
      "desire?不存在于词向量中\n",
      "my...|||Are不存在于词向量中\n",
      "mind?|||I不存在于词向量中\n",
      "hmmm....不存在于词向量中\n",
      "futures.不存在于词向量中\n",
      "Order.不存在于词向量中\n",
      "some...|||For不存在于词向量中\n",
      "Stop.不存在于词向量中\n",
      "Louise不存在于词向量中\n",
      "burning.不存在于词向量中\n",
      "might...'不存在于词向量中\n",
      "withdrawal,不存在于词向量中\n",
      "aid,不存在于词向量中\n",
      "Iceland.不存在于词向量中\n",
      "daunting.不存在于词向量中\n",
      "problems)不存在于词向量中\n",
      "match'不存在于词向量中\n",
      "to...|||Ha,不存在于词向量中\n",
      "Outgoing不存在于词向量中\n",
      "relating,不存在于词向量中\n",
      "Builder不存在于词向量中\n",
      "us....不存在于词向量中\n",
      "(use不存在于词向量中\n",
      "gore,不存在于词向量中\n",
      "Memorize不存在于词向量中\n",
      "Totoro.不存在于词向量中\n",
      "playing?不存在于词向量中\n",
      "don't)不存在于词向量中\n",
      "these...|||I'm不存在于词向量中\n",
      "Members不存在于词向量中\n",
      "stalker.不存在于词向量中\n",
      "oldest.不存在于词向量中\n",
      "aromantic,不存在于词向量中\n",
      "Images不存在于词向量中\n",
      "you?...|||I不存在于词向量中\n",
      "each...|||I'm不存在于词向量中\n",
      "personality...不存在于词向量中\n",
      "majors.不存在于词向量中\n",
      "strokes.不存在于词向量中\n",
      "perceive,不存在于词向量中\n",
      "Reeves不存在于词向量中\n",
      "Fear.不存在于词向量中\n",
      "Grumpy不存在于词向量中\n",
      "^^)不存在于词向量中\n",
      "somewhat...|||I不存在于词向量中\n",
      "either..不存在于词向量中\n",
      "the...|||Another不存在于词向量中\n",
      "type!!不存在于词向量中\n",
      "pokemon,不存在于词向量中\n",
      "many...|||It's不存在于词向量中\n",
      "INFP...|||I'm不存在于词向量中\n",
      "daydream,不存在于词向量中\n",
      "gap,不存在于词向量中\n",
      "school..不存在于词向量中\n",
      "fav,不存在于词向量中\n",
      "of...|||Never不存在于词向量中\n",
      ":p'不存在于词向量中\n",
      "'OMG不存在于词向量中\n",
      ":)|||INFJ不存在于词向量中\n",
      "Kindly不存在于词向量中\n",
      "world'.不存在于词向量中\n",
      "in...|||Don't不存在于词向量中\n",
      "Bruno不存在于词向量中\n",
      "Catholics不存在于词向量中\n",
      ")...|||I不存在于词向量中\n",
      "Mock不存在于词向量中\n",
      "reputation,不存在于词向量中\n",
      "realizing,不存在于词向量中\n",
      "Holidays不存在于词向量中\n",
      "would...|||Hello不存在于词向量中\n",
      "it...|||Hey不存在于词向量中\n",
      "'need'不存在于词向量中\n",
      "elitist.不存在于词向量中\n",
      "and...|||There's不存在于词向量中\n",
      "Although...不存在于词向量中\n",
      "with...|||Wow,不存在于词向量中\n",
      "components,不存在于词向量中\n",
      "try.|||I不存在于词向量中\n",
      "quitting,不存在于词向量中\n",
      "brings.不存在于词向量中\n",
      "people...|||I've不存在于词向量中\n",
      "Work.不存在于词向量中\n",
      "juice.不存在于词向量中\n",
      "headed.不存在于词向量中\n",
      "with...|||Yeah不存在于词向量中\n",
      "nursing,不存在于词向量中\n",
      "them...|||What不存在于词向量中\n",
      "Lashes不存在于词向量中\n",
      "particular)不存在于词向量中\n",
      "technique.不存在于词向量中\n",
      "preschool.不存在于词向量中\n",
      "Wolfgang不存在于词向量中\n",
      "uncomfortable.|||I不存在于词向量中\n",
      "winner.不存在于词向量中\n",
      "'J'不存在于词向量中\n",
      "adopt.不存在于词向量中\n",
      "conflicted,不存在于词向量中\n",
      "therapeutic.不存在于词向量中\n",
      "(seriously不存在于词向量中\n",
      "whole?不存在于词向量中\n",
      "other...|||If不存在于词向量中\n",
      "shits.不存在于词向量中\n",
      "...|||These不存在于词向量中\n",
      "hour.|||I不存在于词向量中\n",
      "Psychiatrist不存在于词向量中\n",
      "Technology.不存在于词向量中\n",
      "pushing,不存在于词向量中\n",
      "(yay不存在于词向量中\n",
      "voted.不存在于词向量中\n",
      "Cali不存在于词向量中\n",
      "dismissive,不存在于词向量中\n",
      "Mist不存在于词向量中\n",
      "even...|||It不存在于词向量中\n",
      "slob,不存在于词向量中\n",
      "Chapman不存在于词向量中\n",
      "SS不存在于词向量中\n",
      "negatives.不存在于词向量中\n",
      "wing):不存在于词向量中\n",
      "IDK.不存在于词向量中\n",
      "Horrors不存在于词向量中\n",
      "Shadows不存在于词向量中\n",
      "Welsh,不存在于词向量中\n",
      "'Holy不存在于词向量中\n",
      "promising,不存在于词向量中\n",
      "IQ?不存在于词向量中\n",
      "have...|||Well不存在于词向量中\n",
      "extrovert)不存在于词向量中\n",
      "creative.|||I不存在于词向量中\n",
      "positively.不存在于词向量中\n",
      "type.|||This不存在于词向量中\n",
      "far.|||I不存在于词向量中\n",
      "ultimatum.不存在于词向量中\n",
      "coordination,不存在于词向量中\n",
      "am...|||This不存在于词向量中\n",
      "ME:不存在于词向量中\n",
      "to.|||If不存在于词向量中\n",
      "nitpicky,不存在于词向量中\n",
      "XX不存在于词向量中\n",
      "away....不存在于词向量中\n",
      "Leo.不存在于词向量中\n",
      "to...|||Thanks.不存在于词向量中\n",
      "style...不存在于词向量中\n",
      "that.|||Yes,不存在于词向量中\n",
      "can...|||For不存在于词向量中\n",
      "taboo,不存在于词向量中\n",
      "underdeveloped,不存在于词向量中\n",
      "convictions,不存在于词向量中\n",
      "complexity,不存在于词向量中\n",
      "Darren不存在于词向量中\n",
      "boring.|||I不存在于词向量中\n",
      "villains,不存在于词向量中\n",
      "citizen,不存在于词向量中\n",
      "scenery.不存在于词向量中\n",
      "Sticks不存在于词向量中\n",
      "warranted.不存在于词向量中\n",
      "ticket,不存在于词向量中\n",
      "badass,不存在于词向量中\n",
      "Sasha不存在于词向量中\n",
      "(ESFJ,不存在于词向量中\n",
      ";)|||When不存在于词向量中\n",
      "them.)不存在于词向量中\n",
      "artwork.不存在于词向量中\n",
      "if...|||Thanks不存在于词向量中\n",
      "it.I不存在于词向量中\n",
      "(I...|||I不存在于词向量中\n",
      "the...|||Hi,不存在于词向量中\n",
      "Alexandria不存在于词向量中\n",
      "idea).不存在于词向量中\n",
      "Stupidity不存在于词向量中\n",
      "Soy不存在于词向量中\n",
      "arena.不存在于词向量中\n",
      "Prisoner不存在于词向量中\n",
      "for...|||Why不存在于词向量中\n",
      "fame.不存在于词向量中\n",
      "ISTJ.|||I不存在于词向量中\n",
      "geometry.不存在于词向量中\n",
      "Pursuit不存在于词向量中\n",
      "Hours不存在于词向量中\n",
      "Examine不存在于词向量中\n",
      "ancient.不存在于词向量中\n",
      "IXTX不存在于词向量中\n",
      "'E'不存在于词向量中\n",
      "subconsciously,不存在于词向量中\n",
      "luck.|||I不存在于词向量中\n",
      "E3不存在于词向量中\n",
      "(you're不存在于词向量中\n",
      "grave,不存在于词向量中\n",
      "Dwight不存在于词向量中\n",
      "long.|||I不存在于词向量中\n",
      "completely!不存在于词向量中\n",
      "at...|||That's不存在于词向量中\n",
      "truth.|||I不存在于词向量中\n",
      "DO.不存在于词向量中\n",
      "intuitives?不存在于词向量中\n",
      "Market不存在于词向量中\n",
      "Batman!不存在于词向量中\n",
      "cocaine,不存在于词向量中\n",
      "TRUE不存在于词向量中\n",
      "detailed.不存在于词向量中\n",
      "PT不存在于词向量中\n",
      "schedules.不存在于词向量中\n",
      "fuzzy,不存在于词向量中\n",
      "assistant,不存在于词向量中\n",
      "so.|||The不存在于词向量中\n",
      "fault?不存在于词向量中\n",
      "communities,不存在于词向量中\n",
      "sometimes.'不存在于词向量中\n",
      "TELL不存在于词向量中\n",
      "more...|||Yeah,不存在于词向量中\n",
      "soothing,不存在于词向量中\n",
      "forward?不存在于词向量中\n",
      ":)|||Sounds不存在于词向量中\n",
      "istj's不存在于词向量中\n",
      "way!|||I不存在于词向量中\n",
      "sort...|||I不存在于词向量中\n",
      "positives.不存在于词向量中\n",
      "yr.不存在于词向量中\n",
      "SOO不存在于词向量中\n",
      "tiresome,不存在于词向量中\n",
      "you've...|||I不存在于词向量中\n",
      "touch?不存在于词向量中\n",
      "drugs...不存在于词向量中\n",
      "and...|||Ah不存在于词向量中\n",
      "practical?不存在于词向量中\n",
      "Seattle.不存在于词向量中\n",
      "region.不存在于词向量中\n",
      "by...|||You不存在于词向量中\n",
      "psychology?不存在于词向量中\n",
      "maintain.不存在于词向量中\n",
      "or...|||There不存在于词向量中\n",
      "'friends不存在于词向量中\n",
      "'i'm不存在于词向量中\n",
      "abusive,不存在于词向量中\n",
      "Calc不存在于词向量中\n",
      "lot...|||The不存在于词向量中\n",
      "crucial.不存在于词向量中\n",
      "Rejected不存在于词向量中\n",
      "accepting,不存在于词向量中\n",
      "post....不存在于词向量中\n",
      "ENTP?|||I不存在于词向量中\n",
      "Ooh不存在于词向量中\n",
      "influenced.不存在于词向量中\n",
      "predictions,不存在于词向量中\n",
      "Tennant不存在于词向量中\n",
      "likes...|||I不存在于词向量中\n",
      "disasters,不存在于词向量中\n",
      "Questioning不存在于词向量中\n",
      "Lex不存在于词向量中\n",
      "bye,不存在于词向量中\n",
      "Umbridge不存在于词向量中\n",
      "was...|||That's不存在于词向量中\n",
      "limitation.不存在于词向量中\n",
      "off-topic.不存在于词向量中\n",
      "lulz.不存在于词向量中\n",
      "ESI不存在于词向量中\n",
      "Night's不存在于词向量中\n",
      "'Today不存在于词向量中\n",
      "not...|||i不存在于词向量中\n",
      "ESFP's,不存在于词向量中\n",
      "Fi-不存在于词向量中\n",
      "Gattaca不存在于词向量中\n",
      "Underworld不存在于词向量中\n",
      "hand..不存在于词向量中\n",
      "hypothesis,不存在于词向量中\n",
      ":)|||Its不存在于词向量中\n",
      "Graduate不存在于词向量中\n",
      ":proud:|||The不存在于词向量中\n",
      "car's不存在于词向量中\n",
      "...|||Yep.不存在于词向量中\n",
      "like).不存在于词向量中\n",
      "recommendations,不存在于词向量中\n",
      "bright.不存在于词向量中\n",
      "trades.不存在于词向量中\n",
      "(soccer)不存在于词向量中\n",
      "Hip-Hop不存在于词向量中\n",
      ":(...不存在于词向量中\n",
      "County,不存在于词向量中\n",
      "a...|||Hmm,不存在于词向量中\n",
      "BUT...不存在于词向量中\n",
      "ISN'T不存在于词向量中\n",
      "reference?不存在于词向量中\n",
      "related)不存在于词向量中\n",
      "S?不存在于词向量中\n",
      "FMK:不存在于词向量中\n",
      "Allyrah不存在于词向量中\n",
      "is...|||Oh,不存在于词向量中\n",
      "Dog,不存在于词向量中\n",
      "cookies?不存在于词向量中\n",
      "character)不存在于词向量中\n",
      "dom...不存在于词向量中\n",
      "to...|||Yep,不存在于词向量中\n",
      "overjoyed不存在于词向量中\n",
      "wanted...|||I不存在于词向量中\n",
      "blues.不存在于词向量中\n",
      "Dizzy不存在于词向量中\n",
      "really...|||Thank不存在于词向量中\n",
      "cannabis.不存在于词向量中\n",
      "weed?不存在于词向量中\n",
      "graphics.不存在于词向量中\n",
      "remembered.不存在于词向量中\n",
      "begin...不存在于词向量中\n",
      "EXXP不存在于词向量中\n",
      "click,不存在于词向量中\n",
      "fifteen,不存在于词向量中\n",
      "coding,不存在于词向量中\n",
      "posts)不存在于词向量中\n",
      "types..不存在于词向量中\n",
      "Si/Ne.不存在于词向量中\n",
      "Awwww不存在于词向量中\n",
      "figure...|||I不存在于词向量中\n",
      "even...|||I've不存在于词向量中\n",
      "easy...|||I不存在于词向量中\n",
      "for...|||Just不存在于词向量中\n",
      "Carson不存在于词向量中\n",
      "shortly,不存在于词向量中\n",
      "bow.不存在于词向量中\n",
      "Victory不存在于词向量中\n",
      "Mormon,不存在于词向量中\n",
      "yogurt,不存在于词向量中\n",
      "myself...|||I'm不存在于词向量中\n",
      "meals.不存在于词向量中\n",
      "grown,不存在于词向量中\n",
      "face).不存在于词向量中\n",
      "vast,不存在于词向量中\n",
      "proof?不存在于词向量中\n",
      "Beliefs不存在于词向量中\n",
      "cure.不存在于词向量中\n",
      "openness,不存在于词向量中\n",
      "not...|||There不存在于词向量中\n",
      "remains,不存在于词向量中\n",
      "British,不存在于词向量中\n",
      "males)不存在于词向量中\n",
      "distress,不存在于词向量中\n",
      "scars,不存在于词向量中\n",
      "WOW,不存在于词向量中\n",
      "Swift.不存在于词向量中\n",
      "overzealous不存在于词向量中\n",
      "achievement.不存在于词向量中\n",
      "Boom不存在于词向量中\n",
      "torture,不存在于词向量中\n",
      "them??不存在于词向量中\n",
      "paramedic不存在于词向量中\n",
      "Supernatural,不存在于词向量中\n",
      "started?不存在于词向量中\n",
      "Effect,不存在于词向量中\n",
      "I'm...|||Don't不存在于词向量中\n",
      "Accurate不存在于词向量中\n",
      "that....|||I'm不存在于词向量中\n",
      "benefit,不存在于词向量中\n",
      "(rarely不存在于词向量中\n",
      "?,不存在于词向量中\n",
      "Bears不存在于词向量中\n",
      "(went不存在于词向量中\n",
      "exist...不存在于词向量中\n",
      "speechless.不存在于词向量中\n",
      "become?不存在于词向量中\n",
      "Diary不存在于词向量中\n",
      "Wand:不存在于词向量中\n",
      "Fi-user,不存在于词向量中\n",
      "(given不存在于词向量中\n",
      "3s,不存在于词向量中\n",
      "Parade不存在于词向量中\n",
      "institution.不存在于词向量中\n",
      "citizens.不存在于词向量中\n",
      "all...|||My不存在于词向量中\n",
      "God.|||I不存在于词向量中\n",
      "5x不存在于词向量中\n",
      "avoidance,不存在于词向量中\n",
      "nicknames.不存在于词向量中\n",
      "cells,不存在于词向量中\n",
      "Croft不存在于词向量中\n",
      "on|||I不存在于词向量中\n",
      "Zuko不存在于词向量中\n",
      "'Alright,不存在于词向量中\n",
      "dissonance.不存在于词向量中\n",
      "sweet...不存在于词向量中\n",
      "general...|||I不存在于词向量中\n",
      "this...|||In不存在于词向量中\n",
      "perceived,不存在于词向量中\n",
      "values...|||I不存在于词向量中\n",
      "Conclusion:不存在于词向量中\n",
      "cups.不存在于词向量中\n",
      "Azrael不存在于词向量中\n",
      "Husband:不存在于词向量中\n",
      "what/who不存在于词向量中\n",
      "...|||Was不存在于词向量中\n",
      "the...|||She不存在于词向量中\n",
      "ESxP.不存在于词向量中\n",
      "has...|||It不存在于词向量中\n",
      "Mode.不存在于词向量中\n",
      "diagrams,不存在于词向量中\n",
      "removed,不存在于词向量中\n",
      "player?不存在于词向量中\n",
      "Daphne不存在于词向量中\n",
      "Loads不存在于词向量中\n",
      "thirties.不存在于词向量中\n",
      "hearted,不存在于词向量中\n",
      "'she不存在于词向量中\n",
      "stream.不存在于词向量中\n",
      "tied.不存在于词向量中\n",
      "Rotten不存在于词向量中\n",
      "JRPGs不存在于词向量中\n",
      "of...|||So,不存在于词向量中\n",
      "before..不存在于词向量中\n",
      "years...|||I'm不存在于词向量中\n",
      "Herman不存在于词向量中\n",
      "breakup?不存在于词向量中\n",
      "other...|||Hi不存在于词向量中\n",
      "am...|||You不存在于词向量中\n",
      "purse.不存在于词向量中\n",
      "had...|||The不存在于词向量中\n",
      "mmm.不存在于词向量中\n",
      "one...I不存在于词向量中\n",
      "got?不存在于词向量中\n",
      "NBC不存在于词向量中\n",
      "stylish.不存在于词向量中\n",
      "positive...|||I不存在于词向量中\n",
      "Okay...不存在于词向量中\n",
      "Te...不存在于词向量中\n",
      "interesting..不存在于词向量中\n",
      "forgiveness.不存在于词向量中\n",
      "'She不存在于词向量中\n",
      "posted...不存在于词向量中\n",
      "btw...不存在于词向量中\n",
      "Nature:不存在于词向量中\n",
      "Realistic不存在于词向量中\n",
      "forgiven.不存在于词向量中\n",
      "profession?不存在于词向量中\n",
      "resurrected.不存在于词向量中\n",
      "right-handed.不存在于词向量中\n",
      "when...|||I've不存在于词向量中\n",
      "procreate,不存在于词向量中\n",
      "because...'不存在于词向量中\n",
      "'do'不存在于词向量中\n",
      "'is不存在于词向量中\n",
      "ENOUGH不存在于词向量中\n",
      "SLEEP不存在于词向量中\n",
      "important)不存在于词向量中\n",
      "swim,不存在于词向量中\n",
      "satisfaction,不存在于词向量中\n",
      "crafting,不存在于词向量中\n",
      "androgynous.不存在于词向量中\n",
      "Up:不存在于词向量中\n",
      "together)不存在于词向量中\n",
      "Love:不存在于词向量中\n",
      "server,不存在于词向量中\n",
      ":crazy:|||The不存在于词向量中\n",
      "throughout,不存在于词向量中\n",
      "Godzilla不存在于词向量中\n",
      "fat?不存在于词向量中\n",
      "toe.不存在于词向量中\n",
      "Charlie,不存在于词向量中\n",
      "fortune.不存在于词向量中\n",
      "Machiavellian不存在于词向量中\n",
      "mins.不存在于词向量中\n",
      "with...|||People不存在于词向量中\n",
      "portray,不存在于词向量中\n",
      "display.不存在于词向量中\n",
      "south.不存在于词向量中\n",
      "favorites?不存在于词向量中\n",
      "Overwatch不存在于词向量中\n",
      "bs,不存在于词向量中\n",
      "(soft不存在于词向量中\n",
      "wound.不存在于词向量中\n",
      "friendly...不存在于词向量中\n",
      "I...|||Also不存在于词向量中\n",
      "on....不存在于词向量中\n",
      "ideas.|||I不存在于词向量中\n",
      "with...|||Haha,不存在于词向量中\n",
      "tho.|||I不存在于词向量中\n",
      "Paranoia不存在于词向量中\n",
      "altered.不存在于词向量中\n",
      "autobiography.不存在于词向量中\n",
      "Hahah,不存在于词向量中\n",
      "NP's不存在于词向量中\n",
      "(forgive不存在于词向量中\n",
      "4...不存在于词向量中\n",
      "extreme...不存在于词向量中\n",
      "Eg.不存在于词向量中\n",
      "Star.不存在于词向量中\n",
      "Identity:不存在于词向量中\n",
      "overnight,不存在于词向量中\n",
      "information.|||I不存在于词向量中\n",
      "Importance不存在于词向量中\n",
      "backfires不存在于词向量中\n",
      "those...|||My不存在于词向量中\n",
      "Qualities不存在于词向量中\n",
      "Fools不存在于词向量中\n",
      "improved,不存在于词向量中\n",
      "Sign:不存在于词向量中\n",
      "noon.不存在于词向量中\n",
      "Pascal不存在于词向量中\n",
      "work/life不存在于词向量中\n",
      "resolutions.不存在于词向量中\n",
      "hours).不存在于词向量中\n",
      ":(|||My不存在于词向量中\n",
      "Enthusiastic不存在于词向量中\n",
      "of...|||Oh,不存在于词向量中\n",
      "conventions,不存在于词向量中\n",
      "staff,不存在于词向量中\n",
      "RPG's,不存在于词向量中\n",
      "golf,不存在于词向量中\n",
      "outspoken.不存在于词向量中\n",
      "Appalachian不存在于词向量中\n",
      "Vermont不存在于词向量中\n",
      "Quartet不存在于词向量中\n",
      "(ENFP),不存在于词向量中\n",
      "Why's不存在于词向量中\n",
      "Psyche不存在于词向量中\n",
      "Aqua不存在于词向量中\n",
      "nervousness,不存在于词向量中\n",
      "Nell不存在于词向量中\n",
      "announces不存在于词向量中\n",
      "(a.k.a.不存在于词向量中\n",
      "decision-making.不存在于词向量中\n",
      "INFJs:不存在于词向量中\n",
      "it's...|||That不存在于词向量中\n",
      "grave.不存在于词向量中\n",
      "srsly.不存在于词向量中\n",
      "reddit.不存在于词向量中\n",
      "rants.不存在于词向量中\n",
      "...|||lol不存在于词向量中\n",
      "troublemaker.不存在于词向量中\n",
      "gay?不存在于词向量中\n",
      "you.|||Yes,不存在于词向量中\n",
      "me.|||How不存在于词向量中\n",
      "Gollum不存在于词向量中\n",
      "what...|||It不存在于词向量中\n",
      "(okay不存在于词向量中\n",
      "Pacifist不存在于词向量中\n",
      "financially,不存在于词向量中\n",
      "up.|||So不存在于词向量中\n",
      "mushy,不存在于词向量中\n",
      "types.|||Not不存在于词向量中\n",
      "left-handed,不存在于词向量中\n",
      "lefty.不存在于词向量中\n",
      "behavior...|||I不存在于词向量中\n",
      "Extrovert,不存在于词向量中\n",
      "iN不存在于词向量中\n",
      "Spy不存在于词向量中\n",
      "wheel.不存在于词向量中\n",
      "labor.不存在于词向量中\n",
      "Hairy不存在于词向量中\n",
      "appear,不存在于词向量中\n",
      "Enjoy.不存在于词向量中\n",
      "unfulfilling.不存在于词向量中\n",
      "Contending不存在于词向量中\n",
      "Cobain,不存在于词向量中\n",
      "Ali不存在于词向量中\n",
      "TEMPERAMENT:不存在于词向量中\n",
      "Initiating不存在于词向量中\n",
      "Counselors不存在于词向量中\n",
      "'at不存在于词向量中\n",
      "you...|||And不存在于词向量中\n",
      "'think'不存在于词向量中\n",
      "internet.|||I不存在于词向量中\n",
      "me.|||Why不存在于词向量中\n",
      "Bridge不存在于词向量中\n",
      "Marry-不存在于词向量中\n",
      "Bed-不存在于词向量中\n",
      "Fall.不存在于词向量中\n",
      "FePa不存在于词向量中\n",
      "shortly.不存在于词向量中\n",
      "hide,不存在于词向量中\n",
      "baffled.不存在于词向量中\n",
      "life?|||I不存在于词向量中\n",
      "berate不存在于词向量中\n",
      "Lean不存在于词向量中\n",
      "expenses.不存在于词向量中\n",
      "zodiac.不存在于词向量中\n",
      "disciplined,不存在于词向量中\n",
      "chilling.不存在于词向量中\n",
      "right.'不存在于词向量中\n",
      "preschool,不存在于词向量中\n",
      "their...|||That不存在于词向量中\n",
      "INTERACTIONS不存在于词向量中\n",
      "BETWEEN不存在于词向量中\n",
      "Version)不存在于词向量中\n",
      "engine,不存在于词向量中\n",
      "astronomer,不存在于词向量中\n",
      "Don鈥檛不存在于词向量中\n",
      "Artsy不存在于词向量中\n",
      "Pisces,不存在于词向量中\n",
      "Echoes不存在于词向量中\n",
      "not...|||For不存在于词向量中\n",
      "?????不存在于词向量中\n",
      "NFJ,不存在于词向量中\n",
      "Extroverts.不存在于词向量中\n",
      "uncreative.不存在于词向量中\n",
      "ENTP/INTP不存在于词向量中\n",
      "were?不存在于词向量中\n",
      "Lateralus不存在于词向量中\n",
      "(okay,不存在于词向量中\n",
      "Uhm...不存在于词向量中\n",
      "ESTP!不存在于词向量中\n",
      "your...|||Well不存在于词向量中\n",
      "DM不存在于词向量中\n",
      "awesome)不存在于词向量中\n",
      "WOMEN不存在于词向量中\n",
      "Squidward不存在于词向量中\n",
      "and...|||Pretty不存在于词向量中\n",
      "psychopath,不存在于词向量中\n",
      "suffer,不存在于词向量中\n",
      "scratch,不存在于词向量中\n",
      "hours...|||I不存在于词向量中\n",
      "you're...|||It不存在于词向量中\n",
      "betrayed,不存在于词向量中\n",
      "I...|||INFP不存在于词向量中\n",
      "seem...|||I'm不存在于词向量中\n",
      "Thatcher不存在于词向量中\n",
      "-...|||You不存在于词向量中\n",
      "(sometimes)不存在于词向量中\n",
      "ISxPs不存在于词向量中\n",
      "know...|||It's不存在于词向量中\n",
      "afterwards?不存在于词向量中\n",
      "Galaxy,不存在于词向量中\n",
      "immortal,不存在于词向量中\n",
      "interesting...'不存在于词向量中\n",
      "though.|||So不存在于词向量中\n",
      "vicious.不存在于词向量中\n",
      "(ha不存在于词向量中\n",
      "fussy,不存在于词向量中\n",
      "Gibson,不存在于词向量中\n",
      "lol|||I've不存在于词向量中\n",
      "Trump:不存在于词向量中\n",
      "hunger.不存在于词向量中\n",
      "protein,不存在于词向量中\n",
      "leaves.不存在于词向量中\n",
      "ice.不存在于词向量中\n",
      "STD不存在于词向量中\n",
      "delusional,不存在于词向量中\n",
      "self-consciousness.不存在于词向量中\n",
      "as...|||How不存在于词向量中\n",
      "Thompson,不存在于词向量中\n",
      "as...|||Yes,不存在于词向量中\n",
      "Fears不存在于词向量中\n",
      "I'mma不存在于词向量中\n",
      "masturbation,不存在于词向量中\n",
      "were...|||This不存在于词向量中\n",
      "US?不存在于词向量中\n",
      "Direct不存在于词向量中\n",
      "OMFG不存在于词向量中\n",
      "Laptop不存在于词向量中\n",
      "Finance不存在于词向量中\n",
      "infiltrating不存在于词向量中\n",
      "Smash不存在于词向量中\n",
      "hotel.不存在于词向量中\n",
      "headphones.不存在于词向量中\n",
      "<insert不存在于词向量中\n",
      "at...|||Thanks不存在于词向量中\n",
      "way|||I不存在于词向量中\n",
      "know...|||Well不存在于词向量中\n",
      "so...|||In不存在于词向量中\n",
      "Williams.不存在于词向量中\n",
      "Emotions.不存在于词向量中\n",
      "Musk不存在于词向量中\n",
      "Sgt.不存在于词向量中\n",
      "associations,不存在于词向量中\n",
      "Pterodactyl不存在于词向量中\n",
      "will.|||I不存在于词向量中\n",
      "'ISFJ不存在于词向量中\n",
      "Fi-Se不存在于词向量中\n",
      "turns.不存在于词向量中\n",
      "Oklahoma不存在于词向量中\n",
      "all|||I不存在于词向量中\n",
      "have...|||So不存在于词向量中\n",
      "partying,不存在于词向量中\n",
      "it.|||Dear不存在于词向量中\n",
      "time.)不存在于词向量中\n",
      "up....不存在于词向量中\n",
      "Naughty不存在于词向量中\n",
      "power...|||I不存在于词向量中\n",
      "I'ma不存在于词向量中\n",
      "how...不存在于词向量中\n",
      "forests,不存在于词向量中\n",
      "tolerable,不存在于词向量中\n",
      "Everything,不存在于词向量中\n",
      "dignity.不存在于词向量中\n",
      "home),不存在于词向量中\n",
      ":)|||There's不存在于词向量中\n",
      "is....|||I不存在于词向量中\n",
      "Visited不存在于词向量中\n",
      "phrasing.不存在于词向量中\n",
      "threads?不存在于词向量中\n",
      "innovation.不存在于词向量中\n",
      "BRO不存在于词向量中\n",
      "NJ,不存在于词向量中\n",
      "always?不存在于词向量中\n",
      "Cover不存在于词向量中\n",
      "Zoo不存在于词向量中\n",
      "Grocery不存在于词向量中\n",
      "Lot's不存在于词向量中\n",
      "(After不存在于词向量中\n",
      "'Two不存在于词向量中\n",
      "Completed不存在于词向量中\n",
      "weirdo,不存在于词向量中\n",
      "T...不存在于词向量中\n",
      "Zach不存在于词向量中\n",
      "flirtation.不存在于词向量中\n",
      "attaching不存在于词向量中\n",
      "Morrowind不存在于词向量中\n",
      "Dot不存在于词向量中\n",
      "see/hear不存在于词向量中\n",
      "Cocky不存在于词向量中\n",
      "discouraged.不存在于词向量中\n",
      "giggling.不存在于词向量中\n",
      "yours...不存在于词向量中\n",
      "rubik's不存在于词向量中\n",
      "cologne,不存在于词向量中\n",
      "it?|||What不存在于词向量中\n",
      "punished.不存在于词向量中\n",
      "Chaotic.不存在于词向量中\n",
      "Calls不存在于词向量中\n",
      "excess.不存在于词向量中\n",
      "minimalist.不存在于词向量中\n",
      "fishing.不存在于词向量中\n",
      "nothing.|||I不存在于词向量中\n",
      "Baptist,不存在于词向量中\n",
      "Xmas不存在于词向量中\n",
      "As...|||I'm不存在于词向量中\n",
      "FACE不存在于词向量中\n",
      "haha|||Oh不存在于词向量中\n",
      "geez,不存在于词向量中\n",
      "5/5不存在于词向量中\n",
      "ER不存在于词向量中\n",
      "Joined不存在于词向量中\n",
      "Hypothetically,不存在于词向量中\n",
      "really...|||If不存在于词向量中\n",
      "a.k.a不存在于词向量中\n",
      "Enneagram's不存在于词向量中\n",
      "Boobs不存在于词向量中\n",
      "cruelty.不存在于词向量中\n",
      "million.不存在于词向量中\n",
      "'just'不存在于词向量中\n",
      "Teddy,不存在于词向量中\n",
      "liked?不存在于词向量中\n",
      "Bozo不存在于词向量中\n",
      "Homer不存在于词向量中\n",
      "dirt.不存在于词向量中\n",
      "warned,不存在于词向量中\n",
      "and...|||lol不存在于词向量中\n",
      "Survey不存在于词向量中\n",
      "Te...|||I不存在于词向量中\n",
      "fools.不存在于词向量中\n",
      "binary.不存在于词向量中\n",
      "that...|||Hi不存在于词向量中\n",
      "better.|||I'm不存在于词向量中\n",
      "person....不存在于词向量中\n",
      "IJ不存在于词向量中\n",
      "not...|||We不存在于词向量中\n",
      "man'不存在于词向量中\n",
      "Terraria,不存在于词向量中\n",
      "Ouran不存在于词向量中\n",
      "Batman:不存在于词向量中\n",
      "application,不存在于词向量中\n",
      ":DD不存在于词向量中\n",
      "employment.不存在于词向量中\n",
      "unhappiness,不存在于词向量中\n",
      "SC2不存在于词向量中\n",
      "Stereotypical不存在于词向量中\n",
      "prick,不存在于词向量中\n",
      "haters.不存在于词向量中\n",
      "50,000不存在于词向量中\n",
      "we...|||I've不存在于词向量中\n",
      "nicht不存在于词向量中\n",
      "Paintings不存在于词向量中\n",
      "SP:不存在于词向量中\n",
      ":confused:.不存在于词向量中\n",
      "Brock不存在于词向量中\n",
      "huh?|||I不存在于词向量中\n",
      "Nikita不存在于词向量中\n",
      "Lip不存在于词向量中\n",
      "alone...|||I不存在于词向量中\n",
      "notice?不存在于词向量中\n",
      "in...|||Are不存在于词向量中\n",
      "spread.不存在于词向量中\n",
      "dollars,不存在于词向量中\n",
      "stackings.不存在于词向量中\n",
      "Bizarre不存在于词向量中\n",
      "wired.不存在于词向量中\n",
      "always.|||I不存在于词向量中\n",
      "'Perhaps不存在于词向量中\n",
      "moral...|||I不存在于词向量中\n",
      "resource.不存在于词向量中\n",
      "boyfriends.不存在于词向量中\n",
      "Ah.不存在于词向量中\n",
      "EVERYBODY不存在于词向量中\n",
      "your...|||One不存在于词向量中\n",
      "behind?不存在于词向量中\n",
      "areas...不存在于词向量中\n",
      "definition?不存在于词向量中\n",
      "Jean-Paul不存在于词向量中\n",
      "magazine.不存在于词向量中\n",
      "cover.不存在于词向量中\n",
      "for...|||By不存在于词向量中\n",
      "it...|||Don't不存在于词向量中\n",
      "me.|||I'll不存在于词向量中\n",
      "personality)不存在于词向量中\n",
      "divine.不存在于词向量中\n",
      "Girls.不存在于词向量中\n",
      "hood,不存在于词向量中\n",
      "hoe,不存在于词向量中\n",
      "Switzerland.不存在于词向量中\n",
      "Millions不存在于词向量中\n",
      "WHAT?不存在于词向量中\n",
      "ENFP/ISTJ不存在于词向量中\n",
      "craziness.不存在于词向量中\n",
      "catalyst.不存在于词向量中\n",
      "true.|||I've不存在于词向量中\n",
      "protector.不存在于词向量中\n",
      "companion,不存在于词向量中\n",
      "easier...不存在于词向量中\n",
      "Fiber不存在于词向量中\n",
      "INFPs).不存在于词向量中\n",
      "I...|||Ha,不存在于词向量中\n",
      "gushing,不存在于词向量中\n",
      "fresh,不存在于词向量中\n",
      "(sorry)不存在于词向量中\n",
      "away..不存在于词向量中\n",
      "curious..不存在于词向量中\n",
      "Fast?不存在于词向量中\n",
      "common?不存在于词向量中\n",
      "be...|||I'd不存在于词向量中\n",
      "Idk.不存在于词向量中\n",
      "8.)不存在于词向量中\n",
      "collective,不存在于词向量中\n",
      "Disk不存在于词向量中\n",
      "made...|||The不存在于词向量中\n",
      "Mac,不存在于词向量中\n",
      "for...|||In不存在于词向量中\n",
      "centers,不存在于词向量中\n",
      "misinterpreted.不存在于词向量中\n",
      "attacked.不存在于词向量中\n",
      "dubstep,不存在于词向量中\n",
      "Greece.不存在于词向量中\n",
      "one...|||My不存在于词向量中\n",
      "Axis不存在于词向量中\n",
      "Butterfly,不存在于词向量中\n",
      "halfway.不存在于词向量中\n",
      "sexism.不存在于词向量中\n",
      "this...|||Well不存在于词向量中\n",
      "Eureka不存在于词向量中\n",
      "Hobo不存在于词向量中\n",
      "with....|||I不存在于词向量中\n",
      "neurotic,不存在于词向量中\n",
      "Lawrence,不存在于词向量中\n",
      "fun..不存在于词向量中\n",
      "Caulfield不存在于词向量中\n",
      "Tree,不存在于词向量中\n",
      "Burden不存在于词向量中\n",
      "tutor,不存在于词向量中\n",
      "hostile.不存在于词向量中\n",
      "favorable.不存在于词向量中\n",
      "Sums不存在于词向量中\n",
      "mind....不存在于词向量中\n",
      "Plegmatic不存在于词向量中\n",
      "daughters,不存在于词向量中\n",
      "time...|||The不存在于词向量中\n",
      "hunch,不存在于词向量中\n",
      "C'mon,不存在于词向量中\n",
      "vicious,不存在于词向量中\n",
      "cold)不存在于词向量中\n",
      "the...|||Thanks!不存在于词向量中\n",
      "spontaneously,不存在于词向量中\n",
      "Dunham不存在于词向量中\n",
      "good.|||I'm不存在于词向量中\n",
      "Intelligent,不存在于词向量中\n",
      "Trainspotting不存在于词向量中\n",
      "explanations.不存在于词向量中\n",
      "my...|||Do不存在于词向量中\n",
      "it's...|||What不存在于词向量中\n",
      "takes...|||I不存在于词向量中\n",
      "writes,不存在于词向量中\n",
      "sometimes.|||I'm不存在于词向量中\n",
      "Forums不存在于词向量中\n",
      "am/was不存在于词向量中\n",
      "-.-)不存在于词向量中\n",
      "humor...|||I不存在于词向量中\n",
      "reversed.不存在于词向量中\n",
      ":ninja:|||I不存在于词向量中\n",
      "Arts.不存在于词向量中\n",
      "drowning,不存在于词向量中\n",
      "shifts.不存在于词向量中\n",
      "Supporting不存在于词向量中\n",
      "cat.|||I不存在于词向量中\n",
      "Memento不存在于词向量中\n",
      "Negotiator不存在于词向量中\n",
      "Kid,不存在于词向量中\n",
      "xSTP.不存在于词向量中\n",
      "me.|||Not不存在于词向量中\n",
      "Ranger不存在于词向量中\n",
      "Bridges不存在于词向量中\n",
      "THAN不存在于词向量中\n",
      "Seymour不存在于词向量中\n",
      "they...|||A不存在于词向量中\n",
      "Associates不存在于词向量中\n",
      "Kiersey's不存在于词向量中\n",
      "hierarchy.不存在于词向量中\n",
      "jam,不存在于词向量中\n",
      "'deep不存在于词向量中\n",
      "...|||Welcome不存在于词向量中\n",
      "detachment,不存在于词向量中\n",
      "younger...不存在于词向量中\n",
      "bake.不存在于词向量中\n",
      "Faces不存在于词向量中\n",
      "Ni-user不存在于词向量中\n",
      "hierarchy,不存在于词向量中\n",
      "Tucker不存在于词向量中\n",
      "Kidding,不存在于词向量中\n",
      "inadequate,不存在于词向量中\n",
      "complaints.不存在于词向量中\n",
      "regards,不存在于词向量中\n",
      "Something's不存在于词向量中\n",
      "The...|||This不存在于词向量中\n",
      "Tribalism不存在于词向量中\n",
      "Zack不存在于词向量中\n",
      "Assessment不存在于词向量中\n",
      "and...|||-不存在于词向量中\n",
      "Selfishness不存在于词向量中\n",
      ":...|||I不存在于词向量中\n",
      "perceptions,不存在于词向量中\n",
      "the...|||Being不存在于词向量中\n",
      "child.|||I不存在于词向量中\n",
      "good,...|||I不存在于词向量中\n",
      "Sade不存在于词向量中\n",
      "something,...|||I不存在于词向量中\n",
      "Stephen,不存在于词向量中\n",
      ":)|||how不存在于词向量中\n",
      "allowed):不存在于词向量中\n",
      "not...|||It不存在于词向量中\n",
      "SM-G360P不存在于词向量中\n",
      "edit.不存在于词向量中\n",
      "idk...不存在于词向量中\n",
      "Grim不存在于词向量中\n",
      "promises.不存在于词向量中\n",
      "asking...不存在于词向量中\n",
      "Curry不存在于词向量中\n",
      "Archer不存在于词向量中\n",
      "HEY不存在于词向量中\n",
      "test's不存在于词向量中\n",
      "Aquinas不存在于词向量中\n",
      "Portland,不存在于词向量中\n",
      "Descartes.不存在于词向量中\n",
      "future.|||I不存在于词向量中\n",
      "60,不存在于词向量中\n",
      "'one不存在于词向量中\n",
      ":tongue:|||Well,不存在于词向量中\n",
      "yourself'不存在于词向量中\n",
      "dear?不存在于词向量中\n",
      "Toby不存在于词向量中\n",
      "Knight:不存在于词向量中\n",
      "ENFP|||My不存在于词向量中\n",
      "continue...|||I不存在于词向量中\n",
      "THESE不存在于词向量中\n",
      "SOUND不存在于词向量中\n",
      "introvert/extrovert不存在于词向量中\n",
      "Stuffed不存在于词向量中\n",
      "liars,不存在于词向量中\n",
      "Otaku不存在于词向量中\n",
      "Rin不存在于词向量中\n",
      "insecure?不存在于词向量中\n",
      "Hardy不存在于词向量中\n",
      "heartbreak,不存在于词向量中\n",
      "quirk,不存在于词向量中\n",
      ":happy:|||If不存在于词向量中\n",
      "dumped.不存在于词向量中\n",
      "wants...|||I不存在于词向量中\n",
      "Formal不存在于词向量中\n",
      "story.|||I不存在于词向量中\n",
      "on'不存在于词向量中\n",
      "imagined.不存在于词向量中\n",
      "Mastodon不存在于词向量中\n",
      "shelter,不存在于词向量中\n",
      "resort,不存在于词向量中\n",
      "NICE不存在于词向量中\n",
      "ICE不存在于词向量中\n",
      "handle...|||I不存在于词向量中\n",
      "temperament?不存在于词向量中\n",
      "death.|||I不存在于词向量中\n",
      "sex,...|||I不存在于词向量中\n",
      "breed.不存在于词向量中\n",
      "X-Files不存在于词向量中\n",
      "X-files不存在于词向量中\n",
      "Goodness不存在于词向量中\n",
      "feelings..不存在于词向量中\n",
      "was...|||Haha,不存在于词向量中\n",
      "my...|||Like不存在于词向量中\n",
      "package,不存在于词向量中\n",
      "lock,不存在于词向量中\n",
      "compelling.不存在于词向量中\n",
      "this...|||How不存在于词向量中\n",
      "reading...不存在于词向量中\n",
      "to...|||Lol不存在于词向量中\n",
      "Anime,不存在于词向量中\n",
      "she...|||That's不存在于词向量中\n",
      ",you不存在于词向量中\n",
      "NT?不存在于词向量中\n",
      "that...|||People不存在于词向量中\n",
      "CHOOSE不存在于词向量中\n",
      "right??不存在于词向量中\n",
      "Thick不存在于词向量中\n",
      "'can't不存在于词向量中\n",
      "about...|||It's不存在于词向量中\n",
      "etc.|||I'm不存在于词向量中\n",
      "Bart不存在于词向量中\n",
      "TMTL不存在于词向量中\n",
      "attention.|||I不存在于词向量中\n",
      "you...|||There不存在于词向量中\n",
      "comfortable?不存在于词向量中\n",
      "a...|||Haha不存在于词向量中\n",
      "two...|||I'm不存在于词向量中\n",
      "ESTPs?不存在于词向量中\n",
      "Pocahontas不存在于词向量中\n",
      "type.|||The不存在于词向量中\n",
      ";D)不存在于词向量中\n",
      "dork.不存在于词向量中\n",
      ":)|||INTP不存在于词向量中\n",
      "of...|||Great不存在于词向量中\n",
      "hike,不存在于词向量中\n",
      "R贸s不存在于词向量中\n",
      "Agnostic,不存在于词向量中\n",
      "Pessoa不存在于词向量中\n",
      "Thinks不存在于词向量中\n",
      "dew,不存在于词向量中\n",
      "true/false不存在于词向量中\n",
      "INFJ'不存在于词向量中\n",
      "x3|||I不存在于词向量中\n",
      "fashion?不存在于词向量中\n",
      "disagreement,不存在于词向量中\n",
      "a...|||Ok,不存在于词向量中\n",
      "are...|||Well,不存在于词向量中\n",
      "twist,不存在于词向量中\n",
      "made...|||I'm不存在于词向量中\n",
      "be...|||One不存在于词向量中\n",
      "(Team不存在于词向量中\n",
      "Single.不存在于词向量中\n",
      "ENxx不存在于词向量中\n",
      "is,...|||I'm不存在于词向量中\n",
      "INXX.不存在于词向量中\n",
      "INCREDIBLY不存在于词向量中\n",
      "Lit不存在于词向量中\n",
      "mission.不存在于词向量中\n",
      "myself.|||My不存在于词向量中\n",
      "avatar.|||I不存在于词向量中\n",
      "is...|||Hello不存在于词向量中\n",
      "--...|||I不存在于词向量中\n",
      "FFVII不存在于词向量中\n",
      "Sera不存在于词向量中\n",
      "trauma.不存在于词向量中\n",
      "tennis.不存在于词向量中\n",
      "goods,不存在于词向量中\n",
      "normal...不存在于词向量中\n",
      "LIFE.不存在于词向量中\n",
      "paid.不存在于词向量中\n",
      "my...|||No不存在于词向量中\n",
      "for...|||Oh不存在于词向量中\n",
      "Developing不存在于词向量中\n",
      "more...|||How不存在于词向量中\n",
      "bind.不存在于词向量中\n",
      "Eg不存在于词向量中\n",
      "Republican.不存在于词向量中\n",
      "Certainly,不存在于词向量中\n",
      "beats,不存在于词向量中\n",
      "Remembering不存在于词向量中\n",
      "Albeit不存在于词向量中\n",
      "germs,不存在于词向量中\n",
      "(emotional不存在于词向量中\n",
      "openness.不存在于词向量中\n",
      "an...|||In不存在于词向量中\n",
      "There'd不存在于词向量中\n",
      "point).不存在于词向量中\n",
      "BACK.不存在于词向量中\n",
      "country).不存在于词向量中\n",
      "responses?不存在于词向量中\n",
      "empathize,不存在于词向量中\n",
      "BFF.不存在于词向量中\n",
      "Saved不存在于词向量中\n",
      "juvenile,不存在于词向量中\n",
      "this...|||What不存在于词向量中\n",
      "(ENFJ不存在于词向量中\n",
      "Chip不存在于词向量中\n",
      "Massachusetts不存在于词向量中\n",
      "Family:不存在于词向量中\n",
      "experimentation.不存在于词向量中\n",
      "Rita不存在于词向量中\n",
      "plays,不存在于词向量中\n",
      "7s.不存在于词向量中\n",
      "x|||I不存在于词向量中\n",
      "lows.不存在于词向量中\n",
      "domineering,不存在于词向量中\n",
      "functionality.不存在于词向量中\n",
      "being...|||This不存在于词向量中\n",
      "romantically?不存在于词向量中\n",
      "expectation.不存在于词向量中\n",
      "ASKED不存在于词向量中\n",
      "Indulgence不存在于词向量中\n",
      "commitment?不存在于词向量中\n",
      "be...|||We不存在于词向量中\n",
      "Graficcha不存在于词向量中\n",
      "quite.不存在于词向量中\n",
      "he...|||This不存在于词向量中\n",
      "substance,不存在于词向量中\n",
      "Strengths不存在于词向量中\n",
      "BETTER不存在于词向量中\n",
      "Ni-Fi.不存在于词向量中\n",
      "Brilliant!不存在于词向量中\n",
      "inflexible.不存在于词向量中\n",
      "volunteering,不存在于词向量中\n",
      "generalizing,不存在于词向量中\n",
      "thesis?不存在于词向量中\n",
      "West:不存在于词向量中\n",
      "disrespectful.不存在于词向量中\n",
      "(here不存在于词向量中\n",
      "breeze,不存在于词向量中\n",
      "foreground不存在于词向量中\n",
      "suppose.|||I不存在于词向量中\n",
      "icon.不存在于词向量中\n",
      "Nana不存在于词向量中\n",
      "ExFP,不存在于词向量中\n",
      "from...|||The不存在于词向量中\n",
      "visionary,不存在于词向量中\n",
      "so...|||What不存在于词向量中\n",
      "jest,不存在于词向量中\n",
      "punch.不存在于词向量中\n",
      "aloud.不存在于词向量中\n",
      ":D|||In不存在于词向量中\n",
      "crowded.不存在于词向量中\n",
      "80,不存在于词向量中\n",
      "Idk...不存在于词向量中\n",
      "like...the不存在于词向量中\n",
      "at...|||There不存在于词向量中\n",
      "series!不存在于词向量中\n",
      "TX不存在于词向量中\n",
      "blocked.不存在于词向量中\n",
      "Donx92t不存在于词向量中\n",
      "silences,不存在于词向量中\n",
      "90's.不存在于词向量中\n",
      "Jackson,不存在于词向量中\n",
      "I...|||Totally不存在于词向量中\n",
      "originally,不存在于词向量中\n",
      "prepared,不存在于词向量中\n",
      "Hajime不存在于词向量中\n",
      "snowflake.不存在于词向量中\n",
      "particles,不存在于词向量中\n",
      "6'5不存在于词向量中\n",
      "Lea不存在于词向量中\n",
      "Justice,不存在于词向量中\n",
      "coach.不存在于词向量中\n",
      "perceivers.不存在于词向量中\n",
      "over...|||The不存在于词向量中\n",
      "Tapatalk|||Don't不存在于词向量中\n",
      "do......不存在于词向量中\n",
      "Should've不存在于词向量中\n",
      "Combination不存在于词向量中\n",
      "feel...|||The不存在于词向量中\n",
      "mannerisms.不存在于词向量中\n",
      "exposed.不存在于词向量中\n",
      "Taoist不存在于词向量中\n",
      "Autobiography不存在于词向量中\n",
      "offered,不存在于词向量中\n",
      "FROM不存在于词向量中\n",
      "...|||Ahh,不存在于词向量中\n",
      "which...|||I'm不存在于词向量中\n",
      "Vision不存在于词向量中\n",
      ":p|||This不存在于词向量中\n",
      "Buddhist.不存在于词向量中\n",
      "unproductive.不存在于词向量中\n",
      "Towers不存在于词向量中\n",
      "IIII不存在于词向量中\n",
      "moon?不存在于词向量中\n",
      ":)|||lol不存在于词向量中\n",
      "months..不存在于词向量中\n",
      "hold...|||I不存在于词向量中\n",
      "special...|||I不存在于词向量中\n",
      "for...|||There不存在于词向量中\n",
      "Indie,不存在于词向量中\n",
      "Live,不存在于词向量中\n",
      "extent?不存在于词向量中\n",
      "(Again不存在于词向量中\n",
      "disassemble不存在于词向量中\n",
      "think...|||1.不存在于词向量中\n",
      "betrayal.不存在于词向量中\n",
      "Alison不存在于词向量中\n",
      "Demons不存在于词向量中\n",
      "Lyrics:不存在于词向量中\n",
      "those...|||The不存在于词向量中\n",
      "promotion,不存在于词向量中\n",
      "recommendation,不存在于词向量中\n",
      "Duo不存在于词向量中\n",
      "Open-mindedness不存在于词向量中\n",
      "conventions.不存在于词向量中\n",
      "hun,不存在于词向量中\n",
      "be...|||Do不存在于词向量中\n",
      "Electrical不存在于词向量中\n",
      "Murdock不存在于词向量中\n",
      "Hero.不存在于词向量中\n",
      "Dance,不存在于词向量中\n",
      "mood?不存在于词向量中\n",
      "(look不存在于词向量中\n",
      "Star:不存在于词向量中\n",
      "Princess:不存在于词向量中\n",
      "Soldier:不存在于词向量中\n",
      "Parent:不存在于词向量中\n",
      "Wasting不存在于词向量中\n",
      "indecisiveness,不存在于词向量中\n",
      "Dang,不存在于词向量中\n",
      "(therefore不存在于词向量中\n",
      "do'不存在于词向量中\n",
      "though....不存在于词向量中\n",
      "stuffs.不存在于词向量中\n",
      "my...|||There不存在于词向量中\n",
      "Karamazov不存在于词向量中\n",
      "autopilot.不存在于词向量中\n",
      "xxTJ:不存在于词向量中\n",
      "Ne-dom,不存在于词向量中\n",
      "So...|||You不存在于词向量中\n",
      "runner,不存在于词向量中\n",
      "hand...|||I不存在于词向量中\n",
      "(within不存在于词向量中\n",
      "allergy,不存在于词向量中\n",
      "unbelievable.不存在于词向量中\n",
      "slate.不存在于词向量中\n",
      "Enfp.不存在于词向量中\n",
      "A.A.不存在于词向量中\n",
      "sculpting,不存在于词向量中\n",
      "Story,不存在于词向量中\n",
      "Taxi不存在于词向量中\n",
      "Study:不存在于词向量中\n",
      "Same.不存在于词向量中\n",
      "...|||the不存在于词向量中\n",
      "large...|||I不存在于词向量中\n",
      "Divergent不存在于词向量中\n",
      "hygiene.不存在于词向量中\n",
      "shocking,不存在于词向量中\n",
      "bangs.不存在于词向量中\n",
      "'thanks'不存在于词向量中\n",
      "post.'不存在于词向量中\n",
      "tracks,不存在于词向量中\n",
      "cheated,不存在于词向量中\n",
      "background)不存在于词向量中\n",
      "auxiliary)不存在于词向量中\n",
      "Soul,不存在于词向量中\n",
      "ISTPs?不存在于词向量中\n",
      "great.|||I不存在于词向量中\n",
      "'Great不存在于词向量中\n",
      "laid.不存在于词向量中\n",
      "Dante不存在于词向量中\n",
      "like...|||How不存在于词向量中\n",
      "truthfully.不存在于词向量中\n",
      "out...|||It不存在于词向量中\n",
      "sure),不存在于词向量中\n",
      "Kenya不存在于词向量中\n",
      "(thought不存在于词向量中\n",
      "disagree.|||I不存在于词向量中\n",
      "Nico不存在于词向量中\n",
      "Weight不存在于词向量中\n",
      "life|||I不存在于词向量中\n",
      "cusp.不存在于词向量中\n",
      "Nike不存在于词向量中\n",
      "psychology:不存在于词向量中\n",
      "C#不存在于词向量中\n",
      "500,000不存在于词向量中\n",
      "'Pretty不存在于词向量中\n",
      "CAPS不存在于词向量中\n",
      "Annoying不存在于词向量中\n",
      "GOAT不存在于词向量中\n",
      "enigma.不存在于词向量中\n",
      "IXTJ.不存在于词向量中\n",
      "how...|||When不存在于词向量中\n",
      "INFP麓s不存在于词向量中\n",
      "than...|||I'm不存在于词向量中\n",
      "Cinnamon83不存在于词向量中\n",
      "lurker,不存在于词向量中\n",
      "Women,不存在于词向量中\n",
      "Heaven's不存在于词向量中\n",
      "sentence...不存在于词向量中\n",
      "Split不存在于词向量中\n",
      "Tactical不存在于词向量中\n",
      "separate,不存在于词向量中\n",
      "music|||I不存在于词向量中\n",
      "despise.不存在于词向量中\n",
      "due,不存在于词向量中\n",
      "Engaging不存在于词向量中\n",
      "forum..不存在于词向量中\n",
      "felt...不存在于词向量中\n",
      "life.|||It's不存在于词向量中\n",
      "^^,不存在于词向量中\n",
      "be...|||First不存在于词向量中\n",
      "Rent不存在于词向量中\n",
      "Pleased不存在于词向量中\n",
      "dogy不存在于词向量中\n",
      "villain's不存在于词向量中\n",
      "facade.不存在于词向量中\n",
      "metabolism.不存在于词向量中\n",
      "Iv'e不存在于词向量中\n",
      "God;不存在于词向量中\n",
      "peeps.不存在于词向量中\n",
      "...|||Wow.不存在于词向量中\n",
      "likely.|||I不存在于词向量中\n",
      "HTC不存在于词向量中\n",
      "dependable.不存在于词向量中\n",
      "Contemporary不存在于词向量中\n",
      "Burial不存在于词向量中\n",
      "have...|||How不存在于词向量中\n",
      "But...|||It不存在于词向量中\n",
      "Prefers不存在于词向量中\n",
      "mind).不存在于词向量中\n",
      "aesthetically,不存在于词向量中\n",
      "whack.不存在于词向量中\n",
      "secure,不存在于词向量中\n",
      "What鈥檚不存在于词向量中\n",
      "Legends.不存在于词向量中\n",
      "therapy?不存在于词向量中\n",
      "tripping,不存在于词向量中\n",
      "glorious.不存在于词向量中\n",
      "quality?不存在于词向量中\n",
      "There...|||I不存在于词向量中\n",
      "percentage.不存在于词向量中\n",
      "developer,不存在于词向量中\n",
      "Canadian.不存在于词向量中\n",
      "a...|||Someone不存在于词向量中\n",
      "I...|||1)不存在于词向量中\n",
      "citizen.不存在于词向量中\n",
      "Intp's不存在于词向量中\n",
      "completed,不存在于词向量中\n",
      "ED不存在于词向量中\n",
      "Factors不存在于词向量中\n",
      "I'd...|||In不存在于词向量中\n",
      "leaped不存在于词向量中\n",
      "snake.不存在于词向量中\n",
      ":)|||We're不存在于词向量中\n",
      "Makeup不存在于词向量中\n",
      "Duh.不存在于词向量中\n",
      "Persuasion不存在于词向量中\n",
      "Basics不存在于词向量中\n",
      "(link不存在于词向量中\n",
      "Easygoing不存在于词向量中\n",
      "Psalm不存在于词向量中\n",
      "Crazy.不存在于词向量中\n",
      "boyfriends,不存在于词向量中\n",
      "Home,不存在于词向量中\n",
      "Deficit不存在于词向量中\n",
      "Animal,不存在于词向量中\n",
      "is.|||It's不存在于词向量中\n",
      "it...|||We不存在于词向量中\n",
      "dust,不存在于词向量中\n",
      "(confirmed)不存在于词向量中\n",
      "as...|||Don't不存在于词向量中\n",
      "PICK不存在于词向量中\n",
      "Playful不存在于词向量中\n",
      "a...|||Ya不存在于词向量中\n",
      "Morse不存在于词向量中\n",
      "typo,不存在于词向量中\n",
      "Rationals不存在于词向量中\n",
      "behalf,不存在于词向量中\n",
      "crazy..不存在于词向量中\n",
      "modesty,不存在于词向量中\n",
      "but...|||Yes,不存在于词向量中\n",
      "with...|||Thanks不存在于词向量中\n",
      "2.5%不存在于词向量中\n",
      "Sergei不存在于词向量中\n",
      "experimental,不存在于词向量中\n",
      "visited.不存在于词向量中\n",
      "uses.不存在于词向量中\n",
      "Misery不存在于词向量中\n",
      "Taurus.不存在于词向量中\n",
      "ESFP's.不存在于词向量中\n",
      "much...|||This不存在于词向量中\n",
      "grandma's不存在于词向量中\n",
      "meh...不存在于词向量中\n",
      "painting?不存在于词向量中\n",
      "I...|||Here's不存在于词向量中\n",
      "Stalker不存在于词向量中\n",
      "'wrong'不存在于词向量中\n",
      "Concept不存在于词向量中\n",
      "Slim不存在于词向量中\n",
      "Sold不存在于词向量中\n",
      "skydiving,不存在于词向量中\n",
      "few...|||If不存在于词向量中\n",
      "INTJness不存在于词向量中\n",
      "general),不存在于词向量中\n",
      "me|||I'm不存在于词向量中\n",
      "Artisans不存在于词向量中\n",
      "epiphanies.不存在于词向量中\n",
      "smiley.不存在于词向量中\n",
      "functional.不存在于词向量中\n",
      "kittens,不存在于词向量中\n",
      "know?!不存在于词向量中\n",
      "coast,不存在于词向量中\n",
      "climbs不存在于词向量中\n",
      "be...|||Don't不存在于词向量中\n",
      "entp?不存在于词向量中\n",
      "ESTP..不存在于词向量中\n",
      "Pursuits不存在于词向量中\n",
      "chuckle,不存在于词向量中\n",
      "memory?不存在于词向量中\n",
      "define,不存在于词向量中\n",
      "tangible.不存在于词向量中\n",
      "INFJ..不存在于词向量中\n",
      "XNFJs不存在于词向量中\n",
      "Racism不存在于词向量中\n",
      "you're...|||What不存在于词向量中\n",
      "add)不存在于词向量中\n",
      "improving,不存在于词向量中\n",
      "and...|||Wow,不存在于词向量中\n",
      "cared,不存在于词向量中\n",
      "networks,不存在于词向量中\n",
      "Smaller不存在于词向量中\n",
      "Muay不存在于词向量中\n",
      "Hmmmm不存在于词向量中\n",
      "ENFJs...不存在于词向量中\n",
      "they...不存在于词向量中\n",
      "coordination.不存在于词向量中\n",
      "update?不存在于词向量中\n",
      "proven,不存在于词向量中\n",
      "seventeen,不存在于词向量中\n",
      "No-one不存在于词向量中\n",
      "thesis,不存在于词向量中\n",
      "badassery.不存在于词向量中\n",
      "to...|||These不存在于词向量中\n",
      "editor.不存在于词向量中\n",
      "The...|||The不存在于词向量中\n",
      "(ENTJ不存在于词向量中\n",
      "hippies.不存在于词向量中\n",
      "Sweetie不存在于词向量中\n",
      "run...不存在于词向量中\n",
      "usage,不存在于词向量中\n",
      "again.'不存在于词向量中\n",
      "minds...不存在于词向量中\n",
      "5'8不存在于词向量中\n",
      "his...|||I've不存在于词向量中\n",
      "buff.不存在于词向量中\n",
      "college.|||I不存在于词向量中\n",
      "Jumping不存在于词向量中\n",
      "cant.不存在于词向量中\n",
      "nowadays...不存在于词向量中\n",
      "be...|||Your不存在于词向量中\n",
      "heaps,不存在于词向量中\n",
      "avail.不存在于词向量中\n",
      ";)|||Yeah不存在于词向量中\n",
      "later...|||I不存在于词向量中\n",
      "Tzu不存在于词向量中\n",
      "suburbs,不存在于词向量中\n",
      "I've...'不存在于词向量中\n",
      "Vivian不存在于词向量中\n",
      "do...|||Well不存在于词向量中\n",
      "fearful,不存在于词向量中\n",
      "immaturity,不存在于词向量中\n",
      "ATM.不存在于词向量中\n",
      ":laughing:|||It's不存在于词向量中\n",
      "his,不存在于词向量中\n",
      "Peregrine's不存在于词向量中\n",
      "xxFx不存在于词向量中\n",
      "out....|||I不存在于词向量中\n",
      "ANYTHING.不存在于词向量中\n",
      "shown.不存在于词向量中\n",
      "E1不存在于词向量中\n",
      "niss.不存在于词向量中\n",
      "now....不存在于词向量中\n",
      "book...不存在于词向量中\n",
      "Shyness不存在于词向量中\n",
      "unsettling.不存在于词向量中\n",
      "Manchester不存在于词向量中\n",
      "Thanksgiving,不存在于词向量中\n",
      "Newton,不存在于词向量中\n",
      "themes.不存在于词向量中\n",
      "lasting,不存在于词向量中\n",
      "THAT.不存在于词向量中\n",
      "9s,不存在于词向量中\n",
      "7s,不存在于词向量中\n",
      "pirate.不存在于词向量中\n",
      "Whoa,不存在于词向量中\n",
      "Bulgarian不存在于词向量中\n",
      "feel...|||I've不存在于词向量中\n",
      "hard|||I不存在于词向量中\n",
      "schizophrenia,不存在于词向量中\n",
      "FANDOM不存在于词向量中\n",
      "Kaiba不存在于词向量中\n",
      "(KJV)不存在于词向量中\n",
      "(?).不存在于词向量中\n",
      "Coconut不存在于词向量中\n",
      "Ya'll不存在于词向量中\n",
      "Alice,不存在于词向量中\n",
      "Abrahamic不存在于词向量中\n",
      "NEEDS不存在于词向量中\n",
      "It...|||This不存在于词向量中\n",
      "Accommodation不存在于词向量中\n",
      "psychologically.不存在于词向量中\n",
      "White.不存在于词向量中\n",
      "sins.不存在于词向量中\n",
      "peoples,不存在于词向量中\n",
      "Witty不存在于词向量中\n",
      "Survivor不存在于词向量中\n",
      "Russian.不存在于词向量中\n",
      "supporter,不存在于词向量中\n",
      "typing's不存在于词向量中\n",
      "ringing.不存在于词向量中\n",
      "Dharma不存在于词向量中\n",
      "DB不存在于词向量中\n",
      "...|||Or不存在于词向量中\n",
      "ISTP?|||I不存在于词向量中\n",
      "prick.不存在于词向量中\n",
      "Burr不存在于词向量中\n",
      ":P|||That不存在于词向量中\n",
      "-Have不存在于词向量中\n",
      "eBay不存在于词向量中\n",
      "Violets不存在于词向量中\n",
      "rainbow,不存在于词向量中\n",
      "Jeez.不存在于词向量中\n",
      "Trait不存在于词向量中\n",
      "AI,不存在于词向量中\n",
      "teachings.不存在于词向量中\n",
      "Terminator不存在于词向量中\n",
      "Game.不存在于词向量中\n",
      "breaking,不存在于词向量中\n",
      "Jeb不存在于词向量中\n",
      "ruthless,不存在于词向量中\n",
      "Paul,不存在于词向量中\n",
      "Absolute不存在于词向量中\n",
      "(Seriously不存在于词向量中\n",
      "annoying?不存在于词向量中\n",
      "Wash不存在于词向量中\n",
      "Kara不存在于词向量中\n",
      "software,不存在于词向量中\n",
      "inexperienced.不存在于词向量中\n",
      "(unhealthy不存在于词向量中\n",
      "guessed,不存在于词向量中\n",
      "and...|||Depends不存在于词向量中\n",
      "Diet不存在于词向量中\n",
      "and...|||Does不存在于词向量中\n",
      "Quixote不存在于词向量中\n",
      "'Nope.不存在于词向量中\n",
      "the...|||Which不存在于词向量中\n",
      "contentment,不存在于词向量中\n",
      "sample,不存在于词向量中\n",
      "not?!不存在于词向量中\n",
      "Misfits不存在于词向量中\n",
      "Tyson.不存在于词向量中\n",
      "thoughts.'不存在于词向量中\n",
      "salute不存在于词向量中\n",
      "there?|||I不存在于词向量中\n",
      "ENFPs...|||I不存在于词向量中\n",
      "Fett不存在于词向量中\n",
      "your...不存在于词向量中\n",
      "Corruption不存在于词向量中\n",
      "flavoured不存在于词向量中\n",
      "Kit不存在于词向量中\n",
      "and...|||Nope,不存在于词向量中\n",
      "PROVE不存在于词向量中\n",
      "games...不存在于词向量中\n",
      "pierced,不存在于词向量中\n",
      "Champloo不存在于词向量中\n",
      ":laughing:,不存在于词向量中\n",
      "link?不存在于词向量中\n",
      "nearby,不存在于词向量中\n",
      "bring.不存在于词向量中\n",
      "knowledge)不存在于词向量中\n",
      "Mindless不存在于词向量中\n",
      "BIRTHDAY不存在于词向量中\n",
      "uncool.不存在于词向量中\n",
      "all!)不存在于词向量中\n",
      ":/|||This不存在于词向量中\n",
      "thing|||I不存在于词向量中\n",
      "blame.不存在于词向量中\n",
      "swings,不存在于词向量中\n",
      "Introspection不存在于词向量中\n",
      "Alina不存在于词向量中\n",
      "gifs,不存在于词向量中\n",
      "contacts.不存在于词向量中\n",
      "eyeliner,不存在于词向量中\n",
      "Buckley不存在于词向量中\n",
      "and...|||Wow.不存在于词向量中\n",
      "individualistic,不存在于词向量中\n",
      "giver,不存在于词向量中\n",
      "comments?不存在于词向量中\n",
      "Enjoys不存在于词向量中\n",
      "ENFP..不存在于词向量中\n",
      "house)不存在于词向量中\n",
      "omg.不存在于词向量中\n",
      "po'不存在于词向量中\n",
      "it.|||In不存在于词向量中\n",
      "myth,不存在于词向量中\n",
      "mechanics.不存在于词向量中\n",
      "skies,不存在于词向量中\n",
      "powder,不存在于词向量中\n",
      "flippin'不存在于词向量中\n",
      "Vimeo不存在于词向量中\n",
      "organizations,不存在于词向量中\n",
      "Ni-不存在于词向量中\n",
      "...When不存在于词向量中\n",
      "Drawn不存在于词向量中\n",
      "gone?不存在于词向量中\n",
      "of..不存在于词向量中\n",
      "questionnaire?不存在于词向量中\n",
      "ghost,不存在于词向量中\n",
      "Whichever不存在于词向量中\n",
      "odds.不存在于词向量中\n",
      "I'm...|||Not不存在于词向量中\n",
      "chart,不存在于词向量中\n",
      "spend,不存在于词向量中\n",
      "sexuality?不存在于词向量中\n",
      "'true不存在于词向量中\n",
      "trigger.不存在于词向量中\n",
      "(idk不存在于词向量中\n",
      "IE,不存在于词向量中\n",
      "Miyazaki's不存在于词向量中\n",
      "floors,不存在于词向量中\n",
      "nobody,不存在于词向量中\n",
      "SLOAN不存在于词向量中\n",
      "BCE.不存在于词向量中\n",
      "Riding不存在于词向量中\n",
      "terrible...|||I不存在于词向量中\n",
      "well!|||I不存在于词向量中\n",
      "...|||Now不存在于词向量中\n",
      "being...|||Yes,不存在于词向量中\n",
      "ruler.不存在于词向量中\n",
      "relish,不存在于词向量中\n",
      "IJ's不存在于词向量中\n",
      "emotionality,不存在于词向量中\n",
      "shiny.不存在于词向量中\n",
      "10char|||I不存在于词向量中\n",
      "Biochemistry不存在于词向量中\n",
      "nut.不存在于词向量中\n",
      "shorter.不存在于词向量中\n",
      "lies?不存在于词向量中\n",
      "calming.不存在于词向量中\n",
      "myself,...|||I不存在于词向量中\n",
      "is...|||Yes不存在于词向量中\n",
      "Ni...|||I不存在于词向量中\n",
      "song)不存在于词向量中\n",
      "M&Ms不存在于词向量中\n",
      "me...|||Oh不存在于词向量中\n",
      "studious,不存在于词向量中\n",
      "if...|||Yes,不存在于词向量中\n",
      "tunes.不存在于词向量中\n",
      "War.不存在于词向量中\n",
      "too!)不存在于词向量中\n",
      "sessions,不存在于词向量中\n",
      "amazing|||I不存在于词向量中\n",
      "Him.不存在于词向量中\n",
      "Lance.不存在于词向量中\n",
      "connotation.不存在于词向量中\n",
      "ENTP-INFJ不存在于词向量中\n",
      "Psychoanalysis不存在于词向量中\n",
      "medium,不存在于词向量中\n",
      "surprises,不存在于词向量中\n",
      "Theon不存在于词向量中\n",
      "shoes/sneakers不存在于词向量中\n",
      "ambidextrous,不存在于词向量中\n",
      "Ima不存在于词向量中\n",
      "cameras,不存在于词向量中\n",
      "(note不存在于词向量中\n",
      "guidelines.不存在于词向量中\n",
      "Navel:不存在于词向量中\n",
      "welcome...hope不存在于词向量中\n",
      "Cocteau不存在于词向量中\n",
      "Happy.不存在于词向量中\n",
      "story..不存在于词向量中\n",
      "hazy.不存在于词向量中\n",
      "sidelines,不存在于词向量中\n",
      "Quote:不存在于词向量中\n",
      "Cautious,不存在于词向量中\n",
      "Na不存在于词向量中\n",
      "posture.不存在于词向量中\n",
      "socionics?不存在于词向量中\n",
      "spoken,不存在于词向量中\n",
      "appears,不存在于词向量中\n",
      "unavoidable.不存在于词向量中\n",
      "contemplating.不存在于词向量中\n",
      "bears,不存在于词向量中\n",
      "you.|||That不存在于词向量中\n",
      "water.|||I不存在于词向量中\n",
      "Flow不存在于词向量中\n",
      "youtube)不存在于词向量中\n",
      "Beam不存在于词向量中\n",
      "Epiphone不存在于词向量中\n",
      "Cisco不存在于词向量中\n",
      "plate,不存在于词向量中\n",
      "beard,不存在于词向量中\n",
      "you...|||Hi,不存在于词向量中\n",
      "end.|||I不存在于词向量中\n",
      "Trial不存在于词向量中\n",
      "feeler?不存在于词向量中\n",
      "avoidant.不存在于词向量中\n",
      "As.不存在于词向量中\n",
      "word),不存在于词向量中\n",
      "jeans)不存在于词向量中\n",
      "them...|||I've不存在于词向量中\n",
      "(Some不存在于词向量中\n",
      "I...|||Wow不存在于词向量中\n",
      "muffin,不存在于词向量中\n",
      "like...|||Thanks不存在于词向量中\n",
      "PTSD,不存在于词向量中\n",
      "aware...|||I不存在于词向量中\n",
      "that...I不存在于词向量中\n",
      "Reynolds不存在于词向量中\n",
      "marry,不存在于词向量中\n",
      "people's.不存在于词向量中\n",
      "Sphere不存在于词向量中\n",
      "earth's不存在于词向量中\n",
      "haha|||You不存在于词向量中\n",
      "ESXPs不存在于词向量中\n",
      "Franklin不存在于词向量中\n",
      "Anais不存在于词向量中\n",
      "60's.不存在于词向量中\n",
      "Ching不存在于词向量中\n",
      "Subscale不存在于词向量中\n",
      "Classes不存在于词向量中\n",
      "2|||I不存在于词向量中\n",
      "I.E.不存在于词向量中\n",
      "intellectuals.不存在于词向量中\n",
      "stress...不存在于词向量中\n",
      "CO不存在于词向量中\n",
      "Duly不存在于词向量中\n",
      "active?不存在于词向量中\n",
      "-He不存在于词向量中\n",
      "gotten,不存在于词向量中\n",
      "Eric,不存在于词向量中\n",
      "Kpop不存在于词向量中\n",
      "eight,不存在于词向量中\n",
      "tho?不存在于词向量中\n",
      "*I'm不存在于词向量中\n",
      "Ayumi不存在于词向量中\n",
      "problematic,不存在于词向量中\n",
      "Kathy不存在于词向量中\n",
      "aid.不存在于词向量中\n",
      "Invest不存在于词向量中\n",
      "Relatively不存在于词向量中\n",
      "Society.不存在于词向量中\n",
      "Frances不存在于词向量中\n",
      "nerd?不存在于词向量中\n",
      "Warren不存在于词向量中\n",
      "conviction,不存在于词向量中\n",
      "Response不存在于词向量中\n",
      "Island.不存在于词向量中\n",
      "'Me不存在于词向量中\n",
      "stress)不存在于词向量中\n",
      "editing.不存在于词向量中\n",
      "out.|||This不存在于词向量中\n",
      "shot...不存在于词向量中\n",
      "complaint,不存在于词向量中\n",
      "Tengo不存在于词向量中\n",
      "Island?不存在于词向量中\n",
      "'Let不存在于词向量中\n",
      "happens...不存在于词向量中\n",
      "high.|||I不存在于词向量中\n",
      "...|||my不存在于词向量中\n",
      "democracy,不存在于词向量中\n",
      "Bale不存在于词向量中\n",
      "behavior)不存在于词向量中\n",
      "directs不存在于词向量中\n",
      "unicorn.不存在于词向量中\n",
      "Barbara不存在于词向量中\n",
      "step...|||I不存在于词向量中\n",
      "perceptive.不存在于词向量中\n",
      "without...'不存在于词向量中\n",
      "Inspiring不存在于词向量中\n",
      "Shinji不存在于词向量中\n",
      "day...|||I'm不存在于词向量中\n",
      "who...|||My不存在于词向量中\n",
      "anger...|||I不存在于词向量中\n",
      "HELP不存在于词向量中\n",
      "rapist,不存在于词向量中\n",
      "Heck!不存在于词向量中\n",
      "think...|||That不存在于词向量中\n",
      "-Which不存在于词向量中\n",
      "ghosts.不存在于词向量中\n",
      "released,不存在于词向量中\n",
      "know.....不存在于词向量中\n",
      "Hellsing不存在于词向量中\n",
      "'Haha!不存在于词向量中\n",
      ":tongue:),不存在于词向量中\n",
      "sad...|||I不存在于词向量中\n",
      ":D|||There不存在于词向量中\n",
      "wouldn't,不存在于词向量中\n",
      "on.|||If不存在于词向量中\n",
      "'me'不存在于词向量中\n",
      "ate,不存在于词向量中\n",
      "competitions.不存在于词向量中\n",
      "asshole?不存在于词向量中\n",
      "BF:不存在于词向量中\n",
      "grandma.不存在于词向量中\n",
      "sadistic,不存在于词向量中\n",
      "Comedian不存在于词向量中\n",
      "xSTx不存在于词向量中\n",
      "ENTP=Ne,不存在于词向量中\n",
      "Islands不存在于词向量中\n",
      "Rand's不存在于词向量中\n",
      "weapon.不存在于词向量中\n",
      "scream,不存在于词向量中\n",
      "Arizona,不存在于词向量中\n",
      "soap,不存在于词向量中\n",
      "backs,不存在于词向量中\n",
      "Windblownhair,不存在于词向量中\n",
      "people.|||You不存在于词向量中\n",
      "we...|||What不存在于词向量中\n",
      "Garrett不存在于词向量中\n",
      "more...|||Don't不存在于词向量中\n",
      "Kyo不存在于词向量中\n",
      "Extrovert.不存在于词向量中\n",
      "hopefully.不存在于词向量中\n",
      "utilized不存在于词向量中\n",
      "my...|||Sorry不存在于词向量中\n",
      "farm.不存在于词向量中\n",
      "sunny,不存在于词向量中\n",
      "west,不存在于词向量中\n",
      "life'.不存在于词向量中\n",
      "Number:不存在于词向量中\n",
      "Airplane不存在于词向量中\n",
      "results)不存在于词向量中\n",
      "repeat...不存在于词向量中\n",
      "headaches,不存在于词向量中\n",
      "butthurt.不存在于词向量中\n",
      "chords,不存在于词向量中\n",
      "when...|||Well不存在于词向量中\n",
      "visiting.不存在于词向量中\n",
      "reversed,不存在于词向量中\n",
      "stackings?不存在于词向量中\n",
      "INTJ/INTP不存在于词向量中\n",
      "40's不存在于词向量中\n",
      "Fav不存在于词向量中\n",
      "wish!不存在于词向量中\n",
      "lol|||i不存在于词向量中\n",
      "astrology?不存在于词向量中\n",
      "if...|||Well,不存在于词向量中\n",
      "behaviour?不存在于词向量中\n",
      "Orgasm不存在于词向量中\n",
      "fuel,不存在于词向量中\n",
      "Programming不存在于词向量中\n",
      "lab.不存在于词向量中\n",
      "hum,不存在于词向量中\n",
      "would...|||This不存在于词向量中\n",
      "dyslexia.不存在于词向量中\n",
      "Quarter不存在于词向量中\n",
      "it...|||Dear不存在于词向量中\n",
      "if...|||Just不存在于词向量中\n",
      "want...|||This不存在于词向量中\n",
      "xD,不存在于词向量中\n",
      "Laissez不存在于词向量中\n",
      "like...|||Thank不存在于词向量中\n",
      "intellectual...|||I不存在于词向量中\n",
      "Do.不存在于词向量中\n",
      "SAMSUNG-SM-N910A不存在于词向量中\n",
      "honest?不存在于词向量中\n",
      "Crimson不存在于词向量中\n",
      "venturing不存在于词向量中\n",
      "how...|||The不存在于词向量中\n",
      "mistyped?不存在于词向量中\n",
      "Intellect,不存在于词向量中\n",
      "backpack.不存在于词向量中\n",
      "attractiveness,不存在于词向量中\n",
      "every.不存在于词向量中\n",
      "Wendy's不存在于词向量中\n",
      "what...|||Well,不存在于词向量中\n",
      "journalist,不存在于词向量中\n",
      "Academic不存在于词向量中\n",
      "pretend...|||I不存在于词向量中\n",
      "ENTps不存在于词向量中\n",
      "'New不存在于词向量中\n",
      "rut.不存在于词向量中\n",
      "write...|||I不存在于词向量中\n",
      "Delusion不存在于词向量中\n",
      ":)|||All不存在于词向量中\n",
      "Deschanel不存在于词向量中\n",
      "a...|||Here's不存在于词向量中\n",
      "Rodney不存在于词向量中\n",
      "thing....不存在于词向量中\n",
      "Satanic不存在于词向量中\n",
      "S-type不存在于词向量中\n",
      "like...|||Dear不存在于词向量中\n",
      "Opening不存在于词向量中\n",
      "off|||I不存在于词向量中\n",
      "Chai不存在于词向量中\n",
      "Linguistic不存在于词向量中\n",
      "Naturalist不存在于词向量中\n",
      "Introversion.不存在于词向量中\n",
      "words..不存在于词向量中\n",
      "translation,不存在于词向量中\n",
      "female...不存在于词向量中\n",
      "whould不存在于词向量中\n",
      "rates.不存在于词向量中\n",
      "Strikes不存在于词向量中\n",
      "it.|||Oh不存在于词向量中\n",
      "beginner,不存在于词向量中\n",
      "banter,不存在于词向量中\n",
      "co-worker,不存在于词向量中\n",
      "Bullshit不存在于词向量中\n",
      "Pond不存在于词向量中\n",
      "toy.不存在于词向量中\n",
      "and....不存在于词向量中\n",
      "people...|||It's不存在于词向量中\n",
      "song.|||I不存在于词向量中\n",
      "mothers.不存在于词向量中\n",
      "Would've不存在于词向量中\n",
      "Points不存在于词向量中\n",
      "Madagascar不存在于词向量中\n",
      "classmates.不存在于词向量中\n",
      "embarrassment,不存在于词向量中\n",
      "on...|||Don't不存在于词向量中\n",
      "Warcraft.不存在于词向量中\n",
      "observe.不存在于词向量中\n",
      "puppy,不存在于词向量中\n",
      "Damn.不存在于词向量中\n",
      "me....|||The不存在于词向量中\n",
      "kid)不存在于词向量中\n",
      "Katsuki不存在于词向量中\n",
      "architect.不存在于词向量中\n",
      "glitter.不存在于词向量中\n",
      "significant,不存在于词向量中\n",
      "Tyson不存在于词向量中\n",
      "Petyr不存在于词向量中\n",
      "get...|||You不存在于词向量中\n",
      "talking...不存在于词向量中\n",
      "violence?不存在于词向量中\n",
      "Opposite不存在于词向量中\n",
      "jokes.|||I不存在于词向量中\n",
      "Frollo不存在于词向量中\n",
      "Ernest不存在于词向量中\n",
      "poets,不存在于词向量中\n",
      "Torment不存在于词向量中\n",
      "F1不存在于词向量中\n",
      "me.|||We不存在于词向量中\n",
      "kind)不存在于词向量中\n",
      "IS,不存在于词向量中\n",
      "DOs不存在于词向量中\n",
      "less)不存在于词向量中\n",
      "Blender不存在于词向量中\n",
      "on...|||Thanks不存在于词向量中\n",
      "E2不存在于词向量中\n",
      "Ouija不存在于词向量中\n",
      "alcohol?不存在于词向量中\n",
      "Where?不存在于词向量中\n",
      "soundtrack,不存在于词向量中\n",
      "ball?不存在于词向量中\n",
      "ONCE不存在于词向量中\n",
      "WOW!不存在于词向量中\n",
      "psychedelics.不存在于词向量中\n",
      "Morris不存在于词向量中\n",
      "haircut.不存在于词向量中\n",
      "FYI:不存在于词向量中\n",
      "swings.不存在于词向量中\n",
      "Listened不存在于词向量中\n",
      "A33fw不存在于词向量中\n",
      "Entertainment不存在于词向量中\n",
      "hits.不存在于词向量中\n",
      "crush?不存在于词向量中\n",
      "AROUND不存在于词向量中\n",
      "Crane不存在于词向量中\n",
      "believe...不存在于词向量中\n",
      "(off不存在于词向量中\n",
      "hunger,不存在于词向量中\n",
      "Sir.不存在于词向量中\n",
      "Mastering不存在于词向量中\n",
      "Och不存在于词向量中\n",
      "Arabic,不存在于词向量中\n",
      "thing?|||I不存在于词向量中\n",
      "麓不存在于词向量中\n",
      "鈻不存在于词向量中\n",
      "y'alls不存在于词向量中\n",
      "Lift不存在于词向量中\n",
      "ENFP;不存在于词向量中\n",
      "names...不存在于词向量中\n",
      "SM-J500FN不存在于词向量中\n",
      "as...|||It's不存在于词向量中\n",
      "intelligences.不存在于词向量中\n",
      "I...|||Before不存在于词向量中\n",
      "INFJ/ISTJ不存在于词向量中\n",
      "phrases,不存在于词向量中\n",
      "SINGLE不存在于词向量中\n",
      "alcoholic,不存在于词向量中\n",
      "as...|||Why不存在于词向量中\n",
      "spark.不存在于词向量中\n",
      "bara不存在于词向量中\n",
      "some...|||How不存在于词向量中\n",
      "terror.不存在于词向量中\n",
      "fling.不存在于词向量中\n",
      "(totally不存在于词向量中\n",
      "sharpness不存在于词向量中\n",
      "Dane不存在于词向量中\n",
      "MIND不存在于词向量中\n",
      ":happy:|||Hello,不存在于词向量中\n",
      "yesterday...不存在于词向量中\n",
      "y.不存在于词向量中\n",
      "and...|||Lol不存在于词向量中\n",
      "concur,不存在于词向量中\n",
      "Hot.不存在于词向量中\n",
      "汀掳)不存在于词向量中\n",
      "Peck不存在于词向量中\n",
      "Telegraph不存在于词向量中\n",
      "villain?不存在于词向量中\n",
      "Libra.不存在于词向量中\n",
      "watch?不存在于词向量中\n",
      "you...|||Dear不存在于词向量中\n",
      "Um.不存在于词向量中\n",
      "doesn't?不存在于词向量中\n",
      "Tunes不存在于词向量中\n",
      "eye...|||I不存在于词向量中\n",
      "Clay's不存在于词向量中\n",
      "type?|||I不存在于词向量中\n",
      "Stella不存在于词向量中\n",
      "Amish不存在于词向量中\n",
      "have...|||Dear不存在于词向量中\n",
      "Nines.不存在于词向量中\n",
      "Messed不存在于词向量中\n",
      "pairs.不存在于词向量中\n",
      ":,)不存在于词向量中\n",
      "and...|||Now不存在于词向量中\n",
      "(already不存在于词向量中\n",
      "Vulcan不存在于词向量中\n",
      "'getting不存在于词向量中\n",
      "trucks,不存在于词向量中\n",
      "Is.不存在于词向量中\n",
      "'Also不存在于词向量中\n",
      "Dostoyevsky不存在于词向量中\n",
      "Ideal:不存在于词向量中\n",
      "LSAT不存在于词向量中\n",
      "even...|||Thank不存在于词向量中\n",
      "SPH-M840不存在于词向量中\n",
      "outrun不存在于词向量中\n",
      "Nations不存在于词向量中\n",
      "EVERYBODY'S不存在于词向量中\n",
      "STORY!!!不存在于词向量中\n",
      "somewhere...不存在于词向量中\n",
      "Remains不存在于词向量中\n",
      "PlushWitch不存在于词向量中\n",
      "HIV不存在于词向量中\n",
      "Hunting.不存在于词向量中\n",
      "learn?不存在于词向量中\n",
      "organize,不存在于词向量中\n",
      "(3,不存在于词向量中\n",
      "(4,不存在于词向量中\n",
      "Giants不存在于词向量中\n",
      "peer.不存在于词向量中\n",
      "capital,不存在于词向量中\n",
      ":P|||Greetings不存在于词向量中\n",
      "Tapatalk|||INFP不存在于词向量中\n",
      "another...|||Itachi不存在于词向量中\n",
      "UAE不存在于词向量中\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理的类，生成训练集和测试集\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self._dataSource = config.dataSource\n",
    "        self._stopWordSource = config.stopWordSource  \n",
    "        \n",
    "        self._sequenceLength = config.sequenceLength  # 每条输入的序列处理为定长\n",
    "        self._embeddingSize = config.model.embeddingSize\n",
    "        self._batchSize = config.batchSize\n",
    "        self._rate = config.rate\n",
    "        \n",
    "        self._stopWordDict = {}\n",
    "        \n",
    "        self.trainReviews = []\n",
    "        self.trainLabels = []\n",
    "        \n",
    "        self.evalReviews = []\n",
    "        self.evalLabels = []\n",
    "        \n",
    "        self.wordEmbedding =None\n",
    "        \n",
    "        self.labelList = []\n",
    "        \n",
    "    def _readData(self, filePath):\n",
    "        \"\"\"\n",
    "        从csv文件中读取数据集\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_csv(filePath)\n",
    "        \n",
    "        if self.config.numClasses == 1:\n",
    "            labels = df[\"sentiment\"].tolist()\n",
    "        elif self.config.numClasses > 1:\n",
    "            labels = df[\"type\"].tolist()\n",
    "            \n",
    "        review = df[\"posts\"].tolist()\n",
    "        reviews = [line.strip().split() for line in review]\n",
    "\n",
    "        return reviews, labels\n",
    "    \n",
    "    def _labelToIndex(self, labels, label2idx):\n",
    "        \"\"\"\n",
    "        将标签转换成索引表示\n",
    "        \"\"\"\n",
    "        labelIds = [label2idx[label] for label in labels]\n",
    "        return labelIds\n",
    "    \n",
    "    def _wordToIndex(self, reviews, word2idx):\n",
    "        \"\"\"\n",
    "        将词转换成索引\n",
    "        \"\"\"\n",
    "        reviewIds = [[word2idx.get(item, word2idx[\"UNK\"]) for item in review] for review in reviews]\n",
    "        return reviewIds\n",
    "        \n",
    "    def _genTrainEvalData(self, x, y, word2idx, rate):\n",
    "        \"\"\"\n",
    "        生成训练集和验证集\n",
    "        \"\"\"\n",
    "        reviews = []\n",
    "        for review in x:\n",
    "            if len(review) >= self._sequenceLength:\n",
    "                reviews.append(review[:self._sequenceLength])\n",
    "            else:\n",
    "                reviews.append(review + [word2idx[\"PAD\"]] * (self._sequenceLength - len(review)))\n",
    "            \n",
    "        trainIndex = int(len(x) * rate)\n",
    "        \n",
    "        trainReviews = np.asarray(reviews[:trainIndex], dtype=\"int64\")\n",
    "        trainLabels = np.array(y[:trainIndex], dtype=\"float32\")\n",
    "        \n",
    "        evalReviews = np.asarray(reviews[trainIndex:], dtype=\"int64\")\n",
    "        evalLabels = np.array(y[trainIndex:], dtype=\"float32\")\n",
    "\n",
    "        return trainReviews, trainLabels, evalReviews, evalLabels\n",
    "        \n",
    "    def _genVocabulary(self, reviews, labels):\n",
    "        \"\"\"\n",
    "        生成词向量和词汇-索引映射字典，可以用全数据集\n",
    "        \"\"\"\n",
    "        \n",
    "        allWords = [word for review in reviews for word in review]\n",
    "        \n",
    "        # 去掉停用词\n",
    "        subWords = [word for word in allWords if word not in self.stopWordDict]\n",
    "        \n",
    "        wordCount = Counter(subWords)  # 统计词频\n",
    "        sortWordCount = sorted(wordCount.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 去除低频词\n",
    "        words = [item[0] for item in sortWordCount if item[1] >= 5]\n",
    "        \n",
    "        vocab, wordEmbedding = self._getWordEmbedding(words)\n",
    "        self.wordEmbedding = wordEmbedding\n",
    "        \n",
    "        word2idx = dict(zip(vocab, list(range(len(vocab)))))\n",
    "        \n",
    "        uniqueLabel = list(set(labels))\n",
    "        label2idx = dict(zip(uniqueLabel, list(range(len(uniqueLabel)))))\n",
    "        self.labelList = list(range(len(uniqueLabel)))\n",
    "        \n",
    "        # 将词汇-索引映射表保存为json数据，之后做inference时直接加载来处理数据\n",
    "        with open(\"./wordJson/word2idx.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(word2idx, f)\n",
    "        \n",
    "        with open(\"./wordJson/label2idx.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(label2idx, f)\n",
    "        \n",
    "        return word2idx, label2idx\n",
    "            \n",
    "    def _getWordEmbedding(self, words):\n",
    "        \"\"\"\n",
    "        按照我们的数据集中的单词取出预训练好的word2vec中的词向量\n",
    "        \"\"\"\n",
    "        \n",
    "        wordVec = gensim.models.KeyedVectors.load_word2vec_format(\"./word2Vec.bin\", binary=True)\n",
    "        vocab = []\n",
    "        wordEmbedding = []\n",
    "        \n",
    "        # 添加 \"pad\" 和 \"UNK\", \n",
    "        vocab.append(\"PAD\")\n",
    "        vocab.append(\"UNK\")\n",
    "        wordEmbedding.append(np.zeros(self._embeddingSize))\n",
    "        wordEmbedding.append(np.random.randn(self._embeddingSize))\n",
    "        \n",
    "        for word in words:\n",
    "            try:\n",
    "                vector = wordVec.wv[word]\n",
    "                vocab.append(word)\n",
    "                wordEmbedding.append(vector)\n",
    "            except:\n",
    "                print(word + \"不存在于词向量中\")\n",
    "                \n",
    "        return vocab, np.array(wordEmbedding)\n",
    "    \n",
    "    def _readStopWord(self, stopWordPath):\n",
    "        \"\"\"\n",
    "        读取停用词\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(stopWordPath, \"r\") as f:\n",
    "            stopWords = f.read()\n",
    "            stopWordList = stopWords.splitlines()\n",
    "            # 将停用词用列表的形式生成，之后查找停用词时会比较快\n",
    "            self.stopWordDict = dict(zip(stopWordList, list(range(len(stopWordList)))))\n",
    "            \n",
    "    def dataGen(self):\n",
    "        \"\"\"\n",
    "        初始化训练集和验证集\n",
    "        \"\"\"\n",
    "        \n",
    "        # 初始化停用词\n",
    "        self._readStopWord(self._stopWordSource)\n",
    "        \n",
    "        # 初始化数据集\n",
    "        reviews, labels = self._readData(self._dataSource)\n",
    "        \n",
    "        # 初始化词汇-索引映射表和词向量矩阵\n",
    "        word2idx, label2idx = self._genVocabulary(reviews, labels)\n",
    "        \n",
    "        # 将标签和句子数值化\n",
    "        labelIds = self._labelToIndex(labels, label2idx)\n",
    "        reviewIds = self._wordToIndex(reviews, word2idx)\n",
    "        \n",
    "        # 初始化训练集和测试集\n",
    "        trainReviews, trainLabels, evalReviews, evalLabels = self._genTrainEvalData(reviewIds, labelIds, word2idx, self._rate)\n",
    "        self.trainReviews = trainReviews\n",
    "        self.trainLabels = trainLabels\n",
    "        \n",
    "        self.evalReviews = evalReviews\n",
    "        self.evalLabels = evalLabels\n",
    "        \n",
    "        \n",
    "data = Dataset(config)\n",
    "data.dataGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28a4a8f0-380f-4f13-8522-3a929e1eb045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 输出batch数据集\n",
    "\n",
    "def nextBatch(x, y, batchSize):\n",
    "        \"\"\"\n",
    "        生成batch数据集，用生成器的方式输出\n",
    "        \"\"\"\n",
    "    \n",
    "        perm = np.arange(len(x))\n",
    "        np.random.shuffle(perm)\n",
    "        x = x[perm]\n",
    "        y = y[perm]\n",
    "        \n",
    "        numBatches = len(x) // batchSize\n",
    "\n",
    "        for i in range(numBatches):\n",
    "            start = i * batchSize\n",
    "            end = start + batchSize\n",
    "            batchX = np.array(x[start: end], dtype=\"int64\")\n",
    "            batchY = np.array(y[start: end], dtype=\"float32\")\n",
    "            \n",
    "            yield batchX, batchY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d656e3a-8372-4bb4-b898-50cac4805a3e",
   "metadata": {},
   "source": [
    "## Bi-LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e9fcdef-e47c-4b4e-8ef3-a6eca9e654c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "class BiLSTM(object):\n",
    "    \"\"\"\n",
    "    Bi-LSTM 用于文本分类\n",
    "    \"\"\"\n",
    "    def __init__(self, config, wordEmbedding):\n",
    "\n",
    "        # 定义模型的输入\n",
    "        self.inputX = tf.placeholder(tf.int32, [None, config.sequenceLength], name=\"inputX\")\n",
    "        self.inputY = tf.placeholder(tf.int32, [None], name=\"inputY\")\n",
    "        \n",
    "        self.dropoutKeepProb = tf.placeholder(tf.float32, name=\"dropoutKeepProb\")\n",
    "        \n",
    "        # 定义l2损失\n",
    "        l2Loss = tf.constant(0.0)\n",
    "        \n",
    "        # 词嵌入层\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "\n",
    "            # 利用预训练的词向量初始化词嵌入矩阵\n",
    "            self.W = tf.Variable(tf.cast(wordEmbedding, dtype=tf.float32, name=\"word2vec\") ,name=\"W\")\n",
    "            # 利用词嵌入矩阵将输入的数据中的词转换成词向量，维度[batch_size, sequence_length, embedding_size]\n",
    "            self.embeddedWords = tf.nn.embedding_lookup(self.W, self.inputX)\n",
    "            \n",
    "        # 定义两层双向LSTM的模型结构\n",
    "        with tf.name_scope(\"Bi-LSTM\"):\n",
    "\n",
    "            for idx, hiddenSize in enumerate(config.model.hiddenSizes):\n",
    "                with tf.name_scope(\"Bi-LSTM\" + str(idx)):\n",
    "                    # 定义前向LSTM结构\n",
    "                    lstmFwCell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_units=hiddenSize, state_is_tuple=True),\n",
    "                                                                 output_keep_prob=self.dropoutKeepProb)\n",
    "                    # 定义反向LSTM结构\n",
    "                    lstmBwCell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_units=hiddenSize, state_is_tuple=True),\n",
    "                                                                 output_keep_prob=self.dropoutKeepProb)\n",
    "\n",
    "\n",
    "                    # 采用动态rnn，可以动态的输入序列的长度，若没有输入，则取序列的全长\n",
    "                    # outputs是一个元祖(output_fw, output_bw)，其中两个元素的维度都是[batch_size, max_time, hidden_size],fw和bw的hidden_size一样\n",
    "                    # self.current_state 是最终的状态，二元组(state_fw, state_bw)，state_fw=[batch_size, s]，s是一个元祖(h, c)\n",
    "                    outputs, self.current_state = tf.nn.bidirectional_dynamic_rnn(lstmFwCell, lstmBwCell, \n",
    "                                                                                  self.embeddedWords, dtype=tf.float32,\n",
    "                                                                                  scope=\"bi-lstm\" + str(idx))\n",
    "        \n",
    "                    # 对outputs中的fw和bw的结果拼接 [batch_size, time_step, hidden_size * 2]\n",
    "                    self.embeddedWords = tf.concat(outputs, 2)\n",
    "        \n",
    "        # 去除最后时间步的输出作为全连接的输入\n",
    "        finalOutput = self.embeddedWords[:, 0, :]\n",
    "        \n",
    "        outputSize = config.model.hiddenSizes[-1] * 2  # 因为是双向LSTM，最终的输出值是fw和bw的拼接，因此要乘以2\n",
    "        output = tf.reshape(finalOutput, [-1, outputSize])  # reshape成全连接层的输入维度\n",
    "        \n",
    "        # 全连接层的输出\n",
    "        with tf.name_scope(\"output\"):\n",
    "            outputW = tf.get_variable(\n",
    "                \"outputW\",\n",
    "                shape=[outputSize, config.numClasses],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            outputB= tf.Variable(tf.constant(0.1, shape=[config.numClasses]), name=\"outputB\")\n",
    "            l2Loss += tf.nn.l2_loss(outputW)\n",
    "            l2Loss += tf.nn.l2_loss(outputB)\n",
    "            self.logits = tf.nn.xw_plus_b(output, outputW, outputB, name=\"logits\")\n",
    "            if config.numClasses == 1:\n",
    "                self.predictions = tf.cast(tf.greater_equal(self.logits, 0.0), tf.float32, name=\"predictions\")\n",
    "            elif config.numClasses > 1:\n",
    "                self.predictions = tf.argmax(self.logits, axis=-1, name=\"predictions\")\n",
    "        \n",
    "        # 计算二元交叉熵损失\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            \n",
    "            if config.numClasses == 1:\n",
    "                losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, labels=tf.cast(tf.reshape(self.inputY, [-1, 1]), \n",
    "                                                                                                    dtype=tf.float32))\n",
    "            elif config.numClasses > 1:\n",
    "                losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=self.inputY)\n",
    "                \n",
    "            self.loss = tf.reduce_mean(losses) + config.model.l2RegLambda * l2Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc73d658-5f76-4b81-ac9b-fcd6fcfd64de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "定义各类性能指标\n",
    "\"\"\"\n",
    "\n",
    "def mean(item: list) -> float:\n",
    "    \"\"\"\n",
    "    计算列表中元素的平均值\n",
    "    :param item: 列表对象\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    res = sum(item) / len(item) if len(item) > 0 else 0\n",
    "    return res\n",
    "\n",
    "\n",
    "def accuracy(pred_y, true_y):\n",
    "    \"\"\"\n",
    "    计算二类和多类的准确率\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if isinstance(pred_y[0], list):\n",
    "        pred_y = [item[0] for item in pred_y]\n",
    "    corr = 0\n",
    "    for i in range(len(pred_y)):\n",
    "        if pred_y[i] == true_y[i]:\n",
    "            corr += 1\n",
    "    acc = corr / len(pred_y) if len(pred_y) > 0 else 0\n",
    "    return acc\n",
    "\n",
    "\n",
    "def binary_precision(pred_y, true_y, positive=1):\n",
    "    \"\"\"\n",
    "    二类的精确率计算\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :param positive: 正例的索引表示\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    corr = 0\n",
    "    pred_corr = 0\n",
    "    for i in range(len(pred_y)):\n",
    "        if pred_y[i] == positive:\n",
    "            pred_corr += 1\n",
    "            if pred_y[i] == true_y[i]:\n",
    "                corr += 1\n",
    "\n",
    "    prec = corr / pred_corr if pred_corr > 0 else 0\n",
    "    return prec\n",
    "\n",
    "\n",
    "def binary_recall(pred_y, true_y, positive=1):\n",
    "    \"\"\"\n",
    "    二类的召回率\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :param positive: 正例的索引表示\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    corr = 0\n",
    "    true_corr = 0\n",
    "    for i in range(len(pred_y)):\n",
    "        if true_y[i] == positive:\n",
    "            true_corr += 1\n",
    "            if pred_y[i] == true_y[i]:\n",
    "                corr += 1\n",
    "\n",
    "    rec = corr / true_corr if true_corr > 0 else 0\n",
    "    return rec\n",
    "\n",
    "\n",
    "def binary_f_beta(pred_y, true_y, beta=1.0, positive=1):\n",
    "    \"\"\"\n",
    "    二类的f beta值\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :param beta: beta值\n",
    "    :param positive: 正例的索引表示\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    precision = binary_precision(pred_y, true_y, positive)\n",
    "    recall = binary_recall(pred_y, true_y, positive)\n",
    "    try:\n",
    "        f_b = (1 + beta * beta) * precision * recall / (beta * beta * precision + recall)\n",
    "    except:\n",
    "        f_b = 0\n",
    "    return f_b\n",
    "\n",
    "\n",
    "def multi_precision(pred_y, true_y, labels):\n",
    "    \"\"\"\n",
    "    多类的精确率\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :param labels: 标签列表\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if isinstance(pred_y[0], list):\n",
    "        pred_y = [item[0] for item in pred_y]\n",
    "\n",
    "    precisions = [binary_precision(pred_y, true_y, label) for label in labels]\n",
    "    prec = mean(precisions)\n",
    "    return prec\n",
    "\n",
    "\n",
    "def multi_recall(pred_y, true_y, labels):\n",
    "    \"\"\"\n",
    "    多类的召回率\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :param labels: 标签列表\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if isinstance(pred_y[0], list):\n",
    "        pred_y = [item[0] for item in pred_y]\n",
    "\n",
    "    recalls = [binary_recall(pred_y, true_y, label) for label in labels]\n",
    "    rec = mean(recalls)\n",
    "    return rec\n",
    "\n",
    "\n",
    "def multi_f_beta(pred_y, true_y, labels, beta=1.0):\n",
    "    \"\"\"\n",
    "    多类的f beta值\n",
    "    :param pred_y: 预测结果\n",
    "    :param true_y: 真实结果\n",
    "    :param labels: 标签列表\n",
    "    :param beta: beta值\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if isinstance(pred_y[0], list):\n",
    "        pred_y = [item[0] for item in pred_y]\n",
    "\n",
    "    f_betas = [binary_f_beta(pred_y, true_y, beta, label) for label in labels]\n",
    "    f_beta = mean(f_betas)\n",
    "    return f_beta\n",
    "\n",
    "\n",
    "def get_binary_metrics(pred_y, true_y, f_beta=1.0):\n",
    "    \"\"\"\n",
    "    得到二分类的性能指标\n",
    "    :param pred_y:\n",
    "    :param true_y:\n",
    "    :param f_beta:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    acc = accuracy(pred_y, true_y)\n",
    "    recall = binary_recall(pred_y, true_y)\n",
    "    precision = binary_precision(pred_y, true_y)\n",
    "    f_beta = binary_f_beta(pred_y, true_y, f_beta)\n",
    "    return acc, recall, precision, f_beta\n",
    "\n",
    "\n",
    "def get_multi_metrics(pred_y, true_y, labels, f_beta=1.0):\n",
    "    \"\"\"\n",
    "    得到多分类的性能指标\n",
    "    :param pred_y:\n",
    "    :param true_y:\n",
    "    :param labels:\n",
    "    :param f_beta:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    acc = accuracy(pred_y, true_y)\n",
    "    recall = multi_recall(pred_y, true_y, labels)\n",
    "    precision = multi_precision(pred_y, true_y, labels)\n",
    "    f_beta = multi_f_beta(pred_y, true_y, labels, f_beta)\n",
    "    return acc, recall, precision, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9ebfd88-4c8e-46d7-88eb-a4f649a31047",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 21:26:16,824 : INFO : Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,851 : INFO : Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,853 : INFO : Summary name bi-lstm0/fw/lstm_cell/kernel:0/grad/hist is illegal; using bi-lstm0/fw/lstm_cell/kernel_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,872 : INFO : Summary name bi-lstm0/fw/lstm_cell/kernel:0/grad/sparsity is illegal; using bi-lstm0/fw/lstm_cell/kernel_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,874 : INFO : Summary name bi-lstm0/fw/lstm_cell/bias:0/grad/hist is illegal; using bi-lstm0/fw/lstm_cell/bias_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,893 : INFO : Summary name bi-lstm0/fw/lstm_cell/bias:0/grad/sparsity is illegal; using bi-lstm0/fw/lstm_cell/bias_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,895 : INFO : Summary name bi-lstm0/bw/lstm_cell/kernel:0/grad/hist is illegal; using bi-lstm0/bw/lstm_cell/kernel_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,913 : INFO : Summary name bi-lstm0/bw/lstm_cell/kernel:0/grad/sparsity is illegal; using bi-lstm0/bw/lstm_cell/kernel_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,915 : INFO : Summary name bi-lstm0/bw/lstm_cell/bias:0/grad/hist is illegal; using bi-lstm0/bw/lstm_cell/bias_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,933 : INFO : Summary name bi-lstm0/bw/lstm_cell/bias:0/grad/sparsity is illegal; using bi-lstm0/bw/lstm_cell/bias_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,936 : INFO : Summary name bi-lstm1/fw/lstm_cell/kernel:0/grad/hist is illegal; using bi-lstm1/fw/lstm_cell/kernel_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,955 : INFO : Summary name bi-lstm1/fw/lstm_cell/kernel:0/grad/sparsity is illegal; using bi-lstm1/fw/lstm_cell/kernel_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,957 : INFO : Summary name bi-lstm1/fw/lstm_cell/bias:0/grad/hist is illegal; using bi-lstm1/fw/lstm_cell/bias_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,975 : INFO : Summary name bi-lstm1/fw/lstm_cell/bias:0/grad/sparsity is illegal; using bi-lstm1/fw/lstm_cell/bias_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,978 : INFO : Summary name bi-lstm1/bw/lstm_cell/kernel:0/grad/hist is illegal; using bi-lstm1/bw/lstm_cell/kernel_0/grad/hist instead.\n",
      "2021-06-27 21:26:16,997 : INFO : Summary name bi-lstm1/bw/lstm_cell/kernel:0/grad/sparsity is illegal; using bi-lstm1/bw/lstm_cell/kernel_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:16,999 : INFO : Summary name bi-lstm1/bw/lstm_cell/bias:0/grad/hist is illegal; using bi-lstm1/bw/lstm_cell/bias_0/grad/hist instead.\n",
      "2021-06-27 21:26:17,017 : INFO : Summary name bi-lstm1/bw/lstm_cell/bias:0/grad/sparsity is illegal; using bi-lstm1/bw/lstm_cell/bias_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:17,019 : INFO : Summary name outputW:0/grad/hist is illegal; using outputW_0/grad/hist instead.\n",
      "2021-06-27 21:26:17,038 : INFO : Summary name outputW:0/grad/sparsity is illegal; using outputW_0/grad/sparsity instead.\n",
      "2021-06-27 21:26:17,040 : INFO : Summary name output/outputB:0/grad/hist is illegal; using output/outputB_0/grad/hist instead.\n",
      "2021-06-27 21:26:17,059 : INFO : Summary name output/outputB:0/grad/sparsity is illegal; using output/outputB_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /workdir/data/workdata/summarys/summarys\n",
      "\n",
      "start training model\n",
      "train: step: 1, loss: 2.851747989654541, acc: 0.03125, recall: 0.03333333333333333, precision: 0.023237179487179488, f_beta: 0.01993534482758621\n",
      "train: step: 2, loss: 2.4624829292297363, acc: 0.125, recall: 0.07589285714285714, precision: 0.02553661616161616, f_beta: 0.0342378526645768\n",
      "train: step: 3, loss: 2.4652059078216553, acc: 0.234375, recall: 0.08680555555555557, precision: 0.045063025210084026, f_beta: 0.05079816017316017\n",
      "train: step: 4, loss: 2.387655019760132, acc: 0.171875, recall: 0.07805059523809524, precision: 0.1018180813439434, f_beta: 0.0558751909854851\n",
      "train: step: 5, loss: 2.474154233932495, acc: 0.234375, recall: 0.08004807692307693, precision: 0.05227913533834587, f_beta: 0.05721507352941176\n",
      "train: step: 6, loss: 2.580913543701172, acc: 0.125, recall: 0.052455357142857144, precision: 0.024877450980392155, f_beta: 0.02621822033898305\n",
      "train: step: 7, loss: 2.5863163471221924, acc: 0.171875, recall: 0.06076388888888889, precision: 0.021155083655083656, f_beta: 0.031292517006802724\n",
      "train: step: 8, loss: 2.282410144805908, acc: 0.1875, recall: 0.07183441558441558, precision: 0.04201388888888889, f_beta: 0.051765188834154346\n",
      "train: step: 9, loss: 2.5211129188537598, acc: 0.125, recall: 0.05797466422466423, precision: 0.05931458247634718, f_beta: 0.05212912087912089\n",
      "train: step: 10, loss: 2.4380905628204346, acc: 0.15625, recall: 0.05947871572871573, precision: 0.043246336996336995, f_beta: 0.046875\n",
      "train: step: 11, loss: 2.4408557415008545, acc: 0.125, recall: 0.04893092105263158, precision: 0.03571428571428571, f_beta: 0.03469967532467533\n",
      "train: step: 12, loss: 2.381443977355957, acc: 0.09375, recall: 0.041068306693306696, precision: 0.027665441176470587, f_beta: 0.031008239072755205\n",
      "train: step: 13, loss: 2.455277681350708, acc: 0.140625, recall: 0.06148538961038961, precision: 0.032184829059829057, f_beta: 0.039705882352941174\n",
      "train: step: 14, loss: 2.447299003601074, acc: 0.109375, recall: 0.03720238095238095, precision: 0.0174512987012987, f_beta: 0.022546419098143235\n",
      "train: step: 15, loss: 2.2869131565093994, acc: 0.1875, recall: 0.08559027777777778, precision: 0.07791241496598639, f_beta: 0.0627824858757062\n",
      "train: step: 16, loss: 2.381369113922119, acc: 0.1875, recall: 0.05480769230769231, precision: 0.03585164835164835, f_beta: 0.03819444444444445\n",
      "train: step: 17, loss: 2.2677435874938965, acc: 0.234375, recall: 0.07847222222222222, precision: 0.09722222222222222, f_beta: 0.05898962148962149\n",
      "train: step: 18, loss: 2.297360897064209, acc: 0.203125, recall: 0.06944444444444445, precision: 0.0296875, f_beta: 0.03759398496240601\n",
      "train: step: 19, loss: 2.315915822982788, acc: 0.234375, recall: 0.0683379120879121, precision: 0.028497770345596432, f_beta: 0.039832285115303984\n",
      "train: step: 20, loss: 2.344493865966797, acc: 0.203125, recall: 0.06662087912087912, precision: 0.020432692307692308, f_beta: 0.030840163934426228\n",
      "train: step: 21, loss: 2.179704427719116, acc: 0.1875, recall: 0.07222222222222223, precision: 0.05977564102564102, f_beta: 0.04212389994297428\n",
      "train: step: 22, loss: 2.2417125701904297, acc: 0.234375, recall: 0.06510180995475112, precision: 0.06741352201257861, f_beta: 0.047172619047619054\n",
      "train: step: 23, loss: 2.190342426300049, acc: 0.25, recall: 0.07524463383838384, precision: 0.07496229260935144, f_beta: 0.06343423733129616\n",
      "train: step: 24, loss: 2.2768561840057373, acc: 0.21875, recall: 0.06185385338345865, precision: 0.055456349206349204, f_beta: 0.0458891369047619\n",
      "train: step: 25, loss: 2.269256114959717, acc: 0.234375, recall: 0.05871212121212121, precision: 0.030059523809523807, f_beta: 0.0388095238095238\n",
      "train: step: 26, loss: 2.5140249729156494, acc: 0.140625, recall: 0.04734848484848485, precision: 0.016792929292929294, f_beta: 0.02322567783094099\n",
      "train: step: 27, loss: 2.1889843940734863, acc: 0.1875, recall: 0.03828125, precision: 0.023800872093023256, f_beta: 0.02703373015873016\n",
      "train: step: 28, loss: 2.6136138439178467, acc: 0.1875, recall: 0.06196581196581197, precision: 0.026643990929705215, f_beta: 0.034050179211469536\n",
      "train: step: 29, loss: 2.4707672595977783, acc: 0.109375, recall: 0.03684440559440559, precision: 0.02324183810375671, f_beta: 0.02628968253968254\n",
      "train: step: 30, loss: 2.177703857421875, acc: 0.125, recall: 0.029641544117647058, precision: 0.01783459595959596, f_beta: 0.02113906359189378\n",
      "train: step: 31, loss: 2.3734521865844727, acc: 0.1875, recall: 0.062276785714285715, precision: 0.04253246753246753, f_beta: 0.04746395005703516\n",
      "train: step: 32, loss: 2.2044057846069336, acc: 0.1875, recall: 0.06803977272727273, precision: 0.05949145962732919, f_beta: 0.051587301587301584\n",
      "train: step: 33, loss: 2.148892402648926, acc: 0.25, recall: 0.06434355118565645, precision: 0.040456081081081084, f_beta: 0.04914789191538685\n",
      "train: step: 34, loss: 2.2879981994628906, acc: 0.234375, recall: 0.06683006535947712, precision: 0.04620859213250517, f_beta: 0.05177370150187735\n",
      "train: step: 35, loss: 2.3313491344451904, acc: 0.234375, recall: 0.08333333333333333, precision: 0.046270161290322576, f_beta: 0.056139279725887586\n",
      "train: step: 36, loss: 2.3709754943847656, acc: 0.25, recall: 0.08402777777777778, precision: 0.04807692307692307, f_beta: 0.05519753591562102\n",
      "train: step: 37, loss: 2.3550314903259277, acc: 0.296875, recall: 0.10301677489177488, precision: 0.095625, f_beta: 0.08760300372142478\n",
      "train: step: 38, loss: 2.4225974082946777, acc: 0.1875, recall: 0.059821428571428574, precision: 0.03461230214385895, f_beta: 0.04168669353347876\n",
      "train: step: 39, loss: 2.318143844604492, acc: 0.1875, recall: 0.07492897727272727, precision: 0.040747549019607844, f_beta: 0.04275943396226415\n",
      "train: step: 40, loss: 2.4758036136627197, acc: 0.125, recall: 0.042735042735042736, precision: 0.01804915514592934, f_beta: 0.025378787878787876\n",
      "train: step: 41, loss: 2.224987506866455, acc: 0.15625, recall: 0.05505952380952381, precision: 0.028208812260536398, f_beta: 0.03713883016208597\n",
      "train: step: 42, loss: 2.296389579772949, acc: 0.1875, recall: 0.07040441176470588, precision: 0.03392857142857143, f_beta: 0.04395292207792208\n",
      "train: step: 43, loss: 2.404262065887451, acc: 0.21875, recall: 0.09334415584415584, precision: 0.09901851365546219, f_beta: 0.07801012753188297\n",
      "train: step: 44, loss: 2.2515242099761963, acc: 0.21875, recall: 0.09096372377622378, precision: 0.0463924287856072, f_beta: 0.05798771121351766\n",
      "train: step: 45, loss: 2.231279134750366, acc: 0.25, recall: 0.08025568181818182, precision: 0.051271645021645024, f_beta: 0.06070674177081499\n",
      "train: step: 46, loss: 2.319751501083374, acc: 0.1875, recall: 0.06177156177156177, precision: 0.03033357771260997, f_beta: 0.039651917849592266\n",
      "train: step: 47, loss: 2.3450069427490234, acc: 0.21875, recall: 0.08197115384615386, precision: 0.0581630267815401, f_beta: 0.06348527783206306\n",
      "train: step: 48, loss: 2.258697748184204, acc: 0.1875, recall: 0.06855782085561497, precision: 0.036558493589743585, f_beta: 0.04601328903654485\n",
      "train: step: 49, loss: 2.241795063018799, acc: 0.21875, recall: 0.07158343301435406, precision: 0.04587609970674487, f_beta: 0.053848563716984765\n",
      "train: step: 50, loss: 2.3127052783966064, acc: 0.140625, recall: 0.060019841269841265, precision: 0.07877604166666667, f_beta: 0.03350531582238899\n",
      "train: step: 51, loss: 2.2319884300231934, acc: 0.234375, recall: 0.07346256684491978, precision: 0.05595159151193634, f_beta: 0.060313030421726074\n",
      "train: step: 52, loss: 2.281961679458618, acc: 0.1875, recall: 0.0623015873015873, precision: 0.031165994623655914, f_beta: 0.03987397904463328\n",
      "train: step: 53, loss: 2.368901014328003, acc: 0.15625, recall: 0.06475694444444444, precision: 0.058500874125874125, f_beta: 0.04191757316757317\n",
      "train: step: 54, loss: 2.210225820541382, acc: 0.1875, recall: 0.053571428571428575, precision: 0.026704545454545453, f_beta: 0.0319683908045977\n",
      "train: step: 55, loss: 2.3127074241638184, acc: 0.25, recall: 0.07682291666666666, precision: 0.08979500891265597, f_beta: 0.04857499831160937\n",
      "train: step: 56, loss: 2.3398754596710205, acc: 0.21875, recall: 0.07266865079365079, precision: 0.04418498168498168, f_beta: 0.04558441558441559\n",
      "train: step: 57, loss: 2.299619197845459, acc: 0.234375, recall: 0.08254419191919192, precision: 0.05140503875968992, f_beta: 0.05252976190476191\n",
      "train: step: 58, loss: 2.1575937271118164, acc: 0.203125, recall: 0.07405303030303031, precision: 0.09988839285714285, f_beta: 0.05053377215509241\n",
      "train: step: 59, loss: 2.2875843048095703, acc: 0.140625, recall: 0.045265151515151515, precision: 0.02517361111111111, f_beta: 0.030529448621553885\n",
      "train: step: 60, loss: 2.335977554321289, acc: 0.234375, recall: 0.08023313492063491, precision: 0.06808035714285714, f_beta: 0.05930543715070569\n",
      "train: step: 61, loss: 2.515665054321289, acc: 0.125, recall: 0.04996392496392496, precision: 0.02708333333333333, f_beta: 0.030213401149933657\n",
      "train: step: 62, loss: 2.398263931274414, acc: 0.25, recall: 0.0748015873015873, precision: 0.05074215000685589, f_beta: 0.05930648457822371\n",
      "train: step: 63, loss: 2.379974603652954, acc: 0.171875, recall: 0.0722470238095238, precision: 0.07547348484848485, f_beta: 0.05632487667371388\n",
      "train: step: 64, loss: 2.5730600357055664, acc: 0.1875, recall: 0.08726551226551227, precision: 0.048062865497076016, f_beta: 0.058207417582417584\n",
      "train: step: 65, loss: 2.5981664657592773, acc: 0.171875, recall: 0.05381944444444444, precision: 0.034374999999999996, f_beta: 0.04074292452830188\n",
      "train: step: 66, loss: 2.514974594116211, acc: 0.09375, recall: 0.03333333333333333, precision: 0.01896551724137931, f_beta: 0.022368421052631583\n",
      "train: step: 67, loss: 2.257934331893921, acc: 0.171875, recall: 0.053285256410256415, precision: 0.029166666666666667, f_beta: 0.036102484472049695\n",
      "train: step: 68, loss: 2.2859957218170166, acc: 0.25, recall: 0.07678810160427808, precision: 0.057236842105263155, f_beta: 0.05769252677147414\n",
      "train: step: 69, loss: 2.2701354026794434, acc: 0.15625, recall: 0.04879679144385027, precision: 0.03070175438596491, f_beta: 0.032547501759324415\n",
      "train: step: 70, loss: 2.4171104431152344, acc: 0.171875, recall: 0.06644917582417582, precision: 0.04459767206477733, f_beta: 0.04799679487179487\n",
      "train: step: 71, loss: 2.2008323669433594, acc: 0.265625, recall: 0.09495192307692309, precision: 0.07824754901960784, f_beta: 0.08287746652572234\n",
      "train: step: 72, loss: 2.5450124740600586, acc: 0.15625, recall: 0.054334554334554336, precision: 0.024632352941176473, f_beta: 0.033063876446435235\n",
      "train: step: 73, loss: 2.372574806213379, acc: 0.1875, recall: 0.06581439393939394, precision: 0.038572994987468676, f_beta: 0.04799679487179487\n",
      "train: step: 74, loss: 2.4483280181884766, acc: 0.125, recall: 0.07048611111111111, precision: 0.024756493506493504, f_beta: 0.034725634725634724\n",
      "train: step: 75, loss: 2.372647762298584, acc: 0.21875, recall: 0.09090909090909091, precision: 0.04342386414754836, f_beta: 0.05780933062880325\n",
      "train: step: 76, loss: 2.339609146118164, acc: 0.25, recall: 0.08522727272727273, precision: 0.049545940170940175, f_beta: 0.062211430180180174\n",
      "train: step: 77, loss: 2.3859081268310547, acc: 0.1875, recall: 0.06770833333333333, precision: 0.03589285714285714, f_beta: 0.04670975323149236\n",
      "train: step: 78, loss: 2.2677860260009766, acc: 0.21875, recall: 0.0703125, precision: 0.047424711511398814, f_beta: 0.05353637590479696\n",
      "train: step: 79, loss: 2.237189769744873, acc: 0.203125, recall: 0.06206597222222222, precision: 0.036730769230769234, f_beta: 0.04586299451511262\n",
      "train: step: 80, loss: 2.5190722942352295, acc: 0.140625, recall: 0.06009615384615385, precision: 0.01939655172413793, f_beta: 0.028571428571428574\n",
      "train: step: 81, loss: 2.135789632797241, acc: 0.265625, recall: 0.07603021978021977, precision: 0.0647493961352657, f_beta: 0.05666666666666667\n",
      "train: step: 82, loss: 2.40559720993042, acc: 0.171875, recall: 0.06574675324675325, precision: 0.05081686930091185, f_beta: 0.04113026819923372\n",
      "train: step: 83, loss: 2.1874196529388428, acc: 0.203125, recall: 0.06321803196803197, precision: 0.06449652777777778, f_beta: 0.04759852216748768\n",
      "train: step: 84, loss: 2.4119112491607666, acc: 0.15625, recall: 0.058333333333333334, precision: 0.019202898550724636, f_beta: 0.02889344262295082\n",
      "start training model\n",
      "train: step: 85, loss: 2.3865551948547363, acc: 0.1875, recall: 0.05892857142857143, precision: 0.05807291666666667, f_beta: 0.04310625814863103\n",
      "train: step: 86, loss: 2.30770206451416, acc: 0.234375, recall: 0.059709821428571425, precision: 0.02794526901669759, f_beta: 0.034999999999999996\n",
      "train: step: 87, loss: 2.3603129386901855, acc: 0.265625, recall: 0.0900297619047619, precision: 0.06422682709447415, f_beta: 0.05476190476190475\n",
      "train: step: 88, loss: 2.388845443725586, acc: 0.203125, recall: 0.07589285714285714, precision: 0.03262578616352201, f_beta: 0.0361456176673568\n",
      "train: step: 89, loss: 2.3977956771850586, acc: 0.1875, recall: 0.05357142857142857, precision: 0.014423076923076924, f_beta: 0.022727272727272728\n",
      "train: step: 90, loss: 2.2379634380340576, acc: 0.28125, recall: 0.06650641025641026, precision: 0.03579545454545455, f_beta: 0.043198529411764705\n",
      "train: step: 91, loss: 2.35864520072937, acc: 0.140625, recall: 0.05625, precision: 0.009698275862068966, f_beta: 0.01654411764705882\n",
      "train: step: 92, loss: 2.39430570602417, acc: 0.21875, recall: 0.06944444444444443, precision: 0.032857142857142856, f_beta: 0.040178571428571425\n",
      "train: step: 93, loss: 2.4101741313934326, acc: 0.203125, recall: 0.06373530982905982, precision: 0.05602678571428571, f_beta: 0.03724355354790137\n",
      "train: step: 94, loss: 2.2415759563446045, acc: 0.3125, recall: 0.06875, precision: 0.08333333333333333, f_beta: 0.04261363636363637\n",
      "train: step: 95, loss: 2.2473015785217285, acc: 0.1875, recall: 0.057348901098901096, precision: 0.023637820512820512, f_beta: 0.027403846153846154\n",
      "train: step: 96, loss: 2.376555919647217, acc: 0.15625, recall: 0.05219780219780219, precision: 0.028125, f_beta: 0.0307601880877743\n",
      "train: step: 97, loss: 2.5237631797790527, acc: 0.171875, recall: 0.060576923076923084, precision: 0.018979690522243714, f_beta: 0.028645833333333336\n",
      "train: step: 98, loss: 2.3404409885406494, acc: 0.234375, recall: 0.07152777777777777, precision: 0.040117521367521364, f_beta: 0.04755434782608696\n",
      "train: step: 99, loss: 2.209545135498047, acc: 0.15625, recall: 0.05897435897435897, precision: 0.09166666666666667, f_beta: 0.040931163135110506\n",
      "train: step: 100, loss: 2.4993808269500732, acc: 0.171875, recall: 0.05208333333333333, precision: 0.021701388888888888, f_beta: 0.02976190476190476\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:28:18.546902, step: 100, loss: 2.237886587778727, acc: 0.24305555555555555,precision: 0.0625, recall: 0.015190972222222222, f_beta: 0.024248117290723036\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-100\n",
      "\n",
      "train: step: 101, loss: 2.4426562786102295, acc: 0.21875, recall: 0.06205357142857143, precision: 0.0888704318936877, f_beta: 0.048401669990029914\n",
      "train: step: 102, loss: 2.246849536895752, acc: 0.15625, recall: 0.040865384615384616, precision: 0.019736842105263157, f_beta: 0.026331018518518517\n",
      "train: step: 103, loss: 2.186265707015991, acc: 0.1875, recall: 0.04182330827067669, precision: 0.03858695652173913, f_beta: 0.032388663967611336\n",
      "train: step: 104, loss: 2.374985933303833, acc: 0.09375, recall: 0.05689102564102565, precision: 0.01828703703703704, f_beta: 0.017361111111111112\n",
      "train: step: 105, loss: 2.243786573410034, acc: 0.265625, recall: 0.06184210526315789, precision: 0.029549319727891155, f_beta: 0.03893716577540107\n",
      "train: step: 106, loss: 2.3222601413726807, acc: 0.25, recall: 0.07564102564102564, precision: 0.060979199372056515, f_beta: 0.048816287878787876\n",
      "train: step: 107, loss: 2.394117832183838, acc: 0.125, recall: 0.07291666666666667, precision: 0.018439108061749573, f_beta: 0.023581429624170966\n",
      "train: step: 108, loss: 2.3900489807128906, acc: 0.15625, recall: 0.05332167832167832, precision: 0.026578073089700997, f_beta: 0.032407407407407406\n",
      "train: step: 109, loss: 2.478268623352051, acc: 0.171875, recall: 0.050347222222222224, precision: 0.034420289855072464, f_beta: 0.03738839285714286\n",
      "train: step: 110, loss: 2.1776657104492188, acc: 0.25, recall: 0.0741421568627451, precision: 0.03307109557109557, f_beta: 0.043740573152337855\n",
      "train: step: 111, loss: 2.5028226375579834, acc: 0.1875, recall: 0.08333333333333334, precision: 0.08186303827751196, f_beta: 0.0421969696969697\n",
      "train: step: 112, loss: 2.228386402130127, acc: 0.171875, recall: 0.04558823529411765, precision: 0.02025462962962963, f_beta: 0.02798317185109638\n",
      "train: step: 113, loss: 2.183316707611084, acc: 0.125, recall: 0.03943452380952381, precision: 0.017376373626373627, f_beta: 0.024100429645542425\n",
      "train: step: 114, loss: 2.262427806854248, acc: 0.265625, recall: 0.06788277511961723, precision: 0.032589285714285716, f_beta: 0.04380341880341881\n",
      "train: step: 115, loss: 2.371964931488037, acc: 0.140625, recall: 0.05505952380952381, precision: 0.01875, f_beta: 0.025607638888888888\n",
      "train: step: 116, loss: 2.2084617614746094, acc: 0.21875, recall: 0.06875, precision: 0.04319234006734007, f_beta: 0.0471079192546584\n",
      "train: step: 117, loss: 2.24495267868042, acc: 0.1875, recall: 0.05304276315789473, precision: 0.023798076923076922, f_beta: 0.03278940886699507\n",
      "train: step: 118, loss: 2.481826066970825, acc: 0.109375, recall: 0.04652777777777778, precision: 0.015472560975609756, f_beta: 0.0225\n",
      "train: step: 119, loss: 2.3587608337402344, acc: 0.15625, recall: 0.05334249084249084, precision: 0.02417428861788618, f_beta: 0.03175743477467616\n",
      "train: step: 120, loss: 2.229465961456299, acc: 0.234375, recall: 0.07477678571428571, precision: 0.039303221288515405, f_beta: 0.04975018853695324\n",
      "train: step: 121, loss: 2.369719982147217, acc: 0.109375, recall: 0.03802083333333334, precision: 0.01789630325814536, f_beta: 0.023060344827586204\n",
      "train: step: 122, loss: 2.322044849395752, acc: 0.234375, recall: 0.0871031746031746, precision: 0.040466589861751154, f_beta: 0.05421842650103519\n",
      "train: step: 123, loss: 2.277336359024048, acc: 0.265625, recall: 0.07840909090909091, precision: 0.046556122448979595, f_beta: 0.05319940476190476\n",
      "train: step: 124, loss: 2.3009448051452637, acc: 0.25, recall: 0.07682291666666666, precision: 0.04405003871467286, f_beta: 0.05307302346776031\n",
      "train: step: 125, loss: 2.363896608352661, acc: 0.125, recall: 0.037946428571428575, precision: 0.021863553113553112, f_beta: 0.026160714285714287\n",
      "train: step: 126, loss: 2.1773037910461426, acc: 0.25, recall: 0.07569444444444445, precision: 0.04538690476190476, f_beta: 0.051358865914786965\n",
      "train: step: 127, loss: 2.3061740398406982, acc: 0.21875, recall: 0.078125, precision: 0.03645833333333333, f_beta: 0.04538690476190477\n",
      "train: step: 128, loss: 2.296304702758789, acc: 0.203125, recall: 0.07539335664335664, precision: 0.06148989898989898, f_beta: 0.0563631874538921\n",
      "train: step: 129, loss: 2.251962184906006, acc: 0.21875, recall: 0.07104700854700854, precision: 0.05007102272727273, f_beta: 0.049797138000986896\n",
      "train: step: 130, loss: 2.3192851543426514, acc: 0.140625, recall: 0.04927884615384615, precision: 0.01933760683760684, f_beta: 0.02699096880131363\n",
      "train: step: 131, loss: 2.1162402629852295, acc: 0.265625, recall: 0.06349206349206349, precision: 0.06338443396226415, f_beta: 0.04496038732394366\n",
      "train: step: 132, loss: 2.2865610122680664, acc: 0.15625, recall: 0.05808080808080808, precision: 0.04078389830508475, f_beta: 0.02743506493506493\n",
      "train: step: 133, loss: 2.3113510608673096, acc: 0.15625, recall: 0.052083333333333336, precision: 0.01059322033898305, f_beta: 0.0176056338028169\n",
      "train: step: 134, loss: 2.413140296936035, acc: 0.1875, recall: 0.0796875, precision: 0.05081686930091185, f_beta: 0.05168251511130768\n",
      "train: step: 135, loss: 2.3298842906951904, acc: 0.21875, recall: 0.07202380952380952, precision: 0.06791666666666667, f_beta: 0.05065104166666666\n",
      "train: step: 136, loss: 2.394784927368164, acc: 0.203125, recall: 0.0625, precision: 0.029166666666666667, f_beta: 0.035070532915360504\n",
      "train: step: 137, loss: 2.451962471008301, acc: 0.109375, recall: 0.04861111111111111, precision: 0.0078125, f_beta: 0.013461538461538462\n",
      "train: step: 138, loss: 2.1958491802215576, acc: 0.234375, recall: 0.06874999999999999, precision: 0.04869186046511628, f_beta: 0.04572368421052632\n",
      "train: step: 139, loss: 2.352391242980957, acc: 0.1875, recall: 0.06678113553113553, precision: 0.03986710963455149, f_beta: 0.044315059940059943\n",
      "train: step: 140, loss: 2.276068687438965, acc: 0.234375, recall: 0.07910839160839161, precision: 0.039248511904761904, f_beta: 0.049040338321405336\n",
      "train: step: 141, loss: 2.3697636127471924, acc: 0.203125, recall: 0.06780417295123177, precision: 0.055002289377289376, f_beta: 0.05352564102564102\n",
      "train: step: 142, loss: 2.413466691970825, acc: 0.140625, recall: 0.05141559829059829, precision: 0.02894736842105263, f_beta: 0.03289371304077186\n",
      "train: step: 143, loss: 2.334545135498047, acc: 0.25, recall: 0.08397435897435898, precision: 0.0828125, f_beta: 0.06711819993069992\n",
      "train: step: 144, loss: 2.2423205375671387, acc: 0.21875, recall: 0.08536953242835596, precision: 0.09889069264069264, f_beta: 0.07671404682274248\n",
      "train: step: 145, loss: 2.4646239280700684, acc: 0.0625, recall: 0.042708333333333334, precision: 0.007862644415917844, f_beta: 0.012184431977559609\n",
      "train: step: 146, loss: 2.348459482192993, acc: 0.171875, recall: 0.05808566433566433, precision: 0.05359162895927602, f_beta: 0.04057400932400932\n",
      "train: step: 147, loss: 2.4083869457244873, acc: 0.171875, recall: 0.06143162393162393, precision: 0.023122710622710624, f_beta: 0.03349358974358974\n",
      "train: step: 148, loss: 2.3130102157592773, acc: 0.234375, recall: 0.06197916666666667, precision: 0.0404265873015873, f_beta: 0.0443452380952381\n",
      "train: step: 149, loss: 2.2816905975341797, acc: 0.1875, recall: 0.06206293706293706, precision: 0.02639411027568922, f_beta: 0.036688112745098034\n",
      "train: step: 150, loss: 2.3374454975128174, acc: 0.046875, recall: 0.028245192307692308, precision: 0.06690658049353701, f_beta: 0.016009609980892438\n",
      "train: step: 151, loss: 2.362399101257324, acc: 0.140625, recall: 0.05381944444444445, precision: 0.019965277777777776, f_beta: 0.02847222222222222\n",
      "train: step: 152, loss: 2.433910846710205, acc: 0.125, recall: 0.05416666666666667, precision: 0.016281512605042014, f_beta: 0.02396514161220044\n",
      "train: step: 153, loss: 2.2259469032287598, acc: 0.21875, recall: 0.06426282051282052, precision: 0.0456296992481203, f_beta: 0.052242996828752636\n",
      "train: step: 154, loss: 2.2793569564819336, acc: 0.15625, recall: 0.06650641025641026, precision: 0.032196969696969696, f_beta: 0.03980158730158731\n",
      "train: step: 155, loss: 2.1844375133514404, acc: 0.3125, recall: 0.11162405303030302, precision: 0.07521416417297425, f_beta: 0.08898809523809524\n",
      "train: step: 156, loss: 2.1601834297180176, acc: 0.15625, recall: 0.05853174603174603, precision: 0.0379829014939309, f_beta: 0.04545221934927817\n",
      "train: step: 157, loss: 2.5409960746765137, acc: 0.125, recall: 0.055803571428571425, precision: 0.0312945632798574, f_beta: 0.03957516339869281\n",
      "train: step: 158, loss: 2.162879467010498, acc: 0.1875, recall: 0.051215277777777776, precision: 0.0416311919504644, f_beta: 0.044426856926856925\n",
      "train: step: 159, loss: 2.3080012798309326, acc: 0.15625, recall: 0.059409340659340656, precision: 0.05943627450980392, f_beta: 0.04977605512489233\n",
      "train: step: 160, loss: 2.298274517059326, acc: 0.171875, recall: 0.07126831501831501, precision: 0.0996436403508772, f_beta: 0.0506951381951382\n",
      "train: step: 161, loss: 2.2356948852539062, acc: 0.203125, recall: 0.07152777777777777, precision: 0.05532094594594594, f_beta: 0.05115501519756839\n",
      "train: step: 162, loss: 2.234893560409546, acc: 0.171875, recall: 0.051893939393939395, precision: 0.029684337044534412, f_beta: 0.03708839918946302\n",
      "train: step: 163, loss: 2.2395710945129395, acc: 0.1875, recall: 0.053505777310924374, precision: 0.026752888655462187, f_beta: 0.03562640471208246\n",
      "train: step: 164, loss: 2.1670193672180176, acc: 0.1875, recall: 0.051587301587301584, precision: 0.030404135338345864, f_beta: 0.03755042686931232\n",
      "train: step: 165, loss: 2.317385673522949, acc: 0.15625, recall: 0.05602904040404041, precision: 0.031647274294333116, f_beta: 0.03511679292929293\n",
      "train: step: 166, loss: 2.1819114685058594, acc: 0.15625, recall: 0.04498626373626374, precision: 0.017436594202898552, f_beta: 0.023750000000000004\n",
      "train: step: 167, loss: 2.391773223876953, acc: 0.15625, recall: 0.06458333333333333, precision: 0.022674418604651164, f_beta: 0.03213443396226415\n",
      "train: step: 168, loss: 2.3132476806640625, acc: 0.234375, recall: 0.06975446428571429, precision: 0.057557189542483664, f_beta: 0.04855760999828796\n",
      "start training model\n",
      "train: step: 169, loss: 2.361037254333496, acc: 0.1875, recall: 0.06423611111111112, precision: 0.03854588394062078, f_beta: 0.04041199813258636\n",
      "train: step: 170, loss: 2.306431293487549, acc: 0.171875, recall: 0.05625, precision: 0.02293113425925926, f_beta: 0.0325352526439483\n",
      "train: step: 171, loss: 2.494344711303711, acc: 0.265625, recall: 0.10277777777777777, precision: 0.09270833333333334, f_beta: 0.0659965034965035\n",
      "train: step: 172, loss: 2.2557058334350586, acc: 0.109375, recall: 0.023026315789473683, precision: 0.014583333333333334, f_beta: 0.017857142857142856\n",
      "train: step: 173, loss: 2.331294059753418, acc: 0.1875, recall: 0.07612179487179488, precision: 0.038839285714285715, f_beta: 0.04599282296650718\n",
      "train: step: 174, loss: 2.175966262817383, acc: 0.15625, recall: 0.04821428571428571, precision: 0.017934782608695653, f_beta: 0.026094276094276097\n",
      "train: step: 175, loss: 2.284733295440674, acc: 0.234375, recall: 0.06490384615384615, precision: 0.0297920892494929, f_beta: 0.04083333333333333\n",
      "train: step: 176, loss: 2.1913042068481445, acc: 0.171875, recall: 0.05880681818181818, precision: 0.03866023035230352, f_beta: 0.037745098039215684\n",
      "train: step: 177, loss: 2.527278423309326, acc: 0.140625, recall: 0.053409090909090906, precision: 0.018682065217391304, f_beta: 0.027406417112299464\n",
      "train: step: 178, loss: 2.3273236751556396, acc: 0.25, recall: 0.08392857142857144, precision: 0.04790521978021978, f_beta: 0.05434853491000783\n",
      "train: step: 179, loss: 2.1778929233551025, acc: 0.203125, recall: 0.06480508870214753, precision: 0.05604260935143288, f_beta: 0.05057795698924731\n",
      "train: step: 180, loss: 2.2767105102539062, acc: 0.1875, recall: 0.06927083333333332, precision: 0.04322638146167558, f_beta: 0.03980158730158731\n",
      "train: step: 181, loss: 2.3626372814178467, acc: 0.203125, recall: 0.05952380952380952, precision: 0.02361111111111111, f_beta: 0.03256434400502197\n",
      "train: step: 182, loss: 2.2761754989624023, acc: 0.21875, recall: 0.09650735294117646, precision: 0.047209193245778616, f_beta: 0.05657353652636672\n",
      "train: step: 183, loss: 2.482198715209961, acc: 0.21875, recall: 0.06823752228163993, precision: 0.037459935897435896, f_beta: 0.04742828782108419\n",
      "train: step: 184, loss: 2.2970170974731445, acc: 0.203125, recall: 0.06290584415584416, precision: 0.026198814655172414, f_beta: 0.03695652173913044\n",
      "train: step: 185, loss: 2.3535990715026855, acc: 0.25, recall: 0.07514880952380952, precision: 0.08744517543859649, f_beta: 0.062375992063492064\n",
      "train: step: 186, loss: 2.131193161010742, acc: 0.234375, recall: 0.06484375, precision: 0.04508627946127946, f_beta: 0.047894429914469495\n",
      "train: step: 187, loss: 2.223906993865967, acc: 0.21875, recall: 0.07011217948717949, precision: 0.02946127946127946, f_beta: 0.04131944444444445\n",
      "train: step: 188, loss: 2.325409412384033, acc: 0.203125, recall: 0.07053571428571428, precision: 0.02624740124740125, f_beta: 0.03736702127659575\n",
      "train: step: 189, loss: 2.1513917446136475, acc: 0.15625, recall: 0.056818181818181816, precision: 0.0196078431372549, f_beta: 0.029132791327913278\n",
      "train: step: 190, loss: 2.182237148284912, acc: 0.171875, recall: 0.042804621848739496, precision: 0.020970394736842105, f_beta: 0.02805023923444976\n",
      "train: step: 191, loss: 2.3739194869995117, acc: 0.15625, recall: 0.06944444444444445, precision: 0.01984627016129032, f_beta: 0.03086890243902439\n",
      "train: step: 192, loss: 2.2458925247192383, acc: 0.21875, recall: 0.06770833333333334, precision: 0.028696236559139783, f_beta: 0.04027777777777778\n",
      "train: step: 193, loss: 2.3470375537872314, acc: 0.140625, recall: 0.05113636363636363, precision: 0.017368421052631578, f_beta: 0.025722789115646256\n",
      "train: step: 194, loss: 2.4053213596343994, acc: 0.1875, recall: 0.06944444444444445, precision: 0.0233983983983984, f_beta: 0.03390269151138717\n",
      "train: step: 195, loss: 2.323859691619873, acc: 0.234375, recall: 0.09034090909090908, precision: 0.031919642857142855, f_beta: 0.0459375\n",
      "train: step: 196, loss: 2.3492069244384766, acc: 0.125, recall: 0.04447115384615385, precision: 0.015046296296296295, f_beta: 0.022448979591836737\n",
      "train: step: 197, loss: 2.4577720165252686, acc: 0.15625, recall: 0.05260416666666667, precision: 0.023014705882352944, f_beta: 0.03080357142857143\n",
      "train: step: 198, loss: 2.4076483249664307, acc: 0.171875, recall: 0.06510416666666667, precision: 0.041759672619047616, f_beta: 0.041869588744588744\n",
      "train: step: 199, loss: 2.432222366333008, acc: 0.203125, recall: 0.08234126984126983, precision: 0.039546783625731, f_beta: 0.04731826241134752\n",
      "train: step: 200, loss: 2.399855136871338, acc: 0.125, recall: 0.05520833333333334, precision: 0.02724904828691645, f_beta: 0.032778442317916004\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:30:09.105166, step: 200, loss: 2.2516712612575955, acc: 0.21180555555555555,precision: 0.062097292936108724, recall: 0.02406458633532773, f_beta: 0.033950808414749525\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-200\n",
      "\n",
      "train: step: 201, loss: 2.3507802486419678, acc: 0.15625, recall: 0.04631410256410256, precision: 0.029761904761904764, f_beta: 0.03448969331322273\n",
      "train: step: 202, loss: 2.22857666015625, acc: 0.171875, recall: 0.0517156862745098, precision: 0.032196969696969696, f_beta: 0.03958683473389356\n",
      "train: step: 203, loss: 2.2683095932006836, acc: 0.21875, recall: 0.06927083333333334, precision: 0.04413205329153605, f_beta: 0.05191935002981514\n",
      "train: step: 204, loss: 2.378875970840454, acc: 0.25, recall: 0.09191176470588235, precision: 0.04547101449275362, f_beta: 0.05973250580720093\n",
      "train: step: 205, loss: 2.2414965629577637, acc: 0.25, recall: 0.07261904761904761, precision: 0.04756302521008403, f_beta: 0.05741995073891625\n",
      "train: step: 206, loss: 2.301403284072876, acc: 0.21875, recall: 0.06490384615384615, precision: 0.03797743055555555, f_beta: 0.046788194444444445\n",
      "train: step: 207, loss: 2.2868552207946777, acc: 0.203125, recall: 0.06986607142857143, precision: 0.03363095238095238, f_beta: 0.045237466022349744\n",
      "train: step: 208, loss: 2.34228777885437, acc: 0.28125, recall: 0.07643457602339182, precision: 0.04369588744588744, f_beta: 0.05315656565656565\n",
      "train: step: 209, loss: 2.2751564979553223, acc: 0.21875, recall: 0.07275641025641025, precision: 0.04180194805194805, f_beta: 0.05006772445820433\n",
      "train: step: 210, loss: 2.2448697090148926, acc: 0.234375, recall: 0.059495192307692304, precision: 0.03674242424242424, f_beta: 0.032460387323943664\n",
      "train: step: 211, loss: 2.337299346923828, acc: 0.125, recall: 0.0625, precision: 0.00847457627118644, f_beta: 0.014925373134328358\n",
      "train: step: 212, loss: 2.242429494857788, acc: 0.203125, recall: 0.05416666666666667, precision: 0.013771186440677966, f_beta: 0.021959459459459457\n",
      "train: step: 213, loss: 2.2056989669799805, acc: 0.265625, recall: 0.0625, precision: 0.016865079365079364, f_beta: 0.0265625\n",
      "train: step: 214, loss: 2.1734328269958496, acc: 0.265625, recall: 0.0625, precision: 0.017137096774193547, f_beta: 0.026898734177215188\n",
      "train: step: 215, loss: 2.365819215774536, acc: 0.171875, recall: 0.0625, precision: 0.011270491803278689, f_beta: 0.019097222222222224\n",
      "train: step: 216, loss: 2.380805730819702, acc: 0.09375, recall: 0.0625, precision: 0.005859375, f_beta: 0.010714285714285714\n",
      "train: step: 217, loss: 2.223461866378784, acc: 0.1875, recall: 0.05913461538461538, precision: 0.022270114942528736, f_beta: 0.02717869718309859\n",
      "train: step: 218, loss: 2.341897964477539, acc: 0.203125, recall: 0.05803571428571429, precision: 0.01310483870967742, f_beta: 0.02138157894736842\n",
      "train: step: 219, loss: 2.1716575622558594, acc: 0.21875, recall: 0.06138392857142857, precision: 0.044642857142857144, f_beta: 0.03392857142857143\n",
      "train: step: 220, loss: 2.2342324256896973, acc: 0.1875, recall: 0.06875, precision: 0.04252049180327869, f_beta: 0.02951388888888889\n",
      "train: step: 221, loss: 2.1135709285736084, acc: 0.1875, recall: 0.05, precision: 0.014705882352941176, f_beta: 0.022727272727272724\n",
      "train: step: 222, loss: 2.2452337741851807, acc: 0.25, recall: 0.07589285714285715, precision: 0.036593707250342, f_beta: 0.04779189352692075\n",
      "train: step: 223, loss: 2.274890661239624, acc: 0.25, recall: 0.06700721153846154, precision: 0.031649245063879214, f_beta: 0.042505159958720326\n",
      "train: step: 224, loss: 2.275134801864624, acc: 0.21875, recall: 0.05823863636363637, precision: 0.024398395721925134, f_beta: 0.033928571428571426\n",
      "train: step: 225, loss: 2.3192105293273926, acc: 0.125, recall: 0.053571428571428575, precision: 0.016428571428571428, f_beta: 0.024851876234364714\n",
      "train: step: 226, loss: 2.0701546669006348, acc: 0.234375, recall: 0.06657239819004525, precision: 0.058141891891891895, f_beta: 0.04576719576719576\n",
      "train: step: 227, loss: 2.216578960418701, acc: 0.25, recall: 0.07061298076923077, precision: 0.03303179824561404, f_beta: 0.04393382352941177\n",
      "train: step: 228, loss: 2.0505964756011963, acc: 0.234375, recall: 0.05989583333333333, precision: 0.029468201754385963, f_beta: 0.03917378917378918\n",
      "train: step: 229, loss: 2.4702365398406982, acc: 0.109375, recall: 0.04403409090909091, precision: 0.014732142857142857, f_beta: 0.02183959451401312\n",
      "train: step: 230, loss: 2.4251632690429688, acc: 0.140625, recall: 0.04895833333333333, precision: 0.04654987760097919, f_beta: 0.03118562472010748\n",
      "train: step: 231, loss: 2.3461508750915527, acc: 0.15625, recall: 0.06092171717171717, precision: 0.038517441860465115, f_beta: 0.03992635596409181\n",
      "train: step: 232, loss: 2.422663688659668, acc: 0.1875, recall: 0.06486742424242424, precision: 0.025723684210526315, f_beta: 0.03640375068946498\n",
      "train: step: 233, loss: 2.3410162925720215, acc: 0.1875, recall: 0.07118055555555555, precision: 0.04091379634857896, f_beta: 0.048017026578073094\n",
      "train: step: 234, loss: 2.440781354904175, acc: 0.1875, recall: 0.08253205128205127, precision: 0.035863095238095236, f_beta: 0.04192927170868347\n",
      "train: step: 235, loss: 2.2256484031677246, acc: 0.234375, recall: 0.07564484126984126, precision: 0.03956330128205128, f_beta: 0.047095959595959594\n",
      "train: step: 236, loss: 2.3683559894561768, acc: 0.203125, recall: 0.07232142857142856, precision: 0.03955518018018018, f_beta: 0.049667366946778715\n",
      "train: step: 237, loss: 2.2677202224731445, acc: 0.203125, recall: 0.0625, precision: 0.06221719457013575, f_beta: 0.051991758241758244\n",
      "train: step: 238, loss: 2.5254292488098145, acc: 0.203125, recall: 0.07765151515151515, precision: 0.03797238372093023, f_beta: 0.044576719576719576\n",
      "train: step: 239, loss: 2.209705352783203, acc: 0.25, recall: 0.07973276723276723, precision: 0.05059523809523809, f_beta: 0.05463203463203463\n",
      "train: step: 240, loss: 2.3234059810638428, acc: 0.140625, recall: 0.05296717171717172, precision: 0.0248241341991342, f_beta: 0.029156373517786563\n",
      "train: step: 241, loss: 2.3939247131347656, acc: 0.234375, recall: 0.06640625, precision: 0.029026679841897232, f_beta: 0.03936757215619695\n",
      "train: step: 242, loss: 2.16117525100708, acc: 0.21875, recall: 0.06646825396825397, precision: 0.03480113636363637, f_beta: 0.04192940294558603\n",
      "train: step: 243, loss: 2.422347068786621, acc: 0.15625, recall: 0.052556818181818184, precision: 0.016927083333333332, f_beta: 0.02418478260869565\n",
      "train: step: 244, loss: 2.3021557331085205, acc: 0.25, recall: 0.058823529411764705, precision: 0.017857142857142856, f_beta: 0.0273972602739726\n",
      "train: step: 245, loss: 2.549118995666504, acc: 0.15625, recall: 0.053125, precision: 0.023529411764705882, f_beta: 0.026190476190476188\n",
      "train: step: 246, loss: 2.362928628921509, acc: 0.171875, recall: 0.060751748251748255, precision: 0.04111842105263158, f_beta: 0.03125\n",
      "train: step: 247, loss: 2.2947568893432617, acc: 0.15625, recall: 0.0625, precision: 0.010416666666666666, f_beta: 0.017857142857142856\n",
      "train: step: 248, loss: 2.393852710723877, acc: 0.1875, recall: 0.07569444444444444, precision: 0.07219827586206896, f_beta: 0.04576489686783804\n",
      "train: step: 249, loss: 2.3109560012817383, acc: 0.234375, recall: 0.06597222222222222, precision: 0.03741496598639456, f_beta: 0.04508706467661692\n",
      "train: step: 250, loss: 2.5106663703918457, acc: 0.1875, recall: 0.06931818181818182, precision: 0.05244252873563218, f_beta: 0.037346711259754736\n",
      "train: step: 251, loss: 2.2317512035369873, acc: 0.265625, recall: 0.08217147435897436, precision: 0.06623427672955974, f_beta: 0.05583003952569171\n",
      "train: step: 252, loss: 2.2630085945129395, acc: 0.171875, recall: 0.052884615384615384, precision: 0.01206140350877193, f_beta: 0.01964285714285714\n",
      "start training model\n",
      "train: step: 253, loss: 2.3098196983337402, acc: 0.203125, recall: 0.0625, precision: 0.013771186440677966, f_beta: 0.022569444444444444\n",
      "train: step: 254, loss: 2.317866802215576, acc: 0.140625, recall: 0.06535218253968254, precision: 0.0796832884097035, f_beta: 0.038071236559139784\n",
      "train: step: 255, loss: 2.3271148204803467, acc: 0.109375, recall: 0.051995798319327734, precision: 0.030296610169491527, f_beta: 0.020833333333333332\n",
      "train: step: 256, loss: 2.1588335037231445, acc: 0.25, recall: 0.07291666666666667, precision: 0.08942307692307692, f_beta: 0.05274520255863539\n",
      "train: step: 257, loss: 2.43595027923584, acc: 0.171875, recall: 0.059375, precision: 0.021843645484949832, f_beta: 0.030266116941529236\n",
      "train: step: 258, loss: 2.4338037967681885, acc: 0.15625, recall: 0.052556818181818184, precision: 0.03800366300366301, f_beta: 0.034058695046007996\n",
      "train: step: 259, loss: 2.2803709506988525, acc: 0.15625, recall: 0.06699134199134199, precision: 0.0515625, f_beta: 0.03719897124152444\n",
      "train: step: 260, loss: 2.253732204437256, acc: 0.21875, recall: 0.05520833333333334, precision: 0.055039414414414414, f_beta: 0.04086387844611529\n",
      "train: step: 261, loss: 2.1129112243652344, acc: 0.234375, recall: 0.07556089743589745, precision: 0.1494417211328976, f_beta: 0.0626729653325398\n",
      "train: step: 262, loss: 2.388693332672119, acc: 0.140625, recall: 0.047991071428571425, precision: 0.0811764705882353, f_beta: 0.039870063879210216\n",
      "train: step: 263, loss: 2.2543106079101562, acc: 0.171875, recall: 0.06448412698412698, precision: 0.08344780219780219, f_beta: 0.045073447893569846\n",
      "train: step: 264, loss: 2.333698272705078, acc: 0.171875, recall: 0.059760551948051945, precision: 0.041666666666666664, f_beta: 0.040478977908989106\n",
      "train: step: 265, loss: 2.1758227348327637, acc: 0.171875, recall: 0.049038461538461545, precision: 0.02291666666666667, f_beta: 0.031153250773993807\n",
      "train: step: 266, loss: 2.218905210494995, acc: 0.125, recall: 0.043560606060606064, precision: 0.017191142191142192, f_beta: 0.02452153110047847\n",
      "train: step: 267, loss: 2.7068357467651367, acc: 0.140625, recall: 0.0716540404040404, precision: 0.029525862068965517, f_beta: 0.034676535087719305\n",
      "train: step: 268, loss: 2.1755242347717285, acc: 0.265625, recall: 0.08869255744255744, precision: 0.1297360248447205, f_beta: 0.07641132980806895\n",
      "train: step: 269, loss: 2.2647886276245117, acc: 0.21875, recall: 0.08613053613053614, precision: 0.07276785714285713, f_beta: 0.057824494346233477\n",
      "train: step: 270, loss: 2.428232192993164, acc: 0.140625, recall: 0.04503676470588235, precision: 0.02060185185185185, f_beta: 0.02640374331550802\n",
      "train: step: 271, loss: 2.270871639251709, acc: 0.109375, recall: 0.03847402597402597, precision: 0.019560904071773636, f_beta: 0.02568922305764411\n",
      "train: step: 272, loss: 2.316326856613159, acc: 0.21875, recall: 0.06621240601503758, precision: 0.04195115546218488, f_beta: 0.049571078431372546\n",
      "train: step: 273, loss: 2.3811826705932617, acc: 0.171875, recall: 0.05872252747252747, precision: 0.03044871794871795, f_beta: 0.038761007511007514\n",
      "train: step: 274, loss: 2.1896731853485107, acc: 0.21875, recall: 0.08996212121212122, precision: 0.04403044871794872, f_beta: 0.04822058082927649\n",
      "train: step: 275, loss: 2.349026679992676, acc: 0.21875, recall: 0.07602813852813853, precision: 0.04383484162895927, f_beta: 0.05499188311688312\n",
      "train: step: 276, loss: 2.2902755737304688, acc: 0.203125, recall: 0.054330065359477125, precision: 0.026450163398692814, f_beta: 0.03555878084179971\n",
      "train: step: 277, loss: 2.4081473350524902, acc: 0.171875, recall: 0.06773989898989899, precision: 0.03867753623188406, f_beta: 0.04181547619047618\n",
      "train: step: 278, loss: 2.332301139831543, acc: 0.21875, recall: 0.06919642857142858, precision: 0.0326672335600907, f_beta: 0.03908730158730159\n",
      "train: step: 279, loss: 2.169910430908203, acc: 0.171875, recall: 0.06006493506493507, precision: 0.022393048128342245, f_beta: 0.02814516129032258\n",
      "train: step: 280, loss: 2.413377523422241, acc: 0.203125, recall: 0.07291666666666667, precision: 0.055113636363636365, f_beta: 0.044024926686217006\n",
      "train: step: 281, loss: 2.2535367012023926, acc: 0.203125, recall: 0.05476190476190476, precision: 0.026860587002096436, f_beta: 0.03109015345268542\n",
      "train: step: 282, loss: 2.238098621368408, acc: 0.28125, recall: 0.07424428104575163, precision: 0.059998037676609106, f_beta: 0.048701298701298704\n",
      "train: step: 283, loss: 2.2823405265808105, acc: 0.15625, recall: 0.06032986111111111, precision: 0.025300171526586618, f_beta: 0.02800179211469534\n",
      "train: step: 284, loss: 2.4022181034088135, acc: 0.171875, recall: 0.049107142857142856, precision: 0.012971698113207548, f_beta: 0.020522388059701493\n",
      "train: step: 285, loss: 2.27990460395813, acc: 0.203125, recall: 0.07959401709401709, precision: 0.08829941860465117, f_beta: 0.04826631701631702\n",
      "train: step: 286, loss: 2.3872623443603516, acc: 0.171875, recall: 0.05889423076923077, precision: 0.019728535353535352, f_beta: 0.029352226720647773\n",
      "train: step: 287, loss: 2.417579174041748, acc: 0.203125, recall: 0.06339285714285714, precision: 0.024616368286445013, f_beta: 0.034722222222222224\n",
      "train: step: 288, loss: 2.146533966064453, acc: 0.234375, recall: 0.06380208333333333, precision: 0.047226914414414414, f_beta: 0.04469339622641509\n",
      "train: step: 289, loss: 2.2591300010681152, acc: 0.21875, recall: 0.06875, precision: 0.028943452380952382, f_beta: 0.0406158357771261\n",
      "train: step: 290, loss: 2.280695915222168, acc: 0.125, recall: 0.04144385026737968, precision: 0.040865384615384616, f_beta: 0.026904761904761904\n",
      "train: step: 291, loss: 2.4251174926757812, acc: 0.203125, recall: 0.060227272727272727, precision: 0.026923076923076925, f_beta: 0.03696236559139785\n",
      "train: step: 292, loss: 2.3378148078918457, acc: 0.1875, recall: 0.08333333333333333, precision: 0.05119047619047619, f_beta: 0.052612481857764876\n",
      "train: step: 293, loss: 2.3466997146606445, acc: 0.203125, recall: 0.07351190476190476, precision: 0.03689713064713065, f_beta: 0.047625517598343686\n",
      "train: step: 294, loss: 2.4478297233581543, acc: 0.140625, recall: 0.07013125763125763, precision: 0.030895390070921985, f_beta: 0.033091787439613524\n",
      "train: step: 295, loss: 2.288905143737793, acc: 0.15625, recall: 0.05022321428571429, precision: 0.02909919028340081, f_beta: 0.03537545787545788\n",
      "train: step: 296, loss: 2.198235034942627, acc: 0.1875, recall: 0.05823863636363637, precision: 0.04010416666666666, f_beta: 0.04367623117623118\n",
      "train: step: 297, loss: 2.4470582008361816, acc: 0.171875, recall: 0.03618421052631579, precision: 0.01636904761904762, f_beta: 0.02254098360655738\n",
      "train: step: 298, loss: 2.2436251640319824, acc: 0.21875, recall: 0.07142857142857142, precision: 0.034345238095238095, f_beta: 0.03931704260651629\n",
      "train: step: 299, loss: 2.250945568084717, acc: 0.203125, recall: 0.07514880952380952, precision: 0.029947916666666664, f_beta: 0.03958333333333333\n",
      "train: step: 300, loss: 2.2409400939941406, acc: 0.171875, recall: 0.049107142857142856, precision: 0.020067401960784312, f_beta: 0.024912587412587416\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:31:59.994649, step: 300, loss: 2.239238421122233, acc: 0.24131944444444445,precision: 0.0625, recall: 0.015141024581128747, f_beta: 0.02416050660865633\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-300\n",
      "\n",
      "train: step: 301, loss: 2.2972538471221924, acc: 0.203125, recall: 0.0739889705882353, precision: 0.0828125, f_beta: 0.035590277777777776\n",
      "train: step: 302, loss: 2.2214107513427734, acc: 0.25, recall: 0.08762792397660818, precision: 0.09313725490196079, f_beta: 0.0625\n",
      "train: step: 303, loss: 2.4952244758605957, acc: 0.1875, recall: 0.07916666666666666, precision: 0.05266106442577031, f_beta: 0.048124211853720046\n",
      "train: step: 304, loss: 2.333404302597046, acc: 0.234375, recall: 0.0703125, precision: 0.03371212121212121, f_beta: 0.04432700603968939\n",
      "train: step: 305, loss: 2.158381462097168, acc: 0.25, recall: 0.0625, precision: 0.03708333333333333, f_beta: 0.03962121212121213\n",
      "train: step: 306, loss: 2.3474340438842773, acc: 0.1875, recall: 0.05714285714285715, precision: 0.04142992424242424, f_beta: 0.03636487751599314\n",
      "train: step: 307, loss: 2.3659517765045166, acc: 0.1875, recall: 0.05714285714285715, precision: 0.02142857142857143, f_beta: 0.029947916666666664\n",
      "train: step: 308, loss: 2.27219820022583, acc: 0.125, recall: 0.041666666666666664, precision: 0.017594108019639933, f_beta: 0.02271186440677966\n",
      "train: step: 309, loss: 2.2471704483032227, acc: 0.140625, recall: 0.04971590909090909, precision: 0.018939393939393936, f_beta: 0.026136363636363638\n",
      "train: step: 310, loss: 2.390559673309326, acc: 0.125, recall: 0.05625, precision: 0.01568627450980392, f_beta: 0.02452153110047847\n",
      "train: step: 311, loss: 2.2539868354797363, acc: 0.15625, recall: 0.04296875, precision: 0.01946022727272727, f_beta: 0.026654411764705878\n",
      "train: step: 312, loss: 2.224012851715088, acc: 0.28125, recall: 0.09305798368298368, precision: 0.05577956989247311, f_beta: 0.05823643410852712\n",
      "train: step: 313, loss: 2.206864356994629, acc: 0.234375, recall: 0.06944444444444445, precision: 0.028633004926108374, f_beta: 0.040032274081429994\n",
      "train: step: 314, loss: 2.166475534439087, acc: 0.21875, recall: 0.05915178571428571, precision: 0.056654911180773246, f_beta: 0.041532540795512496\n",
      "train: step: 315, loss: 2.236865282058716, acc: 0.25, recall: 0.078125, precision: 0.030049261083743842, f_beta: 0.04292527821939586\n",
      "train: step: 316, loss: 2.3066587448120117, acc: 0.234375, recall: 0.07788461538461539, precision: 0.04707080200501253, f_beta: 0.047546419098143236\n",
      "train: step: 317, loss: 2.4440560340881348, acc: 0.171875, recall: 0.0625, precision: 0.018042452830188682, f_beta: 0.025483630952380952\n",
      "train: step: 318, loss: 2.405791759490967, acc: 0.3125, recall: 0.10885416666666665, precision: 0.07625891265597148, f_beta: 0.07013656633221851\n",
      "train: step: 319, loss: 2.278834342956543, acc: 0.203125, recall: 0.06103896103896104, precision: 0.040268685215493726, f_beta: 0.03690433764382446\n",
      "train: step: 320, loss: 1.9682626724243164, acc: 0.25, recall: 0.06666666666666667, precision: 0.06300133689839572, f_beta: 0.04607497387669801\n",
      "train: step: 321, loss: 2.406106472015381, acc: 0.140625, recall: 0.046274038461538464, precision: 0.015485739750445633, f_beta: 0.022203947368421052\n",
      "train: step: 322, loss: 2.439033269882202, acc: 0.21875, recall: 0.055989583333333336, precision: 0.030671296296296294, f_beta: 0.03102678571428571\n",
      "train: step: 323, loss: 2.328874349594116, acc: 0.203125, recall: 0.057738095238095234, precision: 0.02855603448275862, f_beta: 0.02741228070175438\n",
      "train: step: 324, loss: 2.2184386253356934, acc: 0.359375, recall: 0.0625, precision: 0.022817460317460316, f_beta: 0.03343023255813953\n",
      "train: step: 325, loss: 2.237415075302124, acc: 0.25, recall: 0.07291666666666667, precision: 0.07684426229508197, f_beta: 0.041190476190476194\n",
      "train: step: 326, loss: 2.2648255825042725, acc: 0.203125, recall: 0.0625, precision: 0.01331967213114754, f_beta: 0.021959459459459457\n",
      "train: step: 327, loss: 2.386807441711426, acc: 0.203125, recall: 0.0625, precision: 0.0126953125, f_beta: 0.021103896103896104\n",
      "train: step: 328, loss: 2.402493953704834, acc: 0.203125, recall: 0.0625, precision: 0.0126953125, f_beta: 0.021103896103896104\n",
      "train: step: 329, loss: 2.3384101390838623, acc: 0.1875, recall: 0.0625, precision: 0.011904761904761904, f_beta: 0.02\n",
      "train: step: 330, loss: 2.485069513320923, acc: 0.1875, recall: 0.0625, precision: 0.011904761904761904, f_beta: 0.02\n",
      "train: step: 331, loss: 2.1280155181884766, acc: 0.203125, recall: 0.05803571428571429, precision: 0.01310483870967742, f_beta: 0.02138157894736842\n",
      "train: step: 332, loss: 2.1479227542877197, acc: 0.25, recall: 0.058823529411764705, precision: 0.01639344262295082, f_beta: 0.02564102564102564\n",
      "train: step: 333, loss: 2.271209716796875, acc: 0.234375, recall: 0.06765109890109891, precision: 0.04479166666666667, f_beta: 0.03666534181240064\n",
      "train: step: 334, loss: 2.1654772758483887, acc: 0.25, recall: 0.05555555555555555, precision: 0.01694915254237288, f_beta: 0.025974025974025976\n",
      "train: step: 335, loss: 2.3481688499450684, acc: 0.234375, recall: 0.0763888888888889, precision: 0.045021186440677964, f_beta: 0.04180021367521367\n",
      "train: step: 336, loss: 2.4085841178894043, acc: 0.109375, recall: 0.0546875, precision: 0.007291666666666667, f_beta: 0.012867647058823529\n",
      "start training model\n",
      "train: step: 337, loss: 2.434267997741699, acc: 0.171875, recall: 0.05375874125874126, precision: 0.021192528735632182, f_beta: 0.024958574979287492\n",
      "train: step: 338, loss: 2.323974132537842, acc: 0.203125, recall: 0.0578125, precision: 0.021205357142857144, f_beta: 0.02893926056338028\n",
      "train: step: 339, loss: 2.300652503967285, acc: 0.203125, recall: 0.0733901515151515, precision: 0.08370535714285715, f_beta: 0.03708221711953055\n",
      "train: step: 340, loss: 2.2611277103424072, acc: 0.21875, recall: 0.07589285714285714, precision: 0.04915254237288136, f_beta: 0.0393796992481203\n",
      "train: step: 341, loss: 2.2758255004882812, acc: 0.1875, recall: 0.05357142857142857, precision: 0.018653516295025728, f_beta: 0.025522388059701494\n",
      "train: step: 342, loss: 2.1379129886627197, acc: 0.171875, recall: 0.061553030303030304, precision: 0.020178571428571428, f_beta: 0.028058007566204288\n",
      "train: step: 343, loss: 2.1443347930908203, acc: 0.28125, recall: 0.07219251336898395, precision: 0.03365384615384615, f_beta: 0.043478260869565216\n",
      "train: step: 344, loss: 2.2002480030059814, acc: 0.1875, recall: 0.05133928571428571, precision: 0.02976190476190476, f_beta: 0.031705373406193074\n",
      "train: step: 345, loss: 2.5774779319763184, acc: 0.15625, recall: 0.0763888888888889, precision: 0.07901315789473684, f_beta: 0.04026356919579426\n",
      "train: step: 346, loss: 2.24569034576416, acc: 0.21875, recall: 0.06944444444444445, precision: 0.02530364372469636, f_beta: 0.03627232142857143\n",
      "train: step: 347, loss: 2.278717041015625, acc: 0.203125, recall: 0.06696428571428571, precision: 0.025894657258064516, f_beta: 0.0371031746031746\n",
      "train: step: 348, loss: 2.1369450092315674, acc: 0.265625, recall: 0.07142857142857142, precision: 0.06152027027027027, f_beta: 0.05449039264828739\n",
      "train: step: 349, loss: 2.2818706035614014, acc: 0.203125, recall: 0.05993589743589743, precision: 0.02567219679633867, f_beta: 0.035216718266253874\n",
      "train: step: 350, loss: 2.268256425857544, acc: 0.203125, recall: 0.058333333333333334, precision: 0.023526887871853547, f_beta: 0.03351915380217267\n",
      "train: step: 351, loss: 2.419116973876953, acc: 0.140625, recall: 0.06477272727272727, precision: 0.01614583333333333, f_beta: 0.025777552400270454\n",
      "train: step: 352, loss: 2.380791425704956, acc: 0.109375, recall: 0.04142385392385392, precision: 0.033035714285714286, f_beta: 0.025949754901960786\n",
      "train: step: 353, loss: 2.4714975357055664, acc: 0.140625, recall: 0.05795454545454545, precision: 0.014917380660954712, f_beta: 0.02372685185185185\n",
      "train: step: 354, loss: 2.1560096740722656, acc: 0.28125, recall: 0.075, precision: 0.03797846889952153, f_beta: 0.049592044875063745\n",
      "train: step: 355, loss: 2.4295310974121094, acc: 0.203125, recall: 0.07256944444444445, precision: 0.03482142857142857, f_beta: 0.04364583333333333\n",
      "train: step: 356, loss: 2.208357334136963, acc: 0.265625, recall: 0.0523989898989899, precision: 0.0260899814471243, f_beta: 0.03441901408450704\n",
      "train: step: 357, loss: 2.352837562561035, acc: 0.203125, recall: 0.05520833333333334, precision: 0.02232142857142857, f_beta: 0.027705707931801334\n",
      "train: step: 358, loss: 2.4775190353393555, acc: 0.140625, recall: 0.0625, precision: 0.009868421052631578, f_beta: 0.017045454545454544\n",
      "train: step: 359, loss: 2.3288073539733887, acc: 0.28125, recall: 0.09375, precision: 0.06799242424242424, f_beta: 0.0642512077294686\n",
      "train: step: 360, loss: 2.218855857849121, acc: 0.203125, recall: 0.05803571428571429, precision: 0.01331967213114754, f_beta: 0.021666666666666664\n",
      "train: step: 361, loss: 2.4024465084075928, acc: 0.171875, recall: 0.0625, precision: 0.011270491803278689, f_beta: 0.019097222222222224\n",
      "train: step: 362, loss: 2.347531795501709, acc: 0.1875, recall: 0.07298951048951048, precision: 0.06267655367231638, f_beta: 0.03554382664437013\n",
      "train: step: 363, loss: 2.3856797218322754, acc: 0.171875, recall: 0.057291666666666664, precision: 0.011270491803278689, f_beta: 0.018835616438356163\n",
      "train: step: 364, loss: 2.2164440155029297, acc: 0.265625, recall: 0.06944444444444445, precision: 0.03229166666666666, f_beta: 0.035931174089068825\n",
      "train: step: 365, loss: 2.4807214736938477, acc: 0.171875, recall: 0.0625, precision: 0.011270491803278689, f_beta: 0.019097222222222224\n",
      "train: step: 366, loss: 2.215139865875244, acc: 0.21875, recall: 0.06197916666666667, precision: 0.02199074074074074, f_beta: 0.03090366581415175\n",
      "train: step: 367, loss: 2.2028896808624268, acc: 0.265625, recall: 0.09140625, precision: 0.10738636363636364, f_beta: 0.0575187786557409\n",
      "train: step: 368, loss: 2.303551197052002, acc: 0.234375, recall: 0.057720588235294114, precision: 0.022838680926916224, f_beta: 0.03168767507002801\n",
      "train: step: 369, loss: 2.3094048500061035, acc: 0.171875, recall: 0.06442307692307693, precision: 0.023392857142857142, f_beta: 0.030555555555555558\n",
      "train: step: 370, loss: 2.2581558227539062, acc: 0.234375, recall: 0.06039915966386554, precision: 0.02377136752136752, f_beta: 0.03317481884057971\n",
      "train: step: 371, loss: 2.3165476322174072, acc: 0.203125, recall: 0.05476190476190476, precision: 0.025980392156862746, f_beta: 0.03125\n",
      "train: step: 372, loss: 2.36181640625, acc: 0.234375, recall: 0.08447802197802198, precision: 0.030625, f_beta: 0.043546365914786965\n",
      "train: step: 373, loss: 2.247249126434326, acc: 0.203125, recall: 0.07095588235294117, precision: 0.027853260869565216, f_beta: 0.035240800865800864\n",
      "train: step: 374, loss: 2.2215399742126465, acc: 0.21875, recall: 0.06990275349650349, precision: 0.09344951923076923, f_beta: 0.0466288974606236\n",
      "train: step: 375, loss: 2.419804573059082, acc: 0.171875, recall: 0.06875, precision: 0.020040760869565216, f_beta: 0.029704670329670328\n",
      "train: step: 376, loss: 2.253492832183838, acc: 0.25, recall: 0.08649553571428571, precision: 0.037811147186147184, f_beta: 0.04722222222222223\n",
      "train: step: 377, loss: 2.2947494983673096, acc: 0.296875, recall: 0.08234126984126984, precision: 0.04195601851851852, f_beta: 0.05277777777777777\n",
      "train: step: 378, loss: 2.2073235511779785, acc: 0.1875, recall: 0.057692307692307696, precision: 0.025, f_beta: 0.027165032679738563\n",
      "train: step: 379, loss: 2.277294635772705, acc: 0.296875, recall: 0.08958333333333333, precision: 0.05048076923076923, f_beta: 0.05805759803921569\n",
      "train: step: 380, loss: 2.343547821044922, acc: 0.25, recall: 0.05961134453781512, precision: 0.032670454545454544, f_beta: 0.03298611111111111\n",
      "train: step: 381, loss: 2.3404078483581543, acc: 0.171875, recall: 0.07142857142857142, precision: 0.041294642857142856, f_beta: 0.031196581196581197\n",
      "train: step: 382, loss: 2.3186116218566895, acc: 0.21875, recall: 0.07651515151515151, precision: 0.07571737421383648, f_beta: 0.051203855994152045\n",
      "train: step: 383, loss: 2.193476915359497, acc: 0.234375, recall: 0.0609375, precision: 0.030455508474576273, f_beta: 0.03226190476190476\n",
      "train: step: 384, loss: 2.226027011871338, acc: 0.265625, recall: 0.07188813025210083, precision: 0.048295454545454544, f_beta: 0.04747023809523809\n",
      "train: step: 385, loss: 2.347830295562744, acc: 0.171875, recall: 0.0625, precision: 0.01206140350877193, f_beta: 0.02022058823529412\n",
      "train: step: 386, loss: 2.297919988632202, acc: 0.171875, recall: 0.057291666666666664, precision: 0.011088709677419355, f_beta: 0.018581081081081082\n",
      "train: step: 387, loss: 2.2086892127990723, acc: 0.15625, recall: 0.07236842105263158, precision: 0.028935185185185182, f_beta: 0.02773711943793911\n",
      "train: step: 388, loss: 2.311068296432495, acc: 0.203125, recall: 0.06538461538461539, precision: 0.02433533447684391, f_beta: 0.03273809523809524\n",
      "train: step: 389, loss: 2.1016526222229004, acc: 0.234375, recall: 0.05563725490196078, precision: 0.022759433962264153, f_beta: 0.030000000000000002\n",
      "train: step: 390, loss: 2.326777219772339, acc: 0.234375, recall: 0.07266483516483516, precision: 0.08786337209302325, f_beta: 0.045551378446115294\n",
      "train: step: 391, loss: 2.086338996887207, acc: 0.25, recall: 0.09015984015984016, precision: 0.05894607843137255, f_beta: 0.05110245358090186\n",
      "train: step: 392, loss: 2.325390100479126, acc: 0.171875, recall: 0.07133838383838384, precision: 0.02310107655502392, f_beta: 0.03317610062893082\n",
      "train: step: 393, loss: 2.287487745285034, acc: 0.234375, recall: 0.07998251748251749, precision: 0.02909159159159159, f_beta: 0.0421875\n",
      "train: step: 394, loss: 2.301677942276001, acc: 0.1875, recall: 0.06971153846153845, precision: 0.0846590909090909, f_beta: 0.041472530589093275\n",
      "train: step: 395, loss: 2.2887229919433594, acc: 0.25, recall: 0.0765625, precision: 0.0939670138888889, f_beta: 0.05705582833242407\n",
      "train: step: 396, loss: 2.1423583030700684, acc: 0.296875, recall: 0.09147727272727274, precision: 0.06286706349206349, f_beta: 0.07143306096794469\n",
      "train: step: 397, loss: 2.068950891494751, acc: 0.1875, recall: 0.047619047619047616, precision: 0.02746212121212121, f_beta: 0.03375\n",
      "train: step: 398, loss: 2.436030387878418, acc: 0.15625, recall: 0.0732142857142857, precision: 0.026102941176470586, f_beta: 0.03719512195121952\n",
      "train: step: 399, loss: 2.211993455886841, acc: 0.203125, recall: 0.07905505952380952, precision: 0.04036458333333333, f_beta: 0.04935581140350877\n",
      "train: step: 400, loss: 2.35439395904541, acc: 0.171875, recall: 0.055989583333333336, precision: 0.036458333333333336, f_beta: 0.03720394736842106\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:33:51.404417, step: 400, loss: 2.238522662056817, acc: 0.16493055555555555,precision: 0.06463349748066596, recall: 0.04860149648181736, f_beta: 0.03391795513785923\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-400\n",
      "\n",
      "train: step: 401, loss: 2.361137866973877, acc: 0.171875, recall: 0.06684981684981685, precision: 0.03660714285714286, f_beta: 0.04427865365365366\n",
      "train: step: 402, loss: 2.3240702152252197, acc: 0.203125, recall: 0.07024147727272727, precision: 0.03705213903743316, f_beta: 0.04806286549707602\n",
      "train: step: 403, loss: 2.405768394470215, acc: 0.1875, recall: 0.08645833333333333, precision: 0.039042207792207795, f_beta: 0.04954268292682927\n",
      "train: step: 404, loss: 2.2260282039642334, acc: 0.265625, recall: 0.08380325814536341, precision: 0.04671474358974359, f_beta: 0.05899556792413935\n",
      "train: step: 405, loss: 2.2017717361450195, acc: 0.171875, recall: 0.0661907536907537, precision: 0.03236303312159709, f_beta: 0.04187840290381125\n",
      "train: step: 406, loss: 2.334918975830078, acc: 0.203125, recall: 0.0630952380952381, precision: 0.03321158008658009, f_beta: 0.043372555340640453\n",
      "train: step: 407, loss: 2.250617027282715, acc: 0.21875, recall: 0.07291666666666666, precision: 0.04635078463203463, f_beta: 0.05474386724386725\n",
      "train: step: 408, loss: 2.419386386871338, acc: 0.171875, recall: 0.05823863636363637, precision: 0.02558139534883721, f_beta: 0.03235930735930736\n",
      "train: step: 409, loss: 2.0715911388397217, acc: 0.234375, recall: 0.05198863636363636, precision: 0.03118070953436807, f_beta: 0.03800298062593145\n",
      "train: step: 410, loss: 2.273012161254883, acc: 0.234375, recall: 0.06799450549450549, precision: 0.04178571428571429, f_beta: 0.042187499999999996\n",
      "train: step: 411, loss: 2.082324981689453, acc: 0.328125, recall: 0.07767857142857143, precision: 0.04366987179487179, f_beta: 0.050878588840736726\n",
      "train: step: 412, loss: 2.176309108734131, acc: 0.234375, recall: 0.07343749999999999, precision: 0.08519345238095238, f_beta: 0.046609477124183\n",
      "train: step: 413, loss: 2.3521084785461426, acc: 0.203125, recall: 0.07410714285714286, precision: 0.05153508771929824, f_beta: 0.041791044776119404\n",
      "train: step: 414, loss: 2.277939558029175, acc: 0.296875, recall: 0.1029040404040404, precision: 0.10653409090909091, f_beta: 0.06666666666666667\n",
      "train: step: 415, loss: 2.3981597423553467, acc: 0.234375, recall: 0.06862745098039215, precision: 0.02734375, f_beta: 0.03888888888888889\n",
      "train: step: 416, loss: 2.4094467163085938, acc: 0.140625, recall: 0.06056547619047619, precision: 0.04693627450980392, f_beta: 0.03298160173160173\n",
      "train: step: 417, loss: 2.2010862827301025, acc: 0.3125, recall: 0.10890151515151515, precision: 0.06972163865546219, f_beta: 0.06483134920634921\n",
      "train: step: 418, loss: 2.0927436351776123, acc: 0.296875, recall: 0.09111721611721613, precision: 0.06743077324973876, f_beta: 0.05931932191662342\n",
      "train: step: 419, loss: 2.188472032546997, acc: 0.21875, recall: 0.0726461038961039, precision: 0.036627953384418904, f_beta: 0.04672665321380132\n",
      "train: step: 420, loss: 2.315481662750244, acc: 0.1875, recall: 0.07265625, precision: 0.025948660714285716, f_beta: 0.03570331695331696\n",
      "start training model\n",
      "train: step: 421, loss: 2.120244264602661, acc: 0.3125, recall: 0.08984375, precision: 0.044642857142857144, f_beta: 0.059375000000000004\n",
      "train: step: 422, loss: 2.0430595874786377, acc: 0.328125, recall: 0.0963031045751634, precision: 0.05990783410138249, f_beta: 0.06998960626069942\n",
      "train: step: 423, loss: 2.216991901397705, acc: 0.1875, recall: 0.06985294117647059, precision: 0.03938230994152046, f_beta: 0.04348214285714286\n",
      "train: step: 424, loss: 2.2045271396636963, acc: 0.296875, recall: 0.10232683982683982, precision: 0.05625, f_beta: 0.0691742654508612\n",
      "train: step: 425, loss: 2.500659942626953, acc: 0.1875, recall: 0.09322916666666667, precision: 0.03128551136363636, f_beta: 0.04563492063492064\n",
      "train: step: 426, loss: 2.160019874572754, acc: 0.203125, recall: 0.08707264957264957, precision: 0.03553921568627451, f_beta: 0.05029445288753799\n",
      "train: step: 427, loss: 2.290389060974121, acc: 0.359375, recall: 0.12509920634920635, precision: 0.07163078149920254, f_beta: 0.08884615384615385\n",
      "train: step: 428, loss: 2.273021697998047, acc: 0.296875, recall: 0.125, precision: 0.05878310844577711, f_beta: 0.07575187969924811\n",
      "train: step: 429, loss: 2.172715187072754, acc: 0.28125, recall: 0.10993378879892038, precision: 0.10648148148148148, f_beta: 0.08638833992094862\n",
      "train: step: 430, loss: 2.221073627471924, acc: 0.234375, recall: 0.09761904761904762, precision: 0.045617335562987735, f_beta: 0.06018518518518519\n",
      "train: step: 431, loss: 2.1873936653137207, acc: 0.328125, recall: 0.10440340909090909, precision: 0.06031468531468531, f_beta: 0.06710977701543738\n",
      "train: step: 432, loss: 2.1606662273406982, acc: 0.296875, recall: 0.11185064935064935, precision: 0.05064655172413793, f_beta: 0.06282894736842107\n",
      "train: step: 433, loss: 2.068051815032959, acc: 0.296875, recall: 0.09164663461538461, precision: 0.054766414141414144, f_beta: 0.06107456140350877\n",
      "train: step: 434, loss: 2.122903347015381, acc: 0.25, recall: 0.09166666666666667, precision: 0.032058823529411765, f_beta: 0.046741277156023706\n",
      "train: step: 435, loss: 2.1767873764038086, acc: 0.375, recall: 0.10714285714285715, precision: 0.04434974747474747, f_beta: 0.0626984126984127\n",
      "train: step: 436, loss: 2.0273265838623047, acc: 0.34375, recall: 0.08829365079365079, precision: 0.04860248447204969, f_beta: 0.06110004977600796\n",
      "train: step: 437, loss: 2.147238254547119, acc: 0.203125, recall: 0.08806818181818182, precision: 0.024255952380952378, f_beta: 0.03800798258345428\n",
      "train: step: 438, loss: 2.1798453330993652, acc: 0.234375, recall: 0.08697916666666666, precision: 0.04601094470046083, f_beta: 0.05085117585117585\n",
      "train: step: 439, loss: 2.1869938373565674, acc: 0.25, recall: 0.10401785714285715, precision: 0.051747311827956985, f_beta: 0.060918522267206475\n",
      "train: step: 440, loss: 2.006646156311035, acc: 0.390625, recall: 0.1125, precision: 0.06191176470588236, f_beta: 0.07537737317149082\n",
      "train: step: 441, loss: 1.9291692972183228, acc: 0.421875, recall: 0.11389652014652016, precision: 0.06745689655172413, f_beta: 0.0822172619047619\n",
      "train: step: 442, loss: 2.2419395446777344, acc: 0.296875, recall: 0.10795454545454546, precision: 0.04048216276477146, f_beta: 0.05808823529411764\n",
      "train: step: 443, loss: 1.9522651433944702, acc: 0.4375, recall: 0.10648466117216118, precision: 0.0856456043956044, f_beta: 0.08249771062271062\n",
      "train: step: 444, loss: 1.9434096813201904, acc: 0.359375, recall: 0.1, precision: 0.049216830466830466, f_beta: 0.06471913089560148\n",
      "train: step: 445, loss: 2.065199851989746, acc: 0.3125, recall: 0.1, precision: 0.041666666666666664, f_beta: 0.058823529411764705\n",
      "train: step: 446, loss: 2.298063039779663, acc: 0.21875, recall: 0.0797275641025641, precision: 0.08814264112903225, f_beta: 0.047435897435897434\n",
      "train: step: 447, loss: 2.579033851623535, acc: 0.1875, recall: 0.0859375, precision: 0.023726851851851853, f_beta: 0.03677825552825553\n",
      "train: step: 448, loss: 2.288377285003662, acc: 0.21875, recall: 0.09807692307692309, precision: 0.029464285714285714, f_beta: 0.042987804878048784\n",
      "train: step: 449, loss: 2.217587947845459, acc: 0.328125, recall: 0.10576923076923077, precision: 0.05517857142857143, f_beta: 0.06586021505376344\n",
      "train: step: 450, loss: 2.315572738647461, acc: 0.234375, recall: 0.08610660173160173, precision: 0.09453125, f_beta: 0.05803571428571429\n",
      "train: step: 451, loss: 2.0457448959350586, acc: 0.421875, recall: 0.12211538461538463, precision: 0.10048558897243108, f_beta: 0.08928810160427808\n",
      "train: step: 452, loss: 2.3194739818573, acc: 0.234375, recall: 0.08645833333333333, precision: 0.030715811965811964, f_beta: 0.044765446224256294\n",
      "train: step: 453, loss: 2.1052141189575195, acc: 0.296875, recall: 0.08660714285714285, precision: 0.059503335417969566, f_beta: 0.06494360902255639\n",
      "train: step: 454, loss: 2.2057714462280273, acc: 0.296875, recall: 0.09212662337662338, precision: 0.04971590909090909, f_beta: 0.060625937031484264\n",
      "train: step: 455, loss: 2.1656646728515625, acc: 0.25, recall: 0.07692307692307693, precision: 0.037631381381381376, f_beta: 0.049871499468273656\n",
      "train: step: 456, loss: 1.9272022247314453, acc: 0.359375, recall: 0.10141941391941392, precision: 0.0731060606060606, f_beta: 0.08284585385878487\n",
      "train: step: 457, loss: 2.100552558898926, acc: 0.265625, recall: 0.09937718531468531, precision: 0.04950453192640693, f_beta: 0.06359717868338557\n",
      "train: step: 458, loss: 2.1626195907592773, acc: 0.3125, recall: 0.10707720588235295, precision: 0.059375, f_beta: 0.07442719881744272\n",
      "train: step: 459, loss: 2.16935658454895, acc: 0.25, recall: 0.0843648538961039, precision: 0.039298384661835745, f_beta: 0.0515625\n",
      "train: step: 460, loss: 2.1602847576141357, acc: 0.3125, recall: 0.12181372549019608, precision: 0.06729166666666667, f_beta: 0.059971678977381454\n",
      "train: step: 461, loss: 2.411904811859131, acc: 0.21875, recall: 0.09715909090909092, precision: 0.039641203703703706, f_beta: 0.055714700875991195\n",
      "train: step: 462, loss: 1.9904664754867554, acc: 0.390625, recall: 0.10107399910031489, precision: 0.06527777777777778, f_beta: 0.07871970983176416\n",
      "train: step: 463, loss: 2.2947285175323486, acc: 0.25, recall: 0.10989583333333333, precision: 0.045970695970695974, f_beta: 0.06359717868338559\n",
      "train: step: 464, loss: 2.0812835693359375, acc: 0.3125, recall: 0.1177156177156177, precision: 0.06376262626262626, f_beta: 0.07532991202346041\n",
      "train: step: 465, loss: 2.1747941970825195, acc: 0.296875, recall: 0.08868371212121212, precision: 0.05067016317016317, f_beta: 0.05878723110865968\n",
      "train: step: 466, loss: 2.2741570472717285, acc: 0.265625, recall: 0.09877232142857142, precision: 0.04434523809523809, f_beta: 0.058117677915719534\n",
      "train: step: 467, loss: 2.155052661895752, acc: 0.25, recall: 0.10612824675324675, precision: 0.04255952380952381, f_beta: 0.0555672268907563\n",
      "train: step: 468, loss: 2.1321606636047363, acc: 0.265625, recall: 0.09542540792540793, precision: 0.04698275862068965, f_beta: 0.05731124686716792\n",
      "train: step: 469, loss: 2.062150239944458, acc: 0.28125, recall: 0.11378968253968255, precision: 0.054080617658203864, f_beta: 0.06575091575091574\n",
      "train: step: 470, loss: 2.117331027984619, acc: 0.296875, recall: 0.0818452380952381, precision: 0.04915752351097179, f_beta: 0.06132665832290363\n",
      "train: step: 471, loss: 2.059694528579712, acc: 0.25, recall: 0.09047619047619047, precision: 0.03333333333333333, f_beta: 0.04817708333333333\n",
      "train: step: 472, loss: 2.3916993141174316, acc: 0.203125, recall: 0.09226190476190475, precision: 0.05448717948717948, f_beta: 0.04905437352245863\n",
      "train: step: 473, loss: 1.9346916675567627, acc: 0.34375, recall: 0.1175820707070707, precision: 0.09366183385579938, f_beta: 0.09268483709273183\n",
      "train: step: 474, loss: 2.3036911487579346, acc: 0.234375, recall: 0.08759469696969698, precision: 0.04037698412698412, f_beta: 0.05362318840579709\n",
      "train: step: 475, loss: 2.1829147338867188, acc: 0.234375, recall: 0.11041666666666666, precision: 0.0531517094017094, f_beta: 0.06237060041407867\n",
      "train: step: 476, loss: 2.4467592239379883, acc: 0.15625, recall: 0.06882440476190477, precision: 0.03428819444444445, f_beta: 0.040074110671936766\n",
      "train: step: 477, loss: 2.287609100341797, acc: 0.25, recall: 0.12301587301587302, precision: 0.05602678571428571, f_beta: 0.07008838017965807\n",
      "train: step: 478, loss: 2.189255475997925, acc: 0.25, recall: 0.10360863095238095, precision: 0.06392045454545454, f_beta: 0.07478059772296015\n",
      "train: step: 479, loss: 2.063732147216797, acc: 0.359375, recall: 0.12118055555555556, precision: 0.07178819444444444, f_beta: 0.08561901504787961\n",
      "train: step: 480, loss: 2.3165225982666016, acc: 0.203125, recall: 0.09053030303030303, precision: 0.06162464985994398, f_beta: 0.061512445887445893\n",
      "train: step: 481, loss: 2.1081552505493164, acc: 0.265625, recall: 0.078125, precision: 0.0564935064935065, f_beta: 0.06439393939393939\n",
      "train: step: 482, loss: 2.1849164962768555, acc: 0.28125, recall: 0.10881696428571429, precision: 0.07455882352941176, f_beta: 0.0799062180703547\n",
      "train: step: 483, loss: 2.211496591567993, acc: 0.265625, recall: 0.1071969696969697, precision: 0.12276785714285714, f_beta: 0.08484313430842183\n",
      "train: step: 484, loss: 2.1370744705200195, acc: 0.28125, recall: 0.10207847707847709, precision: 0.05485452245414295, f_beta: 0.06964285714285715\n",
      "train: step: 485, loss: 2.26196026802063, acc: 0.171875, recall: 0.06591386554621849, precision: 0.04140625, f_beta: 0.044077255726975226\n",
      "train: step: 486, loss: 1.902592420578003, acc: 0.3125, recall: 0.1, precision: 0.060497835497835495, f_beta: 0.07067307692307692\n",
      "train: step: 487, loss: 2.1922402381896973, acc: 0.28125, recall: 0.10238095238095238, precision: 0.04876612103174603, f_beta: 0.06555966697502312\n",
      "train: step: 488, loss: 2.043783187866211, acc: 0.28125, recall: 0.10692016317016317, precision: 0.11358630952380952, f_beta: 0.08280423280423281\n",
      "train: step: 489, loss: 2.2398993968963623, acc: 0.171875, recall: 0.08828125, precision: 0.03712225274725275, f_beta: 0.04388096222773642\n",
      "train: step: 490, loss: 2.1509714126586914, acc: 0.25, recall: 0.08413461538461539, precision: 0.03995689655172414, f_beta: 0.05327380952380952\n",
      "train: step: 491, loss: 1.9562547206878662, acc: 0.359375, recall: 0.11971153846153847, precision: 0.0678921568627451, f_beta: 0.08332298136645963\n",
      "train: step: 492, loss: 2.120014190673828, acc: 0.3125, recall: 0.10599415204678361, precision: 0.0646701388888889, f_beta: 0.07222222222222222\n",
      "train: step: 493, loss: 2.1638357639312744, acc: 0.25, recall: 0.1087121212121212, precision: 0.06327580574912892, f_beta: 0.06501658659345687\n",
      "train: step: 494, loss: 1.8760299682617188, acc: 0.359375, recall: 0.11454326923076924, precision: 0.07699247542997543, f_beta: 0.08383200354609929\n",
      "train: step: 495, loss: 2.092730760574341, acc: 0.28125, recall: 0.10729166666666667, precision: 0.06529411764705882, f_beta: 0.06296933408316517\n",
      "train: step: 496, loss: 2.2922134399414062, acc: 0.203125, recall: 0.10044642857142858, precision: 0.042538875598086126, f_beta: 0.04867271505376344\n",
      "train: step: 497, loss: 2.1831393241882324, acc: 0.296875, recall: 0.09623579545454546, precision: 0.05629960317460317, f_beta: 0.06836710171183495\n",
      "train: step: 498, loss: 2.3930530548095703, acc: 0.234375, recall: 0.12569444444444444, precision: 0.07259615384615384, f_beta: 0.07488839285714285\n",
      "train: step: 499, loss: 2.0160470008850098, acc: 0.28125, recall: 0.09698426573426575, precision: 0.05606060606060606, f_beta: 0.06866289198606272\n",
      "train: step: 500, loss: 2.305166721343994, acc: 0.21875, recall: 0.09748376623376623, precision: 0.043253722084367244, f_beta: 0.05694526463423635\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:35:43.753963, step: 500, loss: 2.4015560944875083, acc: 0.234375,precision: 0.06995844700630563, recall: 0.04206986356487829, f_beta: 0.043155578248525416\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-500\n",
      "\n",
      "train: step: 501, loss: 2.164942502975464, acc: 0.1875, recall: 0.06151018099547512, precision: 0.03548593350383632, f_beta: 0.043857694592988716\n",
      "train: step: 502, loss: 2.108785390853882, acc: 0.25, recall: 0.09327651515151514, precision: 0.04405100108225109, f_beta: 0.05810629587803501\n",
      "train: step: 503, loss: 2.174426794052124, acc: 0.21875, recall: 0.0832093253968254, precision: 0.042881944444444445, f_beta: 0.05107215299913069\n",
      "train: step: 504, loss: 2.2108495235443115, acc: 0.21875, recall: 0.10445804195804195, precision: 0.10864464482885536, f_beta: 0.06373834498834499\n",
      "start training model\n",
      "train: step: 505, loss: 1.8997464179992676, acc: 0.328125, recall: 0.12864583333333335, precision: 0.07765468227424749, f_beta: 0.0874084249084249\n",
      "train: step: 506, loss: 1.896383285522461, acc: 0.453125, recall: 0.15829831932773109, precision: 0.17006257631257632, f_beta: 0.13392309206811495\n",
      "train: step: 507, loss: 1.851714015007019, acc: 0.296875, recall: 0.11470170454545454, precision: 0.06962481962481962, f_beta: 0.07948709786945081\n",
      "train: step: 508, loss: 2.0772902965545654, acc: 0.28125, recall: 0.10555555555555554, precision: 0.09227807971014493, f_beta: 0.08408521303258144\n",
      "train: step: 509, loss: 1.9498978853225708, acc: 0.234375, recall: 0.10358391608391608, precision: 0.10561342592592593, f_beta: 0.06595872570627129\n",
      "train: step: 510, loss: 1.8464972972869873, acc: 0.453125, recall: 0.1410590277777778, precision: 0.08833333333333333, f_beta: 0.10527839220294463\n",
      "train: step: 511, loss: 2.306662082672119, acc: 0.25, recall: 0.12023809523809523, precision: 0.07908336568322981, f_beta: 0.0768483709273183\n",
      "train: step: 512, loss: 1.8762211799621582, acc: 0.421875, recall: 0.11328125, precision: 0.055360991379310345, f_beta: 0.07415458937198068\n",
      "train: step: 513, loss: 1.8401156663894653, acc: 0.359375, recall: 0.11752136752136752, precision: 0.07652027027027028, f_beta: 0.07487061810370081\n",
      "train: step: 514, loss: 2.1432933807373047, acc: 0.25, recall: 0.09795673076923077, precision: 0.03806818181818182, f_beta: 0.05249169435215947\n",
      "train: step: 515, loss: 2.1617074012756348, acc: 0.21875, recall: 0.14407894736842106, precision: 0.09612068965517241, f_beta: 0.07964015151515151\n",
      "train: step: 516, loss: 1.9562609195709229, acc: 0.296875, recall: 0.11904761904761904, precision: 0.11931818181818181, f_beta: 0.08245206512215497\n",
      "train: step: 517, loss: 1.9714189767837524, acc: 0.34375, recall: 0.11187423687423687, precision: 0.07686011904761904, f_beta: 0.08756309079239118\n",
      "train: step: 518, loss: 1.9990638494491577, acc: 0.296875, recall: 0.10859375, precision: 0.037655279503105585, f_beta: 0.05462184873949579\n",
      "train: step: 519, loss: 1.9216735363006592, acc: 0.359375, recall: 0.12073863636363637, precision: 0.07095135467980296, f_beta: 0.07936373873873875\n",
      "train: step: 520, loss: 1.7058885097503662, acc: 0.421875, recall: 0.11136473820297349, precision: 0.07514880952380952, f_beta: 0.08176659891598916\n",
      "train: step: 521, loss: 2.235654354095459, acc: 0.234375, recall: 0.10503472222222221, precision: 0.05303884711779448, f_beta: 0.057534202235553056\n",
      "train: step: 522, loss: 1.824171781539917, acc: 0.34375, recall: 0.12287087912087913, precision: 0.07946428571428571, f_beta: 0.0900598086124402\n",
      "train: step: 523, loss: 2.1244101524353027, acc: 0.28125, recall: 0.10659722222222223, precision: 0.052714646464646464, f_beta: 0.06782945736434108\n",
      "train: step: 524, loss: 1.9471800327301025, acc: 0.296875, recall: 0.10737179487179488, precision: 0.060069444444444446, f_beta: 0.07069243156199678\n",
      "train: step: 525, loss: 1.862074613571167, acc: 0.40625, recall: 0.1363324175824176, precision: 0.08125, f_beta: 0.09765625\n",
      "train: step: 526, loss: 1.8619418144226074, acc: 0.328125, recall: 0.12678571428571428, precision: 0.06651785714285714, f_beta: 0.08006374963778616\n",
      "train: step: 527, loss: 1.9010316133499146, acc: 0.375, recall: 0.11923076923076922, precision: 0.07137021475256769, f_beta: 0.08344155844155843\n",
      "train: step: 528, loss: 1.9953572750091553, acc: 0.328125, recall: 0.11153846153846153, precision: 0.06403318903318904, f_beta: 0.08075716845878136\n",
      "train: step: 529, loss: 1.734528660774231, acc: 0.359375, recall: 0.1161931818181818, precision: 0.0681469298245614, f_beta: 0.08241758241758243\n",
      "train: step: 530, loss: 1.9540141820907593, acc: 0.328125, recall: 0.14176295518207283, precision: 0.1408174486803519, f_beta: 0.09123046157982638\n",
      "train: step: 531, loss: 2.128645181655884, acc: 0.28125, recall: 0.1016559829059829, precision: 0.0477994227994228, f_beta: 0.06251899984800122\n",
      "train: step: 532, loss: 1.936955213546753, acc: 0.296875, recall: 0.10753968253968255, precision: 0.05348557692307693, f_beta: 0.07025852373148238\n",
      "train: step: 533, loss: 1.8699734210968018, acc: 0.234375, recall: 0.09792780748663102, precision: 0.047935520361990946, f_beta: 0.05556765389082463\n",
      "train: step: 534, loss: 1.9129080772399902, acc: 0.296875, recall: 0.11188811188811189, precision: 0.061439393939393946, f_beta: 0.06726421188630491\n",
      "train: step: 535, loss: 2.0670175552368164, acc: 0.25, recall: 0.10511363636363637, precision: 0.04970397249809015, f_beta: 0.05953379953379954\n",
      "train: step: 536, loss: 1.7941642999649048, acc: 0.4375, recall: 0.1311813186813187, precision: 0.09420955882352941, f_beta: 0.10110107872936408\n",
      "train: step: 537, loss: 1.8789958953857422, acc: 0.3125, recall: 0.12165178571428571, precision: 0.06084077380952381, f_beta: 0.07912504162504162\n",
      "train: step: 538, loss: 2.0638227462768555, acc: 0.328125, recall: 0.11264204545454545, precision: 0.06634615384615385, f_beta: 0.07863984674329502\n",
      "train: step: 539, loss: 1.9075148105621338, acc: 0.3125, recall: 0.12457932692307692, precision: 0.09988755622188905, f_beta: 0.08655094905094907\n",
      "train: step: 540, loss: 1.7988815307617188, acc: 0.40625, recall: 0.14270833333333333, precision: 0.08028985507246378, f_beta: 0.09856442577030813\n",
      "train: step: 541, loss: 1.7991406917572021, acc: 0.4375, recall: 0.13255208333333335, precision: 0.08836236107346164, f_beta: 0.10018115942028985\n",
      "train: step: 542, loss: 1.8864424228668213, acc: 0.375, recall: 0.13541666666666666, precision: 0.07266113516113515, f_beta: 0.09204170233581999\n",
      "train: step: 543, loss: 2.107956647872925, acc: 0.34375, recall: 0.13082837301587302, precision: 0.08437873357228196, f_beta: 0.08368506493506493\n",
      "train: step: 544, loss: 1.9590494632720947, acc: 0.328125, recall: 0.1328125, precision: 0.0671875, f_beta: 0.08484100877192982\n",
      "train: step: 545, loss: 2.0282909870147705, acc: 0.3125, recall: 0.13969017094017094, precision: 0.1654169891640867, f_beta: 0.11729824197120708\n",
      "train: step: 546, loss: 1.9965674877166748, acc: 0.34375, recall: 0.12348484848484848, precision: 0.08341165413533834, f_beta: 0.09063625450180073\n",
      "train: step: 547, loss: 1.9567699432373047, acc: 0.28125, recall: 0.11669580419580419, precision: 0.0669499771062271, f_beta: 0.07243400315208826\n",
      "train: step: 548, loss: 2.0503361225128174, acc: 0.359375, recall: 0.1294642857142857, precision: 0.1180921052631579, f_beta: 0.10615262233925829\n",
      "train: step: 549, loss: 1.8053789138793945, acc: 0.453125, recall: 0.128125, precision: 0.09421296296296297, f_beta: 0.10229856141920095\n",
      "train: step: 550, loss: 1.977980375289917, acc: 0.28125, recall: 0.11464646464646464, precision: 0.06510416666666666, f_beta: 0.0763157894736842\n",
      "train: step: 551, loss: 1.9363707304000854, acc: 0.328125, recall: 0.12026515151515152, precision: 0.05223267622461171, f_beta: 0.06514949729891957\n",
      "train: step: 552, loss: 2.3156075477600098, acc: 0.328125, recall: 0.11591880341880342, precision: 0.07285739687055477, f_beta: 0.07848684210526316\n",
      "train: step: 553, loss: 1.8629333972930908, acc: 0.40625, recall: 0.12723214285714285, precision: 0.09569964349376114, f_beta: 0.10205980532850814\n",
      "train: step: 554, loss: 1.9922077655792236, acc: 0.359375, recall: 0.1205201048951049, precision: 0.06859879032258065, f_beta: 0.08188131313131314\n",
      "train: step: 555, loss: 2.137159824371338, acc: 0.3125, recall: 0.1310096153846154, precision: 0.05760073260073259, f_beta: 0.0751585623678647\n",
      "train: step: 556, loss: 1.7191275358200073, acc: 0.390625, recall: 0.13018048128342247, precision: 0.12645474137931034, f_beta: 0.10095108695652175\n",
      "train: step: 557, loss: 1.9066669940948486, acc: 0.3125, recall: 0.12184343434343434, precision: 0.06563492063492063, f_beta: 0.07861432861432861\n",
      "train: step: 558, loss: 1.806179404258728, acc: 0.390625, recall: 0.1316220238095238, precision: 0.10739087301587302, f_beta: 0.09912280701754386\n",
      "train: step: 559, loss: 2.24070143699646, acc: 0.3125, recall: 0.13293650793650794, precision: 0.06287878787878788, f_beta: 0.08283730158730158\n",
      "train: step: 560, loss: 2.0318942070007324, acc: 0.25, recall: 0.10705544455544455, precision: 0.11079545454545454, f_beta: 0.07202432983682984\n",
      "train: step: 561, loss: 1.7172479629516602, acc: 0.390625, recall: 0.14153554778554778, precision: 0.1365079365079365, f_beta: 0.10934391979387775\n",
      "train: step: 562, loss: 2.1014466285705566, acc: 0.296875, recall: 0.11948529411764705, precision: 0.06647625448028674, f_beta: 0.07504420866489832\n",
      "train: step: 563, loss: 1.8863451480865479, acc: 0.359375, recall: 0.12822420634920634, precision: 0.06677631578947368, f_beta: 0.08553981937602628\n",
      "train: step: 564, loss: 1.8662004470825195, acc: 0.3125, recall: 0.12005494505494506, precision: 0.06126110731373889, f_beta: 0.07979910714285715\n",
      "train: step: 565, loss: 2.040371894836426, acc: 0.296875, recall: 0.11811868686868687, precision: 0.06458333333333333, f_beta: 0.0818452380952381\n",
      "train: step: 566, loss: 2.0910098552703857, acc: 0.296875, recall: 0.12630208333333331, precision: 0.05287878787878787, f_beta: 0.07161902264183932\n",
      "train: step: 567, loss: 1.8311488628387451, acc: 0.390625, recall: 0.13931623931623932, precision: 0.09975090579710144, f_beta: 0.11060740663322186\n",
      "train: step: 568, loss: 1.9203861951828003, acc: 0.296875, recall: 0.10278263403263402, precision: 0.06912878787878787, f_beta: 0.08051470588235295\n",
      "train: step: 569, loss: 2.024061679840088, acc: 0.375, recall: 0.13449754901960784, precision: 0.10833885941644562, f_beta: 0.08959899749373434\n",
      "train: step: 570, loss: 2.140882968902588, acc: 0.21875, recall: 0.13154761904761905, precision: 0.09565145502645503, f_beta: 0.06496212121212121\n",
      "train: step: 571, loss: 1.9197912216186523, acc: 0.390625, recall: 0.1303661616161616, precision: 0.09196428571428572, f_beta: 0.09554093567251462\n",
      "train: step: 572, loss: 2.067577362060547, acc: 0.265625, recall: 0.11177884615384615, precision: 0.07623106060606061, f_beta: 0.07520833333333334\n",
      "train: step: 573, loss: 1.9848411083221436, acc: 0.34375, recall: 0.10620239135864135, precision: 0.0812460468058191, f_beta: 0.08693181818181818\n",
      "train: step: 574, loss: 2.146023750305176, acc: 0.234375, recall: 0.1309185606060606, precision: 0.06452922077922077, f_beta: 0.07833587980646804\n",
      "train: step: 575, loss: 1.8319650888442993, acc: 0.5, recall: 0.17113095238095236, precision: 0.15, f_beta: 0.15419213139801374\n",
      "train: step: 576, loss: 2.090075969696045, acc: 0.359375, recall: 0.15052083333333333, precision: 0.11368439957652753, f_beta: 0.11685144124168514\n",
      "train: step: 577, loss: 2.1549243927001953, acc: 0.328125, recall: 0.11884469696969699, precision: 0.06933170995670995, f_beta: 0.08346800258564965\n",
      "train: step: 578, loss: 2.039424419403076, acc: 0.21875, recall: 0.125, precision: 0.05158138078396699, f_beta: 0.07096431690084941\n",
      "train: step: 579, loss: 1.6755497455596924, acc: 0.4375, recall: 0.12790775401069518, precision: 0.10645833333333334, f_beta: 0.11145833333333335\n",
      "train: step: 580, loss: 2.0316696166992188, acc: 0.328125, recall: 0.12760416666666666, precision: 0.08389700577200578, f_beta: 0.09493284493284493\n",
      "train: step: 581, loss: 2.051675319671631, acc: 0.390625, recall: 0.16649305555555555, precision: 0.13766351402220967, f_beta: 0.1335774317142504\n",
      "train: step: 582, loss: 1.9809842109680176, acc: 0.375, recall: 0.16352831196581197, precision: 0.18476319875776398, f_beta: 0.13672025778880617\n",
      "train: step: 583, loss: 1.983958125114441, acc: 0.34375, recall: 0.14017857142857143, precision: 0.10677083333333333, f_beta: 0.1044451871657754\n",
      "train: step: 584, loss: 1.843529462814331, acc: 0.359375, recall: 0.10597587719298246, precision: 0.07465277777777778, f_beta: 0.08491921861377506\n",
      "train: step: 585, loss: 2.0876340866088867, acc: 0.296875, recall: 0.13151041666666666, precision: 0.08613095238095238, f_beta: 0.09022445419504244\n",
      "train: step: 586, loss: 2.037181854248047, acc: 0.296875, recall: 0.10465706168831168, precision: 0.05875, f_beta: 0.07298908134008877\n",
      "train: step: 587, loss: 1.8461308479309082, acc: 0.40625, recall: 0.14978632478632478, precision: 0.16006944444444446, f_beta: 0.11625713503792322\n",
      "train: step: 588, loss: 1.8783366680145264, acc: 0.4375, recall: 0.13323863636363636, precision: 0.1062192118226601, f_beta: 0.10674603174603173\n",
      "start training model\n",
      "train: step: 589, loss: 1.64328932762146, acc: 0.40625, recall: 0.125, precision: 0.11296296296296296, f_beta: 0.08058608058608059\n",
      "train: step: 590, loss: 2.0488476753234863, acc: 0.3125, recall: 0.11574675324675324, precision: 0.06304976851851851, f_beta: 0.0692546892057296\n",
      "train: step: 591, loss: 2.135770797729492, acc: 0.171875, recall: 0.11939102564102565, precision: 0.036835407239819005, f_beta: 0.042909832202111614\n",
      "train: step: 592, loss: 1.5651593208312988, acc: 0.53125, recall: 0.16964285714285715, precision: 0.1050287356321839, f_beta: 0.12656381412952059\n",
      "train: step: 593, loss: 1.9525964260101318, acc: 0.359375, recall: 0.128125, precision: 0.06660714285714286, f_beta: 0.0831131436314363\n",
      "train: step: 594, loss: 1.940852403640747, acc: 0.359375, recall: 0.12215909090909091, precision: 0.06791610322289836, f_beta: 0.0853794642857143\n",
      "train: step: 595, loss: 1.7663865089416504, acc: 0.46875, recall: 0.15625, precision: 0.09505494505494505, f_beta: 0.11218317972350231\n",
      "train: step: 596, loss: 1.7721484899520874, acc: 0.4375, recall: 0.13984375, precision: 0.08999594155844155, f_beta: 0.10138203742854905\n",
      "train: step: 597, loss: 1.8128941059112549, acc: 0.390625, recall: 0.15056818181818182, precision: 0.08759057971014492, f_beta: 0.09953882868937049\n",
      "train: step: 598, loss: 1.8009252548217773, acc: 0.359375, recall: 0.14781746031746032, precision: 0.12862007783882784, f_beta: 0.10186237373737374\n",
      "train: step: 599, loss: 1.705268383026123, acc: 0.515625, recall: 0.17392676767676768, precision: 0.1222222222222222, f_beta: 0.13948754789272028\n",
      "train: step: 600, loss: 1.7964205741882324, acc: 0.359375, recall: 0.13363095238095238, precision: 0.07297390109890109, f_beta: 0.08969155844155843\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:37:35.862269, step: 600, loss: 2.6754122840033636, acc: 0.1857638888888889,precision: 0.06504673382817733, recall: 0.04190059639981431, f_beta: 0.045314717660044065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 21:37:36,213 : WARNING : From /conda/envs/notebook/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-600\n",
      "\n",
      "train: step: 601, loss: 1.9328763484954834, acc: 0.328125, recall: 0.14488636363636365, precision: 0.10038919413919414, f_beta: 0.10280427090771918\n",
      "train: step: 602, loss: 1.8883551359176636, acc: 0.46875, recall: 0.18244047619047618, precision: 0.12630208333333334, f_beta: 0.14104476604476604\n",
      "train: step: 603, loss: 1.975798487663269, acc: 0.296875, recall: 0.13910308441558442, precision: 0.06828703703703703, f_beta: 0.08840909090909091\n",
      "train: step: 604, loss: 1.645540475845337, acc: 0.46875, recall: 0.14434523809523808, precision: 0.09972222222222221, f_beta: 0.11486633577150818\n",
      "train: step: 605, loss: 1.7603858709335327, acc: 0.375, recall: 0.1598800505050505, precision: 0.09640916149068324, f_beta: 0.1111247947454844\n",
      "train: step: 606, loss: 1.6628282070159912, acc: 0.484375, recall: 0.17672431734931734, precision: 0.17716346153846155, f_beta: 0.14736017267267265\n",
      "train: step: 607, loss: 1.6049859523773193, acc: 0.375, recall: 0.1565563725490196, precision: 0.1495251225490196, f_beta: 0.12651375891265598\n",
      "train: step: 608, loss: 1.6531643867492676, acc: 0.390625, recall: 0.12395833333333334, precision: 0.08970588235294118, f_beta: 0.10157333135274313\n",
      "train: step: 609, loss: 1.5557279586791992, acc: 0.390625, recall: 0.1622624269005848, precision: 0.12487173152934022, f_beta: 0.12420794930875577\n",
      "train: step: 610, loss: 1.5285395383834839, acc: 0.390625, recall: 0.1297706582633053, precision: 0.09028679653679653, f_beta: 0.1008384536610343\n",
      "train: step: 611, loss: 1.735513687133789, acc: 0.453125, recall: 0.15070970695970695, precision: 0.1099826388888889, f_beta: 0.12661957974457974\n",
      "train: step: 612, loss: 1.7750259637832642, acc: 0.4375, recall: 0.14423076923076922, precision: 0.109375, f_beta: 0.12440476190476188\n",
      "train: step: 613, loss: 1.7244025468826294, acc: 0.375, recall: 0.14281759906759905, precision: 0.10934117965367966, f_beta: 0.12156084656084656\n",
      "train: step: 614, loss: 1.8026795387268066, acc: 0.40625, recall: 0.15483193277310925, precision: 0.10349880382775119, f_beta: 0.11762820512820511\n",
      "train: step: 615, loss: 1.8284225463867188, acc: 0.359375, recall: 0.14866071428571428, precision: 0.11319470970206263, f_beta: 0.11311177248677248\n",
      "train: step: 616, loss: 1.8180267810821533, acc: 0.40625, recall: 0.16172070802005012, precision: 0.11854166666666666, f_beta: 0.1263393177866862\n",
      "train: step: 617, loss: 1.5857417583465576, acc: 0.421875, recall: 0.16003787878787878, precision: 0.15292366946778713, f_beta: 0.1198489010989011\n",
      "train: step: 618, loss: 1.8476738929748535, acc: 0.359375, recall: 0.14875541125541125, precision: 0.11587420255183412, f_beta: 0.12181776556776555\n",
      "train: step: 619, loss: 1.7464993000030518, acc: 0.375, recall: 0.1622596153846154, precision: 0.14808423913043478, f_beta: 0.12785087719298247\n",
      "train: step: 620, loss: 1.740065336227417, acc: 0.390625, recall: 0.15722489316239316, precision: 0.13237179487179487, f_beta: 0.1390843837535014\n",
      "train: step: 621, loss: 1.4921746253967285, acc: 0.5, recall: 0.2685905103668262, precision: 0.24273097826086956, f_beta: 0.23432239057239057\n",
      "train: step: 622, loss: 1.9142615795135498, acc: 0.328125, recall: 0.1453373015873016, precision: 0.09932040998217469, f_beta: 0.11240317341329335\n",
      "train: step: 623, loss: 1.5748047828674316, acc: 0.421875, recall: 0.1365950226244344, precision: 0.15797908232118757, f_beta: 0.12824133276499006\n",
      "train: step: 624, loss: 1.7379999160766602, acc: 0.359375, recall: 0.11488095238095239, precision: 0.08601973684210526, f_beta: 0.09831932773109245\n",
      "train: step: 625, loss: 1.7274960279464722, acc: 0.421875, recall: 0.17465277777777777, precision: 0.13042935924369747, f_beta: 0.14050704730052557\n",
      "train: step: 626, loss: 1.5965874195098877, acc: 0.484375, recall: 0.17659293831168832, precision: 0.11822916666666666, f_beta: 0.13835772399015184\n",
      "train: step: 627, loss: 1.675100326538086, acc: 0.4375, recall: 0.14957611832611833, precision: 0.09218189964157707, f_beta: 0.11210929622907845\n",
      "train: step: 628, loss: 1.4888629913330078, acc: 0.484375, recall: 0.1856060606060606, precision: 0.1767274844720497, f_beta: 0.148923483672125\n",
      "train: step: 629, loss: 1.6845729351043701, acc: 0.40625, recall: 0.12843276515151514, precision: 0.1360176282051282, f_beta: 0.102881006006006\n",
      "train: step: 630, loss: 1.7889125347137451, acc: 0.375, recall: 0.13258928571428572, precision: 0.07680246011448058, f_beta: 0.09017555501930502\n",
      "train: step: 631, loss: 1.7674778699874878, acc: 0.453125, recall: 0.18355429292929293, precision: 0.1560496794871795, f_beta: 0.14231902356902357\n",
      "train: step: 632, loss: 1.8826701641082764, acc: 0.28125, recall: 0.1203125, precision: 0.05805652680652681, f_beta: 0.0739456399619739\n",
      "train: step: 633, loss: 1.902777910232544, acc: 0.40625, recall: 0.16267361111111112, precision: 0.17662815126050418, f_beta: 0.13446118991331757\n",
      "train: step: 634, loss: 1.568394660949707, acc: 0.4375, recall: 0.15703125, precision: 0.10535714285714284, f_beta: 0.11805555555555557\n",
      "train: step: 635, loss: 1.7265982627868652, acc: 0.453125, recall: 0.15245535714285716, precision: 0.189119644723093, f_beta: 0.13467004571655733\n",
      "train: step: 636, loss: 2.0329184532165527, acc: 0.390625, recall: 0.13658685064935067, precision: 0.14447916666666666, f_beta: 0.11341844430079723\n",
      "train: step: 637, loss: 1.9135676622390747, acc: 0.296875, recall: 0.11592261904761904, precision: 0.07724519632414369, f_beta: 0.09022002772002773\n",
      "train: step: 638, loss: 1.787491798400879, acc: 0.328125, recall: 0.16711309523809523, precision: 0.15645292207792208, f_beta: 0.14077104526020934\n",
      "train: step: 639, loss: 1.7938945293426514, acc: 0.375, recall: 0.16649305555555555, precision: 0.15775058275058276, f_beta: 0.13450956937799047\n",
      "train: step: 640, loss: 1.7419402599334717, acc: 0.421875, recall: 0.13828125, precision: 0.11584595959595959, f_beta: 0.11848958333333334\n",
      "train: step: 641, loss: 1.7825970649719238, acc: 0.421875, recall: 0.20381944444444441, precision: 0.21960108604845446, f_beta: 0.19744413556083387\n",
      "train: step: 642, loss: 1.9268693923950195, acc: 0.328125, recall: 0.14643308080808082, precision: 0.12690508021390376, f_beta: 0.12207911573720398\n",
      "train: step: 643, loss: 1.9423471689224243, acc: 0.25, recall: 0.09770698051948051, precision: 0.08314732142857142, f_beta: 0.08183609493954322\n",
      "train: step: 644, loss: 1.6967253684997559, acc: 0.40625, recall: 0.1543803418803419, precision: 0.12856947055137843, f_beta: 0.13534759062776303\n",
      "train: step: 645, loss: 1.8595237731933594, acc: 0.328125, recall: 0.17611832611832612, precision: 0.1170157967032967, f_beta: 0.11919149881392445\n",
      "train: step: 646, loss: 1.8363375663757324, acc: 0.3125, recall: 0.11015625, precision: 0.08885645604395605, f_beta: 0.09577343843395801\n",
      "train: step: 647, loss: 1.993991732597351, acc: 0.390625, recall: 0.18749999999999997, precision: 0.1997549019607843, f_beta: 0.17110828108672937\n",
      "train: step: 648, loss: 1.850513219833374, acc: 0.4375, recall: 0.1638888888888889, precision: 0.12785218253968256, f_beta: 0.13371212121212123\n",
      "train: step: 649, loss: 1.998978853225708, acc: 0.296875, recall: 0.15, precision: 0.07860294117647058, f_beta: 0.09326264063106168\n",
      "train: step: 650, loss: 1.5693031549453735, acc: 0.453125, recall: 0.150796568627451, precision: 0.111359126984127, f_beta: 0.11982657799190058\n",
      "train: step: 651, loss: 1.7489733695983887, acc: 0.390625, recall: 0.14583333333333331, precision: 0.15164930555555556, f_beta: 0.12306547619047617\n",
      "train: step: 652, loss: 1.8960120677947998, acc: 0.359375, recall: 0.16597222222222222, precision: 0.1217495739554563, f_beta: 0.12365892379679144\n",
      "train: step: 653, loss: 1.711773157119751, acc: 0.390625, recall: 0.1750801282051282, precision: 0.14324162679425836, f_beta: 0.14156194272295497\n",
      "train: step: 654, loss: 1.533989429473877, acc: 0.390625, recall: 0.13257575757575757, precision: 0.10970022624434389, f_beta: 0.10855796793296793\n",
      "train: step: 655, loss: 1.5215175151824951, acc: 0.546875, recall: 0.20770375457875456, precision: 0.1889968487394958, f_beta: 0.1878638414676721\n",
      "train: step: 656, loss: 1.9586875438690186, acc: 0.375, recall: 0.16142676767676767, precision: 0.20179079696394686, f_beta: 0.133495670995671\n",
      "train: step: 657, loss: 1.9456090927124023, acc: 0.34375, recall: 0.16080638111888113, precision: 0.11529931265984655, f_beta: 0.11688321385902031\n",
      "train: step: 658, loss: 1.8600798845291138, acc: 0.40625, recall: 0.16433823529411765, precision: 0.1321800595238095, f_beta: 0.14304876724231563\n",
      "train: step: 659, loss: 1.7831727266311646, acc: 0.4375, recall: 0.17775106837606836, precision: 0.1449747218636671, f_beta: 0.144017094017094\n",
      "train: step: 660, loss: 1.6847419738769531, acc: 0.40625, recall: 0.1465029761904762, precision: 0.15856384708286883, f_beta: 0.12656387156387156\n",
      "train: step: 661, loss: 1.4585387706756592, acc: 0.484375, recall: 0.1438186813186813, precision: 0.11304414110141665, f_beta: 0.12440318302387268\n",
      "train: step: 662, loss: 2.0441627502441406, acc: 0.296875, recall: 0.14816176470588235, precision: 0.0885731456043956, f_beta: 0.09743761140819965\n",
      "train: step: 663, loss: 1.734675645828247, acc: 0.40625, recall: 0.18349358974358973, precision: 0.1546875, f_beta: 0.1521314333814334\n",
      "train: step: 664, loss: 1.8460936546325684, acc: 0.421875, recall: 0.17569444444444443, precision: 0.11056547619047619, f_beta: 0.127328431372549\n",
      "train: step: 665, loss: 1.6529676914215088, acc: 0.421875, recall: 0.16041666666666665, precision: 0.10994928274340038, f_beta: 0.1271412037037037\n",
      "train: step: 666, loss: 1.6655819416046143, acc: 0.40625, recall: 0.14375000000000002, precision: 0.09248737373737373, f_beta: 0.11177536231884057\n",
      "train: step: 667, loss: 1.690571665763855, acc: 0.40625, recall: 0.17326388888888888, precision: 0.09972527472527473, f_beta: 0.12365906507530548\n",
      "train: step: 668, loss: 1.7787301540374756, acc: 0.328125, recall: 0.14459498834498835, precision: 0.08085664335664336, f_beta: 0.10008012820512821\n",
      "train: step: 669, loss: 1.811773419380188, acc: 0.390625, recall: 0.14970238095238095, precision: 0.0863829185520362, f_beta: 0.107639803835456\n",
      "train: step: 670, loss: 1.8254010677337646, acc: 0.359375, recall: 0.13320707070707072, precision: 0.10151632423304251, f_beta: 0.10000281976088429\n",
      "train: step: 671, loss: 1.7884414196014404, acc: 0.390625, recall: 0.1951388888888889, precision: 0.17052696078431373, f_beta: 0.15400016650016649\n",
      "train: step: 672, loss: 1.7530027627944946, acc: 0.453125, recall: 0.19825261544011544, precision: 0.18964752567693743, f_beta: 0.16332148754023754\n",
      "start training model\n",
      "train: step: 673, loss: 1.6550540924072266, acc: 0.421875, recall: 0.19379578754578755, precision: 0.135989010989011, f_beta: 0.14743953962703962\n",
      "train: step: 674, loss: 1.664726972579956, acc: 0.34375, recall: 0.15649801587301587, precision: 0.10564123376623377, f_beta: 0.11087509600614438\n",
      "train: step: 675, loss: 1.6325538158416748, acc: 0.453125, recall: 0.19166666666666668, precision: 0.20104166666666665, f_beta: 0.16923701298701302\n",
      "train: step: 676, loss: 1.601684331893921, acc: 0.5, recall: 0.2156001984126984, precision: 0.16817141192141194, f_beta: 0.1800921574770259\n",
      "train: step: 677, loss: 1.5410983562469482, acc: 0.5, recall: 0.20676247771836007, precision: 0.18886278195488723, f_beta: 0.18625\n",
      "train: step: 678, loss: 1.4880826473236084, acc: 0.46875, recall: 0.16119281045751632, precision: 0.12912210338680927, f_beta: 0.1374080882352941\n",
      "train: step: 679, loss: 1.4271801710128784, acc: 0.515625, recall: 0.19614898989898988, precision: 0.153125, f_beta: 0.16346153846153846\n",
      "train: step: 680, loss: 1.3917956352233887, acc: 0.53125, recall: 0.20920615842490842, precision: 0.21595982142857142, f_beta: 0.18321903280542984\n",
      "train: step: 681, loss: 1.2954334020614624, acc: 0.5, recall: 0.20950411414565825, precision: 0.18455882352941175, f_beta: 0.17204668014829794\n",
      "train: step: 682, loss: 1.6117219924926758, acc: 0.46875, recall: 0.1484375, precision: 0.10176136363636364, f_beta: 0.11153846153846153\n",
      "train: step: 683, loss: 1.551708459854126, acc: 0.484375, recall: 0.1901098901098901, precision: 0.19381585249042144, f_beta: 0.1760482734319944\n",
      "train: step: 684, loss: 1.3834104537963867, acc: 0.5625, recall: 0.22916666666666666, precision: 0.21850079744816586, f_beta: 0.20092068878833585\n",
      "train: step: 685, loss: 1.3724346160888672, acc: 0.453125, recall: 0.18457454004329005, precision: 0.1624627976190476, f_beta: 0.15727813852813854\n",
      "train: step: 686, loss: 1.7683790922164917, acc: 0.40625, recall: 0.19600694444444444, precision: 0.2234860248447205, f_beta: 0.16650944541569543\n",
      "train: step: 687, loss: 1.5842655897140503, acc: 0.375, recall: 0.16847527472527474, precision: 0.11391369047619047, f_beta: 0.1269055004135649\n",
      "train: step: 688, loss: 1.5938372611999512, acc: 0.5, recall: 0.22526041666666666, precision: 0.20532280219780222, f_beta: 0.1939497461170848\n",
      "train: step: 689, loss: 1.333223581314087, acc: 0.578125, recall: 0.23412698412698413, precision: 0.19159226190476192, f_beta: 0.20334249084249084\n",
      "train: step: 690, loss: 1.4369752407073975, acc: 0.53125, recall: 0.2170673076923077, precision: 0.16911525974025976, f_beta: 0.1788472706155633\n",
      "train: step: 691, loss: 1.641929268836975, acc: 0.40625, recall: 0.1942708333333333, precision: 0.15885416666666666, f_beta: 0.1516707251082251\n",
      "train: step: 692, loss: 1.8791825771331787, acc: 0.40625, recall: 0.18653724747474748, precision: 0.14164195179820177, f_beta: 0.15251846432552954\n",
      "train: step: 693, loss: 1.3817548751831055, acc: 0.5, recall: 0.19657738095238095, precision: 0.15561868686868685, f_beta: 0.16850732600732604\n",
      "train: step: 694, loss: 1.2858877182006836, acc: 0.5625, recall: 0.2101018772893773, precision: 0.18557900432900434, f_beta: 0.19107744107744107\n",
      "train: step: 695, loss: 1.6901658773422241, acc: 0.453125, recall: 0.18419237012987014, precision: 0.16125992063492064, f_beta: 0.16969597210408077\n",
      "train: step: 696, loss: 1.8009990453720093, acc: 0.421875, recall: 0.2090435606060606, precision: 0.15627289377289377, f_beta: 0.17022727272727273\n",
      "train: step: 697, loss: 1.5876116752624512, acc: 0.46875, recall: 0.20872564935064936, precision: 0.21332866479925303, f_beta: 0.18476190476190477\n",
      "train: step: 698, loss: 1.6024346351623535, acc: 0.453125, recall: 0.21626984126984128, precision: 0.1557449494949495, f_beta: 0.17043650793650794\n",
      "train: step: 699, loss: 1.8354864120483398, acc: 0.34375, recall: 0.1681953463203463, precision: 0.1299941378066378, f_beta: 0.1433524698911162\n",
      "train: step: 700, loss: 1.5554704666137695, acc: 0.453125, recall: 0.1657769314019314, precision: 0.15104166666666666, f_beta: 0.14883772628337844\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:39:27.749916, step: 700, loss: 3.046171055899726, acc: 0.1684027777777778,precision: 0.07031439248125264, recall: 0.06106867881722641, f_beta: 0.05956131652712209\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-700\n",
      "\n",
      "train: step: 701, loss: 1.6264119148254395, acc: 0.4375, recall: 0.20430307539682538, precision: 0.1663510101010101, f_beta: 0.17375356125356126\n",
      "train: step: 702, loss: 1.669093370437622, acc: 0.453125, recall: 0.23020833333333332, precision: 0.22903494531784005, f_beta: 0.21331023538447635\n",
      "train: step: 703, loss: 1.9302639961242676, acc: 0.453125, recall: 0.23411458333333332, precision: 0.1338379917184265, f_beta: 0.16056547619047618\n",
      "train: step: 704, loss: 1.7790882587432861, acc: 0.453125, recall: 0.19056372549019607, precision: 0.10678991147741149, f_beta: 0.1299900805228148\n",
      "train: step: 705, loss: 1.6067349910736084, acc: 0.46875, recall: 0.1779491341991342, precision: 0.13080357142857144, f_beta: 0.14732998084291188\n",
      "train: step: 706, loss: 1.5951032638549805, acc: 0.515625, recall: 0.22083333333333333, precision: 0.2583874458874459, f_beta: 0.200477262977263\n",
      "train: step: 707, loss: 1.7516047954559326, acc: 0.421875, recall: 0.1787878787878788, precision: 0.16991987179487178, f_beta: 0.13917557932263816\n",
      "train: step: 708, loss: 1.6896607875823975, acc: 0.46875, recall: 0.18678977272727273, precision: 0.16171875, f_beta: 0.16517221204721205\n",
      "train: step: 709, loss: 1.5895506143569946, acc: 0.46875, recall: 0.220407196969697, precision: 0.162366452991453, f_beta: 0.18229166666666669\n",
      "train: step: 710, loss: 1.4724435806274414, acc: 0.546875, recall: 0.30830965909090907, precision: 0.24895833333333334, f_beta: 0.2555437907000407\n",
      "train: step: 711, loss: 1.479771375656128, acc: 0.484375, recall: 0.2481026785714286, precision: 0.1408219537815126, f_beta: 0.16816385977570186\n",
      "train: step: 712, loss: 1.5086897611618042, acc: 0.421875, recall: 0.19226190476190477, precision: 0.19492694805194805, f_beta: 0.15442323481116585\n",
      "train: step: 713, loss: 1.4155399799346924, acc: 0.5625, recall: 0.2472088675213675, precision: 0.2550459956709957, f_beta: 0.2373015873015873\n",
      "train: step: 714, loss: 1.4974377155303955, acc: 0.53125, recall: 0.27694597069597066, precision: 0.28092870670995673, f_beta: 0.24816014288262866\n",
      "train: step: 715, loss: 1.3936175107955933, acc: 0.484375, recall: 0.19324061355311356, precision: 0.19218749999999998, f_beta: 0.17829246411483254\n",
      "train: step: 716, loss: 1.8404744863510132, acc: 0.421875, recall: 0.22525183150183153, precision: 0.1717436974789916, f_beta: 0.14999221910986615\n",
      "train: step: 717, loss: 1.5510748624801636, acc: 0.46875, recall: 0.2085393772893773, precision: 0.1857142857142857, f_beta: 0.16786109903028004\n",
      "train: step: 718, loss: 1.3949052095413208, acc: 0.546875, recall: 0.21306818181818182, precision: 0.19270833333333331, f_beta: 0.16758594228352292\n",
      "train: step: 719, loss: 1.6521985530853271, acc: 0.390625, recall: 0.16397907647907647, precision: 0.15099691974691976, f_beta: 0.14105113636363636\n",
      "train: step: 720, loss: 1.446793556213379, acc: 0.609375, recall: 0.27254464285714286, precision: 0.24655257936507935, f_beta: 0.24453177822853278\n",
      "train: step: 721, loss: 1.6572582721710205, acc: 0.421875, recall: 0.163697209653092, precision: 0.11235119047619047, f_beta: 0.12083404637631556\n",
      "train: step: 722, loss: 1.4222297668457031, acc: 0.484375, recall: 0.21365440115440118, precision: 0.16261837121212122, f_beta: 0.17870670995670995\n",
      "train: step: 723, loss: 1.5114151239395142, acc: 0.5, recall: 0.2038209033613445, precision: 0.16193910256410257, f_beta: 0.17674278846153846\n",
      "train: step: 724, loss: 1.2894887924194336, acc: 0.5, recall: 0.18506944444444445, precision: 0.16599257224257224, f_beta: 0.15596537240689085\n",
      "train: step: 725, loss: 1.4177844524383545, acc: 0.515625, recall: 0.23774038461538463, precision: 0.21746482683982685, f_beta: 0.19867216117216116\n",
      "train: step: 726, loss: 1.6791260242462158, acc: 0.390625, recall: 0.18177083333333333, precision: 0.146042663476874, f_beta: 0.15237343674843676\n",
      "train: step: 727, loss: 1.6117626428604126, acc: 0.4375, recall: 0.15215435606060607, precision: 0.1537736568986569, f_beta: 0.14555860805860804\n",
      "train: step: 728, loss: 1.5620317459106445, acc: 0.515625, recall: 0.22782738095238098, precision: 0.23099296536796535, f_beta: 0.21477689974457218\n",
      "train: step: 729, loss: 1.430008888244629, acc: 0.5, recall: 0.15625, precision: 0.142734593837535, f_beta: 0.1467376957678682\n",
      "train: step: 730, loss: 1.6060036420822144, acc: 0.5, recall: 0.20758928571428573, precision: 0.15452516233766234, f_beta: 0.1730099610534393\n",
      "train: step: 731, loss: 1.4726572036743164, acc: 0.515625, recall: 0.20101686507936506, precision: 0.20818014705882354, f_beta: 0.19556051587301587\n",
      "train: step: 732, loss: 1.9607908725738525, acc: 0.421875, recall: 0.16448412698412698, precision: 0.1130050505050505, f_beta: 0.12556614532420984\n",
      "train: step: 733, loss: 1.4843438863754272, acc: 0.546875, recall: 0.21387553418803418, precision: 0.19273182957393487, f_beta: 0.19752944188428062\n",
      "train: step: 734, loss: 1.5064787864685059, acc: 0.453125, recall: 0.15512057387057387, precision: 0.14941098740440847, f_beta: 0.13627702942219072\n",
      "train: step: 735, loss: 1.4773852825164795, acc: 0.4375, recall: 0.18764880952380952, precision: 0.13999451754385966, f_beta: 0.15013181263181263\n",
      "train: step: 736, loss: 1.5897082090377808, acc: 0.484375, recall: 0.22843045112781954, precision: 0.23034232923938805, f_beta: 0.20001184758727863\n",
      "train: step: 737, loss: 1.4100069999694824, acc: 0.546875, recall: 0.18823953823953826, precision: 0.16655505952380953, f_beta: 0.1734605911330049\n",
      "train: step: 738, loss: 1.1801388263702393, acc: 0.625, recall: 0.22463942307692308, precision: 0.22451073232323232, f_beta: 0.21352137445887445\n",
      "train: step: 739, loss: 1.4332714080810547, acc: 0.5625, recall: 0.22181186868686867, precision: 0.18031045751633987, f_beta: 0.1963502506265664\n",
      "train: step: 740, loss: 1.5628349781036377, acc: 0.515625, recall: 0.2221455627705628, precision: 0.17832341269841268, f_beta: 0.193412514209928\n",
      "train: step: 741, loss: 1.1702077388763428, acc: 0.71875, recall: 0.31059027777777776, precision: 0.26883116883116887, f_beta: 0.26857521234300175\n",
      "train: step: 742, loss: 1.7489140033721924, acc: 0.421875, recall: 0.20352564102564102, precision: 0.2888257575757575, f_beta: 0.17792527543731906\n",
      "train: step: 743, loss: 1.6736607551574707, acc: 0.453125, recall: 0.1857638888888889, precision: 0.14070165945165944, f_beta: 0.15275424806674806\n",
      "train: step: 744, loss: 1.5465209484100342, acc: 0.484375, recall: 0.2259063852813853, precision: 0.24731585816144638, f_beta: 0.20613509346046108\n",
      "train: step: 745, loss: 1.6975367069244385, acc: 0.453125, recall: 0.20208333333333334, precision: 0.15363906926406926, f_beta: 0.17180994293063256\n",
      "train: step: 746, loss: 1.825519323348999, acc: 0.515625, recall: 0.25029761904761905, precision: 0.17656814803553936, f_beta: 0.19742913349892757\n",
      "train: step: 747, loss: 1.2722830772399902, acc: 0.546875, recall: 0.19835633116883117, precision: 0.1743170766590389, f_beta: 0.175\n",
      "train: step: 748, loss: 1.4243860244750977, acc: 0.53125, recall: 0.23070436507936506, precision: 0.19612956487956484, f_beta: 0.20642416489455961\n",
      "train: step: 749, loss: 1.612681269645691, acc: 0.515625, recall: 0.2545454545454545, precision: 0.25395307817182816, f_beta: 0.2279184704184704\n",
      "train: step: 750, loss: 1.5615437030792236, acc: 0.484375, recall: 0.21552579365079366, precision: 0.19436274509803922, f_beta: 0.19308644730555483\n",
      "train: step: 751, loss: 1.4481267929077148, acc: 0.453125, recall: 0.17769209956709958, precision: 0.1738209706959707, f_beta: 0.16815235690235691\n",
      "train: step: 752, loss: 1.3052253723144531, acc: 0.609375, recall: 0.21718749999999998, precision: 0.19069940476190478, f_beta: 0.19984300239234448\n",
      "train: step: 753, loss: 1.734196424484253, acc: 0.4375, recall: 0.24170673076923077, precision: 0.15294635919635918, f_beta: 0.17469691598723855\n",
      "train: step: 754, loss: 1.5628900527954102, acc: 0.390625, recall: 0.16506410256410256, precision: 0.10662393162393163, f_beta: 0.12775974025974024\n",
      "train: step: 755, loss: 1.854509711265564, acc: 0.421875, recall: 0.18854929792429792, precision: 0.13973214285714286, f_beta: 0.1568843984962406\n",
      "train: step: 756, loss: 1.1753287315368652, acc: 0.65625, recall: 0.25699404761904765, precision: 0.24640065816536402, f_beta: 0.2382722701149425\n",
      "start training model\n",
      "train: step: 757, loss: 1.4070698022842407, acc: 0.578125, recall: 0.26458333333333334, precision: 0.24390076754385964, f_beta: 0.24361945865302642\n",
      "train: step: 758, loss: 1.4840853214263916, acc: 0.4375, recall: 0.18864989177489178, precision: 0.15515581232492998, f_beta: 0.15982135511547277\n",
      "train: step: 759, loss: 1.53887939453125, acc: 0.53125, recall: 0.25148809523809523, precision: 0.24071557971014493, f_beta: 0.22498196248196248\n",
      "train: step: 760, loss: 1.5258680582046509, acc: 0.484375, recall: 0.2045788770053476, precision: 0.16546325051759833, f_beta: 0.1630952380952381\n",
      "train: step: 761, loss: 1.2200089693069458, acc: 0.59375, recall: 0.2500228937728938, precision: 0.2416666666666667, f_beta: 0.23299278846153848\n",
      "train: step: 762, loss: 1.1726346015930176, acc: 0.65625, recall: 0.3168402777777778, precision: 0.3128156565656566, f_beta: 0.30574004455583403\n",
      "train: step: 763, loss: 1.2770870923995972, acc: 0.625, recall: 0.2408234126984127, precision: 0.23986742424242424, f_beta: 0.22713293650793653\n",
      "train: step: 764, loss: 1.3434789180755615, acc: 0.546875, recall: 0.26711309523809523, precision: 0.2181175595238095, f_beta: 0.23505747126436782\n",
      "train: step: 765, loss: 1.2785296440124512, acc: 0.609375, recall: 0.2826140873015873, precision: 0.24490995115995115, f_beta: 0.26055579666307194\n",
      "train: step: 766, loss: 1.03786039352417, acc: 0.65625, recall: 0.25968853450471097, precision: 0.23533390628978865, f_beta: 0.2388211830801391\n",
      "train: step: 767, loss: 1.260049819946289, acc: 0.546875, recall: 0.24291056166056166, precision: 0.2066878434065934, f_beta: 0.21718240093240096\n",
      "train: step: 768, loss: 1.2046496868133545, acc: 0.609375, recall: 0.27291666666666664, precision: 0.26165865384615383, f_beta: 0.2539851784633999\n",
      "train: step: 769, loss: 1.1941380500793457, acc: 0.625, recall: 0.26508699633699634, precision: 0.23345184227537166, f_beta: 0.23580882352941177\n",
      "train: step: 770, loss: 1.1712489128112793, acc: 0.65625, recall: 0.3421186656480774, precision: 0.2683170995670996, f_beta: 0.285768411266503\n",
      "train: step: 771, loss: 1.165350079536438, acc: 0.65625, recall: 0.26761675824175823, precision: 0.25745506535947715, f_beta: 0.2602096688034188\n",
      "train: step: 772, loss: 1.0324711799621582, acc: 0.671875, recall: 0.3221320346320346, precision: 0.3156554383116883, f_beta: 0.30857887239466186\n",
      "train: step: 773, loss: 1.661257028579712, acc: 0.40625, recall: 0.22247474747474746, precision: 0.2229079131652661, f_beta: 0.19058155080213904\n",
      "train: step: 774, loss: 1.3203785419464111, acc: 0.625, recall: 0.3114831349206349, precision: 0.26080560064935066, f_beta: 0.275113597658169\n",
      "train: step: 775, loss: 1.1649219989776611, acc: 0.625, recall: 0.2552083333333333, precision: 0.22755655802530803, f_beta: 0.2297751240694789\n",
      "train: step: 776, loss: 1.4069554805755615, acc: 0.5, recall: 0.25535983624218916, precision: 0.21401098901098903, f_beta: 0.22328132107543874\n",
      "train: step: 777, loss: 1.1854665279388428, acc: 0.625, recall: 0.2725305944055944, precision: 0.229524642024642, f_beta: 0.23957121732223152\n",
      "train: step: 778, loss: 1.151386022567749, acc: 0.5625, recall: 0.23731617647058822, precision: 0.20691964285714284, f_beta: 0.21015889114266395\n",
      "train: step: 779, loss: 1.1147067546844482, acc: 0.5625, recall: 0.2297348484848485, precision: 0.1943204365079365, f_beta: 0.20706594187545246\n",
      "train: step: 780, loss: 1.2517530918121338, acc: 0.46875, recall: 0.2169642857142857, precision: 0.184770091020091, f_beta: 0.19583883297585655\n",
      "train: step: 781, loss: 1.3274941444396973, acc: 0.53125, recall: 0.3172077922077922, precision: 0.23488386613386614, f_beta: 0.2486762491557888\n",
      "train: step: 782, loss: 1.2215898036956787, acc: 0.59375, recall: 0.2733527501909855, precision: 0.2540452694235589, f_beta: 0.25507478632478636\n",
      "train: step: 783, loss: 1.4443504810333252, acc: 0.484375, recall: 0.1977418414918415, precision: 0.2075892857142857, f_beta: 0.17633663391206494\n",
      "train: step: 784, loss: 1.361595630645752, acc: 0.625, recall: 0.3323317307692308, precision: 0.21893939393939393, f_beta: 0.24756778309409885\n",
      "train: step: 785, loss: 1.2909083366394043, acc: 0.59375, recall: 0.29305555555555557, precision: 0.24270833333333336, f_beta: 0.2561633651518397\n",
      "train: step: 786, loss: 1.2307878732681274, acc: 0.578125, recall: 0.32142857142857145, precision: 0.28129370629370626, f_beta: 0.25168650793650793\n",
      "train: step: 787, loss: 1.2970006465911865, acc: 0.5625, recall: 0.23314950980392155, precision: 0.23469611528822054, f_beta: 0.20317629740068066\n",
      "train: step: 788, loss: 1.0091372728347778, acc: 0.65625, recall: 0.2392361111111111, precision: 0.2592288011695907, f_beta: 0.22967332239536187\n",
      "train: step: 789, loss: 1.3259422779083252, acc: 0.59375, recall: 0.31403769841269835, precision: 0.33869047619047615, f_beta: 0.29634342265921215\n",
      "train: step: 790, loss: 1.4283816814422607, acc: 0.53125, recall: 0.2777529761904762, precision: 0.221371336996337, f_beta: 0.22136509324009324\n",
      "train: step: 791, loss: 1.5148396492004395, acc: 0.515625, recall: 0.24859983766233767, precision: 0.2066239316239316, f_beta: 0.22218487394957984\n",
      "train: step: 792, loss: 1.1951695680618286, acc: 0.671875, recall: 0.3984138257575757, precision: 0.38822115384615385, f_beta: 0.38325216450216454\n",
      "train: step: 793, loss: 1.2030820846557617, acc: 0.6875, recall: 0.3040178571428571, precision: 0.26751805985552113, f_beta: 0.27977127039627037\n",
      "train: step: 794, loss: 1.2835955619812012, acc: 0.546875, recall: 0.24575892857142856, precision: 0.21738798589611286, f_beta: 0.2214146964146964\n",
      "train: step: 795, loss: 1.307732105255127, acc: 0.609375, recall: 0.2799039502164502, precision: 0.30163690476190474, f_beta: 0.27545518207282915\n",
      "train: step: 796, loss: 1.3263607025146484, acc: 0.578125, recall: 0.26635154061624644, precision: 0.28063725490196073, f_beta: 0.24232841461943627\n",
      "train: step: 797, loss: 1.3875370025634766, acc: 0.578125, recall: 0.25974025974025977, precision: 0.26373938561438565, f_beta: 0.25152116402116403\n",
      "train: step: 798, loss: 1.4286112785339355, acc: 0.5, recall: 0.2392113095238095, precision: 0.18619123931623932, f_beta: 0.207630186577555\n",
      "train: step: 799, loss: 1.244842290878296, acc: 0.546875, recall: 0.2852772227772227, precision: 0.2654840818903319, f_beta: 0.268777498842154\n",
      "train: step: 800, loss: 1.115583896636963, acc: 0.640625, recall: 0.2765491452991453, precision: 0.2325229458041958, f_beta: 0.24866357114871548\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:41:20.451326, step: 800, loss: 3.417840427822537, acc: 0.16666666666666666,precision: 0.0828745022678846, recall: 0.07838229619060372, f_beta: 0.06856589312979328\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-800\n",
      "\n",
      "train: step: 801, loss: 1.416283369064331, acc: 0.5, recall: 0.21865322177822177, precision: 0.18199505763844, f_beta: 0.19162120493358636\n",
      "train: step: 802, loss: 1.2572531700134277, acc: 0.65625, recall: 0.27440476190476193, precision: 0.2538308913308914, f_beta: 0.2571517695099818\n",
      "train: step: 803, loss: 1.4292337894439697, acc: 0.5, recall: 0.21378829503829505, precision: 0.1856456043956044, f_beta: 0.1973772389890811\n",
      "train: step: 804, loss: 1.2237967252731323, acc: 0.640625, recall: 0.3031994047619047, precision: 0.29240315605447187, f_beta: 0.2836910774410774\n",
      "train: step: 805, loss: 1.1243120431900024, acc: 0.703125, recall: 0.34802350427350426, precision: 0.3057666970710449, f_beta: 0.3153219587430114\n",
      "train: step: 806, loss: 1.3746036291122437, acc: 0.515625, recall: 0.19164949633699632, precision: 0.19293261562998404, f_beta: 0.17943885200257015\n",
      "train: step: 807, loss: 1.4993232488632202, acc: 0.53125, recall: 0.25647095959595956, precision: 0.2544060559006211, f_beta: 0.23742168778933487\n",
      "train: step: 808, loss: 1.4446576833724976, acc: 0.53125, recall: 0.27809065934065935, precision: 0.24384469696969696, f_beta: 0.2527982026143791\n",
      "train: step: 809, loss: 1.714501976966858, acc: 0.484375, recall: 0.20550595238095237, precision: 0.1837719298245614, f_beta: 0.1855923458725183\n",
      "train: step: 810, loss: 1.3459588289260864, acc: 0.53125, recall: 0.23859508547008546, precision: 0.22859185340802987, f_beta: 0.21944444444444447\n",
      "train: step: 811, loss: 1.479152798652649, acc: 0.53125, recall: 0.2716991341991342, precision: 0.2279491341991342, f_beta: 0.24125931938431938\n",
      "train: step: 812, loss: 1.180677056312561, acc: 0.65625, recall: 0.320211038961039, precision: 0.3107638888888889, f_beta: 0.30800937568178943\n",
      "train: step: 813, loss: 1.199713945388794, acc: 0.578125, recall: 0.2564636752136752, precision: 0.2530838815789474, f_beta: 0.2371587768139492\n",
      "train: step: 814, loss: 1.2798662185668945, acc: 0.6875, recall: 0.32265625000000003, precision: 0.3160087719298246, f_beta: 0.29744736604319144\n",
      "train: step: 815, loss: 1.3339265584945679, acc: 0.5625, recall: 0.2535597572362278, precision: 0.2627890749601276, f_beta: 0.22341487535453053\n",
      "train: step: 816, loss: 1.4195259809494019, acc: 0.546875, recall: 0.24895833333333334, precision: 0.2397272866022866, f_beta: 0.2390404734154734\n",
      "train: step: 817, loss: 1.5024399757385254, acc: 0.4375, recall: 0.25044642857142857, precision: 0.21927083333333333, f_beta: 0.2208213601532567\n",
      "train: step: 818, loss: 1.348189353942871, acc: 0.609375, recall: 0.24866452991452992, precision: 0.31420454545454546, f_beta: 0.24440899680030115\n",
      "train: step: 819, loss: 1.4876477718353271, acc: 0.53125, recall: 0.22628933566433568, precision: 0.19871031746031748, f_beta: 0.19602550227550225\n",
      "train: step: 820, loss: 1.5938447713851929, acc: 0.515625, recall: 0.2064709595959596, precision: 0.1767601271277742, f_beta: 0.18768804112554113\n",
      "train: step: 821, loss: 1.2814748287200928, acc: 0.625, recall: 0.32568681318681314, precision: 0.28443605006105005, f_beta: 0.2879308191808192\n",
      "train: step: 822, loss: 1.171553134918213, acc: 0.625, recall: 0.2775122549019608, precision: 0.24253982494114074, f_beta: 0.24840277777777778\n",
      "train: step: 839, loss: 1.2394063472747803, acc: 0.578125, recall: 0.2299558080808081, precision: 0.2303711456671983, f_beta: 0.21089770913939712\n",
      "train: step: 840, loss: 1.3030959367752075, acc: 0.53125, recall: 0.2407852564102564, precision: 0.23258928571428572, f_beta: 0.20977011494252873\n",
      "start training model\n",
      "train: step: 841, loss: 1.0313708782196045, acc: 0.703125, recall: 0.29776785714285714, precision: 0.2798363095238095, f_beta: 0.28612917972831764\n",
      "train: step: 842, loss: 0.9320789575576782, acc: 0.734375, recall: 0.3835193452380952, precision: 0.3117288961038961, f_beta: 0.33035714285714285\n",
      "train: step: 843, loss: 1.4328875541687012, acc: 0.546875, recall: 0.3014423076923077, precision: 0.21518308080808082, f_beta: 0.24764384920634921\n",
      "train: step: 844, loss: 1.175004482269287, acc: 0.625, recall: 0.3014069264069264, precision: 0.24222689075630252, f_beta: 0.26276788345753865\n",
      "train: step: 845, loss: 0.9267065525054932, acc: 0.765625, recall: 0.31875, precision: 0.3065104166666667, f_beta: 0.30177174975562077\n",
      "train: step: 846, loss: 0.9968745112419128, acc: 0.640625, recall: 0.28125, precision: 0.23715776182881448, f_beta: 0.24472502471728477\n",
      "train: step: 847, loss: 1.1318981647491455, acc: 0.71875, recall: 0.3931727994227994, precision: 0.29612522893772897, f_beta: 0.3293800709939148\n",
      "train: step: 848, loss: 0.9386085271835327, acc: 0.65625, recall: 0.30457042957042957, precision: 0.2680262445887446, f_beta: 0.27693972693972696\n",
      "train: step: 849, loss: 0.9476652145385742, acc: 0.78125, recall: 0.3868914072039072, precision: 0.33193542568542567, f_beta: 0.35143012445644023\n",
      "train: step: 850, loss: 1.1379001140594482, acc: 0.6875, recall: 0.3068181818181818, precision: 0.25108901515151516, f_beta: 0.271195652173913\n",
      "train: step: 851, loss: 0.9217284917831421, acc: 0.734375, recall: 0.346577380952381, precision: 0.31974206349206347, f_beta: 0.3287354659859197\n",
      "train: step: 852, loss: 0.852191686630249, acc: 0.78125, recall: 0.38288690476190473, precision: 0.40260416666666665, f_beta: 0.36831709956709957\n",
      "train: step: 853, loss: 1.1130187511444092, acc: 0.59375, recall: 0.30326704545454547, precision: 0.27630095598845594, f_beta: 0.2787245514147688\n",
      "train: step: 854, loss: 0.8366880416870117, acc: 0.765625, recall: 0.4118055555555556, precision: 0.3923611111111111, f_beta: 0.38587802108022695\n",
      "train: step: 855, loss: 0.9981354475021362, acc: 0.703125, recall: 0.3618055555555556, precision: 0.2716391859774213, f_beta: 0.2950497419247419\n",
      "train: step: 856, loss: 1.086087703704834, acc: 0.640625, recall: 0.31232638888888886, precision: 0.26614583333333336, f_beta: 0.27511345293853035\n",
      "train: step: 857, loss: 0.9133738279342651, acc: 0.734375, recall: 0.34876373626373625, precision: 0.29229052197802197, f_beta: 0.31107142857142855\n",
      "train: step: 858, loss: 0.8509784936904907, acc: 0.75, recall: 0.38048115079365075, precision: 0.3271329365079365, f_beta: 0.3433854522670312\n",
      "train: step: 859, loss: 0.8696932792663574, acc: 0.703125, recall: 0.2922585227272727, precision: 0.26679067460317457, f_beta: 0.27054884453781514\n",
      "train: step: 860, loss: 1.3844221830368042, acc: 0.578125, recall: 0.2976190476190476, precision: 0.24144491129785248, f_beta: 0.26273674242424244\n",
      "train: step: 861, loss: 0.7242840528488159, acc: 0.78125, recall: 0.2931502525252525, precision: 0.28107638888888886, f_beta: 0.28640078954357895\n",
      "train: step: 862, loss: 1.1671686172485352, acc: 0.5625, recall: 0.27818362193362195, precision: 0.2690191752691753, f_beta: 0.24756944444444443\n",
      "train: step: 863, loss: 1.063617467880249, acc: 0.6875, recall: 0.287995337995338, precision: 0.26339285714285715, f_beta: 0.2704580231596361\n",
      "train: step: 864, loss: 0.8499006032943726, acc: 0.703125, recall: 0.315207953810895, precision: 0.3009455821955822, f_beta: 0.3017528338596887\n",
      "train: step: 865, loss: 0.924574613571167, acc: 0.734375, recall: 0.29778138528138526, precision: 0.28020156926406925, f_beta: 0.28520498672238914\n",
      "train: step: 866, loss: 0.8511285781860352, acc: 0.703125, recall: 0.32663690476190477, precision: 0.26826923076923076, f_beta: 0.2878201659451659\n",
      "train: step: 867, loss: 0.9498487114906311, acc: 0.6875, recall: 0.3411458333333333, precision: 0.2771405677655678, f_beta: 0.29954969902762774\n",
      "train: step: 868, loss: 1.0320056676864624, acc: 0.65625, recall: 0.3116560522810523, precision: 0.2636363636363636, f_beta: 0.27931300725418373\n",
      "train: step: 869, loss: 1.0890394449234009, acc: 0.6875, recall: 0.36875, precision: 0.36167478354978355, f_beta: 0.35707670618854825\n",
      "train: step: 870, loss: 0.7627947330474854, acc: 0.765625, recall: 0.3958333333333333, precision: 0.3516369047619048, f_beta: 0.3633256304308936\n",
      "train: step: 871, loss: 1.4914823770523071, acc: 0.5, recall: 0.24531250000000002, precision: 0.18854166666666666, f_beta: 0.2082175925925926\n",
      "train: step: 872, loss: 0.9456887245178223, acc: 0.671875, recall: 0.31835178710178713, precision: 0.28191738816738815, f_beta: 0.2908474858474858\n",
      "train: step: 873, loss: 1.0484751462936401, acc: 0.65625, recall: 0.31425865800865804, precision: 0.269429788961039, f_beta: 0.27474747474747474\n",
      "train: step: 874, loss: 1.1167978048324585, acc: 0.65625, recall: 0.32196969696969696, precision: 0.2944617882117882, f_beta: 0.2987276875559608\n",
      "train: step: 875, loss: 1.1261597871780396, acc: 0.625, recall: 0.3166576479076479, precision: 0.27604166666666663, f_beta: 0.2857952440389511\n",
      "train: step: 876, loss: 1.0184048414230347, acc: 0.703125, recall: 0.3249458874458874, precision: 0.27486645299145296, f_beta: 0.29415064102564104\n",
      "train: step: 877, loss: 1.1634440422058105, acc: 0.578125, recall: 0.2869791666666667, precision: 0.26564407814407814, f_beta: 0.2685845721827731\n",
      "train: step: 878, loss: 1.103266716003418, acc: 0.640625, recall: 0.3400297619047619, precision: 0.3651535964035964, f_beta: 0.3205934343434343\n",
      "train: step: 879, loss: 1.1103792190551758, acc: 0.625, recall: 0.2829861111111111, precision: 0.2415674603174603, f_beta: 0.2572309226720991\n",
      "train: step: 880, loss: 0.8113523721694946, acc: 0.734375, recall: 0.28680555555555554, precision: 0.30919555322128855, f_beta: 0.2832049486461251\n",
      "train: step: 881, loss: 0.754767119884491, acc: 0.8125, recall: 0.3121221405228758, precision: 0.31980473570547097, f_beta: 0.30887651113076814\n",
      "train: step: 882, loss: 1.0547348260879517, acc: 0.65625, recall: 0.32845279720279724, precision: 0.275261544011544, f_beta: 0.2928460020371785\n",
      "train: step: 883, loss: 0.9013868570327759, acc: 0.703125, recall: 0.3665178571428572, precision: 0.32418154761904766, f_beta: 0.33729129597289265\n",
      "train: step: 884, loss: 0.9674283266067505, acc: 0.6875, recall: 0.33565301120448177, precision: 0.2739955357142857, f_beta: 0.29698660714285713\n",
      "train: step: 885, loss: 1.0621790885925293, acc: 0.671875, recall: 0.2709325396825397, precision: 0.24362789987789987, f_beta: 0.25048218325791854\n",
      "train: step: 886, loss: 0.8230113983154297, acc: 0.75, recall: 0.3101190476190476, precision: 0.30452533577533575, f_beta: 0.2926224656773856\n",
      "train: step: 887, loss: 1.136601209640503, acc: 0.671875, recall: 0.4118303571428571, precision: 0.32711988304093564, f_beta: 0.34219457013574656\n",
      "train: step: 888, loss: 0.878462016582489, acc: 0.671875, recall: 0.26875, precision: 0.25879329004329005, f_beta: 0.24923233882412382\n",
      "train: step: 889, loss: 0.9374122023582458, acc: 0.65625, recall: 0.28020833333333334, precision: 0.2519345238095238, f_beta: 0.2586085204151171\n",
      "train: step: 890, loss: 0.9096848964691162, acc: 0.703125, recall: 0.3130208333333333, precision: 0.2619295634920635, f_beta: 0.2832471450118509\n",
      "train: step: 891, loss: 1.1513729095458984, acc: 0.625, recall: 0.28937156593406593, precision: 0.2648042929292929, f_beta: 0.2705835830835831\n",
      "train: step: 892, loss: 1.065671682357788, acc: 0.703125, recall: 0.31381639194139194, precision: 0.32589285714285715, f_beta: 0.29671956134232347\n",
      "train: step: 893, loss: 0.797600507736206, acc: 0.78125, recall: 0.2994791666666667, precision: 0.2958158263305322, f_beta: 0.2961916786916787\n",
      "train: step: 894, loss: 0.8463424444198608, acc: 0.71875, recall: 0.4038690476190476, precision: 0.3200024801587302, f_beta: 0.3404525864627732\n",
      "train: step: 895, loss: 1.2198107242584229, acc: 0.578125, recall: 0.2577683346065699, precision: 0.24645598370927319, f_beta: 0.24310515873015873\n",
      "train: step: 896, loss: 0.9716265201568604, acc: 0.71875, recall: 0.36875, precision: 0.3544642857142857, f_beta: 0.33721001221001223\n",
      "train: step: 897, loss: 0.9598531723022461, acc: 0.65625, recall: 0.3373737373737374, precision: 0.2978438228438228, f_beta: 0.29772357028935975\n",
      "train: step: 898, loss: 1.2802174091339111, acc: 0.640625, recall: 0.2743872549019608, precision: 0.2390625, f_beta: 0.249262789182144\n",
      "train: step: 899, loss: 1.4848861694335938, acc: 0.484375, recall: 0.23234126984126985, precision: 0.19583333333333333, f_beta: 0.20481540518305225\n",
      "train: step: 900, loss: 0.6594316363334656, acc: 0.796875, recall: 0.3196428571428572, precision: 0.34542410714285715, f_beta: 0.32286140583554374\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:43:13.232269, step: 900, loss: 3.929739819632636, acc: 0.1545138888888889,precision: 0.07577058003318969, recall: 0.06556398946507952, f_beta: 0.06222657352957576\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-900\n",
      "\n",
      "train: step: 901, loss: 1.168586015701294, acc: 0.625, recall: 0.3351438492063492, precision: 0.2778481934731935, f_beta: 0.29246510921083974\n",
      "train: step: 902, loss: 1.5144950151443481, acc: 0.5625, recall: 0.26264880952380953, precision: 0.2572646103896104, f_beta: 0.2513798701298702\n",
      "train: step: 903, loss: 1.2517952919006348, acc: 0.640625, recall: 0.3197916666666667, precision: 0.246875, f_beta: 0.26938582251082255\n",
      "train: step: 904, loss: 0.7381035089492798, acc: 0.8125, recall: 0.3156288156288156, precision: 0.29836309523809523, f_beta: 0.3045691032823386\n",
      "train: step: 905, loss: 1.034923791885376, acc: 0.640625, recall: 0.2745535714285714, precision: 0.2675420168067227, f_beta: 0.2639268727440042\n",
      "train: step: 906, loss: 0.877253532409668, acc: 0.75, recall: 0.328125, precision: 0.3353298611111111, f_beta: 0.31727512913767664\n",
      "train: step: 907, loss: 1.1225992441177368, acc: 0.625, recall: 0.25863095238095235, precision: 0.25967261904761907, f_beta: 0.25047467152730307\n",
      "train: step: 908, loss: 1.0600595474243164, acc: 0.640625, recall: 0.2882436497326203, precision: 0.2677083333333333, f_beta: 0.2715728715728716\n",
      "train: step: 909, loss: 1.3138936758041382, acc: 0.59375, recall: 0.29332386363636365, precision: 0.23888888888888887, f_beta: 0.25349220791995725\n",
      "train: step: 910, loss: 1.035722017288208, acc: 0.640625, recall: 0.35819909257409255, precision: 0.28451930014430016, f_beta: 0.2855289763577807\n",
      "train: step: 911, loss: 1.182605504989624, acc: 0.59375, recall: 0.3171130952380952, precision: 0.2994791666666667, f_beta: 0.2809153469079939\n",
      "train: step: 912, loss: 0.9500601291656494, acc: 0.65625, recall: 0.3123816287878788, precision: 0.26345559056956114, f_beta: 0.2742314788754417\n",
      "train: step: 913, loss: 0.9076653718948364, acc: 0.6875, recall: 0.3571158008658008, precision: 0.31306818181818186, f_beta: 0.31289231601731604\n",
      "train: step: 914, loss: 1.1064889430999756, acc: 0.65625, recall: 0.35245535714285714, precision: 0.3345180860805861, f_beta: 0.3372282608695652\n",
      "train: step: 915, loss: 1.2070729732513428, acc: 0.59375, recall: 0.3170386904761905, precision: 0.2943714985994398, f_beta: 0.3010800691244239\n",
      "train: step: 916, loss: 1.2286808490753174, acc: 0.59375, recall: 0.2977430555555556, precision: 0.2579162157287157, f_beta: 0.2571606634106634\n",
      "train: step: 917, loss: 1.3103764057159424, acc: 0.640625, recall: 0.36446314102564104, precision: 0.33888888888888885, f_beta: 0.32672413793103444\n",
      "train: step: 918, loss: 1.0353938341140747, acc: 0.71875, recall: 0.30520833333333336, precision: 0.2544642857142857, f_beta: 0.2739029790660225\n",
      "train: step: 919, loss: 1.01070237159729, acc: 0.625, recall: 0.30036630036630035, precision: 0.26588893133010777, f_beta: 0.27325181538891213\n",
      "train: step: 920, loss: 1.1414737701416016, acc: 0.671875, recall: 0.3677520396270396, precision: 0.3434343434343434, f_beta: 0.3457971317897789\n",
      "train: step: 921, loss: 1.1333332061767578, acc: 0.671875, recall: 0.3435096153846154, precision: 0.3251488095238095, f_beta: 0.3225595238095238\n",
      "train: step: 922, loss: 1.2334136962890625, acc: 0.65625, recall: 0.3623421717171717, precision: 0.31376262626262624, f_beta: 0.306344696969697\n",
      "train: step: 923, loss: 1.018646240234375, acc: 0.65625, recall: 0.3217086834733893, precision: 0.286656746031746, f_beta: 0.29393329194025786\n",
      "train: step: 924, loss: 0.9861311912536621, acc: 0.671875, recall: 0.3440815580618212, precision: 0.31456766917293233, f_beta: 0.3001537935748462\n",
      "start training model\n",
      "train: step: 925, loss: 0.9232168197631836, acc: 0.65625, recall: 0.35, precision: 0.30328144078144076, f_beta: 0.31614145658263304\n",
      "train: step: 926, loss: 0.901308536529541, acc: 0.78125, recall: 0.36363636363636365, precision: 0.33036858974358974, f_beta: 0.3414783679588777\n",
      "train: step: 927, loss: 0.8713053464889526, acc: 0.765625, recall: 0.40625000000000006, precision: 0.35, f_beta: 0.36227935139573064\n",
      "train: step: 928, loss: 1.077160358428955, acc: 0.640625, recall: 0.35555555555555557, precision: 0.3039347804972805, f_beta: 0.3051282051282051\n",
      "train: step: 929, loss: 0.4851979613304138, acc: 0.828125, recall: 0.353228021978022, precision: 0.3572916666666667, f_beta: 0.35264550264550265\n",
      "train: step: 930, loss: 0.7983372807502747, acc: 0.71875, recall: 0.2951923076923077, precision: 0.2725694444444444, f_beta: 0.27642992424242424\n",
      "train: step: 931, loss: 0.8195355534553528, acc: 0.71875, recall: 0.3524305555555556, precision: 0.34275846702317286, f_beta: 0.3246063748079877\n",
      "train: step: 932, loss: 0.8261124491691589, acc: 0.71875, recall: 0.4076923076923077, precision: 0.30021061454884984, f_beta: 0.32152195327891925\n",
      "train: step: 933, loss: 0.8092930316925049, acc: 0.75, recall: 0.3924408924408924, precision: 0.36284722222222227, f_beta: 0.3637732919254658\n",
      "train: step: 934, loss: 0.6863337755203247, acc: 0.78125, recall: 0.43333333333333335, precision: 0.3480902777777778, f_beta: 0.3674779834962902\n",
      "train: step: 935, loss: 0.8915051221847534, acc: 0.75, recall: 0.3980769230769231, precision: 0.359375, f_beta: 0.3742623117623118\n",
      "train: step: 936, loss: 0.8673462867736816, acc: 0.796875, recall: 0.4363095238095238, precision: 0.3784051120448179, f_beta: 0.4012877747252747\n",
      "train: step: 937, loss: 0.6521278619766235, acc: 0.8125, recall: 0.4083806818181818, precision: 0.38802083333333337, f_beta: 0.38990575396825394\n",
      "train: step: 938, loss: 0.8652349710464478, acc: 0.734375, recall: 0.4326923076923077, precision: 0.37318948412698416, f_beta: 0.38093434343434346\n",
      "train: step: 939, loss: 0.7603853940963745, acc: 0.78125, recall: 0.37515262515262515, precision: 0.35922417043740573, f_beta: 0.36289423296002243\n",
      "train: step: 940, loss: 1.0405521392822266, acc: 0.6875, recall: 0.3899034992784992, precision: 0.3385890151515152, f_beta: 0.3519897382029735\n",
      "train: step: 941, loss: 0.5629619359970093, acc: 0.828125, recall: 0.3480902777777778, precision: 0.3637152777777778, f_beta: 0.35478670634920634\n",
      "train: step: 942, loss: 0.6871588826179504, acc: 0.75, recall: 0.34707497363747364, precision: 0.31951659451659453, f_beta: 0.33198051948051943\n",
      "train: step: 943, loss: 0.49789726734161377, acc: 0.828125, recall: 0.3877361673414305, precision: 0.36446314102564104, f_beta: 0.3722909972909973\n",
      "train: step: 944, loss: 0.5255659818649292, acc: 0.859375, recall: 0.3524305555555556, precision: 0.3273103632478632, f_beta: 0.33881944444444445\n",
      "train: step: 945, loss: 0.6347939968109131, acc: 0.765625, recall: 0.35979567307692306, precision: 0.34663461538461543, f_beta: 0.34712475504035606\n",
      "train: step: 946, loss: 1.2438595294952393, acc: 0.625, recall: 0.32055097680097683, precision: 0.2799062049062049, f_beta: 0.288178015771526\n",
      "train: step: 947, loss: 0.5212802290916443, acc: 0.828125, recall: 0.3361736673414305, precision: 0.32092069115095434, f_beta: 0.3280005904183536\n",
      "train: step: 948, loss: 0.5763747692108154, acc: 0.828125, recall: 0.4725694444444445, precision: 0.37351190476190477, f_beta: 0.4009303774928775\n",
      "train: step: 949, loss: 0.9492394328117371, acc: 0.71875, recall: 0.351963141025641, precision: 0.30404647435897436, f_beta: 0.3204606157731158\n",
      "train: step: 950, loss: 0.9221539497375488, acc: 0.734375, recall: 0.3600446428571428, precision: 0.3378472222222222, f_beta: 0.34665978997925595\n",
      "train: step: 951, loss: 0.9233497381210327, acc: 0.734375, recall: 0.38686204146730463, precision: 0.36649305555555556, f_beta: 0.3489719538912314\n",
      "train: step: 952, loss: 0.8657919764518738, acc: 0.671875, recall: 0.33862920168067223, precision: 0.37842261904761904, f_beta: 0.31753351712942235\n",
      "train: step: 953, loss: 0.6030545830726624, acc: 0.859375, recall: 0.4535714285714286, precision: 0.42267628205128205, f_beta: 0.41586116734143047\n",
      "train: step: 954, loss: 0.8393052816390991, acc: 0.75, recall: 0.3915404040404041, precision: 0.340719696969697, f_beta: 0.35029121098200044\n",
      "train: step: 955, loss: 0.7686285376548767, acc: 0.78125, recall: 0.4458062770562771, precision: 0.4465909090909091, f_beta: 0.4033831298636396\n",
      "train: step: 956, loss: 1.0811052322387695, acc: 0.65625, recall: 0.2815972222222222, precision: 0.2826007326007326, f_beta: 0.27677808302808304\n",
      "train: step: 957, loss: 0.7895917296409607, acc: 0.734375, recall: 0.36216517857142855, precision: 0.30877976190476186, f_beta: 0.3195390160142663\n",
      "train: step: 958, loss: 0.5462182760238647, acc: 0.859375, recall: 0.4811011904761905, precision: 0.4625, f_beta: 0.45669642857142856\n",
      "train: step: 959, loss: 0.7783823609352112, acc: 0.734375, recall: 0.3514136904761905, precision: 0.3587053571428572, f_beta: 0.3480271464646465\n",
      "train: step: 960, loss: 0.8506972789764404, acc: 0.765625, recall: 0.35213675213675216, precision: 0.3436298076923077, f_beta: 0.3395346279537456\n",
      "train: step: 961, loss: 0.8948057293891907, acc: 0.71875, recall: 0.3984375, precision: 0.3737655573593074, f_beta: 0.3811500195121799\n",
      "train: step: 962, loss: 0.8727713823318481, acc: 0.703125, recall: 0.35, precision: 0.32908653846153846, f_beta: 0.3344002525252525\n",
      "train: step: 963, loss: 0.7418017983436584, acc: 0.765625, recall: 0.3496867715617716, precision: 0.29717261904761905, f_beta: 0.3172131642512077\n",
      "train: step: 964, loss: 0.8282498121261597, acc: 0.78125, recall: 0.42688041125541126, precision: 0.38999542124542125, f_beta: 0.38215488215488214\n",
      "train: step: 965, loss: 0.8982243537902832, acc: 0.6875, recall: 0.36383928571428575, precision: 0.3873511904761905, f_beta: 0.31659958746703204\n",
      "train: step: 966, loss: 0.890743613243103, acc: 0.671875, recall: 0.36363636363636365, precision: 0.3469818376068376, f_beta: 0.31108130999435346\n",
      "train: step: 967, loss: 0.6253628730773926, acc: 0.78125, recall: 0.3878968253968254, precision: 0.3595610119047619, f_beta: 0.3586143783532222\n",
      "train: step: 968, loss: 0.720952033996582, acc: 0.796875, recall: 0.4337069180819181, precision: 0.41121031746031744, f_beta: 0.4183823944597602\n",
      "train: step: 969, loss: 0.9405093193054199, acc: 0.71875, recall: 0.3395833333333333, precision: 0.3224431818181818, f_beta: 0.32079406367290003\n",
      "train: step: 970, loss: 1.0394375324249268, acc: 0.625, recall: 0.35252403846153846, precision: 0.3235818001443001, f_beta: 0.3077462121212121\n",
      "train: step: 971, loss: 0.7114688158035278, acc: 0.75, recall: 0.3854166666666667, precision: 0.3339285714285714, f_beta: 0.3424145299145299\n",
      "train: step: 972, loss: 0.759101390838623, acc: 0.75, recall: 0.3580492424242424, precision: 0.32690972222222214, f_beta: 0.338687840727689\n",
      "train: step: 973, loss: 0.5778098702430725, acc: 0.796875, recall: 0.38248938561438567, precision: 0.3389423076923077, f_beta: 0.3509662243214875\n",
      "train: step: 974, loss: 0.733157753944397, acc: 0.8125, recall: 0.4574835526315789, precision: 0.3949023838004101, f_beta: 0.4152918992557151\n",
      "train: step: 975, loss: 0.7057895064353943, acc: 0.734375, recall: 0.4024959415584416, precision: 0.33871673669467783, f_beta: 0.35068663866091343\n",
      "train: step: 976, loss: 1.1812233924865723, acc: 0.640625, recall: 0.35305059523809523, precision: 0.2976190476190476, f_beta: 0.31457662707662715\n",
      "train: step: 977, loss: 0.6947014927864075, acc: 0.78125, recall: 0.425, precision: 0.38122519841269836, f_beta: 0.3813391718476008\n",
      "train: step: 978, loss: 0.8803281784057617, acc: 0.75, recall: 0.3937229437229437, precision: 0.35328733766233766, f_beta: 0.3658061594202898\n",
      "train: step: 979, loss: 0.891292929649353, acc: 0.671875, recall: 0.3287774725274725, precision: 0.2706529581529582, f_beta: 0.2871222527472527\n",
      "train: step: 980, loss: 1.1561623811721802, acc: 0.59375, recall: 0.31299603174603174, precision: 0.28720238095238093, f_beta: 0.2970180860805861\n",
      "train: step: 981, loss: 0.7483025789260864, acc: 0.734375, recall: 0.34994588744588745, precision: 0.3325126262626263, f_beta: 0.3358076563958917\n",
      "train: step: 982, loss: 0.6418263912200928, acc: 0.8125, recall: 0.4822916666666667, precision: 0.4260912698412698, f_beta: 0.42878898635477586\n",
      "train: step: 983, loss: 0.43450719118118286, acc: 0.875, recall: 0.5175438596491229, precision: 0.49270833333333336, f_beta: 0.5017830330330331\n",
      "train: step: 984, loss: 0.9567564129829407, acc: 0.71875, recall: 0.450895979020979, precision: 0.36723484848484844, f_beta: 0.38556110556110557\n",
      "train: step: 985, loss: 0.7976779341697693, acc: 0.796875, recall: 0.44072420634920634, precision: 0.4, f_beta: 0.409478021978022\n",
      "train: step: 986, loss: 0.780301034450531, acc: 0.796875, recall: 0.4461137820512821, precision: 0.35925480769230766, f_beta: 0.384414400514944\n",
      "train: step: 987, loss: 0.6131545305252075, acc: 0.859375, recall: 0.5351415945165945, precision: 0.5246212121212122, f_beta: 0.49857295482295483\n",
      "train: step: 988, loss: 0.6851158142089844, acc: 0.78125, recall: 0.3738839285714286, precision: 0.33510154061624653, f_beta: 0.34698885344046637\n",
      "train: step: 989, loss: 0.7663173079490662, acc: 0.765625, recall: 0.36160714285714285, precision: 0.3795634920634921, f_beta: 0.36024121352785143\n",
      "train: step: 990, loss: 0.8262521028518677, acc: 0.71875, recall: 0.43561507936507937, precision: 0.3858211233211233, f_beta: 0.39477154789654795\n",
      "train: step: 991, loss: 0.8905102014541626, acc: 0.703125, recall: 0.35873397435897436, precision: 0.3280448717948718, f_beta: 0.32534652847152845\n",
      "train: step: 992, loss: 0.9666194915771484, acc: 0.65625, recall: 0.3326194638694639, precision: 0.2999866452991453, f_beta: 0.30613099619678563\n",
      "train: step: 993, loss: 0.5789647698402405, acc: 0.84375, recall: 0.459375, precision: 0.4769965277777778, f_beta: 0.4485410575048733\n",
      "train: step: 994, loss: 0.9066515564918518, acc: 0.65625, recall: 0.2890625, precision: 0.22844291125541127, f_beta: 0.24962327075098814\n",
      "train: step: 995, loss: 1.0512657165527344, acc: 0.65625, recall: 0.3079441391941392, precision: 0.3137019230769231, f_beta: 0.3029239027880332\n",
      "train: step: 996, loss: 0.7956187129020691, acc: 0.71875, recall: 0.3723214285714286, precision: 0.35401785714285716, f_beta: 0.3497878959276018\n",
      "train: step: 997, loss: 0.6598420739173889, acc: 0.78125, recall: 0.4132891414141414, precision: 0.39864718614718614, f_beta: 0.40172241973712564\n",
      "train: step: 998, loss: 1.0234179496765137, acc: 0.65625, recall: 0.30773809523809526, precision: 0.28734217171717175, f_beta: 0.2945932539682539\n",
      "train: step: 999, loss: 0.7664967775344849, acc: 0.796875, recall: 0.36810897435897433, precision: 0.3392857142857143, f_beta: 0.3503663003663004\n",
      "train: step: 1000, loss: 1.0153381824493408, acc: 0.71875, recall: 0.443328373015873, precision: 0.43377976190476186, f_beta: 0.41006753663003664\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:45:05.246289, step: 1000, loss: 4.3009454939100475, acc: 0.16145833333333334,precision: 0.07887823924895003, recall: 0.0915161680019136, f_beta: 0.07283577197237585\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1000\n",
      "\n",
      "train: step: 1001, loss: 0.8911867141723633, acc: 0.734375, recall: 0.355654761904762, precision: 0.353125, f_beta: 0.3480982905982906\n",
      "train: step: 1002, loss: 0.8082654476165771, acc: 0.78125, recall: 0.4238467261904762, precision: 0.40234375, f_beta: 0.40924180883771405\n",
      "train: step: 1003, loss: 1.0117104053497314, acc: 0.65625, recall: 0.3401356456043956, precision: 0.2903104707792208, f_beta: 0.3065305731406275\n",
      "train: step: 1004, loss: 0.8860805034637451, acc: 0.640625, recall: 0.27006448412698414, precision: 0.30326704545454547, f_beta: 0.2800213675213675\n",
      "train: step: 1005, loss: 1.013707160949707, acc: 0.71875, recall: 0.357514880952381, precision: 0.30751488095238094, f_beta: 0.3185397437013816\n",
      "train: step: 1006, loss: 1.028960108757019, acc: 0.703125, recall: 0.34521103896103894, precision: 0.31314831002331006, f_beta: 0.3088626952757388\n",
      "train: step: 1007, loss: 0.7224625945091248, acc: 0.8125, recall: 0.34715544871794873, precision: 0.3128720238095238, f_beta: 0.3266346153846154\n",
      "train: step: 1008, loss: 0.9587514996528625, acc: 0.734375, recall: 0.4, precision: 0.3828125, f_beta: 0.3544308213716108\n",
      "start training model\n",
      "train: step: 1009, loss: 0.5359356999397278, acc: 0.828125, recall: 0.3660714285714286, precision: 0.3276041666666667, f_beta: 0.34329172289698606\n",
      "train: step: 1010, loss: 0.5939391851425171, acc: 0.828125, recall: 0.40179135101010105, precision: 0.40789930555555554, f_beta: 0.3894410889355742\n",
      "train: step: 1011, loss: 0.6917389631271362, acc: 0.765625, recall: 0.43506944444444445, precision: 0.396113782051282, f_beta: 0.3940301120448179\n",
      "train: step: 1012, loss: 0.792062520980835, acc: 0.8125, recall: 0.39663461538461536, precision: 0.36584429824561404, f_beta: 0.37717765894236477\n",
      "train: step: 1013, loss: 0.532590389251709, acc: 0.859375, recall: 0.4598214285714286, precision: 0.42873168498168496, f_beta: 0.4338346586987892\n",
      "train: step: 1014, loss: 0.5800739526748657, acc: 0.84375, recall: 0.3880208333333333, precision: 0.3515873015873016, f_beta: 0.3554423309178744\n",
      "train: step: 1015, loss: 0.7732721567153931, acc: 0.765625, recall: 0.42168421855921856, precision: 0.3810096153846153, f_beta: 0.39629809188632714\n",
      "train: step: 1016, loss: 0.34474116563796997, acc: 0.9375, recall: 0.5588235294117647, precision: 0.5145833333333334, f_beta: 0.5281385281385281\n",
      "train: step: 1017, loss: 0.7588931322097778, acc: 0.734375, recall: 0.36607142857142855, precision: 0.309672619047619, f_beta: 0.3263888888888889\n",
      "train: step: 1018, loss: 0.7133910655975342, acc: 0.765625, recall: 0.38385416666666666, precision: 0.3895833333333333, f_beta: 0.3757367825672779\n",
      "train: step: 1019, loss: 0.7315664291381836, acc: 0.734375, recall: 0.40838675213675213, precision: 0.42831387362637363, f_beta: 0.3971397801544861\n",
      "train: step: 1020, loss: 0.5324941277503967, acc: 0.8125, recall: 0.3725360576923077, precision: 0.34296875, f_beta: 0.3512326388888889\n",
      "train: step: 1021, loss: 0.7153295278549194, acc: 0.75, recall: 0.43030753968253965, precision: 0.38978174603174603, f_beta: 0.40242853551677077\n",
      "train: step: 1022, loss: 0.7624759674072266, acc: 0.78125, recall: 0.4593952922077922, precision: 0.3758470695970696, f_beta: 0.39786525974025977\n",
      "train: step: 1023, loss: 0.569703996181488, acc: 0.828125, recall: 0.42861519607843135, precision: 0.4410714285714286, f_beta: 0.43104187479187484\n",
      "train: step: 1024, loss: 0.6402997970581055, acc: 0.828125, recall: 0.4011591478696742, precision: 0.3504464285714286, f_beta: 0.35818142768270644\n",
      "train: step: 1025, loss: 0.7713745832443237, acc: 0.765625, recall: 0.4305555555555556, precision: 0.3722870879120879, f_beta: 0.38291814021219056\n",
      "train: step: 1026, loss: 0.4161551594734192, acc: 0.890625, recall: 0.4583333333333333, precision: 0.44761904761904764, f_beta: 0.4509433305485937\n",
      "train: step: 1027, loss: 0.857968270778656, acc: 0.734375, recall: 0.3967013888888889, precision: 0.4025592463092463, f_beta: 0.38167569659442724\n",
      "train: step: 1028, loss: 0.5739439129829407, acc: 0.890625, recall: 0.45625, precision: 0.43348214285714287, f_beta: 0.42431024141550455\n",
      "train: step: 1029, loss: 0.745224118232727, acc: 0.796875, recall: 0.44880952380952377, precision: 0.4321962759462759, f_beta: 0.42981837606837614\n",
      "train: step: 1030, loss: 0.8691576719284058, acc: 0.703125, recall: 0.4319444444444444, precision: 0.3895292207792208, f_beta: 0.3858411416799575\n",
      "train: step: 1031, loss: 0.5784429311752319, acc: 0.796875, recall: 0.41517857142857145, precision: 0.3972222222222222, f_beta: 0.4022157853040206\n",
      "train: step: 1032, loss: 0.6499509215354919, acc: 0.765625, recall: 0.39618055555555554, precision: 0.3411782661782662, f_beta: 0.3586747198879552\n",
      "train: step: 1033, loss: 0.7910256385803223, acc: 0.71875, recall: 0.36944444444444446, precision: 0.37777777777777777, f_beta: 0.3644998229176728\n",
      "train: step: 1034, loss: 0.667900800704956, acc: 0.78125, recall: 0.4162326388888889, precision: 0.41610004578754584, f_beta: 0.3942960054706659\n",
      "train: step: 1035, loss: 0.6897252202033997, acc: 0.8125, recall: 0.40625, precision: 0.3782467532467533, f_beta: 0.38994338994338995\n",
      "train: step: 1036, loss: 0.6839554905891418, acc: 0.75, recall: 0.4322916666666667, precision: 0.421875, f_beta: 0.41763855661881977\n",
      "train: step: 1037, loss: 0.6192798614501953, acc: 0.796875, recall: 0.43938873626373626, precision: 0.4161931818181819, f_beta: 0.4179899267399267\n",
      "train: step: 1038, loss: 0.7330586910247803, acc: 0.78125, recall: 0.3757440476190476, precision: 0.3489583333333333, f_beta: 0.3573008073008073\n",
      "train: step: 1039, loss: 0.540288507938385, acc: 0.84375, recall: 0.5256076388888888, precision: 0.5167613636363636, f_beta: 0.5084172488643551\n",
      "train: step: 1040, loss: 0.6638292670249939, acc: 0.796875, recall: 0.38470123626373626, precision: 0.4201179029304029, f_beta: 0.391453373015873\n",
      "train: step: 1041, loss: 0.3689417839050293, acc: 0.890625, recall: 0.490327380952381, precision: 0.47256944444444443, f_beta: 0.47755583536833535\n",
      "train: step: 1042, loss: 0.5630450248718262, acc: 0.875, recall: 0.54375, precision: 0.5716269841269841, f_beta: 0.5298930300865285\n",
      "train: step: 1043, loss: 0.41345298290252686, acc: 0.859375, recall: 0.4248798076923077, precision: 0.402930402930403, f_beta: 0.3969322344322344\n",
      "train: step: 1044, loss: 0.6146539449691772, acc: 0.78125, recall: 0.44046052631578947, precision: 0.40501373626373627, f_beta: 0.4137698412698413\n",
      "train: step: 1045, loss: 0.531243085861206, acc: 0.84375, recall: 0.4479166666666667, precision: 0.424968671679198, f_beta: 0.42171717171717166\n",
      "train: step: 1046, loss: 0.5782353281974792, acc: 0.828125, recall: 0.42613636363636365, precision: 0.37395833333333334, f_beta: 0.3767857142857143\n",
      "train: step: 1047, loss: 0.7411791682243347, acc: 0.765625, recall: 0.47817460317460314, precision: 0.393328373015873, f_beta: 0.41199813258636786\n",
      "train: step: 1048, loss: 0.6835482120513916, acc: 0.8125, recall: 0.4547348484848485, precision: 0.41030844155844165, f_beta: 0.4241892446633826\n",
      "train: step: 1049, loss: 0.7366125583648682, acc: 0.75, recall: 0.4075520833333333, precision: 0.373921130952381, f_beta: 0.3743765782828283\n",
      "train: step: 1050, loss: 0.6484838724136353, acc: 0.8125, recall: 0.5052083333333333, precision: 0.4678571428571429, f_beta: 0.45585404483430797\n",
      "train: step: 1051, loss: 0.5079131126403809, acc: 0.84375, recall: 0.5119047619047619, precision: 0.4474431818181818, f_beta: 0.45405500296804646\n",
      "train: step: 1052, loss: 0.5809692144393921, acc: 0.8125, recall: 0.39711718020541553, precision: 0.39322916666666663, f_beta: 0.3944295900178253\n",
      "train: step: 1053, loss: 0.7180163860321045, acc: 0.765625, recall: 0.38898809523809524, precision: 0.3933035714285714, f_beta: 0.38619979557479556\n",
      "train: step: 1054, loss: 0.5951591730117798, acc: 0.8125, recall: 0.3229166666666667, precision: 0.3029491341991342, f_beta: 0.30749876051837877\n",
      "train: step: 1055, loss: 0.6962233781814575, acc: 0.765625, recall: 0.46974206349206354, precision: 0.41443452380952384, f_beta: 0.4203643578643579\n",
      "train: step: 1056, loss: 0.7047097086906433, acc: 0.765625, recall: 0.3600388071895425, precision: 0.33273225957049485, f_beta: 0.34041053921568626\n",
      "train: step: 1057, loss: 0.45578116178512573, acc: 0.890625, recall: 0.5052083333333333, precision: 0.4988839285714286, f_beta: 0.49724858474858474\n",
      "train: step: 1058, loss: 0.6247537136077881, acc: 0.78125, recall: 0.41510416666666666, precision: 0.38750789141414144, f_beta: 0.38591279253636945\n",
      "train: step: 1059, loss: 0.7665390372276306, acc: 0.71875, recall: 0.3754006410256411, precision: 0.33205128205128204, f_beta: 0.3495104895104896\n",
      "train: step: 1060, loss: 0.6773490905761719, acc: 0.796875, recall: 0.4212622549019608, precision: 0.39010416666666664, f_beta: 0.3969223484848485\n",
      "train: step: 1061, loss: 0.42768946290016174, acc: 0.859375, recall: 0.43903186274509803, precision: 0.42119726678550207, f_beta: 0.4273520277676288\n",
      "train: step: 1062, loss: 0.635097861289978, acc: 0.8125, recall: 0.43707386363636364, precision: 0.44548611111111114, f_beta: 0.4354713510118006\n",
      "train: step: 1063, loss: 0.5746999382972717, acc: 0.84375, recall: 0.5256696428571429, precision: 0.46845238095238095, f_beta: 0.4859126984126984\n",
      "train: step: 1064, loss: 0.972698450088501, acc: 0.6875, recall: 0.3983630952380952, precision: 0.38390151515151516, f_beta: 0.38098181058707375\n",
      "train: step: 1065, loss: 0.6864104270935059, acc: 0.796875, recall: 0.4205357142857143, precision: 0.3755208333333333, f_beta: 0.38726851851851857\n",
      "train: step: 1066, loss: 0.6524271368980408, acc: 0.796875, recall: 0.4061011904761904, precision: 0.4166666666666667, f_beta: 0.3895947802197802\n",
      "train: step: 1067, loss: 0.5838561058044434, acc: 0.78125, recall: 0.36641865079365077, precision: 0.39826388888888886, f_beta: 0.3644414065466697\n",
      "train: step: 1068, loss: 0.7894325256347656, acc: 0.734375, recall: 0.34873511904761906, precision: 0.33214285714285713, f_beta: 0.3316943473193473\n",
      "train: step: 1069, loss: 0.7613070011138916, acc: 0.734375, recall: 0.38349358974358977, precision: 0.38958333333333334, f_beta: 0.37985446570972886\n",
      "train: step: 1070, loss: 0.506914496421814, acc: 0.828125, recall: 0.45952380952380956, precision: 0.44193722943722946, f_beta: 0.44843478889531524\n",
      "train: step: 1071, loss: 0.6852270364761353, acc: 0.765625, recall: 0.44098011363636364, precision: 0.36810064935064934, f_beta: 0.36995356793743894\n",
      "train: step: 1072, loss: 0.43637412786483765, acc: 0.8125, recall: 0.34672619047619047, precision: 0.37572843822843827, f_beta: 0.35244565217391305\n",
      "train: step: 1073, loss: 0.5938520431518555, acc: 0.8125, recall: 0.4878472222222222, precision: 0.4789624183006536, f_beta: 0.4591675685425685\n",
      "train: step: 1074, loss: 0.49826982617378235, acc: 0.875, recall: 0.4191468253968254, precision: 0.40736607142857145, f_beta: 0.41142429193899777\n",
      "train: step: 1075, loss: 0.694416880607605, acc: 0.78125, recall: 0.3402777777777778, precision: 0.3103693181818182, f_beta: 0.30305429864253397\n",
      "train: step: 1076, loss: 0.590847373008728, acc: 0.78125, recall: 0.3949032738095238, precision: 0.4127604166666667, f_beta: 0.38682177197802203\n",
      "train: step: 1077, loss: 0.47049325704574585, acc: 0.90625, recall: 0.45738636363636365, precision: 0.45416666666666666, f_beta: 0.4533730158730159\n",
      "train: step: 1078, loss: 0.5893254280090332, acc: 0.796875, recall: 0.4395363408521303, precision: 0.46294642857142854, f_beta: 0.44126984126984126\n",
      "train: step: 1079, loss: 0.7797435522079468, acc: 0.796875, recall: 0.5337752525252526, precision: 0.45494281045751633, f_beta: 0.4815904581529582\n",
      "train: step: 1080, loss: 0.5902695059776306, acc: 0.828125, recall: 0.4770833333333333, precision: 0.44223484848484845, f_beta: 0.44102365026278073\n",
      "train: step: 1081, loss: 0.672027051448822, acc: 0.75, recall: 0.30913461538461534, precision: 0.3265997023809524, f_beta: 0.3113172043010753\n",
      "train: step: 1082, loss: 0.5901170969009399, acc: 0.828125, recall: 0.5290178571428572, precision: 0.4839015151515152, f_beta: 0.497184065934066\n",
      "train: step: 1083, loss: 0.8734704256057739, acc: 0.71875, recall: 0.47301136363636365, precision: 0.45798611111111104, f_beta: 0.4457318722943723\n",
      "train: step: 1084, loss: 0.7825822830200195, acc: 0.75, recall: 0.4171875, precision: 0.36410984848484845, f_beta: 0.37388649425287357\n",
      "train: step: 1085, loss: 0.691470205783844, acc: 0.8125, recall: 0.4526515151515152, precision: 0.4005681818181818, f_beta: 0.42068981742894784\n",
      "train: step: 1086, loss: 0.4482049345970154, acc: 0.859375, recall: 0.4713541666666667, precision: 0.42545405982905987, f_beta: 0.4392376373626374\n",
      "train: step: 1087, loss: 0.7958536148071289, acc: 0.796875, recall: 0.4257742257742258, precision: 0.4396306818181818, f_beta: 0.4199204357470487\n",
      "train: step: 1088, loss: 0.6963606476783752, acc: 0.78125, recall: 0.4974431818181818, precision: 0.4682291666666667, f_beta: 0.45673791589480955\n",
      "train: step: 1089, loss: 0.623336911201477, acc: 0.796875, recall: 0.41813725490196085, precision: 0.3805465367965368, f_beta: 0.3901910296167804\n",
      "train: step: 1090, loss: 0.3896644711494446, acc: 0.875, recall: 0.4342261904761905, precision: 0.44823232323232326, f_beta: 0.43653273809523807\n",
      "train: step: 1091, loss: 0.5617344975471497, acc: 0.84375, recall: 0.46770833333333334, precision: 0.4370265151515152, f_beta: 0.4404217064400131\n",
      "train: step: 1092, loss: 0.8142165541648865, acc: 0.6875, recall: 0.3654513888888889, precision: 0.358953373015873, f_beta: 0.3563201300333653\n",
      "start training model\n",
      "train: step: 1093, loss: 0.5610518455505371, acc: 0.828125, recall: 0.43472222222222223, precision: 0.391025641025641, f_beta: 0.40934210526315795\n",
      "train: step: 1094, loss: 0.37037593126296997, acc: 0.90625, recall: 0.49107142857142855, precision: 0.43576388888888895, f_beta: 0.45133726567550103\n",
      "train: step: 1095, loss: 0.3576872646808624, acc: 0.90625, recall: 0.5104166666666667, precision: 0.4756944444444444, f_beta: 0.47627801120448177\n",
      "train: step: 1096, loss: 0.4930732548236847, acc: 0.921875, recall: 0.6428571428571429, precision: 0.5994791666666667, f_beta: 0.604048990462034\n",
      "train: step: 1097, loss: 0.5219837427139282, acc: 0.859375, recall: 0.5145833333333334, precision: 0.49970238095238095, f_beta: 0.504503367003367\n",
      "train: step: 1098, loss: 0.4250775873661041, acc: 0.875, recall: 0.46875, precision: 0.41778273809523814, f_beta: 0.4354828042328042\n",
      "train: step: 1099, loss: 0.3604930341243744, acc: 0.875, recall: 0.4708333333333333, precision: 0.4296875, f_beta: 0.43720238095238095\n",
      "train: step: 1100, loss: 0.48454293608665466, acc: 0.90625, recall: 0.525, precision: 0.48680555555555555, f_beta: 0.4974983414418399\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:46:57.410882, step: 1100, loss: 4.9965991444057885, acc: 0.203125,precision: 0.08814798185202598, recall: 0.0927159645909646, f_beta: 0.08250614366652913\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1100\n",
      "\n",
      "train: step: 1101, loss: 0.5306776762008667, acc: 0.8125, recall: 0.4975198412698413, precision: 0.4510416666666666, f_beta: 0.44424019607843135\n",
      "train: step: 1102, loss: 0.41324853897094727, acc: 0.90625, recall: 0.4598214285714286, precision: 0.4310966810966811, f_beta: 0.4323412698412698\n",
      "train: step: 1103, loss: 0.3127254843711853, acc: 0.90625, recall: 0.47916666666666663, precision: 0.414463141025641, f_beta: 0.43916666666666665\n",
      "train: step: 1104, loss: 0.47194281220436096, acc: 0.890625, recall: 0.5431547619047619, precision: 0.5119047619047619, f_beta: 0.5112179487179487\n",
      "train: step: 1105, loss: 0.44491836428642273, acc: 0.859375, recall: 0.5104166666666667, precision: 0.53125, f_beta: 0.5002976190476189\n",
      "train: step: 1106, loss: 0.23992124199867249, acc: 0.9375, recall: 0.46875, precision: 0.4877232142857143, f_beta: 0.4726851851851852\n",
      "train: step: 1107, loss: 0.2669928967952728, acc: 0.921875, recall: 0.5, precision: 0.4318181818181818, f_beta: 0.45535714285714285\n",
      "train: step: 1108, loss: 0.5238670110702515, acc: 0.875, recall: 0.503125, precision: 0.49046052631578946, f_beta: 0.48124731874731874\n",
      "train: step: 1109, loss: 0.5399723052978516, acc: 0.84375, recall: 0.53125, precision: 0.4317708333333333, f_beta: 0.4616071428571429\n",
      "train: step: 1110, loss: 0.41922247409820557, acc: 0.859375, recall: 0.48958333333333337, precision: 0.4208333333333334, f_beta: 0.44254385964912285\n",
      "train: step: 1111, loss: 0.3882286548614502, acc: 0.875, recall: 0.5364583333333333, precision: 0.5318181818181817, f_beta: 0.5103448275862068\n",
      "train: step: 1112, loss: 0.540235161781311, acc: 0.84375, recall: 0.4576118326118326, precision: 0.440625, f_beta: 0.4469039732197627\n",
      "train: step: 1113, loss: 0.5239677429199219, acc: 0.78125, recall: 0.3680555555555556, precision: 0.375, f_beta: 0.3713235294117647\n",
      "train: step: 1114, loss: 0.3737117052078247, acc: 0.859375, recall: 0.40014204545454546, precision: 0.40714285714285714, f_beta: 0.40054824561403507\n",
      "train: step: 1115, loss: 0.6545946002006531, acc: 0.859375, recall: 0.4961805555555555, precision: 0.4847222222222222, f_beta: 0.48080993761140817\n",
      "train: step: 1116, loss: 0.539624810218811, acc: 0.890625, recall: 0.59375, precision: 0.5724826388888888, f_beta: 0.5719589155310218\n",
      "train: step: 1117, loss: 0.48917749524116516, acc: 0.859375, recall: 0.4630681818181818, precision: 0.41964285714285715, f_beta: 0.4293727106227106\n",
      "train: step: 1118, loss: 0.6262850761413574, acc: 0.78125, recall: 0.4461805555555556, precision: 0.42544642857142856, f_beta: 0.42752774186597714\n",
      "train: step: 1119, loss: 0.493651419878006, acc: 0.828125, recall: 0.4504464285714286, precision: 0.3907738095238095, f_beta: 0.41145247029393367\n",
      "train: step: 1120, loss: 0.6638505458831787, acc: 0.765625, recall: 0.48541666666666666, precision: 0.42678571428571427, f_beta: 0.4473833677497471\n",
      "train: step: 1121, loss: 0.2538408041000366, acc: 0.9375, recall: 0.6125, precision: 0.6020833333333334, f_beta: 0.6068181818181818\n",
      "train: step: 1122, loss: 0.368267297744751, acc: 0.890625, recall: 0.4909722222222222, precision: 0.44270833333333337, f_beta: 0.4536647992530346\n",
      "train: step: 1123, loss: 0.46751952171325684, acc: 0.859375, recall: 0.5803571428571428, precision: 0.5215773809523809, f_beta: 0.5235185185185185\n",
      "train: step: 1124, loss: 0.4983009696006775, acc: 0.875, recall: 0.6041666666666666, precision: 0.55625, f_beta: 0.5755681818181818\n",
      "train: step: 1125, loss: 0.4431752860546112, acc: 0.828125, recall: 0.4166666666666667, precision: 0.4322610294117647, f_beta: 0.4126737297789929\n",
      "train: step: 1126, loss: 0.47591838240623474, acc: 0.859375, recall: 0.5318181818181817, precision: 0.4779761904761905, f_beta: 0.4928571428571428\n",
      "train: step: 1127, loss: 0.3215508759021759, acc: 0.890625, recall: 0.45833333333333337, precision: 0.4416666666666667, f_beta: 0.44879385964912283\n",
      "train: step: 1128, loss: 0.44756484031677246, acc: 0.828125, recall: 0.45674984737484736, precision: 0.46716651404151405, f_beta: 0.45454756596060947\n",
      "train: step: 1129, loss: 0.4250210225582123, acc: 0.828125, recall: 0.3810763888888889, precision: 0.37899305555555557, f_beta: 0.37814327485380117\n",
      "train: step: 1130, loss: 0.48255330324172974, acc: 0.890625, recall: 0.5020833333333333, precision: 0.5023561507936508, f_beta: 0.4797442753325107\n",
      "train: step: 1131, loss: 0.5291085243225098, acc: 0.828125, recall: 0.3918542395104895, precision: 0.40846748737373734, f_beta: 0.38770768345216877\n",
      "train: step: 1132, loss: 0.5785675048828125, acc: 0.828125, recall: 0.5391098484848484, precision: 0.5715277777777777, f_beta: 0.5106986215538847\n",
      "train: step: 1133, loss: 0.5148663520812988, acc: 0.8125, recall: 0.4144345238095238, precision: 0.42013888888888884, f_beta: 0.40579290966918846\n",
      "train: step: 1134, loss: 0.49471503496170044, acc: 0.828125, recall: 0.42500000000000004, precision: 0.42708333333333337, f_beta: 0.4118890977443609\n",
      "train: step: 1135, loss: 0.4355732202529907, acc: 0.875, recall: 0.5395833333333333, precision: 0.5171130952380952, f_beta: 0.4903915830546265\n",
      "train: step: 1136, loss: 0.44455379247665405, acc: 0.859375, recall: 0.44608516483516486, precision: 0.41464915293040294, f_beta: 0.427516838000709\n",
      "train: step: 1137, loss: 0.5805370807647705, acc: 0.828125, recall: 0.578125, precision: 0.5791666666666666, f_beta: 0.5534667325428195\n",
      "train: step: 1138, loss: 0.7498271465301514, acc: 0.796875, recall: 0.5297619047619048, precision: 0.49188311688311687, f_beta: 0.4748432792840687\n",
      "train: step: 1139, loss: 0.48608970642089844, acc: 0.84375, recall: 0.47845123626373626, precision: 0.44575892857142857, f_beta: 0.4537229437229437\n",
      "train: step: 1140, loss: 0.5713855028152466, acc: 0.828125, recall: 0.4859375, precision: 0.4583333333333333, f_beta: 0.4431547619047619\n",
      "train: step: 1141, loss: 0.6475456953048706, acc: 0.84375, recall: 0.5, precision: 0.4322916666666667, f_beta: 0.4505681818181818\n",
      "train: step: 1142, loss: 0.7248104810714722, acc: 0.78125, recall: 0.4630208333333333, precision: 0.4280460858585859, f_beta: 0.4335349462365592\n",
      "train: step: 1143, loss: 0.5903658270835876, acc: 0.875, recall: 0.46767769607843135, precision: 0.4359577922077922, f_beta: 0.44942210567210567\n",
      "train: step: 1144, loss: 0.330443799495697, acc: 0.90625, recall: 0.46875, precision: 0.4513888888888889, f_beta: 0.44897504456327986\n",
      "train: step: 1145, loss: 0.4997222423553467, acc: 0.890625, recall: 0.5104166666666666, precision: 0.5133928571428572, f_beta: 0.5044642857142857\n",
      "train: step: 1146, loss: 0.38611841201782227, acc: 0.90625, recall: 0.453125, precision: 0.42708333333333337, f_beta: 0.4375\n",
      "train: step: 1147, loss: 0.31248122453689575, acc: 0.890625, recall: 0.4895833333333333, precision: 0.46527777777777773, f_beta: 0.4588541666666667\n",
      "train: step: 1148, loss: 0.686077892780304, acc: 0.78125, recall: 0.44394841269841273, precision: 0.44957386363636365, f_beta: 0.4338235294117647\n",
      "train: step: 1149, loss: 0.6245800852775574, acc: 0.84375, recall: 0.5555555555555556, precision: 0.565625, f_beta: 0.5213235294117646\n",
      "train: step: 1150, loss: 0.5916231274604797, acc: 0.84375, recall: 0.5838541666666667, precision: 0.6383928571428572, f_beta: 0.5759539072039073\n",
      "train: step: 1151, loss: 0.7354529500007629, acc: 0.71875, recall: 0.40625, precision: 0.3473557692307692, f_beta: 0.3590248599439776\n",
      "train: step: 1152, loss: 0.590900182723999, acc: 0.796875, recall: 0.4595352564102564, precision: 0.4270104895104895, f_beta: 0.43866612554112555\n",
      "train: step: 1153, loss: 0.46802544593811035, acc: 0.84375, recall: 0.4895833333333333, precision: 0.4861111111111111, f_beta: 0.47810050940438875\n",
      "train: step: 1154, loss: 0.5202715396881104, acc: 0.796875, recall: 0.4967105263157895, precision: 0.4458333333333333, f_beta: 0.4484821672321673\n",
      "train: step: 1155, loss: 0.5741859674453735, acc: 0.84375, recall: 0.5416666666666666, precision: 0.5052083333333333, f_beta: 0.4782738095238095\n",
      "train: step: 1156, loss: 0.7236506938934326, acc: 0.765625, recall: 0.5230654761904762, precision: 0.5345486111111112, f_beta: 0.5097082961972668\n",
      "train: step: 1157, loss: 0.48205286264419556, acc: 0.84375, recall: 0.4518887362637363, precision: 0.46031162464986, f_beta: 0.4538401875901876\n",
      "train: step: 1158, loss: 0.7284407615661621, acc: 0.796875, recall: 0.4875, precision: 0.5057291666666667, f_beta: 0.4873123706004141\n",
      "train: step: 1159, loss: 0.35180291533470154, acc: 0.890625, recall: 0.5049603174603174, precision: 0.503125, f_beta: 0.4824880593262946\n",
      "train: step: 1160, loss: 0.5824922323226929, acc: 0.8125, recall: 0.4979166666666667, precision: 0.4650297619047619, f_beta: 0.47158119658119657\n",
      "train: step: 1161, loss: 0.5032948851585388, acc: 0.828125, recall: 0.49371936274509803, precision: 0.4649553571428572, f_beta: 0.4475852272727273\n",
      "train: step: 1162, loss: 0.6141794919967651, acc: 0.828125, recall: 0.3948412698412699, precision: 0.39073183760683766, f_beta: 0.3874074074074074\n",
      "train: step: 1163, loss: 0.6852807402610779, acc: 0.84375, recall: 0.5520833333333333, precision: 0.43703258547008544, f_beta: 0.47791593822843825\n",
      "train: step: 1164, loss: 0.3657938838005066, acc: 0.859375, recall: 0.4754464285714286, precision: 0.41190476190476194, f_beta: 0.42342032967032966\n",
      "train: step: 1165, loss: 0.4358867406845093, acc: 0.84375, recall: 0.45468749999999997, precision: 0.4947916666666667, f_beta: 0.4627010474693541\n",
      "train: step: 1166, loss: 0.5190712213516235, acc: 0.84375, recall: 0.4513888888888889, precision: 0.4350198412698412, f_beta: 0.4253393665158371\n",
      "train: step: 1167, loss: 0.6382980346679688, acc: 0.859375, recall: 0.46875, precision: 0.44766865079365076, f_beta: 0.4398789323421677\n",
      "train: step: 1168, loss: 0.4627370238304138, acc: 0.8125, recall: 0.47708333333333336, precision: 0.49106691919191925, f_beta: 0.4707282913165266\n",
      "train: step: 1169, loss: 0.3283590078353882, acc: 0.875, recall: 0.5635044642857143, precision: 0.5145833333333334, f_beta: 0.5231988180576891\n",
      "train: step: 1170, loss: 0.5951236486434937, acc: 0.828125, recall: 0.5223214285714286, precision: 0.4920138888888889, f_beta: 0.48526890421240265\n",
      "train: step: 1171, loss: 0.5312321186065674, acc: 0.875, recall: 0.5863095238095237, precision: 0.5082070707070707, f_beta: 0.5327544897557686\n",
      "train: step: 1172, loss: 0.4163651466369629, acc: 0.875, recall: 0.49088541666666663, precision: 0.45028195488721806, f_beta: 0.45368937042324137\n",
      "train: step: 1173, loss: 0.49761056900024414, acc: 0.828125, recall: 0.5997596153846154, precision: 0.4869791666666667, f_beta: 0.49062500000000003\n",
      "train: step: 1174, loss: 0.6216539144515991, acc: 0.78125, recall: 0.4605902777777778, precision: 0.4027777777777778, f_beta: 0.41872572892793486\n",
      "train: step: 1175, loss: 0.45738309621810913, acc: 0.84375, recall: 0.4650771103896104, precision: 0.46458333333333335, f_beta: 0.462987012987013\n",
      "train: step: 1176, loss: 0.34470856189727783, acc: 0.921875, recall: 0.4591346153846154, precision: 0.4181547619047619, f_beta: 0.42748397435897434\n",
      "start training model\n",
      "train: step: 1177, loss: 0.6006035804748535, acc: 0.796875, recall: 0.49444444444444446, precision: 0.475, f_beta: 0.47586805555555556\n",
      "train: step: 1178, loss: 0.33699026703834534, acc: 0.875, recall: 0.475, precision: 0.4875, f_beta: 0.4634615384615385\n",
      "train: step: 1179, loss: 0.28566527366638184, acc: 0.90625, recall: 0.534375, precision: 0.5770676691729324, f_beta: 0.5305709118209119\n",
      "train: step: 1180, loss: 0.41749751567840576, acc: 0.890625, recall: 0.5520833333333333, precision: 0.5123355263157895, f_beta: 0.512298906048906\n",
      "train: step: 1181, loss: 0.4498804807662964, acc: 0.859375, recall: 0.40625, precision: 0.39464285714285713, f_beta: 0.3981424466338259\n",
      "train: step: 1182, loss: 0.32457417249679565, acc: 0.90625, recall: 0.5267857142857143, precision: 0.4756944444444445, f_beta: 0.4940393518518518\n",
      "train: step: 1183, loss: 0.5561158657073975, acc: 0.8125, recall: 0.47435897435897434, precision: 0.39831730769230766, f_beta: 0.4284107705160337\n",
      "train: step: 1184, loss: 0.36411458253860474, acc: 0.90625, recall: 0.5104166666666667, precision: 0.47172619047619047, f_beta: 0.48125\n",
      "train: step: 1185, loss: 0.35698115825653076, acc: 0.90625, recall: 0.5208333333333334, precision: 0.5291666666666667, f_beta: 0.5118055555555556\n",
      "train: step: 1186, loss: 0.503292441368103, acc: 0.828125, recall: 0.45681818181818185, precision: 0.3997395833333333, f_beta: 0.4170463875205254\n",
      "train: step: 1187, loss: 0.5148729085922241, acc: 0.84375, recall: 0.5511363636363636, precision: 0.5183531746031746, f_beta: 0.5170756939139292\n",
      "train: step: 1188, loss: 0.49592912197113037, acc: 0.828125, recall: 0.4639423076923077, precision: 0.43402777777777785, f_beta: 0.44385416666666666\n",
      "train: step: 1189, loss: 0.42075827717781067, acc: 0.90625, recall: 0.5162098930481284, precision: 0.5019325037707392, f_beta: 0.5063235294117647\n",
      "train: step: 1190, loss: 0.39037203788757324, acc: 0.875, recall: 0.5568181818181819, precision: 0.5255681818181819, f_beta: 0.5285055524185959\n",
      "train: step: 1191, loss: 0.37548714876174927, acc: 0.90625, recall: 0.6818181818181818, precision: 0.5708333333333333, f_beta: 0.6093975468975469\n",
      "train: step: 1192, loss: 0.36832183599472046, acc: 0.890625, recall: 0.4342261904761905, precision: 0.4208333333333334, f_beta: 0.4209935897435898\n",
      "train: step: 1193, loss: 0.6525996923446655, acc: 0.796875, recall: 0.47916666666666663, precision: 0.4859375, f_beta: 0.47500000000000003\n",
      "train: step: 1194, loss: 0.4590008854866028, acc: 0.90625, recall: 0.6612540849673203, precision: 0.6258680555555556, f_beta: 0.6380366161616162\n",
      "train: step: 1195, loss: 0.6125229597091675, acc: 0.78125, recall: 0.47395833333333337, precision: 0.4977964743589744, f_beta: 0.44244047619047616\n",
      "train: step: 1196, loss: 0.3825374245643616, acc: 0.890625, recall: 0.5963541666666666, precision: 0.5979166666666667, f_beta: 0.5865914786967419\n",
      "train: step: 1197, loss: 0.3325701951980591, acc: 0.921875, recall: 0.5833333333333334, precision: 0.5625, f_beta: 0.55\n",
      "train: step: 1198, loss: 0.24734458327293396, acc: 0.953125, recall: 0.59375, precision: 0.5724431818181819, f_beta: 0.5714285714285714\n",
      "train: step: 1199, loss: 0.2907034754753113, acc: 0.921875, recall: 0.6354166666666666, precision: 0.6183712121212122, f_beta: 0.6109649122807017\n",
      "train: step: 1200, loss: 0.3755280375480652, acc: 0.90625, recall: 0.7020833333333334, precision: 0.6354166666666667, f_beta: 0.6564660787343854\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:48:48.900811, step: 1200, loss: 5.487682130601671, acc: 0.1527777777777778,precision: 0.07551447150582857, recall: 0.08526988058238058, f_beta: 0.07261882709577427\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1200\n",
      "\n",
      "train: step: 1201, loss: 0.36444586515426636, acc: 0.890625, recall: 0.5299107142857142, precision: 0.5625, f_beta: 0.5157407407407408\n",
      "train: step: 1202, loss: 0.3791272044181824, acc: 0.890625, recall: 0.5904605263157895, precision: 0.5520833333333334, f_beta: 0.5676289926289927\n",
      "train: step: 1203, loss: 0.39775267243385315, acc: 0.90625, recall: 0.5993589743589745, precision: 0.5399305555555556, f_beta: 0.5536449579831932\n",
      "train: step: 1204, loss: 0.6751842498779297, acc: 0.765625, recall: 0.4835069444444445, precision: 0.43937815656565654, f_beta: 0.44521590434419384\n",
      "train: step: 1205, loss: 0.2189134657382965, acc: 0.9375, recall: 0.4354166666666667, precision: 0.5, f_beta: 0.45972222222222225\n",
      "train: step: 1206, loss: 0.6503634452819824, acc: 0.84375, recall: 0.5635416666666666, precision: 0.5553571428571429, f_beta: 0.5221773049075681\n",
      "train: step: 1207, loss: 0.2831953465938568, acc: 0.921875, recall: 0.5734375, precision: 0.5639880952380952, f_beta: 0.5549145299145299\n",
      "train: step: 1208, loss: 0.35935524106025696, acc: 0.890625, recall: 0.5041666666666667, precision: 0.4861111111111111, f_beta: 0.4802827380952381\n",
      "train: step: 1209, loss: 0.2964843511581421, acc: 0.90625, recall: 0.64453125, precision: 0.6588541666666666, f_beta: 0.6438172043010753\n",
      "train: step: 1210, loss: 0.35918450355529785, acc: 0.90625, recall: 0.53125, precision: 0.4922348484848485, f_beta: 0.508829365079365\n",
      "train: step: 1211, loss: 0.38311171531677246, acc: 0.90625, recall: 0.70703125, precision: 0.6726190476190476, f_beta: 0.672983870967742\n",
      "train: step: 1212, loss: 0.30506640672683716, acc: 0.9375, recall: 0.6160714285714286, precision: 0.609375, f_beta: 0.6008470695970696\n",
      "train: step: 1213, loss: 0.4515761733055115, acc: 0.84375, recall: 0.5744047619047619, precision: 0.5519345238095238, f_beta: 0.5493589743589743\n",
      "train: step: 1214, loss: 0.43894892930984497, acc: 0.875, recall: 0.4916666666666667, precision: 0.5052083333333334, f_beta: 0.47619047619047616\n",
      "train: step: 1215, loss: 0.4462290108203888, acc: 0.859375, recall: 0.5260416666666667, precision: 0.4610243055555555, f_beta: 0.48120765290475914\n",
      "train: step: 1216, loss: 0.2690998613834381, acc: 0.90625, recall: 0.509469696969697, precision: 0.4898538961038961, f_beta: 0.49679232804232804\n",
      "train: step: 1217, loss: 0.38404855132102966, acc: 0.890625, recall: 0.5354166666666667, precision: 0.5354582369385001, f_beta: 0.5337386526516961\n",
      "train: step: 1218, loss: 0.4300094246864319, acc: 0.859375, recall: 0.5071428571428571, precision: 0.5166666666666667, f_beta: 0.49872202056866305\n",
      "train: step: 1219, loss: 0.4094749391078949, acc: 0.875, recall: 0.5052083333333334, precision: 0.5442708333333333, f_beta: 0.48958333333333337\n",
      "train: step: 1220, loss: 0.20694760978221893, acc: 0.9375, recall: 0.5625, precision: 0.5109375, f_beta: 0.5305555555555557\n",
      "train: step: 1221, loss: 0.3292900621891022, acc: 0.953125, recall: 0.5625, precision: 0.5338541666666666, f_beta: 0.5466873706004141\n",
      "train: step: 1222, loss: 0.16685566306114197, acc: 0.984375, recall: 0.625, precision: 0.6125, f_beta: 0.6180555555555556\n",
      "train: step: 1223, loss: 0.3382563292980194, acc: 0.921875, recall: 0.5458333333333334, precision: 0.5993589743589745, f_beta: 0.5616327063740857\n",
      "train: step: 1224, loss: 0.2783823013305664, acc: 0.90625, recall: 0.6, precision: 0.509375, f_beta: 0.5362938596491228\n",
      "train: step: 1225, loss: 0.3963342607021332, acc: 0.875, recall: 0.5026515151515152, precision: 0.4672348484848485, f_beta: 0.4754803675856308\n",
      "train: step: 1226, loss: 0.5571541786193848, acc: 0.875, recall: 0.5108112373737373, precision: 0.5434027777777778, f_beta: 0.5212672025331873\n",
      "train: step: 1227, loss: 0.26159465312957764, acc: 0.921875, recall: 0.625, precision: 0.7022174873737373, f_beta: 0.6475812099033161\n",
      "train: step: 1228, loss: 0.3765963315963745, acc: 0.90625, recall: 0.61875, precision: 0.625, f_beta: 0.5982142857142857\n",
      "train: step: 1229, loss: 0.4032341539859772, acc: 0.875, recall: 0.48958333333333337, precision: 0.48951048951048953, f_beta: 0.4778571428571428\n",
      "train: step: 1230, loss: 0.6030521988868713, acc: 0.828125, recall: 0.46484375, precision: 0.4854166666666666, f_beta: 0.45252030675417776\n",
      "train: step: 1231, loss: 0.27380239963531494, acc: 0.90625, recall: 0.5104166666666666, precision: 0.49583333333333335, f_beta: 0.4978448275862069\n",
      "train: step: 1232, loss: 0.5697566270828247, acc: 0.8125, recall: 0.4337797619047619, precision: 0.3976190476190476, f_beta: 0.40837241462241464\n",
      "train: step: 1233, loss: 0.22522132098674774, acc: 0.921875, recall: 0.4703125, precision: 0.453125, f_beta: 0.45608552631578947\n",
      "train: step: 1234, loss: 0.2863242030143738, acc: 0.921875, recall: 0.5398351648351649, precision: 0.4826388888888889, f_beta: 0.4938235294117647\n",
      "train: step: 1235, loss: 0.6106415390968323, acc: 0.8125, recall: 0.5587797619047619, precision: 0.48578869047619044, f_beta: 0.5112637362637362\n",
      "train: step: 1236, loss: 0.4786338806152344, acc: 0.84375, recall: 0.4609375, precision: 0.4632936507936508, f_beta: 0.4540158371040724\n",
      "train: step: 1237, loss: 0.7582270503044128, acc: 0.78125, recall: 0.4739583333333333, precision: 0.49246031746031743, f_beta: 0.45783039424343774\n",
      "train: step: 1238, loss: 0.4065408706665039, acc: 0.859375, recall: 0.5972222222222222, precision: 0.6119791666666666, f_beta: 0.5727728047740835\n",
      "train: step: 1239, loss: 0.442426860332489, acc: 0.890625, recall: 0.5277777777777778, precision: 0.4682765151515152, f_beta: 0.47554112554112554\n",
      "train: step: 1240, loss: 0.788814902305603, acc: 0.828125, recall: 0.5900735294117647, precision: 0.5208333333333333, f_beta: 0.52325487012987\n",
      "train: step: 1241, loss: 0.49698033928871155, acc: 0.84375, recall: 0.6020833333333334, precision: 0.6226190476190476, f_beta: 0.5838121194898689\n",
      "train: step: 1242, loss: 0.45434844493865967, acc: 0.890625, recall: 0.4650297619047619, precision: 0.5029761904761905, f_beta: 0.47096653346653344\n",
      "train: step: 1243, loss: 0.24381136894226074, acc: 0.953125, recall: 0.5416666666666666, precision: 0.5166666666666666, f_beta: 0.521875\n",
      "train: step: 1244, loss: 0.36735203862190247, acc: 0.890625, recall: 0.5920138888888888, precision: 0.6170634920634921, f_beta: 0.5785383597883598\n",
      "train: step: 1245, loss: 0.22588655352592468, acc: 0.921875, recall: 0.5625, precision: 0.5692401960784313, f_beta: 0.5549242424242424\n",
      "train: step: 1246, loss: 0.3380378484725952, acc: 0.875, recall: 0.49037698412698416, precision: 0.49900793650793657, f_beta: 0.4713488270633411\n",
      "train: step: 1247, loss: 0.2348962277173996, acc: 0.9375, recall: 0.5234375, precision: 0.5329861111111112, f_beta: 0.5248867753623189\n",
      "train: step: 1248, loss: 0.516136884689331, acc: 0.859375, recall: 0.3984375, precision: 0.3904017857142857, f_beta: 0.38668536324786323\n",
      "train: step: 1249, loss: 0.3423779606819153, acc: 0.875, recall: 0.39583333333333337, precision: 0.3776515151515151, f_beta: 0.38439754689754696\n",
      "train: step: 1250, loss: 0.544662594795227, acc: 0.84375, recall: 0.5256076388888888, precision: 0.4595734126984127, f_beta: 0.4736287122375832\n",
      "train: step: 1251, loss: 0.3991028368473053, acc: 0.875, recall: 0.5889136904761905, precision: 0.5806051587301588, f_beta: 0.5652272019919079\n",
      "train: step: 1252, loss: 0.3391987979412079, acc: 0.921875, recall: 0.5446428571428572, precision: 0.5145089285714286, f_beta: 0.5222756410256411\n",
      "train: step: 1253, loss: 0.4705030024051666, acc: 0.875, recall: 0.4266493055555556, precision: 0.3875, f_beta: 0.398077241649348\n",
      "train: step: 1254, loss: 0.20744381844997406, acc: 0.96875, recall: 0.5416666666666666, precision: 0.546875, f_beta: 0.5410714285714285\n",
      "train: step: 1255, loss: 0.44914570450782776, acc: 0.84375, recall: 0.5389880952380952, precision: 0.54375, f_beta: 0.5200570263070263\n",
      "train: step: 1256, loss: 0.23509611189365387, acc: 0.890625, recall: 0.421218487394958, precision: 0.3816964285714286, f_beta: 0.39069778726708076\n",
      "train: step: 1257, loss: 0.4335326552391052, acc: 0.859375, recall: 0.53125, precision: 0.5354166666666667, f_beta: 0.514186507936508\n",
      "train: step: 1258, loss: 0.35899338126182556, acc: 0.90625, recall: 0.5510912698412699, precision: 0.46428571428571425, f_beta: 0.48961056644880174\n",
      "train: step: 1259, loss: 0.3765888512134552, acc: 0.859375, recall: 0.4639880952380953, precision: 0.4845238095238095, f_beta: 0.467419215774479\n",
      "train: step: 1260, loss: 0.4129672050476074, acc: 0.875, recall: 0.55625, precision: 0.4488095238095238, f_beta: 0.4876827485380117\n",
      "start training model\n",
      "train: step: 1261, loss: 0.2529222369194031, acc: 0.921875, recall: 0.5625, precision: 0.5395833333333333, f_beta: 0.5409722222222222\n",
      "train: step: 1262, loss: 0.4402921795845032, acc: 0.890625, recall: 0.6927083333333333, precision: 0.6436011904761904, f_beta: 0.6508540372670807\n",
      "train: step: 1263, loss: 0.2390780746936798, acc: 0.921875, recall: 0.5724431818181818, precision: 0.5494791666666667, f_beta: 0.5584821428571429\n",
      "train: step: 1264, loss: 0.21434254944324493, acc: 0.953125, recall: 0.6666666666666667, precision: 0.6785714285714286, f_beta: 0.6701923076923078\n",
      "train: step: 1265, loss: 0.3301878273487091, acc: 0.90625, recall: 0.586338141025641, precision: 0.5409722222222222, f_beta: 0.5534573285836073\n",
      "train: step: 1266, loss: 0.30380523204803467, acc: 0.90625, recall: 0.55625, precision: 0.5234375, f_beta: 0.5237938596491228\n",
      "train: step: 1267, loss: 0.28172242641448975, acc: 0.9375, recall: 0.55, precision: 0.5205357142857143, f_beta: 0.5306712962962963\n",
      "train: step: 1268, loss: 0.4065666198730469, acc: 0.90625, recall: 0.59609375, precision: 0.5652901785714286, f_beta: 0.5718689805166097\n",
      "train: step: 1269, loss: 0.4558500051498413, acc: 0.875, recall: 0.42187500000000006, precision: 0.4279119318181818, f_beta: 0.4235791090629801\n",
      "train: step: 1270, loss: 0.3017374873161316, acc: 0.9375, recall: 0.625, precision: 0.6264880952380952, f_beta: 0.6181089743589744\n",
      "train: step: 1271, loss: 0.23947462439537048, acc: 0.90625, recall: 0.515625, precision: 0.5, f_beta: 0.4863095238095238\n",
      "train: step: 1272, loss: 0.24253901839256287, acc: 0.90625, recall: 0.5264423076923077, precision: 0.5083333333333333, f_beta: 0.5009722222222223\n",
      "train: step: 1273, loss: 0.29805052280426025, acc: 0.921875, recall: 0.48626373626373626, precision: 0.4809027777777778, f_beta: 0.48197802197802203\n",
      "train: step: 1274, loss: 0.38211071491241455, acc: 0.921875, recall: 0.5625, precision: 0.5724431818181818, f_beta: 0.5407738095238095\n",
      "train: step: 1275, loss: 0.222407266497612, acc: 0.921875, recall: 0.5729166666666666, precision: 0.5918898809523809, f_beta: 0.5768518518518518\n",
      "train: step: 1276, loss: 0.19045063853263855, acc: 0.953125, recall: 0.5625, precision: 0.5119047619047619, f_beta: 0.5326923076923077\n",
      "train: step: 1277, loss: 0.24172371625900269, acc: 0.96875, recall: 0.675, precision: 0.65625, f_beta: 0.6597222222222222\n",
      "train: step: 1278, loss: 0.277787983417511, acc: 0.890625, recall: 0.5625, precision: 0.5296875, f_beta: 0.5322916666666666\n",
      "train: step: 1279, loss: 0.22496578097343445, acc: 0.9375, recall: 0.49107142857142855, precision: 0.42708333333333337, f_beta: 0.44310897435897434\n",
      "train: step: 1280, loss: 0.322140634059906, acc: 0.90625, recall: 0.5729166666666666, precision: 0.59375, f_beta: 0.5776515151515151\n",
      "train: step: 1281, loss: 0.3774891793727875, acc: 0.875, recall: 0.6160714285714286, precision: 0.5395833333333333, f_beta: 0.56741452991453\n",
      "train: step: 1282, loss: 0.5367381572723389, acc: 0.890625, recall: 0.6389423076923078, precision: 0.6569940476190477, f_beta: 0.634331918081918\n",
      "train: step: 1283, loss: 0.28793421387672424, acc: 0.9375, recall: 0.6770833333333334, precision: 0.6770833333333334, f_beta: 0.6657196969696969\n",
      "train: step: 1284, loss: 0.3606644868850708, acc: 0.90625, recall: 0.5989583333333334, precision: 0.5889880952380953, f_beta: 0.5704742625795257\n",
      "train: step: 1285, loss: 0.3473138213157654, acc: 0.921875, recall: 0.5375, precision: 0.517156862745098, f_beta: 0.5137310606060606\n",
      "train: step: 1286, loss: 0.3163565397262573, acc: 0.875, recall: 0.5431547619047619, precision: 0.6212797619047619, f_beta: 0.5585393772893772\n",
      "train: step: 1287, loss: 0.393406480550766, acc: 0.875, recall: 0.5811011904761905, precision: 0.5375, f_beta: 0.5503580055210491\n",
      "train: step: 1288, loss: 0.27736926078796387, acc: 0.921875, recall: 0.5840277777777778, precision: 0.5431547619047619, f_beta: 0.5526171197223828\n",
      "train: step: 1289, loss: 0.3225401043891907, acc: 0.921875, recall: 0.5318181818181817, precision: 0.5171568627450981, f_beta: 0.5107548701298701\n",
      "train: step: 1290, loss: 0.4017590582370758, acc: 0.859375, recall: 0.5625, precision: 0.5783110119047619, f_beta: 0.5395776938115647\n",
      "train: step: 1291, loss: 0.29760897159576416, acc: 0.890625, recall: 0.6135416666666667, precision: 0.5760416666666667, f_beta: 0.5734417565653264\n",
      "train: step: 1292, loss: 0.30251672863960266, acc: 0.890625, recall: 0.5364583333333333, precision: 0.5666666666666667, f_beta: 0.5204968944099378\n",
      "train: step: 1293, loss: 0.20061251521110535, acc: 0.953125, recall: 0.5364583333333334, precision: 0.5416666666666666, f_beta: 0.5353896103896104\n",
      "train: step: 1294, loss: 0.3688412606716156, acc: 0.90625, recall: 0.6354166666666666, precision: 0.6729166666666666, f_beta: 0.635642446633826\n",
      "train: step: 1295, loss: 0.354733943939209, acc: 0.890625, recall: 0.5442708333333333, precision: 0.5083333333333333, f_beta: 0.523088023088023\n",
      "train: step: 1296, loss: 0.2653520703315735, acc: 0.9375, recall: 0.546875, precision: 0.49609374999999994, f_beta: 0.5078052995391704\n",
      "train: step: 1297, loss: 0.347954124212265, acc: 0.90625, recall: 0.5552083333333333, precision: 0.5420673076923077, f_beta: 0.5270138888888889\n",
      "train: step: 1298, loss: 0.3585039973258972, acc: 0.890625, recall: 0.6145833333333333, precision: 0.6436298076923077, f_beta: 0.6079166666666667\n",
      "train: step: 1299, loss: 0.3419940173625946, acc: 0.90625, recall: 0.5868589743589744, precision: 0.5608173076923076, f_beta: 0.56122491638796\n",
      "train: step: 1300, loss: 0.39194029569625854, acc: 0.890625, recall: 0.4930555555555556, precision: 0.5104166666666666, f_beta: 0.4795909865922654\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:50:41.346359, step: 1300, loss: 5.727157062954372, acc: 0.14930555555555555,precision: 0.05712240662172939, recall: 0.0806891989183656, f_beta: 0.06293953743749309\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1300\n",
      "\n",
      "train: step: 1301, loss: 0.2661154866218567, acc: 0.890625, recall: 0.5208333333333333, precision: 0.55625, f_beta: 0.5263170498084292\n",
      "train: step: 1302, loss: 0.15597838163375854, acc: 0.9375, recall: 0.525, precision: 0.5, f_beta: 0.4967105263157895\n",
      "train: step: 1303, loss: 0.47940996289253235, acc: 0.828125, recall: 0.5158955627705628, precision: 0.49952651515151514, f_beta: 0.49227392977392975\n",
      "train: step: 1304, loss: 0.2898772954940796, acc: 0.9375, recall: 0.59375, precision: 0.5555555555555556, f_beta: 0.5692401960784315\n",
      "train: step: 1305, loss: 0.34880611300468445, acc: 0.859375, recall: 0.625, precision: 0.5416666666666667, f_beta: 0.5621753246753247\n",
      "train: step: 1306, loss: 0.24218527972698212, acc: 0.90625, recall: 0.515625, precision: 0.4884672619047619, f_beta: 0.4858173076923077\n",
      "train: step: 1307, loss: 0.33346137404441833, acc: 0.890625, recall: 0.5952380952380952, precision: 0.6056547619047619, f_beta: 0.5799679487179488\n",
      "train: step: 1308, loss: 0.3753609359264374, acc: 0.890625, recall: 0.5902901785714285, precision: 0.5843137254901961, f_beta: 0.5653876824929457\n",
      "train: step: 1309, loss: 0.24201297760009766, acc: 0.9375, recall: 0.625, precision: 0.5568181818181819, f_beta: 0.5782738095238096\n",
      "train: step: 1310, loss: 0.22891110181808472, acc: 0.921875, recall: 0.3869485294117647, precision: 0.4175137362637363, f_beta: 0.395246989852253\n",
      "train: step: 1311, loss: 0.3213992118835449, acc: 0.90625, recall: 0.6854166666666667, precision: 0.6677083333333333, f_beta: 0.6683261183261183\n",
      "train: step: 1312, loss: 0.1592189520597458, acc: 0.953125, recall: 0.578125, precision: 0.55625, f_beta: 0.5606986215538847\n",
      "train: step: 1313, loss: 0.32594355940818787, acc: 0.890625, recall: 0.6743055555555556, precision: 0.609375, f_beta: 0.6162326772814389\n",
      "train: step: 1314, loss: 0.34901636838912964, acc: 0.921875, recall: 0.5223214285714286, precision: 0.5260416666666666, f_beta: 0.5164414323421676\n",
      "train: step: 1315, loss: 0.2381349503993988, acc: 0.921875, recall: 0.6770833333333334, precision: 0.6666666666666667, f_beta: 0.66875\n",
      "train: step: 1316, loss: 0.335502028465271, acc: 0.90625, recall: 0.6822916666666666, precision: 0.6828125, f_beta: 0.6570048309178744\n",
      "train: step: 1317, loss: 0.2000044286251068, acc: 0.953125, recall: 0.5625, precision: 0.525, f_beta: 0.5383771929824561\n",
      "train: step: 1318, loss: 0.17946262657642365, acc: 0.96875, recall: 0.6875, precision: 0.6510416666666666, f_beta: 0.6660714285714285\n",
      "train: step: 1319, loss: 0.30066853761672974, acc: 0.890625, recall: 0.5424107142857143, precision: 0.6026785714285715, f_beta: 0.5595238095238095\n",
      "train: step: 1320, loss: 0.2638888657093048, acc: 0.9375, recall: 0.5520833333333334, precision: 0.5236111111111111, f_beta: 0.5343505094043888\n",
      "train: step: 1321, loss: 0.27579939365386963, acc: 0.890625, recall: 0.5, precision: 0.5066964285714286, f_beta: 0.4940018315018315\n",
      "train: step: 1322, loss: 0.2181781679391861, acc: 0.9375, recall: 0.5833333333333333, precision: 0.5520833333333333, f_beta: 0.5526515151515151\n",
      "train: step: 1323, loss: 0.4301494359970093, acc: 0.890625, recall: 0.5625, precision: 0.5546875, f_beta: 0.5420703748006379\n",
      "train: step: 1324, loss: 0.3002071678638458, acc: 0.921875, recall: 0.59375, precision: 0.546875, f_beta: 0.5548458485958486\n",
      "train: step: 1325, loss: 0.36451077461242676, acc: 0.875, recall: 0.640625, precision: 0.5643887362637363, f_beta: 0.5925993752624187\n",
      "train: step: 1326, loss: 0.3526405096054077, acc: 0.859375, recall: 0.5503472222222223, precision: 0.5632478632478632, f_beta: 0.5326759351759353\n",
      "train: step: 1327, loss: 0.29650256037712097, acc: 0.90625, recall: 0.61875, precision: 0.59375, f_beta: 0.5946271929824561\n",
      "train: step: 1328, loss: 0.33950430154800415, acc: 0.875, recall: 0.560763888888889, precision: 0.5723214285714286, f_beta: 0.5407943363825717\n",
      "train: step: 1329, loss: 0.387546569108963, acc: 0.875, recall: 0.5364583333333334, precision: 0.5199652777777778, f_beta: 0.5189732142857143\n",
      "train: step: 1330, loss: 0.20675788819789886, acc: 0.953125, recall: 0.6145833333333333, precision: 0.6458333333333334, f_beta: 0.6255681818181819\n",
      "train: step: 1331, loss: 0.438245952129364, acc: 0.859375, recall: 0.5525297619047619, precision: 0.51171875, f_beta: 0.5062169327191104\n",
      "train: step: 1332, loss: 0.3879517614841461, acc: 0.90625, recall: 0.6731150793650793, precision: 0.6736111111111112, f_beta: 0.6635110294117648\n",
      "train: step: 1333, loss: 0.45956751704216003, acc: 0.84375, recall: 0.5819978632478633, precision: 0.5841346153846154, f_beta: 0.563691161779397\n",
      "train: step: 1334, loss: 0.4372396767139435, acc: 0.90625, recall: 0.48309294871794867, precision: 0.5310019841269842, f_beta: 0.49275591646915184\n",
      "train: step: 1335, loss: 0.46785837411880493, acc: 0.84375, recall: 0.5483173076923078, precision: 0.5630681818181817, f_beta: 0.5401695134575569\n",
      "train: step: 1336, loss: 0.34448015689849854, acc: 0.875, recall: 0.5651041666666667, precision: 0.5405505952380953, f_beta: 0.547769418081918\n",
      "train: step: 1337, loss: 0.32625341415405273, acc: 0.859375, recall: 0.5034722222222222, precision: 0.4930555555555555, f_beta: 0.4816351540616246\n",
      "train: step: 1338, loss: 0.4155251085758209, acc: 0.859375, recall: 0.5818181818181818, precision: 0.5212339743589745, f_beta: 0.5427224310776942\n",
      "train: step: 1339, loss: 0.3553532361984253, acc: 0.859375, recall: 0.5451388888888888, precision: 0.4970982142857143, f_beta: 0.5116557734204793\n",
      "train: step: 1340, loss: 0.4647817611694336, acc: 0.859375, recall: 0.5651515151515152, precision: 0.5099431818181819, f_beta: 0.5197989510489511\n",
      "train: step: 1341, loss: 0.20638301968574524, acc: 0.953125, recall: 0.6514423076923077, precision: 0.6484375, f_beta: 0.6391666666666667\n",
      "train: step: 1342, loss: 0.38648104667663574, acc: 0.875, recall: 0.5583333333333333, precision: 0.5314732142857143, f_beta: 0.5332127613094038\n",
      "train: step: 1343, loss: 0.32194018363952637, acc: 0.921875, recall: 0.5625, precision: 0.5552083333333333, f_beta: 0.5537310213940648\n",
      "train: step: 1344, loss: 0.21726062893867493, acc: 0.953125, recall: 0.55625, precision: 0.5111607142857143, f_beta: 0.5271338067390698\n",
      "start training model\n",
      "train: step: 1345, loss: 0.3452189564704895, acc: 0.921875, recall: 0.5104166666666666, precision: 0.53359375, f_beta: 0.5166620318872821\n",
      "train: step: 1346, loss: 0.246383935213089, acc: 0.90625, recall: 0.5651041666666667, precision: 0.5457589285714286, f_beta: 0.5368589743589745\n",
      "train: step: 1347, loss: 0.1320335417985916, acc: 0.953125, recall: 0.7803030303030303, precision: 0.7604166666666666, f_beta: 0.7604166666666667\n",
      "train: step: 1348, loss: 0.21252334117889404, acc: 0.9375, recall: 0.6302083333333334, precision: 0.6257440476190477, f_beta: 0.6174768518518519\n",
      "train: step: 1349, loss: 0.17011654376983643, acc: 0.9375, recall: 0.609375, precision: 0.5764423076923078, f_beta: 0.5857936507936508\n",
      "train: step: 1350, loss: 0.3692478537559509, acc: 0.890625, recall: 0.5758928571428572, precision: 0.5354166666666667, f_beta: 0.5342105263157895\n",
      "train: step: 1351, loss: 0.47072407603263855, acc: 0.859375, recall: 0.5989583333333333, precision: 0.579782196969697, f_beta: 0.5682151483781919\n",
      "train: step: 1352, loss: 0.18970367312431335, acc: 0.9375, recall: 0.6291666666666667, precision: 0.640625, f_beta: 0.6211152882205514\n",
      "train: step: 1353, loss: 0.4136890769004822, acc: 0.875, recall: 0.5201480263157895, precision: 0.4842105263157895, f_beta: 0.4855994152046784\n",
      "train: step: 1354, loss: 0.12540577352046967, acc: 0.953125, recall: 0.7013888888888888, precision: 0.7443181818181819, f_beta: 0.7120973389355743\n",
      "train: step: 1355, loss: 0.17914476990699768, acc: 0.953125, recall: 0.6380208333333333, precision: 0.6458333333333333, f_beta: 0.6416666666666666\n",
      "train: step: 1356, loss: 0.29189321398735046, acc: 0.9375, recall: 0.6229166666666668, precision: 0.6395833333333334, f_beta: 0.6189327485380117\n",
      "train: step: 1357, loss: 0.22025036811828613, acc: 0.90625, recall: 0.5833333333333333, precision: 0.5796875, f_beta: 0.5770833333333334\n",
      "train: step: 1358, loss: 0.19204550981521606, acc: 0.953125, recall: 0.64375, precision: 0.659375, f_beta: 0.6458333333333334\n",
      "train: step: 1359, loss: 0.27364370226860046, acc: 0.90625, recall: 0.5135416666666667, precision: 0.48958333333333337, f_beta: 0.4885912698412699\n",
      "train: step: 1360, loss: 0.24293148517608643, acc: 0.921875, recall: 0.58125, precision: 0.5677083333333334, f_beta: 0.5653769841269841\n",
      "train: step: 1361, loss: 0.3088418245315552, acc: 0.921875, recall: 0.4576923076923077, precision: 0.44871794871794873, f_beta: 0.45190283400809717\n",
      "train: step: 1362, loss: 0.2888711094856262, acc: 0.890625, recall: 0.5698390151515151, precision: 0.5625, f_beta: 0.5651041666666666\n",
      "train: step: 1363, loss: 0.3489964008331299, acc: 0.90625, recall: 0.5625, precision: 0.59375, f_beta: 0.5625\n",
      "train: step: 1364, loss: 0.384331613779068, acc: 0.875, recall: 0.546875, precision: 0.5279017857142857, f_beta: 0.5256628787878788\n",
      "train: step: 1365, loss: 0.30065444111824036, acc: 0.90625, recall: 0.609375, precision: 0.5958333333333333, f_beta: 0.5666666666666667\n",
      "train: step: 1366, loss: 0.4528087377548218, acc: 0.875, recall: 0.5734577922077921, precision: 0.56875, f_beta: 0.5618417210808515\n",
      "train: step: 1367, loss: 0.18897917866706848, acc: 0.953125, recall: 0.59375, precision: 0.5833333333333334, f_beta: 0.5776515151515151\n",
      "train: step: 1368, loss: 0.24036341905593872, acc: 0.953125, recall: 0.5625, precision: 0.5473214285714286, f_beta: 0.5544028340080972\n",
      "train: step: 1369, loss: 0.2942929267883301, acc: 0.90625, recall: 0.5625, precision: 0.5613839285714286, f_beta: 0.5445970695970697\n",
      "train: step: 1370, loss: 0.2614731192588806, acc: 0.9375, recall: 0.7135416666666666, precision: 0.6822916666666666, f_beta: 0.684187370600414\n",
      "train: step: 1371, loss: 0.47557908296585083, acc: 0.875, recall: 0.6458333333333333, precision: 0.6638888888888889, f_beta: 0.6300040849673202\n",
      "train: step: 1372, loss: 0.260451078414917, acc: 0.875, recall: 0.5750000000000001, precision: 0.5526041666666667, f_beta: 0.5586874382927015\n",
      "train: step: 1373, loss: 0.2979279160499573, acc: 0.921875, recall: 0.5854166666666667, precision: 0.5828598484848484, f_beta: 0.5752976190476191\n",
      "train: step: 1374, loss: 0.1700707972049713, acc: 0.96875, recall: 0.7135416666666666, precision: 0.6875, f_beta: 0.6869047619047619\n",
      "train: step: 1375, loss: 0.21962058544158936, acc: 0.921875, recall: 0.59375, precision: 0.6302083333333334, f_beta: 0.5848214285714286\n",
      "train: step: 1376, loss: 0.34641599655151367, acc: 0.90625, recall: 0.7005208333333333, precision: 0.6714015151515151, f_beta: 0.66875\n",
      "train: step: 1377, loss: 0.15486487746238708, acc: 0.9375, recall: 0.671875, precision: 0.6493055555555556, f_beta: 0.6567131398013751\n",
      "train: step: 1378, loss: 0.196654811501503, acc: 0.9375, recall: 0.602353896103896, precision: 0.6036931818181819, f_beta: 0.6008597883597884\n",
      "train: step: 1379, loss: 0.24334661662578583, acc: 0.921875, recall: 0.6212797619047619, precision: 0.578125, f_beta: 0.5920673076923078\n",
      "train: step: 1380, loss: 0.45530909299850464, acc: 0.890625, recall: 0.6180555555555556, precision: 0.6390625, f_beta: 0.6073468810601164\n",
      "train: step: 1381, loss: 0.17624732851982117, acc: 0.9375, recall: 0.5729166666666666, precision: 0.5889423076923077, f_beta: 0.5683333333333334\n",
      "train: step: 1382, loss: 0.08596403896808624, acc: 0.984375, recall: 0.6145833333333334, precision: 0.59375, f_beta: 0.5984848484848485\n",
      "train: step: 1383, loss: 0.1861695498228073, acc: 0.9375, recall: 0.5625, precision: 0.5833333333333333, f_beta: 0.5583333333333333\n",
      "train: step: 1384, loss: 0.3296305537223816, acc: 0.9375, recall: 0.6693181818181818, precision: 0.6354166666666667, f_beta: 0.6442460317460318\n",
      "train: step: 1385, loss: 0.1796436607837677, acc: 0.953125, recall: 0.71875, precision: 0.7451923076923077, f_beta: 0.7296428571428573\n",
      "train: step: 1386, loss: 0.22106710076332092, acc: 0.921875, recall: 0.6614583333333333, precision: 0.6361607142857143, f_beta: 0.6278935185185185\n",
      "train: step: 1387, loss: 0.44408780336380005, acc: 0.890625, recall: 0.6593749999999999, precision: 0.6328124999999999, f_beta: 0.6251595928226363\n",
      "train: step: 1388, loss: 0.18481072783470154, acc: 0.953125, recall: 0.5625, precision: 0.5264423076923077, f_beta: 0.5421428571428571\n",
      "train: step: 1389, loss: 0.14892125129699707, acc: 0.9375, recall: 0.5, precision: 0.5133928571428572, f_beta: 0.5\n",
      "train: step: 1390, loss: 0.2760154604911804, acc: 0.921875, recall: 0.5729166666666666, precision: 0.5347222222222222, f_beta: 0.5463235294117647\n",
      "train: step: 1391, loss: 0.25782257318496704, acc: 0.921875, recall: 0.7708333333333334, precision: 0.7098214285714286, f_beta: 0.7267399267399267\n",
      "train: step: 1392, loss: 0.1808212399482727, acc: 0.953125, recall: 0.75, precision: 0.69375, f_beta: 0.7152777777777779\n",
      "train: step: 1393, loss: 0.11710753291845322, acc: 0.96875, recall: 0.625, precision: 0.61875, f_beta: 0.6217105263157895\n",
      "train: step: 1394, loss: 0.4620922803878784, acc: 0.875, recall: 0.5, precision: 0.47613636363636364, f_beta: 0.485290404040404\n",
      "train: step: 1395, loss: 0.3314872682094574, acc: 0.90625, recall: 0.565625, precision: 0.4973214285714286, f_beta: 0.5189026251526252\n",
      "train: step: 1396, loss: 0.26840293407440186, acc: 0.90625, recall: 0.721875, precision: 0.6711309523809523, f_beta: 0.6869047619047619\n",
      "train: step: 1397, loss: 0.18430812656879425, acc: 0.921875, recall: 0.4917200854700855, precision: 0.4473214285714286, f_beta: 0.46312881562881564\n",
      "train: step: 1398, loss: 0.35475271940231323, acc: 0.90625, recall: 0.6276041666666667, precision: 0.6024305555555556, f_beta: 0.5936449579831933\n",
      "train: step: 1399, loss: 0.22328490018844604, acc: 0.9375, recall: 0.5379464285714286, precision: 0.5416396103896104, f_beta: 0.5376903797956429\n",
      "train: step: 1400, loss: 0.21432214975357056, acc: 0.953125, recall: 0.5555555555555556, precision: 0.5498737373737373, f_beta: 0.5525793650793651\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:52:33.764586, step: 1400, loss: 5.80117925008138, acc: 0.15625,precision: 0.07716032265664619, recall: 0.09878559111095876, f_beta: 0.07536504043973831\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1400\n",
      "\n",
      "train: step: 1401, loss: 0.15984295308589935, acc: 0.953125, recall: 0.59375, precision: 0.5729166666666666, f_beta: 0.5716873706004141\n",
      "train: step: 1402, loss: 0.32291677594184875, acc: 0.921875, recall: 0.6145833333333334, precision: 0.6458333333333334, f_beta: 0.6104166666666666\n",
      "train: step: 1403, loss: 0.4432362914085388, acc: 0.921875, recall: 0.7916666666666667, precision: 0.7786458333333333, f_beta: 0.7701992753623188\n",
      "train: step: 1404, loss: 0.2552647292613983, acc: 0.9375, recall: 0.7451923076923077, precision: 0.7938034188034189, f_beta: 0.7580208333333335\n",
      "train: step: 1405, loss: 0.27853551506996155, acc: 0.921875, recall: 0.6041666666666666, precision: 0.6149839743589743, f_beta: 0.5937797619047619\n",
      "train: step: 1406, loss: 0.29292917251586914, acc: 0.90625, recall: 0.6614583333333333, precision: 0.7087339743589743, f_beta: 0.6763964598997494\n",
      "train: step: 1407, loss: 0.15702663362026215, acc: 0.9375, recall: 0.5625, precision: 0.6197916666666667, f_beta: 0.5806159420289855\n",
      "train: step: 1408, loss: 0.20950201153755188, acc: 0.953125, recall: 0.609375, precision: 0.6171875, f_beta: 0.611904761904762\n",
      "train: step: 1409, loss: 0.38345229625701904, acc: 0.921875, recall: 0.5702380952380952, precision: 0.6056985294117647, f_beta: 0.5765598625512419\n",
      "train: step: 1410, loss: 0.1334782838821411, acc: 0.96875, recall: 0.59375, precision: 0.5848214285714286, f_beta: 0.5889423076923077\n",
      "train: step: 1411, loss: 0.233560249209404, acc: 0.9375, recall: 0.7038690476190476, precision: 0.6510416666666666, f_beta: 0.653339947089947\n",
      "train: step: 1412, loss: 0.16304895281791687, acc: 0.96875, recall: 0.6822916666666666, precision: 0.65625, f_beta: 0.6639492753623188\n",
      "train: step: 1413, loss: 0.2458864450454712, acc: 0.9375, recall: 0.6935096153846154, precision: 0.7116013071895425, f_beta: 0.6928233225108225\n",
      "train: step: 1414, loss: 0.12337161600589752, acc: 0.984375, recall: 0.53125, precision: 0.5625, f_beta: 0.5416666666666666\n",
      "train: step: 1415, loss: 0.1835424304008484, acc: 0.953125, recall: 0.625, precision: 0.6201923076923077, f_beta: 0.6225\n",
      "train: step: 1416, loss: 0.39538389444351196, acc: 0.875, recall: 0.5755208333333333, precision: 0.5625, f_beta: 0.5607142857142857\n",
      "train: step: 1417, loss: 0.1776168942451477, acc: 0.9375, recall: 0.5763888888888888, precision: 0.5763888888888888, f_beta: 0.5680555555555555\n",
      "train: step: 1418, loss: 0.2440924495458603, acc: 0.921875, recall: 0.59375, precision: 0.55234375, f_beta: 0.5663935314826656\n",
      "train: step: 1419, loss: 0.18228323757648468, acc: 0.921875, recall: 0.62109375, precision: 0.6514423076923077, f_beta: 0.6309005376344086\n",
      "train: step: 1420, loss: 0.2991243898868561, acc: 0.90625, recall: 0.65625, precision: 0.615625, f_beta: 0.6264880952380952\n",
      "train: step: 1421, loss: 0.0750817209482193, acc: 0.96875, recall: 0.59375, precision: 0.6041666666666666, f_beta: 0.5916666666666667\n",
      "train: step: 1422, loss: 0.3054012358188629, acc: 0.90625, recall: 0.5083333333333333, precision: 0.5138888888888888, f_beta: 0.5109649122807017\n",
      "train: step: 1423, loss: 0.25371646881103516, acc: 0.921875, recall: 0.634046052631579, precision: 0.6119791666666666, f_beta: 0.611205808080808\n",
      "train: step: 1424, loss: 0.37436383962631226, acc: 0.890625, recall: 0.6222222222222222, precision: 0.6510416666666666, f_beta: 0.604045960489459\n",
      "train: step: 1425, loss: 0.16430014371871948, acc: 0.9375, recall: 0.6568181818181817, precision: 0.609375, f_beta: 0.6209550865800866\n",
      "train: step: 1426, loss: 0.38166528940200806, acc: 0.921875, recall: 0.6145833333333333, precision: 0.6291666666666667, f_beta: 0.6092105263157895\n",
      "train: step: 1427, loss: 0.14137260615825653, acc: 0.953125, recall: 0.6416666666666667, precision: 0.6471354166666666, f_beta: 0.6306501271253774\n",
      "train: step: 1428, loss: 0.15109004080295563, acc: 0.953125, recall: 0.59375, precision: 0.59375, f_beta: 0.5833333333333333\n",
      "start training model\n",
      "train: step: 1429, loss: 0.25486716628074646, acc: 0.90625, recall: 0.6369047619047619, precision: 0.5744047619047619, f_beta: 0.5982142857142857\n",
      "train: step: 1430, loss: 0.08150826394557953, acc: 0.984375, recall: 0.6145833333333333, precision: 0.6193181818181818, f_beta: 0.6163419913419914\n",
      "train: step: 1431, loss: 0.22951191663742065, acc: 0.9375, recall: 0.4875, precision: 0.4822916666666667, f_beta: 0.48339371980676327\n",
      "train: step: 1432, loss: 0.14421534538269043, acc: 0.96875, recall: 0.625, precision: 0.6024305555555556, f_beta: 0.6123949579831933\n",
      "train: step: 1433, loss: 0.1879752278327942, acc: 0.921875, recall: 0.6510416666666666, precision: 0.6286931818181818, f_beta: 0.6296130952380952\n",
      "train: step: 1434, loss: 0.17383694648742676, acc: 0.921875, recall: 0.525, precision: 0.5, f_beta: 0.5071271929824561\n",
      "train: step: 1435, loss: 0.15023639798164368, acc: 0.96875, recall: 0.609375, precision: 0.59375, f_beta: 0.6004464285714286\n",
      "train: step: 1436, loss: 0.34048497676849365, acc: 0.9375, recall: 0.6770833333333333, precision: 0.6541666666666667, f_beta: 0.6623737373737374\n",
      "train: step: 1437, loss: 0.10520569980144501, acc: 0.96875, recall: 0.6160714285714286, precision: 0.6015625, f_beta: 0.6070970695970697\n",
      "train: step: 1438, loss: 0.13588596880435944, acc: 0.953125, recall: 0.59375, precision: 0.625, f_beta: 0.6041666666666667\n",
      "train: step: 1439, loss: 0.2595755457878113, acc: 0.9375, recall: 0.6770833333333333, precision: 0.7083333333333334, f_beta: 0.6716386872353297\n",
      "train: step: 1440, loss: 0.2549135088920593, acc: 0.921875, recall: 0.5169270833333334, precision: 0.5744047619047619, f_beta: 0.514009511993383\n",
      "train: step: 1441, loss: 0.14517880976200104, acc: 0.953125, recall: 0.5354166666666667, precision: 0.5546875, f_beta: 0.5425438596491228\n",
      "train: step: 1442, loss: 0.1458640992641449, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "train: step: 1443, loss: 0.17187398672103882, acc: 0.96875, recall: 0.71875, precision: 0.7098214285714286, f_beta: 0.7035256410256411\n",
      "train: step: 1444, loss: 0.15937800705432892, acc: 0.984375, recall: 0.6225, precision: 0.6041666666666666, f_beta: 0.6112244897959184\n",
      "train: step: 1445, loss: 0.17104965448379517, acc: 0.96875, recall: 0.7239583333333334, precision: 0.71875, f_beta: 0.7181547619047619\n",
      "train: step: 1446, loss: 0.13327330350875854, acc: 0.96875, recall: 0.6145833333333334, precision: 0.625, f_beta: 0.6193181818181819\n",
      "train: step: 1447, loss: 0.19656315445899963, acc: 0.96875, recall: 0.7083333333333334, precision: 0.7083333333333334, f_beta: 0.6979166666666667\n",
      "train: step: 1448, loss: 0.2932327091693878, acc: 0.9375, recall: 0.6354166666666666, precision: 0.7070512820512821, f_beta: 0.6545138888888888\n",
      "train: step: 1449, loss: 0.1694483906030655, acc: 0.921875, recall: 0.5833333333333334, precision: 0.53125, f_beta: 0.5458333333333333\n",
      "train: step: 1450, loss: 0.1711859256029129, acc: 0.96875, recall: 0.71875, precision: 0.7395833333333334, f_beta: 0.7234848484848485\n",
      "train: step: 1451, loss: 0.4164392352104187, acc: 0.890625, recall: 0.7057291666666666, precision: 0.625, f_beta: 0.6455357142857142\n",
      "train: step: 1452, loss: 0.10729782283306122, acc: 0.96875, recall: 0.7885416666666666, precision: 0.78125, f_beta: 0.7775641025641027\n",
      "train: step: 1453, loss: 0.20323148369789124, acc: 0.9375, recall: 0.5875, precision: 0.5984848484848485, f_beta: 0.5854010025062657\n",
      "train: step: 1454, loss: 0.145178884267807, acc: 0.953125, recall: 0.7604166666666666, precision: 0.7395833333333333, f_beta: 0.7375\n",
      "train: step: 1455, loss: 0.10534200072288513, acc: 0.96875, recall: 0.65625, precision: 0.6510416666666666, f_beta: 0.6431159420289855\n",
      "train: step: 1456, loss: 0.23744940757751465, acc: 0.9375, recall: 0.76875, precision: 0.7447916666666667, f_beta: 0.7424603174603175\n",
      "train: step: 1457, loss: 0.11730659008026123, acc: 0.96875, recall: 0.59375, precision: 0.609375, f_beta: 0.5952380952380952\n",
      "train: step: 1458, loss: 0.12103971838951111, acc: 0.9375, recall: 0.6171875, precision: 0.6517857142857143, f_beta: 0.6185185185185185\n",
      "train: step: 1459, loss: 0.11840298771858215, acc: 0.984375, recall: 0.75, precision: 0.7395833333333333, f_beta: 0.7443181818181819\n",
      "train: step: 1460, loss: 0.14656610786914825, acc: 0.96875, recall: 0.7879464285714286, precision: 0.7723214285714286, f_beta: 0.773809523809524\n",
      "train: step: 1461, loss: 0.09674747288227081, acc: 0.953125, recall: 0.5875, precision: 0.5833333333333333, f_beta: 0.5758771929824562\n",
      "train: step: 1462, loss: 0.40222591161727905, acc: 0.875, recall: 0.4427083333333333, precision: 0.4432291666666667, f_beta: 0.4346563460693896\n",
      "train: step: 1463, loss: 0.21198105812072754, acc: 0.921875, recall: 0.6875, precision: 0.6609848484848484, f_beta: 0.6616071428571428\n",
      "train: step: 1464, loss: 0.19051319360733032, acc: 0.9375, recall: 0.5625, precision: 0.5892857142857143, f_beta: 0.5581018518518519\n",
      "train: step: 1465, loss: 0.3940891623497009, acc: 0.890625, recall: 0.6489583333333333, precision: 0.640625, f_beta: 0.6382936507936509\n",
      "train: step: 1466, loss: 0.24023127555847168, acc: 0.9375, recall: 0.5885416666666667, precision: 0.625, f_beta: 0.6035714285714286\n",
      "train: step: 1467, loss: 0.3590034544467926, acc: 0.890625, recall: 0.6607142857142857, precision: 0.6744047619047618, f_beta: 0.6468479437229437\n",
      "train: step: 1468, loss: 0.19303148984909058, acc: 0.9375, recall: 0.7229166666666667, precision: 0.7000000000000001, f_beta: 0.7004803675856307\n",
      "train: step: 1469, loss: 0.1532110869884491, acc: 0.984375, recall: 0.5625, precision: 0.53125, f_beta: 0.5416666666666666\n",
      "train: step: 1470, loss: 0.2540888488292694, acc: 0.90625, recall: 0.5963541666666667, precision: 0.640625, f_beta: 0.5972826086956522\n",
      "train: step: 1471, loss: 0.08881242573261261, acc: 0.984375, recall: 0.625, precision: 0.6160714285714286, f_beta: 0.6201923076923077\n",
      "train: step: 1472, loss: 0.26758208870887756, acc: 0.90625, recall: 0.6818181818181819, precision: 0.6510416666666666, f_beta: 0.6609730848861285\n",
      "train: step: 1473, loss: 0.33777689933776855, acc: 0.921875, recall: 0.5848214285714286, precision: 0.577190170940171, f_beta: 0.5800575037707392\n",
      "train: step: 1474, loss: 0.30024564266204834, acc: 0.90625, recall: 0.5652083333333333, precision: 0.5208333333333333, f_beta: 0.5272959183673469\n",
      "train: step: 1475, loss: 0.24948081374168396, acc: 0.9375, recall: 0.7118589743589744, precision: 0.703125, f_beta: 0.6988888888888889\n",
      "train: step: 1476, loss: 0.16093041002750397, acc: 0.953125, recall: 0.5052083333333333, precision: 0.5338541666666667, f_beta: 0.5160714285714285\n",
      "train: step: 1477, loss: 0.2961782217025757, acc: 0.875, recall: 0.5372023809523809, precision: 0.558306277056277, f_beta: 0.5339489214489215\n",
      "train: step: 1478, loss: 0.2517520785331726, acc: 0.9375, recall: 0.8062499999999999, precision: 0.7864583333333333, f_beta: 0.7743055555555556\n",
      "train: step: 1479, loss: 0.3022153675556183, acc: 0.875, recall: 0.6123737373737375, precision: 0.6291666666666667, f_beta: 0.5998949579831934\n",
      "train: step: 1480, loss: 0.12454500794410706, acc: 0.96875, recall: 0.625, precision: 0.65625, f_beta: 0.6276515151515152\n",
      "train: step: 1481, loss: 0.15737007558345795, acc: 0.9375, recall: 0.5416666666666666, precision: 0.5555555555555556, f_beta: 0.5463235294117648\n",
      "train: step: 1482, loss: 0.14516180753707886, acc: 0.9375, recall: 0.5260416666666666, precision: 0.55625, f_beta: 0.5356598016781083\n",
      "train: step: 1483, loss: 0.24430495500564575, acc: 0.953125, recall: 0.6875, precision: 0.6875, f_beta: 0.6800595238095237\n",
      "train: step: 1484, loss: 0.2805211544036865, acc: 0.9375, recall: 0.6922348484848484, precision: 0.6746651785714286, f_beta: 0.6756166548505258\n",
      "train: step: 1485, loss: 0.11963819712400436, acc: 0.96875, recall: 0.59375, precision: 0.5885416666666666, f_beta: 0.5806159420289855\n",
      "train: step: 1486, loss: 0.20998424291610718, acc: 0.953125, recall: 0.725, precision: 0.7135416666666666, f_beta: 0.7117941029485256\n",
      "train: step: 1487, loss: 0.3042999505996704, acc: 0.90625, recall: 0.578125, precision: 0.6139423076923077, f_beta: 0.5817105263157896\n",
      "train: step: 1488, loss: 0.27537813782691956, acc: 0.90625, recall: 0.65625, precision: 0.6171875, f_beta: 0.6208333333333333\n",
      "train: step: 1489, loss: 0.16471807658672333, acc: 0.984375, recall: 0.8125, precision: 0.8035714285714286, f_beta: 0.8076923076923077\n",
      "train: step: 1490, loss: 0.19584651291370392, acc: 0.96875, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1491, loss: 0.12368854880332947, acc: 0.96875, recall: 0.6666666666666667, precision: 0.671875, f_beta: 0.6660714285714285\n",
      "train: step: 1492, loss: 0.24172347784042358, acc: 0.890625, recall: 0.53125, precision: 0.4962797619047619, f_beta: 0.5023195006747638\n",
      "train: step: 1493, loss: 0.2244337797164917, acc: 0.921875, recall: 0.578125, precision: 0.5902777777777778, f_beta: 0.5671875\n",
      "train: step: 1494, loss: 0.21122759580612183, acc: 0.90625, recall: 0.5481770833333334, precision: 0.515625, f_beta: 0.5265552995391705\n",
      "train: step: 1495, loss: 0.1890084594488144, acc: 0.96875, recall: 0.734375, precision: 0.71875, f_beta: 0.7202380952380952\n",
      "train: step: 1496, loss: 0.23863691091537476, acc: 0.9375, recall: 0.674404761904762, precision: 0.640625, f_beta: 0.6520114942528734\n",
      "train: step: 1497, loss: 0.30453556776046753, acc: 0.890625, recall: 0.5145089285714286, precision: 0.5, f_beta: 0.503525641025641\n",
      "train: step: 1498, loss: 0.2168189138174057, acc: 0.921875, recall: 0.6180555555555556, precision: 0.5607638888888888, f_beta: 0.5841269841269842\n",
      "train: step: 1499, loss: 0.2680402398109436, acc: 0.921875, recall: 0.6796875, precision: 0.5729166666666666, f_beta: 0.6083333333333334\n",
      "train: step: 1500, loss: 0.151834174990654, acc: 0.9375, recall: 0.6670673076923077, precision: 0.6041666666666667, f_beta: 0.618306277056277\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:54:25.467800, step: 1500, loss: 6.162942197587755, acc: 0.16145833333333334,precision: 0.07380116932813012, recall: 0.0912067791050634, f_beta: 0.07478867545312418\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1500\n",
      "\n",
      "train: step: 1501, loss: 0.19894251227378845, acc: 0.96875, recall: 0.75, precision: 0.7254464285714286, f_beta: 0.7362637362637363\n",
      "train: step: 1502, loss: 0.10205709934234619, acc: 0.953125, recall: 0.6, precision: 0.5875, f_beta: 0.586222020568663\n",
      "train: step: 1503, loss: 0.35070013999938965, acc: 0.921875, recall: 0.7552083333333333, precision: 0.7299107142857143, f_beta: 0.7362268518518519\n",
      "train: step: 1504, loss: 0.128495991230011, acc: 0.953125, recall: 0.65625, precision: 0.6145833333333334, f_beta: 0.6145833333333333\n",
      "train: step: 1505, loss: 0.5090972185134888, acc: 0.875, recall: 0.6390625, precision: 0.5869047619047618, f_beta: 0.5957878567792361\n",
      "train: step: 1506, loss: 0.1591588258743286, acc: 0.9375, recall: 0.5338541666666666, precision: 0.5260416666666667, f_beta: 0.5222826086956522\n",
      "train: step: 1507, loss: 0.12917384505271912, acc: 0.9375, recall: 0.5916666666666666, precision: 0.5864583333333333, f_beta: 0.588475790513834\n",
      "train: step: 1508, loss: 0.23905782401561737, acc: 0.9375, recall: 0.6369047619047619, precision: 0.6473214285714286, f_beta: 0.6312229437229436\n",
      "train: step: 1509, loss: 0.1426483541727066, acc: 0.96875, recall: 0.6354166666666667, precision: 0.6785714285714286, f_beta: 0.6493589743589743\n",
      "train: step: 1510, loss: 0.15129640698432922, acc: 0.9375, recall: 0.6319444444444444, precision: 0.6229166666666667, f_beta: 0.6266865079365079\n",
      "train: step: 1511, loss: 0.1899573653936386, acc: 0.953125, recall: 0.5163690476190477, precision: 0.5379464285714286, f_beta: 0.5199337699337699\n",
      "train: step: 1512, loss: 0.22075119614601135, acc: 0.9375, recall: 0.6517857142857143, precision: 0.6458333333333333, f_beta: 0.6331018518518519\n",
      "start training model\n",
      "train: step: 1513, loss: 0.07632526755332947, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1514, loss: 0.1270565688610077, acc: 0.953125, recall: 0.6160714285714286, precision: 0.5770833333333333, f_beta: 0.5919028340080972\n",
      "train: step: 1515, loss: 0.276225209236145, acc: 0.90625, recall: 0.7098214285714286, precision: 0.6625, f_beta: 0.6762664418914419\n",
      "train: step: 1516, loss: 0.19396620988845825, acc: 0.953125, recall: 0.6505681818181819, precision: 0.6545138888888888, f_beta: 0.6447966142978931\n",
      "train: step: 1517, loss: 0.0918792188167572, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7465277777777778, f_beta: 0.7434065934065934\n",
      "train: step: 1518, loss: 0.0762946605682373, acc: 0.96875, recall: 0.6875, precision: 0.6979166666666667, f_beta: 0.6854166666666666\n",
      "train: step: 1519, loss: 0.08941632509231567, acc: 0.96875, recall: 0.7447916666666666, precision: 0.7421875, f_beta: 0.7431159420289855\n",
      "train: step: 1520, loss: 0.1896212249994278, acc: 0.921875, recall: 0.5889423076923077, precision: 0.5940104166666667, f_beta: 0.5838610639501981\n",
      "train: step: 1521, loss: 0.07037478685379028, acc: 0.984375, recall: 0.7447916666666667, precision: 0.7291666666666667, f_beta: 0.7347826086956522\n",
      "train: step: 1522, loss: 0.1163121685385704, acc: 0.953125, recall: 0.640625, precision: 0.625, f_beta: 0.60625\n",
      "train: step: 1523, loss: 0.13334740698337555, acc: 0.96875, recall: 0.5625, precision: 0.515625, f_beta: 0.5327380952380952\n",
      "train: step: 1524, loss: 0.11137329041957855, acc: 0.953125, recall: 0.6697916666666667, precision: 0.6541666666666667, f_beta: 0.6583937198067633\n",
      "train: step: 1525, loss: 0.15087544918060303, acc: 0.953125, recall: 0.6627604166666666, precision: 0.6302083333333333, f_beta: 0.6432219662058372\n",
      "train: step: 1526, loss: 0.18529188632965088, acc: 0.953125, recall: 0.6514423076923077, precision: 0.65625, f_beta: 0.6433333333333333\n",
      "train: step: 1527, loss: 0.10506979376077652, acc: 0.96875, recall: 0.65625, precision: 0.671875, f_beta: 0.6577380952380952\n",
      "train: step: 1528, loss: 0.304357647895813, acc: 0.890625, recall: 0.6423611111111112, precision: 0.6084280303030303, f_beta: 0.6103422619047618\n",
      "train: step: 1529, loss: 0.21536511182785034, acc: 0.953125, recall: 0.5416666666666666, precision: 0.5487637362637362, f_beta: 0.5426923076923077\n",
      "train: step: 1530, loss: 0.12603245675563812, acc: 0.96875, recall: 0.734375, precision: 0.7421875, f_beta: 0.736904761904762\n",
      "train: step: 1531, loss: 0.2680850028991699, acc: 0.890625, recall: 0.605654761904762, precision: 0.5954861111111112, f_beta: 0.5697302149604782\n",
      "train: step: 1532, loss: 0.17675068974494934, acc: 0.9375, recall: 0.6770833333333334, precision: 0.6708333333333334, f_beta: 0.6633771929824561\n",
      "train: step: 1533, loss: 0.09918557107448578, acc: 0.984375, recall: 0.6875, precision: 0.6805555555555556, f_beta: 0.6838235294117647\n",
      "train: step: 1534, loss: 0.16603250801563263, acc: 0.953125, recall: 0.6473214285714286, precision: 0.640625, f_beta: 0.6326264315394751\n",
      "train: step: 1535, loss: 0.14332829415798187, acc: 0.96875, recall: 0.6458333333333333, precision: 0.6666666666666666, f_beta: 0.64375\n",
      "train: step: 1536, loss: 0.1871965527534485, acc: 0.9375, recall: 0.71484375, precision: 0.7083333333333334, f_beta: 0.700635386119257\n",
      "train: step: 1537, loss: 0.11261346936225891, acc: 0.96875, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 1538, loss: 0.16991375386714935, acc: 0.9375, recall: 0.68125, precision: 0.640625, f_beta: 0.6544486215538848\n",
      "train: step: 1539, loss: 0.29893767833709717, acc: 0.921875, recall: 0.654040404040404, precision: 0.625, f_beta: 0.6332282913165266\n",
      "train: step: 1540, loss: 0.18476565182209015, acc: 0.921875, recall: 0.6160714285714285, precision: 0.6297348484848484, f_beta: 0.6130494505494506\n",
      "train: step: 1541, loss: 0.18857279419898987, acc: 0.953125, recall: 0.6369047619047619, precision: 0.6302083333333333, f_beta: 0.6279304029304028\n",
      "train: step: 1542, loss: 0.11972137540578842, acc: 0.953125, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 1543, loss: 0.19267703592777252, acc: 0.953125, recall: 0.7098214285714286, precision: 0.7083333333333333, f_beta: 0.6978438228438228\n",
      "train: step: 1544, loss: 0.1252569854259491, acc: 0.96875, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 1545, loss: 0.31985563039779663, acc: 0.921875, recall: 0.5364583333333334, precision: 0.6065319548872181, f_beta: 0.5542017400570032\n",
      "train: step: 1546, loss: 0.1396670639514923, acc: 0.953125, recall: 0.65625, precision: 0.6419270833333333, f_beta: 0.6426267281105991\n",
      "train: step: 1547, loss: 0.14013716578483582, acc: 0.984375, recall: 0.7451923076923077, precision: 0.7443181818181819, f_beta: 0.7445238095238096\n",
      "train: step: 1548, loss: 0.20569480955600739, acc: 0.953125, recall: 0.53125, precision: 0.5535714285714286, f_beta: 0.5368589743589743\n",
      "train: step: 1549, loss: 0.20029008388519287, acc: 0.953125, recall: 0.59375, precision: 0.6071428571428572, f_beta: 0.59375\n",
      "train: step: 1550, loss: 0.17509722709655762, acc: 0.96875, recall: 0.6875, precision: 0.6354166666666666, f_beta: 0.6541666666666668\n",
      "train: step: 1551, loss: 0.12362124770879745, acc: 0.984375, recall: 0.5625, precision: 0.5520833333333334, f_beta: 0.5568181818181819\n",
      "train: step: 1552, loss: 0.20804625749588013, acc: 0.9375, recall: 0.65625, precision: 0.6234375, f_beta: 0.6277777777777778\n",
      "train: step: 1553, loss: 0.21589231491088867, acc: 0.953125, recall: 0.65625, precision: 0.671875, f_beta: 0.6577380952380952\n",
      "train: step: 1554, loss: 0.17104320228099823, acc: 0.953125, recall: 0.671875, precision: 0.6722756410256411, f_beta: 0.6703896103896104\n",
      "train: step: 1555, loss: 0.24183838069438934, acc: 0.921875, recall: 0.6125, precision: 0.546875, f_beta: 0.5701118326118326\n",
      "train: step: 1556, loss: 0.069842129945755, acc: 0.984375, recall: 0.6875, precision: 0.671875, f_beta: 0.6785714285714286\n",
      "train: step: 1557, loss: 0.2023194283246994, acc: 0.96875, recall: 0.8854166666666666, precision: 0.8854166666666667, f_beta: 0.8708333333333333\n",
      "train: step: 1558, loss: 0.17733639478683472, acc: 0.953125, recall: 0.7708333333333334, precision: 0.7739583333333333, f_beta: 0.7695048309178745\n",
      "train: step: 1559, loss: 0.2509164810180664, acc: 0.9375, recall: 0.7636363636363637, precision: 0.7591346153846154, f_beta: 0.7491410818713451\n",
      "train: step: 1560, loss: 0.23955853283405304, acc: 0.90625, recall: 0.6182291666666666, precision: 0.6466346153846154, f_beta: 0.6195114942528736\n",
      "train: step: 1561, loss: 0.18405942618846893, acc: 0.9375, recall: 0.6118055555555556, precision: 0.58125, f_beta: 0.5902562779497764\n",
      "train: step: 1562, loss: 0.15634392201900482, acc: 0.96875, recall: 0.7310855263157895, precision: 0.6979166666666667, f_beta: 0.706048906048906\n",
      "train: step: 1563, loss: 0.13506217300891876, acc: 0.96875, recall: 0.6180555555555556, precision: 0.6208333333333333, f_beta: 0.6191683569979716\n",
      "train: step: 1564, loss: 0.22779414057731628, acc: 0.921875, recall: 0.5736607142857143, precision: 0.58125, f_beta: 0.5755621693121693\n",
      "train: step: 1565, loss: 0.21364086866378784, acc: 0.953125, recall: 0.5868055555555556, precision: 0.5920138888888888, f_beta: 0.5820048309178744\n",
      "train: step: 1566, loss: 0.25243255496025085, acc: 0.9375, recall: 0.70625, precision: 0.71875, f_beta: 0.7013888888888888\n",
      "train: step: 1567, loss: 0.13969579339027405, acc: 0.9375, recall: 0.6510416666666666, precision: 0.6041666666666666, f_beta: 0.6097826086956522\n",
      "train: step: 1568, loss: 0.05880621820688248, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1569, loss: 0.4020921587944031, acc: 0.90625, recall: 0.5482638888888889, precision: 0.5505681818181818, f_beta: 0.5455298786181139\n",
      "train: step: 1570, loss: 0.15047253668308258, acc: 0.9375, recall: 0.5375, precision: 0.5260416666666667, f_beta: 0.525975790513834\n",
      "train: step: 1571, loss: 0.14680998027324677, acc: 0.953125, recall: 0.765625, precision: 0.7630208333333334, f_beta: 0.7520562770562771\n",
      "train: step: 1572, loss: 0.36635732650756836, acc: 0.90625, recall: 0.6193181818181819, precision: 0.5458333333333334, f_beta: 0.5718916857360794\n",
      "train: step: 1573, loss: 0.1176542341709137, acc: 0.9375, recall: 0.5047348484848484, precision: 0.5305555555555556, f_beta: 0.5120254998551145\n",
      "train: step: 1574, loss: 0.20976951718330383, acc: 0.921875, recall: 0.64375, precision: 0.6291666666666667, f_beta: 0.620436507936508\n",
      "train: step: 1575, loss: 0.2785899341106415, acc: 0.890625, recall: 0.5800137362637363, precision: 0.5855113636363637, f_beta: 0.5655555555555556\n",
      "train: step: 1576, loss: 0.2181391417980194, acc: 0.953125, recall: 0.65625, precision: 0.6354166666666666, f_beta: 0.6333333333333333\n",
      "train: step: 1577, loss: 0.15192097425460815, acc: 0.953125, recall: 0.703125, precision: 0.734375, f_beta: 0.7113095238095237\n",
      "train: step: 1578, loss: 0.0786421000957489, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6805555555555556, f_beta: 0.6713235294117648\n",
      "train: step: 1579, loss: 0.11359530687332153, acc: 0.953125, recall: 0.6125, precision: 0.609375, f_beta: 0.6091269841269842\n",
      "train: step: 1580, loss: 0.3446187376976013, acc: 0.890625, recall: 0.5967261904761905, precision: 0.5583333333333333, f_beta: 0.5684367715617715\n",
      "train: step: 1581, loss: 0.21228118240833282, acc: 0.96875, recall: 0.6875, precision: 0.7213541666666667, f_beta: 0.6916666666666667\n",
      "train: step: 1582, loss: 0.19693231582641602, acc: 0.953125, recall: 0.7410714285714286, precision: 0.703125, f_beta: 0.7076923076923077\n",
      "train: step: 1583, loss: 0.3144613206386566, acc: 0.890625, recall: 0.6562500000000001, precision: 0.6708333333333333, f_beta: 0.6420138888888889\n",
      "train: step: 1584, loss: 0.09155264496803284, acc: 0.953125, recall: 0.4166666666666667, precision: 0.4375, f_beta: 0.42585403726708076\n",
      "train: step: 1585, loss: 0.2662045955657959, acc: 0.875, recall: 0.484469696969697, precision: 0.47916666666666663, f_beta: 0.4790948275862069\n",
      "train: step: 1586, loss: 0.2821001410484314, acc: 0.921875, recall: 0.6847222222222223, precision: 0.6572916666666667, f_beta: 0.6663971509656496\n",
      "train: step: 1587, loss: 0.10739681124687195, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7291666666666667, f_beta: 0.725\n",
      "train: step: 1588, loss: 0.17727181315422058, acc: 0.9375, recall: 0.6666666666666667, precision: 0.6484375, f_beta: 0.65\n",
      "train: step: 1589, loss: 0.15171808004379272, acc: 0.96875, recall: 0.59375, precision: 0.62109375, f_beta: 0.6048020527859237\n",
      "train: step: 1590, loss: 0.20977568626403809, acc: 0.96875, recall: 0.7135416666666667, precision: 0.7286931818181818, f_beta: 0.7188988095238096\n",
      "train: step: 1591, loss: 0.123531773686409, acc: 0.953125, recall: 0.65625, precision: 0.6145833333333333, f_beta: 0.6208333333333333\n",
      "train: step: 1592, loss: 0.2308472841978073, acc: 0.9375, recall: 0.5833333333333333, precision: 0.5993589743589743, f_beta: 0.57875\n",
      "train: step: 1593, loss: 0.19915956258773804, acc: 0.90625, recall: 0.6645833333333333, precision: 0.7034527972027973, f_beta: 0.661954365079365\n",
      "train: step: 1594, loss: 0.09192085266113281, acc: 0.96875, recall: 0.7083333333333334, precision: 0.7291666666666667, f_beta: 0.7125\n",
      "train: step: 1595, loss: 0.16675056517124176, acc: 0.9375, recall: 0.5760416666666667, precision: 0.6041666666666666, f_beta: 0.586525974025974\n",
      "train: step: 1596, loss: 0.5172216892242432, acc: 0.828125, recall: 0.4401041666666667, precision: 0.45730311355311354, f_beta: 0.43905062328975375\n",
      "start training model\n",
      "train: step: 1597, loss: 0.14532074332237244, acc: 0.953125, recall: 0.6979166666666666, precision: 0.6979166666666667, f_beta: 0.6833333333333332\n",
      "train: step: 1598, loss: 0.12201900780200958, acc: 0.984375, recall: 0.7916666666666666, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 1599, loss: 0.049263834953308105, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1600, loss: 0.2123575210571289, acc: 0.9375, recall: 0.6317401960784315, precision: 0.61875, f_beta: 0.6156499202551835\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:56:18.345052, step: 1600, loss: 6.435834884643555, acc: 0.13368055555555555,precision: 0.06463950446793584, recall: 0.09314862017067899, f_beta: 0.06744628584834851\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1600\n",
      "\n",
      "train: step: 1601, loss: 0.32226014137268066, acc: 0.90625, recall: 0.6041666666666667, precision: 0.5681089743589743, f_beta: 0.5832142857142857\n",
      "train: step: 1602, loss: 0.27934733033180237, acc: 0.9375, recall: 0.5758928571428572, precision: 0.5672348484848484, f_beta: 0.5574404761904762\n",
      "train: step: 1603, loss: 0.1982623189687729, acc: 0.9375, recall: 0.703125, precision: 0.7083333333333334, f_beta: 0.6978896103896103\n",
      "train: step: 1604, loss: 0.11591371893882751, acc: 0.953125, recall: 0.7274305555555556, precision: 0.7139423076923077, f_beta: 0.7140616246498599\n",
      "train: step: 1605, loss: 0.14250051975250244, acc: 0.9375, recall: 0.65625, precision: 0.6291666666666667, f_beta: 0.6335494120677186\n",
      "train: step: 1606, loss: 0.09615359455347061, acc: 0.984375, recall: 0.8625, precision: 0.8541666666666666, f_beta: 0.8555555555555556\n",
      "train: step: 1607, loss: 0.0890641063451767, acc: 0.96875, recall: 0.8333333333333334, precision: 0.8452380952380952, f_beta: 0.8326923076923077\n",
      "train: step: 1608, loss: 0.20833039283752441, acc: 0.953125, recall: 0.7295673076923077, precision: 0.703125, f_beta: 0.7136931818181819\n",
      "train: step: 1609, loss: 0.02980424277484417, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1610, loss: 0.12526296079158783, acc: 0.96875, recall: 0.5416666666666666, precision: 0.55, f_beta: 0.5430555555555556\n",
      "train: step: 1611, loss: 0.189191073179245, acc: 0.921875, recall: 0.6625, precision: 0.65625, f_beta: 0.6592105263157896\n",
      "train: step: 1612, loss: 0.13779744505882263, acc: 0.953125, recall: 0.59375, precision: 0.6354166666666667, f_beta: 0.5946428571428571\n",
      "train: step: 1613, loss: 0.057654038071632385, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1614, loss: 0.11045323312282562, acc: 0.953125, recall: 0.6041666666666666, precision: 0.5859375, f_beta: 0.5875\n",
      "train: step: 1615, loss: 0.20962180197238922, acc: 0.921875, recall: 0.5625, precision: 0.5494791666666667, f_beta: 0.5556159420289855\n",
      "train: step: 1616, loss: 0.08309374004602432, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1617, loss: 0.12474460899829865, acc: 0.953125, recall: 0.7604166666666666, precision: 0.7760416666666666, f_beta: 0.7619047619047619\n",
      "train: step: 1618, loss: 0.09586416184902191, acc: 0.96875, recall: 0.7291666666666666, precision: 0.6979166666666667, f_beta: 0.7041666666666667\n",
      "train: step: 1619, loss: 0.24678465723991394, acc: 0.921875, recall: 0.7318181818181819, precision: 0.6788194444444444, f_beta: 0.6984307359307358\n",
      "train: step: 1620, loss: 0.22729149460792542, acc: 0.953125, recall: 0.75, precision: 0.7410714285714286, f_beta: 0.734775641025641\n",
      "train: step: 1621, loss: 0.10848914086818695, acc: 0.96875, recall: 0.7395833333333333, precision: 0.7430555555555556, f_beta: 0.7406417112299466\n",
      "train: step: 1622, loss: 0.05591822415590286, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6666666666666666, f_beta: 0.6625\n",
      "train: step: 1623, loss: 0.13912317156791687, acc: 0.984375, recall: 0.75, precision: 0.7430555555555556, f_beta: 0.7463235294117647\n",
      "train: step: 1624, loss: 0.01722673699259758, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1625, loss: 0.17053502798080444, acc: 0.96875, recall: 0.71875, precision: 0.6875, f_beta: 0.6874999999999999\n",
      "train: step: 1626, loss: 0.18299788236618042, acc: 0.953125, recall: 0.7135416666666666, precision: 0.6770833333333333, f_beta: 0.6910326086956522\n",
      "train: step: 1627, loss: 0.08528035879135132, acc: 0.96875, recall: 0.6796875, precision: 0.6875, f_beta: 0.6833333333333333\n",
      "train: step: 1628, loss: 0.1229153499007225, acc: 0.953125, recall: 0.6517857142857143, precision: 0.6302083333333333, f_beta: 0.6289081289081289\n",
      "train: step: 1629, loss: 0.13721972703933716, acc: 0.9375, recall: 0.65625, precision: 0.6264880952380952, f_beta: 0.628525641025641\n",
      "train: step: 1630, loss: 0.3026168644428253, acc: 0.90625, recall: 0.5889136904761905, precision: 0.5774305555555556, f_beta: 0.5765048064680418\n",
      "train: step: 1631, loss: 0.07903008162975311, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1632, loss: 0.09961758553981781, acc: 0.953125, recall: 0.6770833333333334, precision: 0.6197916666666666, f_beta: 0.639556277056277\n",
      "train: step: 1633, loss: 0.19433236122131348, acc: 0.9375, recall: 0.625, precision: 0.584375, f_beta: 0.6004464285714286\n",
      "train: step: 1634, loss: 0.04996560513973236, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666666, f_beta: 0.675\n",
      "train: step: 1635, loss: 0.17397475242614746, acc: 0.953125, recall: 0.8493589743589743, precision: 0.8020833333333334, f_beta: 0.8126515151515152\n",
      "train: step: 1636, loss: 0.07830389589071274, acc: 0.96875, recall: 0.65, precision: 0.6830357142857143, f_beta: 0.6610623781676412\n",
      "train: step: 1637, loss: 0.2950592637062073, acc: 0.921875, recall: 0.6625, precision: 0.6701388888888888, f_beta: 0.652501690331305\n",
      "train: step: 1638, loss: 0.09859950840473175, acc: 0.96875, recall: 0.65625, precision: 0.6666666666666667, f_beta: 0.6541666666666667\n",
      "train: step: 1639, loss: 0.16797785460948944, acc: 0.953125, recall: 0.6979166666666666, precision: 0.7028769841269842, f_beta: 0.6873491704374057\n",
      "train: step: 1640, loss: 0.18635590374469757, acc: 0.9375, recall: 0.7041666666666666, precision: 0.6911931818181818, f_beta: 0.6895676691729323\n",
      "train: step: 1641, loss: 0.11750397086143494, acc: 0.984375, recall: 0.7291666666666667, precision: 0.74375, f_beta: 0.7342105263157894\n",
      "train: step: 1642, loss: 0.023279402405023575, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1643, loss: 0.04542600363492966, acc: 0.984375, recall: 0.59375, precision: 0.625, f_beta: 0.6041666666666666\n",
      "train: step: 1644, loss: 0.08004029095172882, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 1645, loss: 0.25562936067581177, acc: 0.921875, recall: 0.6180555555555556, precision: 0.65625, f_beta: 0.6227457484970274\n",
      "train: step: 1646, loss: 0.06821213662624359, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 1647, loss: 0.09419982880353928, acc: 0.96875, recall: 0.4967105263157895, precision: 0.47916666666666663, f_beta: 0.4858108108108108\n",
      "train: step: 1648, loss: 0.2357618510723114, acc: 0.9375, recall: 0.8333333333333333, precision: 0.8645833333333334, f_beta: 0.81875\n",
      "train: step: 1649, loss: 0.20764614641666412, acc: 0.953125, recall: 0.5841346153846154, precision: 0.6145833333333334, f_beta: 0.5932765151515151\n",
      "train: step: 1650, loss: 0.18583238124847412, acc: 0.921875, recall: 0.55, precision: 0.5145833333333333, f_beta: 0.527266081871345\n",
      "train: step: 1651, loss: 0.1990678459405899, acc: 0.921875, recall: 0.58125, precision: 0.5572916666666666, f_beta: 0.5549603174603175\n",
      "train: step: 1652, loss: 0.07846367359161377, acc: 0.984375, recall: 0.8125, precision: 0.8020833333333334, f_beta: 0.8068181818181819\n",
      "train: step: 1653, loss: 0.22524604201316833, acc: 0.9375, recall: 0.578125, precision: 0.625, f_beta: 0.5905591238471672\n",
      "train: step: 1654, loss: 0.1685897707939148, acc: 0.953125, recall: 0.6875, precision: 0.6333333333333333, f_beta: 0.654040404040404\n",
      "train: step: 1655, loss: 0.1328856348991394, acc: 0.953125, recall: 0.6354166666666667, precision: 0.6666666666666666, f_beta: 0.6416666666666666\n",
      "train: step: 1656, loss: 0.08659715205430984, acc: 0.96875, recall: 0.6153846153846154, precision: 0.625, f_beta: 0.6197916666666666\n",
      "train: step: 1657, loss: 0.05965117737650871, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1658, loss: 0.09008313715457916, acc: 0.96875, recall: 0.6875, precision: 0.6805555555555556, f_beta: 0.6838235294117647\n",
      "train: step: 1659, loss: 0.01880490593612194, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 1660, loss: 0.12354670464992523, acc: 0.953125, recall: 0.6875, precision: 0.6349431818181819, f_beta: 0.6547619047619048\n",
      "train: step: 1661, loss: 0.2646695375442505, acc: 0.921875, recall: 0.7306985294117647, precision: 0.7068452380952381, f_beta: 0.7156060606060606\n",
      "train: step: 1662, loss: 0.11152113974094391, acc: 0.96875, recall: 0.603125, precision: 0.6041666666666667, f_beta: 0.600281954887218\n",
      "train: step: 1663, loss: 0.06597974896430969, acc: 0.96875, recall: 0.625, precision: 0.6041666666666666, f_beta: 0.6125\n",
      "train: step: 1664, loss: 0.07981826364994049, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 1665, loss: 0.10841110348701477, acc: 0.96875, recall: 0.65625, precision: 0.6354166666666666, f_beta: 0.6333333333333333\n",
      "train: step: 1666, loss: 0.2424679547548294, acc: 0.921875, recall: 0.5744047619047619, precision: 0.5833333333333334, f_beta: 0.5624271561771561\n",
      "train: step: 1667, loss: 0.047679685056209564, acc: 0.984375, recall: 0.65625, precision: 0.6822916666666666, f_beta: 0.6639492753623188\n",
      "train: step: 1668, loss: 0.0836392492055893, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6541666666666667, f_beta: 0.6555555555555556\n",
      "train: step: 1669, loss: 0.1918681263923645, acc: 0.953125, recall: 0.796875, precision: 0.7930555555555556, f_beta: 0.7929505135387489\n",
      "train: step: 1670, loss: 0.19127342104911804, acc: 0.921875, recall: 0.7256944444444444, precision: 0.7237103174603174, f_beta: 0.7069649713032066\n",
      "train: step: 1671, loss: 0.158791184425354, acc: 0.96875, recall: 0.55625, precision: 0.5572916666666667, f_beta: 0.5564931350114417\n",
      "train: step: 1672, loss: 0.20642079412937164, acc: 0.9375, recall: 0.6041666666666666, precision: 0.6354166666666666, f_beta: 0.6145833333333333\n",
      "train: step: 1673, loss: 0.24426083266735077, acc: 0.953125, recall: 0.6822916666666666, precision: 0.6458333333333334, f_beta: 0.6535326086956522\n",
      "train: step: 1674, loss: 0.12882967293262482, acc: 0.9375, recall: 0.7005208333333334, precision: 0.726461038961039, f_beta: 0.7074404761904762\n",
      "train: step: 1675, loss: 0.08083119988441467, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6875, f_beta: 0.6818181818181819\n",
      "train: step: 1676, loss: 0.07583221793174744, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1677, loss: 0.16006112098693848, acc: 0.96875, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 1678, loss: 0.16907627880573273, acc: 0.96875, recall: 0.74375, precision: 0.7274305555555556, f_beta: 0.7341054842989827\n",
      "train: step: 1679, loss: 0.02915465272963047, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1680, loss: 0.19613035023212433, acc: 0.953125, recall: 0.7443181818181819, precision: 0.7139423076923077, f_beta: 0.7236904761904762\n",
      "start training model\n",
      "train: step: 1681, loss: 0.020756153389811516, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1682, loss: 0.0783378928899765, acc: 0.96875, recall: 0.6875, precision: 0.6604166666666668, f_beta: 0.6717105263157895\n",
      "train: step: 1683, loss: 0.039287351071834564, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1684, loss: 0.10819697380065918, acc: 0.96875, recall: 0.7135416666666666, precision: 0.71875, f_beta: 0.7077380952380953\n",
      "train: step: 1685, loss: 0.10628685355186462, acc: 0.96875, recall: 0.8125, precision: 0.8, f_beta: 0.8055555555555556\n",
      "train: step: 1686, loss: 0.17786994576454163, acc: 0.9375, recall: 0.6526041666666667, precision: 0.6212797619047619, f_beta: 0.6266854427037494\n",
      "train: step: 1687, loss: 0.29785990715026855, acc: 0.9375, recall: 0.7479166666666667, precision: 0.7306547619047619, f_beta: 0.7153311965811966\n",
      "train: step: 1688, loss: 0.05838792771100998, acc: 0.984375, recall: 0.5416666666666666, precision: 0.5580357142857143, f_beta: 0.5476851851851852\n",
      "train: step: 1689, loss: 0.08791764825582504, acc: 0.96875, recall: 0.6979166666666666, precision: 0.73125, f_beta: 0.7064327485380117\n",
      "train: step: 1690, loss: 0.07164479047060013, acc: 0.984375, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 1691, loss: 0.0727602019906044, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7291666666666667, f_beta: 0.725\n",
      "train: step: 1692, loss: 0.17702078819274902, acc: 0.96875, recall: 0.7139423076923077, precision: 0.7258771929824562, f_beta: 0.7124774774774775\n",
      "train: step: 1693, loss: 0.10523365437984467, acc: 0.953125, recall: 0.5625, precision: 0.5255681818181818, f_beta: 0.5386904761904762\n",
      "train: step: 1694, loss: 0.11172840744256973, acc: 0.96875, recall: 0.6875, precision: 0.734375, f_beta: 0.6994047619047619\n",
      "train: step: 1695, loss: 0.14099881052970886, acc: 0.953125, recall: 0.5520833333333333, precision: 0.56875, f_beta: 0.5510416666666667\n",
      "train: step: 1696, loss: 0.15050330758094788, acc: 0.953125, recall: 0.7708333333333333, precision: 0.765625, f_beta: 0.7514880952380952\n",
      "train: step: 1697, loss: 0.13561546802520752, acc: 0.9375, recall: 0.6319444444444444, precision: 0.59375, f_beta: 0.5919642857142857\n",
      "train: step: 1698, loss: 0.1166524589061737, acc: 0.953125, recall: 0.7083333333333334, precision: 0.6979166666666667, f_beta: 0.6854166666666666\n",
      "train: step: 1699, loss: 0.07797364890575409, acc: 0.96875, recall: 0.5875, precision: 0.5729166666666667, f_beta: 0.5675438596491228\n",
      "train: step: 1700, loss: 0.020213857293128967, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T21:58:11.465738, step: 1700, loss: 6.508324570126003, acc: 0.140625,precision: 0.06453922235172235, recall: 0.08760927140216355, f_beta: 0.06795241693644515\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1700\n",
      "\n",
      "train: step: 1701, loss: 0.06374187022447586, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7291666666666666, f_beta: 0.725\n",
      "train: step: 1702, loss: 0.028351519256830215, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1703, loss: 0.08106663823127747, acc: 0.953125, recall: 0.5625, precision: 0.6197916666666666, f_beta: 0.5806159420289855\n",
      "train: step: 1704, loss: 0.12578514218330383, acc: 0.96875, recall: 0.7604166666666667, precision: 0.7604166666666667, f_beta: 0.75\n",
      "train: step: 1705, loss: 0.109841488301754, acc: 0.96875, recall: 0.6875, precision: 0.6785714285714286, f_beta: 0.6826923076923077\n",
      "train: step: 1706, loss: 0.08771917223930359, acc: 0.96875, recall: 0.5625, precision: 0.5208333333333334, f_beta: 0.53125\n",
      "train: step: 1707, loss: 0.06565280258655548, acc: 0.984375, recall: 0.75, precision: 0.7291666666666666, f_beta: 0.7375\n",
      "train: step: 1708, loss: 0.0726599171757698, acc: 0.96875, recall: 0.7458333333333333, precision: 0.7330357142857142, f_beta: 0.7385855683269477\n",
      "train: step: 1709, loss: 0.14485490322113037, acc: 0.984375, recall: 0.6875, precision: 0.6833333333333333, f_beta: 0.6853448275862069\n",
      "train: step: 1710, loss: 0.19401311874389648, acc: 0.9375, recall: 0.7410714285714286, precision: 0.6942401960784313, f_beta: 0.7099650349650349\n",
      "train: step: 1711, loss: 0.16112375259399414, acc: 0.9375, recall: 0.6604166666666667, precision: 0.6413690476190477, f_beta: 0.6381457115009747\n",
      "train: step: 1712, loss: 0.030449528247117996, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1713, loss: 0.09341701865196228, acc: 0.953125, recall: 0.5916666666666667, precision: 0.59375, f_beta: 0.5847222222222223\n",
      "train: step: 1714, loss: 0.12392719089984894, acc: 0.96875, recall: 0.6701923076923078, precision: 0.6723214285714286, f_beta: 0.6699583895636528\n",
      "train: step: 1715, loss: 0.15689516067504883, acc: 0.953125, recall: 0.7451923076923077, precision: 0.6994047619047619, f_beta: 0.7114423076923078\n",
      "train: step: 1716, loss: 0.1279374361038208, acc: 0.96875, recall: 0.796875, precision: 0.7875, f_beta: 0.7879464285714286\n",
      "train: step: 1717, loss: 0.07276652753353119, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666666, f_beta: 0.675\n",
      "train: step: 1718, loss: 0.2380024939775467, acc: 0.9375, recall: 0.6400297619047619, precision: 0.6685554029304029, f_beta: 0.6514186507936508\n",
      "train: step: 1719, loss: 0.07789958268404007, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 1720, loss: 0.10784225165843964, acc: 0.96875, recall: 0.75, precision: 0.765625, f_beta: 0.7514880952380952\n",
      "train: step: 1721, loss: 0.14853613078594208, acc: 0.953125, recall: 0.625, precision: 0.58125, f_beta: 0.5972222222222222\n",
      "train: step: 1722, loss: 0.09416699409484863, acc: 0.953125, recall: 0.71875, precision: 0.7791666666666667, f_beta: 0.7305555555555555\n",
      "train: step: 1723, loss: 0.2147468775510788, acc: 0.9375, recall: 0.6909722222222222, precision: 0.6708333333333333, f_beta: 0.6722007223942209\n",
      "train: step: 1724, loss: 0.07150602340698242, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 1725, loss: 0.10258366167545319, acc: 0.96875, recall: 0.6875, precision: 0.6354166666666667, f_beta: 0.6541666666666667\n",
      "train: step: 1726, loss: 0.13589799404144287, acc: 0.984375, recall: 0.8125, precision: 0.796875, f_beta: 0.8035714285714286\n",
      "train: step: 1727, loss: 0.14345026016235352, acc: 0.96875, recall: 0.6822916666666667, precision: 0.6666666666666667, f_beta: 0.6722826086956522\n",
      "train: step: 1728, loss: 0.05442415922880173, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1729, loss: 0.04801561310887337, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1730, loss: 0.19731523096561432, acc: 0.9375, recall: 0.7166666666666667, precision: 0.71875, f_beta: 0.7097222222222221\n",
      "train: step: 1731, loss: 0.06621859222650528, acc: 0.96875, recall: 0.7760416666666666, precision: 0.78125, f_beta: 0.7681159420289856\n",
      "train: step: 1732, loss: 0.033574752509593964, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1733, loss: 0.1645742654800415, acc: 0.953125, recall: 0.59375, precision: 0.6125, f_beta: 0.5972222222222223\n",
      "train: step: 1734, loss: 0.041380882263183594, acc: 0.984375, recall: 0.6666666666666666, precision: 0.65625, f_beta: 0.6541666666666667\n",
      "train: step: 1735, loss: 0.050021860748529434, acc: 0.984375, recall: 0.6145833333333334, precision: 0.6041666666666667, f_beta: 0.6068181818181818\n",
      "train: step: 1736, loss: 0.07998611032962799, acc: 0.96875, recall: 0.6666666666666666, precision: 0.675, f_beta: 0.6680555555555556\n",
      "train: step: 1737, loss: 0.06312935799360275, acc: 0.984375, recall: 0.6197916666666667, precision: 0.6041666666666666, f_beta: 0.6097826086956522\n",
      "train: step: 1738, loss: 0.08523709326982498, acc: 0.96875, recall: 0.6770833333333333, precision: 0.65, f_beta: 0.657695374800638\n",
      "train: step: 1739, loss: 0.08551646769046783, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666667, f_beta: 0.675\n",
      "train: step: 1740, loss: 0.02902090921998024, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1741, loss: 0.22787845134735107, acc: 0.96875, recall: 0.7395104895104896, precision: 0.740728021978022, f_beta: 0.7399013024013025\n",
      "train: step: 1742, loss: 0.11445176601409912, acc: 0.953125, recall: 0.746875, precision: 0.7222222222222223, f_beta: 0.7322209653092006\n",
      "train: step: 1743, loss: 0.17764107882976532, acc: 0.9375, recall: 0.6979166666666667, precision: 0.7139423076923077, f_beta: 0.6933333333333334\n",
      "train: step: 1744, loss: 0.1593814194202423, acc: 0.96875, recall: 0.6875, precision: 0.6822916666666667, f_beta: 0.6847826086956521\n",
      "train: step: 1745, loss: 0.26558637619018555, acc: 0.9375, recall: 0.7041666666666666, precision: 0.703125, f_beta: 0.684375\n",
      "train: step: 1746, loss: 0.10846257209777832, acc: 0.9375, recall: 0.6974431818181818, precision: 0.7104166666666667, f_beta: 0.6919642857142857\n",
      "train: step: 1747, loss: 0.07281134277582169, acc: 0.953125, recall: 0.71875, precision: 0.7322916666666667, f_beta: 0.7195048309178745\n",
      "train: step: 1748, loss: 0.0570092499256134, acc: 0.984375, recall: 0.6826923076923077, precision: 0.6805555555555556, f_beta: 0.6813235294117648\n",
      "train: step: 1749, loss: 0.14689263701438904, acc: 0.953125, recall: 0.640625, precision: 0.625, f_beta: 0.6264880952380952\n",
      "train: step: 1750, loss: 0.12482446432113647, acc: 0.984375, recall: 0.8125, precision: 0.8076923076923077, f_beta: 0.81\n",
      "train: step: 1751, loss: 0.04834670573472977, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1752, loss: 0.1510402113199234, acc: 0.9375, recall: 0.703525641025641, precision: 0.7109375, f_beta: 0.6912500000000001\n",
      "train: step: 1753, loss: 0.07042175531387329, acc: 0.96875, recall: 0.68125, precision: 0.675, f_beta: 0.6772660818713451\n",
      "train: step: 1754, loss: 0.18755796551704407, acc: 0.90625, recall: 0.6614583333333334, precision: 0.6823593073593074, f_beta: 0.6576453152111047\n",
      "train: step: 1755, loss: 0.13368377089500427, acc: 0.953125, recall: 0.7410714285714286, precision: 0.6875, f_beta: 0.7014423076923076\n",
      "train: step: 1756, loss: 0.11223720014095306, acc: 0.953125, recall: 0.6354166666666666, precision: 0.6354166666666666, f_beta: 0.6208333333333332\n",
      "train: step: 1757, loss: 0.08506343513727188, acc: 0.96875, recall: 0.7109375, precision: 0.71875, f_beta: 0.7041666666666666\n",
      "train: step: 1758, loss: 0.18218399584293365, acc: 0.921875, recall: 0.58125, precision: 0.6026785714285714, f_beta: 0.5844907407407407\n",
      "train: step: 1759, loss: 0.1159529909491539, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 1760, loss: 0.08948066830635071, acc: 0.96875, recall: 0.6197916666666666, precision: 0.6041666666666666, f_beta: 0.6097826086956523\n",
      "train: step: 1761, loss: 0.12965211272239685, acc: 0.9375, recall: 0.6236979166666667, precision: 0.6654119318181818, f_beta: 0.6361731150793651\n",
      "train: step: 1762, loss: 0.0973275899887085, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 1763, loss: 0.16891174018383026, acc: 0.953125, recall: 0.6625, precision: 0.6229166666666667, f_beta: 0.6325670498084291\n",
      "train: step: 1764, loss: 0.19257226586341858, acc: 0.96875, recall: 0.5833333333333333, precision: 0.6145104895104896, f_beta: 0.5945238095238096\n",
      "start training model\n",
      "train: step: 1765, loss: 0.07498794794082642, acc: 0.96875, recall: 0.59375, precision: 0.5989583333333333, f_beta: 0.5889492753623189\n",
      "train: step: 1766, loss: 0.054837197065353394, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666666, f_beta: 0.675\n",
      "train: step: 1767, loss: 0.05012285336852074, acc: 0.984375, recall: 0.71875, precision: 0.7421875, f_beta: 0.725\n",
      "train: step: 1768, loss: 0.11172636598348618, acc: 0.984375, recall: 0.65625, precision: 0.6830357142857143, f_beta: 0.664351851851852\n",
      "train: step: 1769, loss: 0.15385089814662933, acc: 0.96875, recall: 0.5431547619047619, precision: 0.5535287081339713, f_beta: 0.5473451098451098\n",
      "train: step: 1770, loss: 0.05307287350296974, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1771, loss: 0.0696563571691513, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "train: step: 1772, loss: 0.10860294848680496, acc: 0.96875, recall: 0.6125, precision: 0.6125, f_beta: 0.6125\n",
      "train: step: 1773, loss: 0.1036909967660904, acc: 0.96875, recall: 0.6597222222222222, precision: 0.6510416666666666, f_beta: 0.6498949579831933\n",
      "train: step: 1774, loss: 0.03691524639725685, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1775, loss: 0.07323074340820312, acc: 0.984375, recall: 0.796875, precision: 0.8080357142857143, f_beta: 0.8012566137566138\n",
      "train: step: 1776, loss: 0.037300560623407364, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1777, loss: 0.06214311718940735, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848484\n",
      "train: step: 1778, loss: 0.06336748600006104, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1779, loss: 0.0792250782251358, acc: 0.984375, recall: 0.75, precision: 0.7421875, f_beta: 0.7458333333333333\n",
      "train: step: 1780, loss: 0.125639870762825, acc: 0.96875, recall: 0.7875, precision: 0.7911931818181818, f_beta: 0.7859400656814449\n",
      "train: step: 1781, loss: 0.10581579804420471, acc: 0.96875, recall: 0.65625, precision: 0.6458333333333333, f_beta: 0.6354166666666666\n",
      "train: step: 1782, loss: 0.18311184644699097, acc: 0.96875, recall: 0.7755681818181818, precision: 0.7708333333333334, f_beta: 0.7636904761904761\n",
      "train: step: 1783, loss: 0.1545616090297699, acc: 0.953125, recall: 0.5520833333333333, precision: 0.515625, f_beta: 0.5270562770562771\n",
      "train: step: 1784, loss: 0.013169359415769577, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1785, loss: 0.09352567791938782, acc: 0.96875, recall: 0.7375, precision: 0.7410714285714286, f_beta: 0.7382478632478633\n",
      "train: step: 1786, loss: 0.06052643060684204, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 1787, loss: 0.10597249865531921, acc: 0.96875, recall: 0.5625, precision: 0.5208333333333334, f_beta: 0.53125\n",
      "train: step: 1788, loss: 0.10384660959243774, acc: 0.984375, recall: 0.6875, precision: 0.68125, f_beta: 0.6842105263157895\n",
      "train: step: 1789, loss: 0.020818740129470825, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1790, loss: 0.08155746757984161, acc: 0.96875, recall: 0.6770833333333333, precision: 0.671875, f_beta: 0.6728896103896105\n",
      "train: step: 1791, loss: 0.023548388853669167, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1792, loss: 0.03616652637720108, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1793, loss: 0.16675511002540588, acc: 0.96875, recall: 0.7838541666666666, precision: 0.7838541666666666, f_beta: 0.7791666666666667\n",
      "train: step: 1794, loss: 0.026393041014671326, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1795, loss: 0.10770170390605927, acc: 0.96875, recall: 0.6354166666666667, precision: 0.6458333333333333, f_beta: 0.6276515151515152\n",
      "train: step: 1796, loss: 0.08799582719802856, acc: 0.984375, recall: 0.8125, precision: 0.78125, f_beta: 0.7916666666666666\n",
      "train: step: 1797, loss: 0.12958061695098877, acc: 0.953125, recall: 0.53125, precision: 0.5375, f_beta: 0.5260416666666666\n",
      "train: step: 1798, loss: 0.18558759987354279, acc: 0.953125, recall: 0.7604166666666667, precision: 0.7541666666666667, f_beta: 0.7425438596491228\n",
      "train: step: 1799, loss: 0.030650459229946136, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7455357142857143, f_beta: 0.742003367003367\n",
      "train: step: 1800, loss: 0.11551646143198013, acc: 0.96875, recall: 0.609375, precision: 0.625, f_beta: 0.6160714285714286\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:00:03.312063, step: 1800, loss: 6.6964311599731445, acc: 0.16319444444444445,precision: 0.08286430082144092, recall: 0.11489026020276022, f_beta: 0.08420243025452177\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1800\n",
      "\n",
      "train: step: 1801, loss: 0.14415602385997772, acc: 0.96875, recall: 0.75, precision: 0.78125, f_beta: 0.7604166666666666\n",
      "train: step: 1802, loss: 0.05775899812579155, acc: 0.984375, recall: 0.7421875, precision: 0.7375, f_beta: 0.7388888888888889\n",
      "train: step: 1803, loss: 0.13484568893909454, acc: 0.984375, recall: 0.55859375, precision: 0.5625, f_beta: 0.560483870967742\n",
      "train: step: 1804, loss: 0.0770643949508667, acc: 0.96875, recall: 0.78125, precision: 0.8, f_beta: 0.7847222222222222\n",
      "train: step: 1805, loss: 0.09486699104309082, acc: 0.984375, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1806, loss: 0.14931720495224, acc: 0.96875, recall: 0.7395833333333334, precision: 0.7187500000000001, f_beta: 0.7261363636363636\n",
      "train: step: 1807, loss: 0.018092965707182884, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 1808, loss: 0.06997019797563553, acc: 0.96875, recall: 0.625, precision: 0.62109375, f_beta: 0.622983870967742\n",
      "train: step: 1809, loss: 0.05827838554978371, acc: 0.984375, recall: 0.671875, precision: 0.6875, f_beta: 0.6785714285714286\n",
      "train: step: 1810, loss: 0.21469718217849731, acc: 0.9375, recall: 0.6201923076923077, precision: 0.6110777243589743, f_beta: 0.6154587873557018\n",
      "train: step: 1811, loss: 0.06220295652747154, acc: 0.984375, recall: 0.8055555555555556, precision: 0.8020833333333334, f_beta: 0.8031417112299466\n",
      "train: step: 1812, loss: 0.050296179950237274, acc: 0.96875, recall: 0.74609375, precision: 0.7447916666666666, f_beta: 0.7452664796633941\n",
      "train: step: 1813, loss: 0.11285450309515, acc: 0.953125, recall: 0.640625, precision: 0.6484375, f_beta: 0.643154761904762\n",
      "train: step: 1814, loss: 0.09590239077806473, acc: 0.96875, recall: 0.8, precision: 0.7916666666666667, f_beta: 0.7930555555555556\n",
      "train: step: 1815, loss: 0.029320023953914642, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1816, loss: 0.13586938381195068, acc: 0.96875, recall: 0.7083333333333333, precision: 0.7291666666666666, f_beta: 0.70625\n",
      "train: step: 1817, loss: 0.06505107134580612, acc: 0.984375, recall: 0.71875, precision: 0.7291666666666667, f_beta: 0.7166666666666667\n",
      "train: step: 1818, loss: 0.07897667586803436, acc: 0.96875, recall: 0.734375, precision: 0.7125, f_beta: 0.7169486215538846\n",
      "train: step: 1819, loss: 0.06673046946525574, acc: 0.96875, recall: 0.68125, precision: 0.6764423076923077, f_beta: 0.6784210526315789\n",
      "train: step: 1820, loss: 0.04154244810342789, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1821, loss: 0.045899648219347, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1822, loss: 0.05011030659079552, acc: 0.984375, recall: 0.7291666666666666, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 1823, loss: 0.09656423330307007, acc: 0.96875, recall: 0.65625, precision: 0.671875, f_beta: 0.6577380952380952\n",
      "train: step: 1824, loss: 0.17677682638168335, acc: 0.9375, recall: 0.703125, precision: 0.728125, f_beta: 0.7080200501253133\n",
      "train: step: 1825, loss: 0.0973844975233078, acc: 0.96875, recall: 0.796875, precision: 0.8068181818181818, f_beta: 0.800595238095238\n",
      "train: step: 1826, loss: 0.03076419048011303, acc: 0.984375, recall: 0.7447916666666666, precision: 0.71875, f_beta: 0.7264492753623188\n",
      "train: step: 1827, loss: 0.10373988747596741, acc: 0.96875, recall: 0.7604166666666666, precision: 0.78125, f_beta: 0.7583333333333333\n",
      "train: step: 1828, loss: 0.038414325565099716, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1829, loss: 0.12607493996620178, acc: 0.9375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 1830, loss: 0.01482236385345459, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1831, loss: 0.12235254049301147, acc: 0.953125, recall: 0.7734375, precision: 0.7447916666666666, f_beta: 0.7452380952380951\n",
      "train: step: 1832, loss: 0.11805514246225357, acc: 0.9375, recall: 0.5895833333333333, precision: 0.6193181818181819, f_beta: 0.5990353037766831\n",
      "train: step: 1833, loss: 0.1860218197107315, acc: 0.953125, recall: 0.8020833333333334, precision: 0.7943181818181819, f_beta: 0.7968975468975469\n",
      "train: step: 1834, loss: 0.02663262188434601, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1835, loss: 0.12743061780929565, acc: 0.953125, recall: 0.775, precision: 0.7781723484848485, f_beta: 0.768734335839599\n",
      "train: step: 1836, loss: 0.12668724358081818, acc: 0.953125, recall: 0.7083333333333333, precision: 0.734375, f_beta: 0.7098214285714286\n",
      "train: step: 1837, loss: 0.05498318746685982, acc: 0.96875, recall: 0.7274305555555556, precision: 0.74609375, f_beta: 0.7353788289509352\n",
      "train: step: 1838, loss: 0.07536070048809052, acc: 0.984375, recall: 0.71875, precision: 0.74375, f_beta: 0.7258771929824561\n",
      "train: step: 1839, loss: 0.11902730166912079, acc: 0.96875, recall: 0.5859375, precision: 0.6089015151515151, f_beta: 0.5913419913419914\n",
      "train: step: 1840, loss: 0.08696138113737106, acc: 0.96875, recall: 0.64375, precision: 0.6785714285714286, f_beta: 0.6549145299145299\n",
      "train: step: 1841, loss: 0.11910909414291382, acc: 0.953125, recall: 0.703125, precision: 0.7220982142857143, f_beta: 0.7048280423280423\n",
      "train: step: 1842, loss: 0.03290687873959541, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1843, loss: 0.18599636852741241, acc: 0.921875, recall: 0.6145833333333334, precision: 0.628125, f_beta: 0.6013618326118326\n",
      "train: step: 1844, loss: 0.02278301864862442, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1845, loss: 0.11786870658397675, acc: 0.984375, recall: 0.7443181818181819, precision: 0.7430555555555556, f_beta: 0.7433473389355743\n",
      "train: step: 1846, loss: 0.09611675888299942, acc: 0.953125, recall: 0.818452380952381, precision: 0.87109375, f_beta: 0.8373357228195938\n",
      "train: step: 1847, loss: 0.14286035299301147, acc: 0.9375, recall: 0.6354166666666667, precision: 0.6333333333333333, f_beta: 0.6207070707070708\n",
      "train: step: 1848, loss: 0.06974661350250244, acc: 0.96875, recall: 0.609375, precision: 0.6145833333333334, f_beta: 0.6103896103896104\n",
      "start training model\n",
      "train: step: 1849, loss: 0.07808245718479156, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666666, f_beta: 0.8\n",
      "train: step: 1850, loss: 0.14012742042541504, acc: 0.953125, recall: 0.6934523809523809, precision: 0.71875, f_beta: 0.7039351851851852\n",
      "train: step: 1851, loss: 0.04159679263830185, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1852, loss: 0.04248155653476715, acc: 0.984375, recall: 0.6125, precision: 0.625, f_beta: 0.6180555555555556\n",
      "train: step: 1853, loss: 0.012254789471626282, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1854, loss: 0.016577647998929024, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1855, loss: 0.08491586148738861, acc: 0.96875, recall: 0.6796875, precision: 0.6666666666666666, f_beta: 0.6708333333333334\n",
      "train: step: 1856, loss: 0.016256559640169144, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1857, loss: 0.04290613904595375, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 1858, loss: 0.08086593449115753, acc: 0.953125, recall: 0.65625, precision: 0.6458333333333333, f_beta: 0.6401515151515151\n",
      "train: step: 1859, loss: 0.022068381309509277, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 1860, loss: 0.05938394367694855, acc: 0.96875, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 1861, loss: 0.024284951388835907, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1862, loss: 0.14624455571174622, acc: 0.984375, recall: 0.8645833333333334, precision: 0.84375, f_beta: 0.8484848484848485\n",
      "train: step: 1863, loss: 0.0808463916182518, acc: 0.96875, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 1864, loss: 0.02799508534371853, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1865, loss: 0.13114124536514282, acc: 0.96875, recall: 0.75, precision: 0.7375, f_beta: 0.7430555555555556\n",
      "train: step: 1866, loss: 0.021234553307294846, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1867, loss: 0.03543809801340103, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 1868, loss: 0.04035309702157974, acc: 0.984375, recall: 0.7375, precision: 0.75, f_beta: 0.7430555555555556\n",
      "train: step: 1869, loss: 0.042409539222717285, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7458333333333333, f_beta: 0.7353448275862069\n",
      "train: step: 1870, loss: 0.06342160701751709, acc: 0.96875, recall: 0.625, precision: 0.6160714285714286, f_beta: 0.6201923076923077\n",
      "train: step: 1871, loss: 0.11985844373703003, acc: 0.984375, recall: 0.59375, precision: 0.625, f_beta: 0.6041666666666666\n",
      "train: step: 1872, loss: 0.05565657466650009, acc: 0.984375, recall: 0.6125, precision: 0.625, f_beta: 0.6180555555555556\n",
      "train: step: 1873, loss: 0.03501628711819649, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1874, loss: 0.01998094469308853, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1875, loss: 0.010893022641539574, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1876, loss: 0.09577085822820663, acc: 0.984375, recall: 0.75, precision: 0.7430555555555556, f_beta: 0.7463235294117647\n",
      "train: step: 1877, loss: 0.06123535335063934, acc: 0.96875, recall: 0.65625, precision: 0.6796875, f_beta: 0.6625\n",
      "train: step: 1878, loss: 0.07430589199066162, acc: 0.96875, recall: 0.796875, precision: 0.75, f_beta: 0.7619047619047619\n",
      "train: step: 1879, loss: 0.08589541912078857, acc: 0.96875, recall: 0.75, precision: 0.70625, f_beta: 0.7222222222222222\n",
      "train: step: 1880, loss: 0.0570702888071537, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666667, f_beta: 0.8\n",
      "train: step: 1881, loss: 0.051870595663785934, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 1882, loss: 0.0049171182326972485, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1883, loss: 0.04125623777508736, acc: 0.984375, recall: 0.8125, precision: 0.8055555555555556, f_beta: 0.8088235294117647\n",
      "train: step: 1884, loss: 0.14034287631511688, acc: 0.96875, recall: 0.70625, precision: 0.7375, f_beta: 0.7152777777777778\n",
      "train: step: 1885, loss: 0.04915153235197067, acc: 0.984375, recall: 0.7916666666666667, precision: 0.7916666666666667, f_beta: 0.7875\n",
      "train: step: 1886, loss: 0.006669517606496811, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1887, loss: 0.06666519492864609, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 1888, loss: 0.028149280697107315, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666667\n",
      "train: step: 1889, loss: 0.1261570155620575, acc: 0.96875, recall: 0.78125, precision: 0.7604166666666667, f_beta: 0.7583333333333333\n",
      "train: step: 1890, loss: 0.015822753310203552, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1891, loss: 0.05841600149869919, acc: 0.984375, recall: 0.65625, precision: 0.65625, f_beta: 0.6458333333333333\n",
      "train: step: 1892, loss: 0.09423463046550751, acc: 0.96875, recall: 0.8368055555555556, precision: 0.8416666666666667, f_beta: 0.831045751633987\n",
      "train: step: 1893, loss: 0.13128601014614105, acc: 0.96875, recall: 0.7916666666666666, precision: 0.7708333333333333, f_beta: 0.76875\n",
      "train: step: 1894, loss: 0.02293107658624649, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1895, loss: 0.03153062239289284, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1896, loss: 0.020426210016012192, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1897, loss: 0.10882265120744705, acc: 0.984375, recall: 0.65625, precision: 0.6826923076923077, f_beta: 0.6641666666666666\n",
      "train: step: 1898, loss: 0.10115731507539749, acc: 0.96875, recall: 0.7118055555555556, precision: 0.7187500000000001, f_beta: 0.707308377896613\n",
      "train: step: 1899, loss: 0.008021313697099686, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1900, loss: 0.10618617385625839, acc: 0.984375, recall: 0.75, precision: 0.7430555555555556, f_beta: 0.7463235294117647\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:01:55.760627, step: 1900, loss: 7.019339561462402, acc: 0.14930555555555555,precision: 0.07361557088159901, recall: 0.10935621091871092, f_beta: 0.07729021895197104\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-1900\n",
      "\n",
      "train: step: 1901, loss: 0.04756923019886017, acc: 0.984375, recall: 0.84375, precision: 0.87109375, f_beta: 0.8521505376344085\n",
      "train: step: 1902, loss: 0.11307834088802338, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1903, loss: 0.006562193389981985, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1904, loss: 0.0355229414999485, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1905, loss: 0.03181193768978119, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1906, loss: 0.06304159015417099, acc: 0.96875, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1907, loss: 0.09105786681175232, acc: 0.984375, recall: 0.6160714285714286, precision: 0.625, f_beta: 0.6201923076923077\n",
      "train: step: 1908, loss: 0.055689532309770584, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7375, f_beta: 0.7373737373737375\n",
      "train: step: 1909, loss: 0.04303288087248802, acc: 0.984375, recall: 0.6818181818181819, precision: 0.6805555555555556, f_beta: 0.6808473389355743\n",
      "train: step: 1910, loss: 0.06869896501302719, acc: 0.96875, recall: 0.625, precision: 0.578125, f_beta: 0.5952380952380952\n",
      "train: step: 1911, loss: 0.07291551679372787, acc: 0.953125, recall: 0.6197916666666666, precision: 0.5885416666666666, f_beta: 0.6008540372670808\n",
      "train: step: 1912, loss: 0.03413604944944382, acc: 0.984375, recall: 0.6666666666666666, precision: 0.675, f_beta: 0.6680555555555555\n",
      "train: step: 1913, loss: 0.04455707222223282, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6458333333333333, f_beta: 0.64375\n",
      "train: step: 1914, loss: 0.0612398236989975, acc: 0.96875, recall: 0.7760416666666666, precision: 0.7916666666666667, f_beta: 0.7785714285714286\n",
      "train: step: 1915, loss: 0.13641467690467834, acc: 0.953125, recall: 0.8645833333333334, precision: 0.8958333333333334, f_beta: 0.8589015151515151\n",
      "train: step: 1916, loss: 0.013141604140400887, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1917, loss: 0.040691010653972626, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6875, f_beta: 0.675\n",
      "train: step: 1918, loss: 0.06779444217681885, acc: 0.96875, recall: 0.6875, precision: 0.6796875, f_beta: 0.6833333333333333\n",
      "train: step: 1919, loss: 0.10474226623773575, acc: 0.96875, recall: 0.6785714285714286, precision: 0.6604166666666667, f_beta: 0.6669028340080972\n",
      "train: step: 1920, loss: 0.1368561089038849, acc: 0.96875, recall: 0.6875, precision: 0.7326923076923078, f_beta: 0.6988888888888889\n",
      "train: step: 1921, loss: 0.024446677416563034, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1922, loss: 0.044084735214710236, acc: 0.984375, recall: 0.65625, precision: 0.6785714285714286, f_beta: 0.6618589743589743\n",
      "train: step: 1923, loss: 0.040643639862537384, acc: 0.96875, recall: 0.7604166666666666, precision: 0.7767857142857143, f_beta: 0.7560185185185186\n",
      "train: step: 1924, loss: 0.07597418874502182, acc: 0.96875, recall: 0.7375, precision: 0.7083333333333333, f_beta: 0.7118055555555556\n",
      "train: step: 1925, loss: 0.022857867181301117, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1926, loss: 0.018047399818897247, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1927, loss: 0.055275384336709976, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8125, f_beta: 0.8\n",
      "train: step: 1928, loss: 0.014621848240494728, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1929, loss: 0.03151308745145798, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1930, loss: 0.061508677899837494, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1931, loss: 0.08715987205505371, acc: 0.984375, recall: 0.7458333333333333, precision: 0.7291666666666666, f_beta: 0.7353448275862069\n",
      "train: step: 1932, loss: 0.05531078577041626, acc: 0.96875, recall: 0.8046875, precision: 0.7916666666666666, f_beta: 0.7958333333333334\n",
      "start training model\n",
      "train: step: 1933, loss: 0.021073248237371445, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 1934, loss: 0.03103816509246826, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1935, loss: 0.07158491015434265, acc: 0.984375, recall: 0.7916666666666666, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 1936, loss: 0.038747385144233704, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1937, loss: 0.015378807671368122, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1938, loss: 0.04084017127752304, acc: 0.984375, recall: 0.80625, precision: 0.7916666666666666, f_beta: 0.7967105263157895\n",
      "train: step: 1939, loss: 0.010836707428097725, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1940, loss: 0.02255520410835743, acc: 0.984375, recall: 0.675, precision: 0.6785714285714286, f_beta: 0.6757478632478633\n",
      "train: step: 1941, loss: 0.01443415880203247, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1942, loss: 0.02017866261303425, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1943, loss: 0.039731062948703766, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1944, loss: 0.014806902036070824, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1945, loss: 0.049964193254709244, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1946, loss: 0.06333848088979721, acc: 0.96875, recall: 0.6875, precision: 0.6666666666666667, f_beta: 0.675\n",
      "train: step: 1947, loss: 0.045888304710388184, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1948, loss: 0.007911346852779388, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1949, loss: 0.07654208689928055, acc: 0.96875, recall: 0.8541666666666667, precision: 0.8380681818181818, f_beta: 0.8386904761904762\n",
      "train: step: 1950, loss: 0.0409676767885685, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6805555555555556, f_beta: 0.6713235294117647\n",
      "train: step: 1951, loss: 0.0048753973096609116, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1952, loss: 0.01944020390510559, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 1953, loss: 0.07359063625335693, acc: 0.953125, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 1954, loss: 0.009420376271009445, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1955, loss: 0.007989258505403996, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1956, loss: 0.047568466514348984, acc: 0.984375, recall: 0.6666666666666666, precision: 0.675, f_beta: 0.6680555555555556\n",
      "train: step: 1957, loss: 0.019033219665288925, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1958, loss: 0.15476036071777344, acc: 0.9375, recall: 0.6473214285714286, precision: 0.65625, f_beta: 0.641025641025641\n",
      "train: step: 1959, loss: 0.09698319435119629, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 1960, loss: 0.03518601506948471, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1961, loss: 0.029270606115460396, acc: 0.984375, recall: 0.671875, precision: 0.6666666666666666, f_beta: 0.6660714285714285\n",
      "train: step: 1962, loss: 0.014344077557325363, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1963, loss: 0.10740038752555847, acc: 0.96875, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 1964, loss: 0.011456795036792755, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1965, loss: 0.011739767156541348, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1966, loss: 0.21665534377098083, acc: 0.953125, recall: 0.6510416666666666, precision: 0.6493055555555556, f_beta: 0.6394394714407503\n",
      "train: step: 1967, loss: 0.025812668725848198, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1968, loss: 0.06482046097517014, acc: 0.96875, recall: 0.75, precision: 0.7375, f_beta: 0.7430555555555556\n",
      "train: step: 1969, loss: 0.023972850292921066, acc: 0.984375, recall: 0.7916666666666667, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 1970, loss: 0.12332113087177277, acc: 0.9375, recall: 0.7694978632478633, precision: 0.7760416666666667, f_beta: 0.7645909865922653\n",
      "train: step: 1971, loss: 0.015395515598356724, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1972, loss: 0.05675268545746803, acc: 0.96875, recall: 0.6818181818181818, precision: 0.65625, f_beta: 0.6636904761904763\n",
      "train: step: 1973, loss: 0.043960221111774445, acc: 0.984375, recall: 0.671875, precision: 0.6666666666666667, f_beta: 0.6660714285714286\n",
      "train: step: 1974, loss: 0.1254732459783554, acc: 0.96875, recall: 0.8083333333333333, precision: 0.76875, f_beta: 0.7825670498084292\n",
      "train: step: 1975, loss: 0.025992054492235184, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1976, loss: 0.019397666677832603, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 1977, loss: 0.0951511338353157, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 1978, loss: 0.03490254282951355, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 1979, loss: 0.09775952994823456, acc: 0.96875, recall: 0.6770833333333334, precision: 0.6517857142857143, f_beta: 0.6586700336700336\n",
      "train: step: 1980, loss: 0.07276094704866409, acc: 0.984375, recall: 0.65625, precision: 0.6666666666666667, f_beta: 0.6541666666666667\n",
      "train: step: 1981, loss: 0.12785792350769043, acc: 0.984375, recall: 0.6213235294117647, precision: 0.6201923076923077, f_beta: 0.6206060606060606\n",
      "train: step: 1982, loss: 0.05417579039931297, acc: 0.984375, recall: 0.875, precision: 0.84375, f_beta: 0.8541666666666667\n",
      "train: step: 1983, loss: 0.1124458760023117, acc: 0.9375, recall: 0.6818181818181819, precision: 0.6309523809523809, f_beta: 0.6488756613756613\n",
      "train: step: 1984, loss: 0.12399528920650482, acc: 0.953125, recall: 0.5234375, precision: 0.5208333333333334, f_beta: 0.50625\n",
      "train: step: 1985, loss: 0.012262646108865738, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1986, loss: 0.06562426686286926, acc: 0.96875, recall: 0.625, precision: 0.6145833333333334, f_beta: 0.6193181818181819\n",
      "train: step: 1987, loss: 0.10275613516569138, acc: 0.953125, recall: 0.7135416666666667, precision: 0.7028769841269841, f_beta: 0.6992539323421676\n",
      "train: step: 1988, loss: 0.009131593629717827, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1989, loss: 0.06837645173072815, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 1990, loss: 0.15849822759628296, acc: 0.96875, recall: 0.7791666666666667, precision: 0.7916666666666666, f_beta: 0.7805555555555557\n",
      "train: step: 1991, loss: 0.07874177396297455, acc: 0.96875, recall: 0.7451923076923077, precision: 0.71875, f_beta: 0.7266666666666667\n",
      "train: step: 1992, loss: 0.09672924876213074, acc: 0.984375, recall: 0.8541666666666667, precision: 0.84375, f_beta: 0.8416666666666667\n",
      "train: step: 1993, loss: 0.030585050582885742, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 1994, loss: 0.018672430887818336, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 1995, loss: 0.03370098024606705, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 1996, loss: 0.023731322959065437, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 1997, loss: 0.048755746334791183, acc: 0.984375, recall: 0.80625, precision: 0.8083333333333333, f_beta: 0.8070553539019963\n",
      "train: step: 1998, loss: 0.07810946553945541, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6770833333333334, f_beta: 0.6693181818181818\n",
      "train: step: 1999, loss: 0.07173030823469162, acc: 0.96875, recall: 0.625, precision: 0.6171875, f_beta: 0.6208333333333333\n",
      "train: step: 2000, loss: 0.00566227687522769, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:03:47.423931, step: 2000, loss: 7.234064102172852, acc: 0.14756944444444445,precision: 0.06719651875901875, recall: 0.08032092612362218, f_beta: 0.06786910038878256\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2000\n",
      "\n",
      "train: step: 2001, loss: 0.10552000999450684, acc: 0.96875, recall: 0.75, precision: 0.7098214285714286, f_beta: 0.7243589743589743\n",
      "train: step: 2002, loss: 0.032885078340768814, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 2003, loss: 0.18476444482803345, acc: 0.96875, recall: 0.6625, precision: 0.6796875, f_beta: 0.6677083333333333\n",
      "train: step: 2004, loss: 0.048610661178827286, acc: 0.96875, recall: 0.6055555555555556, precision: 0.6055555555555556, f_beta: 0.6037581699346406\n",
      "train: step: 2005, loss: 0.037476830184459686, acc: 0.984375, recall: 0.8125, precision: 0.78125, f_beta: 0.7916666666666666\n",
      "train: step: 2006, loss: 0.06909964978694916, acc: 0.96875, recall: 0.5410714285714285, precision: 0.5410714285714285, f_beta: 0.5410714285714285\n",
      "train: step: 2007, loss: 0.04191773012280464, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2008, loss: 0.12774258852005005, acc: 0.953125, recall: 0.7421875, precision: 0.7708333333333334, f_beta: 0.75\n",
      "train: step: 2009, loss: 0.10539576411247253, acc: 0.96875, recall: 0.59375, precision: 0.5859375, f_beta: 0.5791666666666666\n",
      "train: step: 2010, loss: 0.022312719374895096, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2011, loss: 0.03998323157429695, acc: 0.984375, recall: 0.671875, precision: 0.6666666666666666, f_beta: 0.6660714285714285\n",
      "train: step: 2012, loss: 0.06927042454481125, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 2013, loss: 0.12207761406898499, acc: 0.96875, recall: 0.71875, precision: 0.7109375, f_beta: 0.7145833333333333\n",
      "train: step: 2014, loss: 0.08610038459300995, acc: 0.984375, recall: 0.8125, precision: 0.78125, f_beta: 0.7916666666666666\n",
      "train: step: 2015, loss: 0.09056813269853592, acc: 0.984375, recall: 0.68125, precision: 0.671875, f_beta: 0.675281954887218\n",
      "train: step: 2016, loss: 0.0955047756433487, acc: 0.96875, recall: 0.7395833333333334, precision: 0.7291666666666667, f_beta: 0.7329545454545454\n",
      "start training model\n",
      "train: step: 2017, loss: 0.004685773514211178, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2018, loss: 0.05794472619891167, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 2019, loss: 0.05065595731139183, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2020, loss: 0.011239231564104557, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2021, loss: 0.03660675510764122, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2022, loss: 0.06458587199449539, acc: 0.984375, recall: 0.875, precision: 0.84375, f_beta: 0.8541666666666666\n",
      "train: step: 2023, loss: 0.14898353815078735, acc: 0.96875, recall: 0.7916666666666666, precision: 0.7847222222222222, f_beta: 0.7879901960784313\n",
      "train: step: 2024, loss: 0.21940326690673828, acc: 0.921875, recall: 0.7853422619047619, precision: 0.8127705627705628, f_beta: 0.7857346357346359\n",
      "train: step: 2025, loss: 0.05187230929732323, acc: 0.984375, recall: 0.6145833333333334, precision: 0.6215277777777778, f_beta: 0.6175324675324675\n",
      "train: step: 2026, loss: 0.06074470281600952, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7375, f_beta: 0.7382478632478633\n",
      "train: step: 2027, loss: 0.028597872704267502, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2028, loss: 0.04719774052500725, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2029, loss: 0.04649324342608452, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6354166666666666, f_beta: 0.6416666666666666\n",
      "train: step: 2030, loss: 0.03944055363535881, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2031, loss: 0.006088630761951208, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2032, loss: 0.010465423576533794, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2033, loss: 0.0343184769153595, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2034, loss: 0.007294333074241877, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2035, loss: 0.043659355491399765, acc: 0.984375, recall: 0.75, precision: 0.7395833333333334, f_beta: 0.7443181818181819\n",
      "train: step: 2036, loss: 0.12066137045621872, acc: 0.953125, recall: 0.7443181818181818, precision: 0.6874999999999999, f_beta: 0.708008658008658\n",
      "train: step: 2037, loss: 0.03098871372640133, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2038, loss: 0.04482169821858406, acc: 0.984375, recall: 0.6875, precision: 0.6818181818181819, f_beta: 0.6845238095238095\n",
      "train: step: 2039, loss: 0.09109482169151306, acc: 0.984375, recall: 0.8697916666666666, precision: 0.8680555555555556, f_beta: 0.8686061381074169\n",
      "train: step: 2040, loss: 0.05290434882044792, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2041, loss: 0.0550943985581398, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2042, loss: 0.036246296018362045, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2043, loss: 0.048409730195999146, acc: 0.984375, recall: 0.71875, precision: 0.7375, f_beta: 0.7222222222222223\n",
      "train: step: 2044, loss: 0.06111965700984001, acc: 0.96875, recall: 0.859375, precision: 0.84375, f_beta: 0.8457674571805007\n",
      "train: step: 2045, loss: 0.012412103824317455, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2046, loss: 0.08898815512657166, acc: 0.953125, recall: 0.671875, precision: 0.6875, f_beta: 0.6785714285714286\n",
      "train: step: 2047, loss: 0.056119561195373535, acc: 0.984375, recall: 0.7410714285714286, precision: 0.75, f_beta: 0.7451923076923077\n",
      "train: step: 2048, loss: 0.018171316012740135, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2049, loss: 0.011297308839857578, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2050, loss: 0.018254060298204422, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2051, loss: 0.006072159390896559, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2052, loss: 0.03170183673501015, acc: 0.984375, recall: 0.6875, precision: 0.6785714285714286, f_beta: 0.6826923076923077\n",
      "train: step: 2053, loss: 0.09725534915924072, acc: 0.96875, recall: 0.7838541666666666, precision: 0.77734375, f_beta: 0.7729838709677421\n",
      "train: step: 2054, loss: 0.06761164963245392, acc: 0.984375, recall: 0.6041666666666666, precision: 0.6160714285714286, f_beta: 0.6076923076923078\n",
      "train: step: 2055, loss: 0.048671264201402664, acc: 0.984375, recall: 0.7916666666666667, precision: 0.7916666666666666, f_beta: 0.7875\n",
      "train: step: 2056, loss: 0.06262539327144623, acc: 0.984375, recall: 0.6875, precision: 0.6785714285714286, f_beta: 0.6826923076923077\n",
      "train: step: 2057, loss: 0.11693409085273743, acc: 0.96875, recall: 0.75, precision: 0.7421875, f_beta: 0.7458333333333333\n",
      "train: step: 2058, loss: 0.0112551124766469, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2059, loss: 0.028050478547811508, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2060, loss: 0.02525447867810726, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2061, loss: 0.02069622464478016, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2062, loss: 0.014310789294540882, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2063, loss: 0.039791546761989594, acc: 0.984375, recall: 0.71875, precision: 0.7410714285714286, f_beta: 0.7243589743589745\n",
      "train: step: 2064, loss: 0.12202591449022293, acc: 0.953125, recall: 0.6979166666666666, precision: 0.75, f_beta: 0.7166666666666667\n",
      "train: step: 2065, loss: 0.05871090292930603, acc: 0.984375, recall: 0.84375, precision: 0.8660714285714286, f_beta: 0.8493589743589743\n",
      "train: step: 2066, loss: 0.014780206605792046, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2067, loss: 0.06646528840065002, acc: 0.984375, recall: 0.8541666666666666, precision: 0.8671875, f_beta: 0.8583333333333334\n",
      "train: step: 2068, loss: 0.00779181020334363, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2069, loss: 0.0066796401515603065, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2070, loss: 0.13125157356262207, acc: 0.96875, recall: 0.6875, precision: 0.6761363636363636, f_beta: 0.68125\n",
      "train: step: 2071, loss: 0.09123264998197556, acc: 0.96875, recall: 0.6875, precision: 0.734375, f_beta: 0.6994047619047619\n",
      "train: step: 2072, loss: 0.02899962291121483, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2073, loss: 0.022256985306739807, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2074, loss: 0.12697800993919373, acc: 0.984375, recall: 0.6818181818181819, precision: 0.675, f_beta: 0.6775793650793651\n",
      "train: step: 2075, loss: 0.056602030992507935, acc: 0.984375, recall: 0.7458333333333333, precision: 0.7443181818181819, f_beta: 0.7448686371100164\n",
      "train: step: 2076, loss: 0.02211623266339302, acc: 0.984375, recall: 0.6796875, precision: 0.6770833333333333, f_beta: 0.6776515151515152\n",
      "train: step: 2077, loss: 0.004592223558574915, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2078, loss: 0.021338561549782753, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2079, loss: 0.014318722300231457, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2080, loss: 0.04815732687711716, acc: 0.96875, recall: 0.6109375, precision: 0.5729166666666666, f_beta: 0.5842105263157895\n",
      "train: step: 2081, loss: 0.05973563343286514, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2082, loss: 0.01970779150724411, acc: 0.984375, recall: 0.671875, precision: 0.6666666666666667, f_beta: 0.6660714285714286\n",
      "train: step: 2083, loss: 0.04941580444574356, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7410714285714286, f_beta: 0.7326923076923078\n",
      "train: step: 2084, loss: 0.0960940569639206, acc: 0.984375, recall: 0.9375, precision: 0.90625, f_beta: 0.9166666666666666\n",
      "train: step: 2085, loss: 0.10547642409801483, acc: 0.953125, recall: 0.75, precision: 0.7916666666666666, f_beta: 0.759344362745098\n",
      "train: step: 2086, loss: 0.04358883574604988, acc: 0.984375, recall: 0.71875, precision: 0.7421875, f_beta: 0.725\n",
      "train: step: 2087, loss: 0.03616733476519585, acc: 0.984375, recall: 0.6208333333333333, precision: 0.61875, f_beta: 0.6195553539019965\n",
      "train: step: 2088, loss: 0.07211489230394363, acc: 0.96875, recall: 0.7291666666666667, precision: 0.7083333333333334, f_beta: 0.7109848484848484\n",
      "train: step: 2089, loss: 0.0756581574678421, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7463235294117647, f_beta: 0.7432983682983683\n",
      "train: step: 2090, loss: 0.1601569950580597, acc: 0.984375, recall: 0.71875, precision: 0.7451923076923077, f_beta: 0.7266666666666666\n",
      "train: step: 2091, loss: 0.05650384724140167, acc: 0.984375, recall: 0.71875, precision: 0.74375, f_beta: 0.7258771929824561\n",
      "train: step: 2092, loss: 0.031036680564284325, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2093, loss: 0.03515205532312393, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666667\n",
      "train: step: 2094, loss: 0.11159119009971619, acc: 0.953125, recall: 0.821875, precision: 0.8072916666666666, f_beta: 0.79968671679198\n",
      "train: step: 2095, loss: 0.01845606602728367, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2096, loss: 0.20389056205749512, acc: 0.953125, recall: 0.6631944444444444, precision: 0.6276041666666667, f_beta: 0.6357142857142857\n",
      "train: step: 2097, loss: 0.04674014821648598, acc: 0.984375, recall: 0.7375, precision: 0.75, f_beta: 0.7430555555555556\n",
      "train: step: 2098, loss: 0.17493078112602234, acc: 0.921875, recall: 0.7395833333333334, precision: 0.6770833333333333, f_beta: 0.6922348484848485\n",
      "train: step: 2099, loss: 0.05113208666443825, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2100, loss: 0.33827564120292664, acc: 0.90625, recall: 0.625, precision: 0.6826923076923077, f_beta: 0.6433333333333332\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:05:39.450939, step: 2100, loss: 7.30445655186971, acc: 0.1440972222222222,precision: 0.07515829078329078, recall: 0.1058807319223986, f_beta: 0.08192571651678979\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2100\n",
      "\n",
      "start training model\n",
      "train: step: 2101, loss: 0.014692386612296104, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2102, loss: 0.07495834678411484, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2103, loss: 0.01753103919327259, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2104, loss: 0.012891885824501514, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2105, loss: 0.010027333162724972, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2106, loss: 0.010821901261806488, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2107, loss: 0.003933158703148365, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2108, loss: 0.06711187213659286, acc: 0.984375, recall: 0.7291666666666666, precision: 0.74609375, f_beta: 0.7354838709677419\n",
      "train: step: 2109, loss: 0.017995560541749, acc: 0.984375, recall: 0.65625, precision: 0.671875, f_beta: 0.6577380952380952\n",
      "train: step: 2110, loss: 0.004914439748972654, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2111, loss: 0.03198637813329697, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2112, loss: 0.08424074947834015, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666667\n",
      "train: step: 2113, loss: 0.01716969721019268, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2114, loss: 0.01856832206249237, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2115, loss: 0.04523877054452896, acc: 0.96875, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2116, loss: 0.056483570486307144, acc: 0.96875, recall: 0.7708333333333334, precision: 0.7604166666666666, f_beta: 0.7526515151515152\n",
      "train: step: 2117, loss: 0.05751420557498932, acc: 0.96875, recall: 0.74375, precision: 0.7145833333333333, f_beta: 0.723722020568663\n",
      "train: step: 2118, loss: 0.04072265326976776, acc: 0.984375, recall: 0.75, precision: 0.7410714285714286, f_beta: 0.7451923076923077\n",
      "train: step: 2119, loss: 0.013236870057880878, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2120, loss: 0.011171886697411537, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2121, loss: 0.03929198905825615, acc: 0.984375, recall: 0.625, precision: 0.59375, f_beta: 0.6041666666666666\n",
      "train: step: 2122, loss: 0.06382259726524353, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666667\n",
      "train: step: 2123, loss: 0.10987372696399689, acc: 0.953125, recall: 0.6979166666666666, precision: 0.6822916666666666, f_beta: 0.6785714285714286\n",
      "train: step: 2124, loss: 0.015723755583167076, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2125, loss: 0.0246079470962286, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666666, f_beta: 0.675\n",
      "train: step: 2126, loss: 0.11510208994150162, acc: 0.984375, recall: 0.84375, precision: 0.8660714285714286, f_beta: 0.8493589743589743\n",
      "train: step: 2127, loss: 0.03607010468840599, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2128, loss: 0.03567472845315933, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2129, loss: 0.04223129525780678, acc: 0.984375, recall: 0.609375, precision: 0.625, f_beta: 0.6160714285714286\n",
      "train: step: 2130, loss: 0.03756525367498398, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2131, loss: 0.10609424114227295, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 2132, loss: 0.03785138577222824, acc: 0.984375, recall: 0.7421875, precision: 0.7291666666666666, f_beta: 0.7333333333333334\n",
      "train: step: 2133, loss: 0.11566157639026642, acc: 0.96875, recall: 0.8229166666666666, precision: 0.8680555555555556, f_beta: 0.8379901960784314\n",
      "train: step: 2134, loss: 0.05547977238893509, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2135, loss: 0.14918763935565948, acc: 0.96875, recall: 0.8125, precision: 0.7604166666666666, f_beta: 0.7791666666666667\n",
      "train: step: 2136, loss: 0.06926005333662033, acc: 0.96875, recall: 0.65625, precision: 0.6805555555555556, f_beta: 0.6629901960784313\n",
      "train: step: 2137, loss: 0.0510881133377552, acc: 0.984375, recall: 0.8125, precision: 0.78125, f_beta: 0.7916666666666667\n",
      "train: step: 2138, loss: 0.041521426290273666, acc: 0.984375, recall: 0.8645833333333334, precision: 0.859375, f_beta: 0.8603896103896105\n",
      "train: step: 2139, loss: 0.061912138015031815, acc: 0.984375, recall: 0.8035714285714286, precision: 0.8088235294117647, f_beta: 0.8057983682983683\n",
      "train: step: 2140, loss: 0.07028267532587051, acc: 0.96875, recall: 0.7291666666666667, precision: 0.6979166666666666, f_beta: 0.7041666666666666\n",
      "train: step: 2141, loss: 0.014169452711939812, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2142, loss: 0.11822392046451569, acc: 0.96875, recall: 0.7604166666666666, precision: 0.8125, f_beta: 0.7791666666666667\n",
      "train: step: 2143, loss: 0.06009848043322563, acc: 0.96875, recall: 0.6666666666666666, precision: 0.65625, f_beta: 0.6541666666666667\n",
      "train: step: 2144, loss: 0.04493319243192673, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6875, f_beta: 0.6818181818181819\n",
      "train: step: 2145, loss: 0.04500903934240341, acc: 0.96875, recall: 0.8020833333333334, precision: 0.765625, f_beta: 0.7770562770562771\n",
      "train: step: 2146, loss: 0.016421731561422348, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2147, loss: 0.045053381472826004, acc: 0.984375, recall: 0.6125, precision: 0.61875, f_beta: 0.6147660818713451\n",
      "train: step: 2148, loss: 0.037274666130542755, acc: 0.984375, recall: 0.7916666666666666, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 2149, loss: 0.00738314725458622, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2150, loss: 0.02143242210149765, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2151, loss: 0.015793856233358383, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2152, loss: 0.04257974028587341, acc: 0.984375, recall: 0.734375, precision: 0.7291666666666666, f_beta: 0.7285714285714285\n",
      "train: step: 2153, loss: 0.13997146487236023, acc: 0.96875, recall: 0.7916666666666667, precision: 0.75, f_beta: 0.7583333333333333\n",
      "train: step: 2154, loss: 0.04585034400224686, acc: 0.96875, recall: 0.5993589743589743, precision: 0.61875, f_beta: 0.6067105263157895\n",
      "train: step: 2155, loss: 0.004670633468776941, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2156, loss: 0.06939049065113068, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 2157, loss: 0.040604203939437866, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 2158, loss: 0.0058294846676290035, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2159, loss: 0.043679963797330856, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2160, loss: 0.048874933272600174, acc: 0.984375, recall: 0.7375, precision: 0.7410714285714286, f_beta: 0.7382478632478633\n",
      "train: step: 2161, loss: 0.08452208340167999, acc: 0.96875, recall: 0.7291666666666666, precision: 0.734375, f_beta: 0.7285714285714286\n",
      "train: step: 2162, loss: 0.04284744709730148, acc: 0.96875, recall: 0.7708333333333334, precision: 0.7723214285714286, f_beta: 0.7603438228438228\n",
      "train: step: 2163, loss: 0.08170060813426971, acc: 0.96875, recall: 0.703125, precision: 0.7421875, f_beta: 0.7160714285714286\n",
      "train: step: 2164, loss: 0.00804693903774023, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2165, loss: 0.08955784887075424, acc: 0.96875, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 2166, loss: 0.011823605746030807, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2167, loss: 0.09922318905591965, acc: 0.96875, recall: 0.8125, precision: 0.8035714285714286, f_beta: 0.8076923076923077\n",
      "train: step: 2168, loss: 0.013017449527978897, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2169, loss: 0.05428977310657501, acc: 0.984375, recall: 0.84375, precision: 0.8680555555555556, f_beta: 0.8504901960784313\n",
      "train: step: 2170, loss: 0.009214695543050766, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2171, loss: 0.07130921632051468, acc: 0.984375, recall: 0.6796875, precision: 0.6770833333333334, f_beta: 0.6776515151515151\n",
      "train: step: 2172, loss: 0.017229285091161728, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2173, loss: 0.01310084480792284, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2174, loss: 0.13680367171764374, acc: 0.96875, recall: 0.7083333333333333, precision: 0.7410714285714286, f_beta: 0.7139423076923077\n",
      "train: step: 2175, loss: 0.018256131559610367, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2176, loss: 0.056429482996463776, acc: 0.984375, recall: 0.6875, precision: 0.6796875, f_beta: 0.6833333333333333\n",
      "train: step: 2177, loss: 0.10321559756994247, acc: 0.953125, recall: 0.725, precision: 0.75, f_beta: 0.734375\n",
      "train: step: 2178, loss: 0.07321053743362427, acc: 0.96875, recall: 0.78125, precision: 0.78125, f_beta: 0.78125\n",
      "train: step: 2179, loss: 0.05468473583459854, acc: 0.96875, recall: 0.7386363636363636, precision: 0.7213541666666666, f_beta: 0.7270833333333334\n",
      "train: step: 2180, loss: 0.02640410326421261, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2181, loss: 0.12942379713058472, acc: 0.96875, recall: 0.78125, precision: 0.7708333333333334, f_beta: 0.7678030303030303\n",
      "train: step: 2182, loss: 0.09428602457046509, acc: 0.96875, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2183, loss: 0.09173266589641571, acc: 0.984375, recall: 0.8088235294117647, precision: 0.8125, f_beta: 0.8106060606060606\n",
      "train: step: 2184, loss: 0.20190812647342682, acc: 0.96875, recall: 0.625, precision: 0.6517857142857143, f_beta: 0.6226851851851851\n",
      "start training model\n",
      "train: step: 2185, loss: 0.031371571123600006, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 2186, loss: 0.05760433152318001, acc: 0.984375, recall: 0.8080357142857143, precision: 0.7916666666666667, f_beta: 0.7976851851851852\n",
      "train: step: 2187, loss: 0.12172982096672058, acc: 0.953125, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2188, loss: 0.0803728923201561, acc: 0.96875, recall: 0.78125, precision: 0.7604166666666666, f_beta: 0.7583333333333333\n",
      "train: step: 2189, loss: 0.051917802542448044, acc: 0.96875, recall: 0.828125, precision: 0.859375, f_beta: 0.8385416666666666\n",
      "train: step: 2190, loss: 0.0066567943431437016, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2191, loss: 0.09802962094545364, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848485\n",
      "train: step: 2192, loss: 0.02453804388642311, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2193, loss: 0.06433205306529999, acc: 0.984375, recall: 0.7375, precision: 0.7421875, f_beta: 0.7388888888888889\n",
      "train: step: 2194, loss: 0.0094066821038723, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2195, loss: 0.005468220449984074, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2196, loss: 0.007552655413746834, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2197, loss: 0.012896198779344559, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2198, loss: 0.006387035828083754, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2199, loss: 0.08242589980363846, acc: 0.96875, recall: 0.75, precision: 0.7098214285714286, f_beta: 0.7243589743589745\n",
      "train: step: 2200, loss: 0.02150389552116394, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:07:31.330693, step: 2200, loss: 7.085404290093316, acc: 0.18229166666666666,precision: 0.08223417774581993, recall: 0.10287603985520652, f_beta: 0.08303675499422863\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2200\n",
      "\n",
      "train: step: 2201, loss: 0.007443191949278116, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2202, loss: 0.02021610736846924, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2203, loss: 0.004890205804258585, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2204, loss: 0.015360649675130844, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2205, loss: 0.1456751972436905, acc: 0.96875, recall: 0.721875, precision: 0.7265625, f_beta: 0.721031746031746\n",
      "train: step: 2206, loss: 0.005944800563156605, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2207, loss: 0.11734150350093842, acc: 0.953125, recall: 0.59375, precision: 0.6101190476190477, f_beta: 0.5961700336700337\n",
      "train: step: 2208, loss: 0.07035970687866211, acc: 0.984375, recall: 0.6041666666666667, precision: 0.625, f_beta: 0.6125\n",
      "train: step: 2209, loss: 0.05531730502843857, acc: 0.96875, recall: 0.68125, precision: 0.68125, f_beta: 0.680921052631579\n",
      "train: step: 2210, loss: 0.04665051028132439, acc: 0.984375, recall: 0.6666666666666667, precision: 0.6875, f_beta: 0.675\n",
      "train: step: 2211, loss: 0.003910509403795004, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2212, loss: 0.10251843929290771, acc: 0.96875, recall: 0.8088235294117647, precision: 0.8035714285714286, f_beta: 0.8057983682983683\n",
      "train: step: 2213, loss: 0.021061351522803307, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2214, loss: 0.07565762102603912, acc: 0.984375, recall: 0.7395833333333334, precision: 0.71875, f_beta: 0.7234848484848484\n",
      "train: step: 2215, loss: 0.03682349994778633, acc: 0.984375, recall: 0.8, precision: 0.8125, f_beta: 0.8055555555555556\n",
      "train: step: 2216, loss: 0.17866922914981842, acc: 0.953125, recall: 0.759375, precision: 0.7827380952380952, f_beta: 0.7629949665132731\n",
      "train: step: 2217, loss: 0.01586735062301159, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2218, loss: 0.0035762430634349585, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2219, loss: 0.04601428657770157, acc: 0.96875, recall: 0.71875, precision: 0.7291666666666666, f_beta: 0.7166666666666667\n",
      "train: step: 2220, loss: 0.009857796132564545, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2221, loss: 0.017216484993696213, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2222, loss: 0.021727366372942924, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2223, loss: 0.006534157320857048, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2224, loss: 0.12313802540302277, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 2225, loss: 0.06430484354496002, acc: 0.984375, recall: 0.75, precision: 0.74375, f_beta: 0.7467105263157895\n",
      "train: step: 2226, loss: 0.016560086980462074, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2227, loss: 0.012738758698105812, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2228, loss: 0.06779219955205917, acc: 0.96875, recall: 0.6685855263157895, precision: 0.675, f_beta: 0.6699377949377949\n",
      "train: step: 2229, loss: 0.00636304821819067, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2230, loss: 0.0031471268739551306, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2231, loss: 0.06727927923202515, acc: 0.984375, recall: 0.671875, precision: 0.6796875, f_beta: 0.674404761904762\n",
      "train: step: 2232, loss: 0.02110988460481167, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 2233, loss: 0.043414704501628876, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 2234, loss: 0.012956214137375355, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2235, loss: 0.10218164324760437, acc: 0.953125, recall: 0.6125, precision: 0.6785714285714286, f_beta: 0.6340811965811965\n",
      "train: step: 2236, loss: 0.037541430443525314, acc: 0.984375, recall: 0.625, precision: 0.6041666666666666, f_beta: 0.6125\n",
      "train: step: 2237, loss: 0.015426000580191612, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2238, loss: 0.02753773145377636, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2239, loss: 0.06567724049091339, acc: 0.984375, recall: 0.5535714285714286, precision: 0.55625, f_beta: 0.5544028340080971\n",
      "train: step: 2240, loss: 0.05691223591566086, acc: 0.984375, recall: 0.625, precision: 0.6160714285714286, f_beta: 0.6201923076923077\n",
      "train: step: 2241, loss: 0.009803078137338161, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2242, loss: 0.027473829686641693, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2243, loss: 0.06635518372058868, acc: 0.984375, recall: 0.71875, precision: 0.74609375, f_beta: 0.7271505376344085\n",
      "train: step: 2244, loss: 0.037621498107910156, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7451923076923077, f_beta: 0.7418181818181818\n",
      "train: step: 2245, loss: 0.2751227021217346, acc: 0.953125, recall: 0.6032986111111112, precision: 0.6125, f_beta: 0.6060763888888889\n",
      "train: step: 2246, loss: 0.03803689032793045, acc: 0.984375, recall: 0.675, precision: 0.65625, f_beta: 0.6597222222222222\n",
      "train: step: 2247, loss: 0.08726724982261658, acc: 0.953125, recall: 0.6629901960784313, precision: 0.6736111111111112, f_beta: 0.6652935606060606\n",
      "train: step: 2248, loss: 0.03271985054016113, acc: 0.984375, recall: 0.6796875, precision: 0.6875, f_beta: 0.6833333333333333\n",
      "train: step: 2249, loss: 0.008264516480267048, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2250, loss: 0.10008637607097626, acc: 0.953125, recall: 0.71875, precision: 0.6822916666666667, f_beta: 0.6902625152625153\n",
      "train: step: 2251, loss: 0.04915700852870941, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2252, loss: 0.10176193714141846, acc: 0.984375, recall: 0.84375, precision: 0.8671875, f_beta: 0.85\n",
      "train: step: 2253, loss: 0.10407984256744385, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7291666666666666, f_beta: 0.725\n",
      "train: step: 2254, loss: 0.014993807300925255, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2255, loss: 0.019535163417458534, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2256, loss: 0.10298366844654083, acc: 0.96875, recall: 0.7451923076923077, precision: 0.6875, f_beta: 0.7058333333333333\n",
      "train: step: 2257, loss: 0.027532994747161865, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2258, loss: 0.08471456170082092, acc: 0.953125, recall: 0.8541666666666667, precision: 0.8104166666666667, f_beta: 0.8222222222222222\n",
      "train: step: 2259, loss: 0.011320751160383224, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2260, loss: 0.059194814413785934, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6708333333333334, f_beta: 0.6660287081339714\n",
      "train: step: 2261, loss: 0.00866775680333376, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2262, loss: 0.041786570101976395, acc: 0.984375, recall: 0.8, precision: 0.8068181818181818, f_beta: 0.8025793650793651\n",
      "train: step: 2263, loss: 0.014409276656806469, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2264, loss: 0.07189525663852692, acc: 0.96875, recall: 0.625, precision: 0.6125, f_beta: 0.6180555555555556\n",
      "train: step: 2265, loss: 0.0662894994020462, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8, f_beta: 0.7930555555555556\n",
      "train: step: 2266, loss: 0.03881452605128288, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2267, loss: 0.038241226226091385, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 2268, loss: 0.01624954491853714, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 2269, loss: 0.08234800398349762, acc: 0.96875, recall: 0.7604166666666666, precision: 0.8007478632478633, f_beta: 0.7729901960784314\n",
      "train: step: 2270, loss: 0.14814415574073792, acc: 0.96875, recall: 0.6875, precision: 0.6604166666666667, f_beta: 0.6717105263157894\n",
      "train: step: 2271, loss: 0.01644158363342285, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2272, loss: 0.00868404284119606, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2273, loss: 0.005748338997364044, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2274, loss: 0.03292129188776016, acc: 0.984375, recall: 0.734375, precision: 0.734375, f_beta: 0.7321428571428571\n",
      "train: step: 2275, loss: 0.06969642639160156, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 2276, loss: 0.06201612204313278, acc: 0.984375, recall: 0.8541666666666667, precision: 0.8541666666666667, f_beta: 0.85\n",
      "train: step: 2277, loss: 0.0069325827062129974, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2278, loss: 0.09190627932548523, acc: 0.96875, recall: 0.7130681818181818, precision: 0.7291666666666666, f_beta: 0.7136904761904762\n",
      "train: step: 2279, loss: 0.0802079364657402, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8125, f_beta: 0.8\n",
      "train: step: 2280, loss: 0.03201308473944664, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2281, loss: 0.06333020329475403, acc: 0.96875, recall: 0.5208333333333333, precision: 0.5520833333333333, f_beta: 0.5318181818181817\n",
      "train: step: 2282, loss: 0.01614651083946228, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2283, loss: 0.0953136682510376, acc: 0.96875, recall: 0.75, precision: 0.7395833333333334, f_beta: 0.7443181818181818\n",
      "train: step: 2284, loss: 0.014218595810234547, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2285, loss: 0.012117614969611168, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2286, loss: 0.019701754674315453, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2287, loss: 0.027606669813394547, acc: 0.984375, recall: 0.6666666666666666, precision: 0.65625, f_beta: 0.6541666666666667\n",
      "train: step: 2288, loss: 0.01872275397181511, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2289, loss: 0.007590798195451498, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2290, loss: 0.023939991369843483, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2291, loss: 0.06341356784105301, acc: 0.984375, recall: 0.671875, precision: 0.6666666666666667, f_beta: 0.6660714285714286\n",
      "train: step: 2292, loss: 0.0069334497675299644, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2293, loss: 0.009444383904337883, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2294, loss: 0.012587233446538448, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2295, loss: 0.039257753640413284, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2296, loss: 0.022302335128188133, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2297, loss: 0.012440712191164494, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2298, loss: 0.13454541563987732, acc: 0.96875, recall: 0.6666666666666666, precision: 0.640625, f_beta: 0.6452380952380953\n",
      "train: step: 2299, loss: 0.006833416875451803, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2300, loss: 0.008598008193075657, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:09:23.481168, step: 2300, loss: 7.418753306070964, acc: 0.16666666666666666,precision: 0.07733573028255046, recall: 0.08737792368307074, f_beta: 0.0769059680840422\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2300\n",
      "\n",
      "train: step: 2301, loss: 0.010297219268977642, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2302, loss: 0.004868088755756617, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2303, loss: 0.08608277142047882, acc: 0.96875, recall: 0.703125, precision: 0.7285714285714286, f_beta: 0.7084859584859584\n",
      "train: step: 2304, loss: 0.04263357073068619, acc: 0.96875, recall: 0.6875, precision: 0.7430555555555556, f_beta: 0.704656862745098\n",
      "train: step: 2305, loss: 0.04008733481168747, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6875, f_beta: 0.675\n",
      "train: step: 2306, loss: 0.10132858902215958, acc: 0.984375, recall: 0.8671875, precision: 0.8671875, f_beta: 0.8666666666666667\n",
      "train: step: 2307, loss: 0.006953681819140911, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2308, loss: 0.013434872031211853, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2309, loss: 0.04359937459230423, acc: 0.984375, recall: 0.875, precision: 0.84375, f_beta: 0.8541666666666667\n",
      "train: step: 2310, loss: 0.016248464584350586, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2311, loss: 0.11760793626308441, acc: 0.984375, recall: 0.7916666666666667, precision: 0.8068181818181818, f_beta: 0.7970238095238096\n",
      "train: step: 2312, loss: 0.017711572349071503, acc: 0.984375, recall: 0.796875, precision: 0.8, f_beta: 0.7966269841269842\n",
      "train: step: 2313, loss: 0.019426103681325912, acc: 0.984375, recall: 0.6830357142857143, precision: 0.6822916666666666, f_beta: 0.6824677938808373\n",
      "train: step: 2314, loss: 0.009633851237595081, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2315, loss: 0.026170972734689713, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 2316, loss: 0.043151065707206726, acc: 0.984375, recall: 0.71875, precision: 0.7375, f_beta: 0.7222222222222222\n",
      "train: step: 2317, loss: 0.03766033053398132, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 2318, loss: 0.0398787222802639, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 2319, loss: 0.0057873837649822235, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2320, loss: 0.028656933456659317, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666667\n",
      "train: step: 2321, loss: 0.008981574326753616, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2322, loss: 0.02120365761220455, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2323, loss: 0.0037495549768209457, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2324, loss: 0.006112548056989908, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2325, loss: 0.00822004210203886, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2326, loss: 0.006733784452080727, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2327, loss: 0.039434220641851425, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 2328, loss: 0.11013349890708923, acc: 0.984375, recall: 0.7916666666666667, precision: 0.7916666666666667, f_beta: 0.7875\n",
      "train: step: 2329, loss: 0.01834157481789589, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2330, loss: 0.03543119877576828, acc: 0.984375, recall: 0.84375, precision: 0.875, f_beta: 0.8541666666666667\n",
      "train: step: 2331, loss: 0.0698896050453186, acc: 0.984375, recall: 0.7451923076923077, precision: 0.7430555555555556, f_beta: 0.7438235294117648\n",
      "train: step: 2332, loss: 0.014879677444696426, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2333, loss: 0.00249313423410058, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2334, loss: 0.008038213476538658, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2335, loss: 0.016584644094109535, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2336, loss: 0.1225145161151886, acc: 0.96875, recall: 0.7708333333333333, precision: 0.78125, f_beta: 0.7604166666666666\n",
      "train: step: 2337, loss: 0.13582655787467957, acc: 0.96875, recall: 0.625, precision: 0.5885416666666666, f_beta: 0.6035714285714285\n",
      "train: step: 2338, loss: 0.0461667962372303, acc: 0.96875, recall: 0.6660714285714286, precision: 0.6728896103896104, f_beta: 0.6686507936507936\n",
      "train: step: 2339, loss: 0.0423344261944294, acc: 0.96875, recall: 0.675, precision: 0.680921052631579, f_beta: 0.6770833333333334\n",
      "train: step: 2340, loss: 0.02413935586810112, acc: 0.984375, recall: 0.8, precision: 0.8076923076923077, f_beta: 0.8030555555555556\n",
      "train: step: 2341, loss: 0.015977201983332634, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2342, loss: 0.043555233627557755, acc: 0.984375, recall: 0.7455357142857143, precision: 0.75, f_beta: 0.7476851851851851\n",
      "train: step: 2343, loss: 0.050232913345098495, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2344, loss: 0.04452391713857651, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7430555555555556, f_beta: 0.7338235294117648\n",
      "train: step: 2345, loss: 0.042035941034555435, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2346, loss: 0.053181495517492294, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2347, loss: 0.10144810378551483, acc: 0.96875, recall: 0.6875, precision: 0.7322916666666667, f_beta: 0.6986714975845411\n",
      "train: step: 2348, loss: 0.08781315386295319, acc: 0.96875, recall: 0.7135416666666666, precision: 0.7291666666666666, f_beta: 0.713949275362319\n",
      "train: step: 2349, loss: 0.017468709498643875, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2350, loss: 0.030761389061808586, acc: 0.984375, recall: 0.7455357142857143, precision: 0.7421875, f_beta: 0.7435185185185186\n",
      "train: step: 2351, loss: 0.03591563552618027, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 2352, loss: 0.009227965027093887, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "start training model\n",
      "train: step: 2353, loss: 0.0350346677005291, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2354, loss: 0.009690692648291588, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2355, loss: 0.01543198898434639, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2356, loss: 0.02218577079474926, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2357, loss: 0.03742275387048721, acc: 0.984375, recall: 0.7375, precision: 0.7421875, f_beta: 0.7388888888888889\n",
      "train: step: 2358, loss: 0.009301324374973774, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2359, loss: 0.015238218009471893, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2360, loss: 0.05510224029421806, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 2361, loss: 0.012974212877452374, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2362, loss: 0.012212280184030533, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2363, loss: 0.06141316518187523, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2364, loss: 0.08115442842245102, acc: 0.984375, recall: 0.5625, precision: 0.5583333333333333, f_beta: 0.5603448275862069\n",
      "train: step: 2365, loss: 0.03075597994029522, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2366, loss: 0.02886177971959114, acc: 0.984375, recall: 0.8, precision: 0.7916666666666666, f_beta: 0.7930555555555556\n",
      "train: step: 2367, loss: 0.08581016957759857, acc: 0.96875, recall: 0.6071428571428572, precision: 0.61875, f_beta: 0.6112938596491229\n",
      "train: step: 2368, loss: 0.009596246294677258, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2369, loss: 0.011996262706816196, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2370, loss: 0.05731504037976265, acc: 0.96875, recall: 0.7318181818181818, precision: 0.6875, f_beta: 0.6984126984126985\n",
      "train: step: 2371, loss: 0.06988004595041275, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 2372, loss: 0.024695347994565964, acc: 0.984375, recall: 0.7421875, precision: 0.71875, f_beta: 0.725\n",
      "train: step: 2373, loss: 0.014816624112427235, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2374, loss: 0.014368169009685516, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2375, loss: 0.009210257790982723, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2376, loss: 0.037501946091651917, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666666\n",
      "train: step: 2377, loss: 0.03936024382710457, acc: 0.984375, recall: 0.84375, precision: 0.8625, f_beta: 0.8472222222222223\n",
      "train: step: 2378, loss: 0.024762524291872978, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2379, loss: 0.01104181818664074, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2380, loss: 0.009210621938109398, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2381, loss: 0.01595662534236908, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2382, loss: 0.021953128278255463, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2383, loss: 0.051123782992362976, acc: 0.984375, recall: 0.7916666666666667, precision: 0.796875, f_beta: 0.7910714285714286\n",
      "train: step: 2384, loss: 0.07055484503507614, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8035714285714286, f_beta: 0.8020104895104895\n",
      "train: step: 2385, loss: 0.003563151927664876, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2386, loss: 0.02277948148548603, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2387, loss: 0.003420184599235654, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2388, loss: 0.011370660737156868, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2389, loss: 0.07504360377788544, acc: 0.984375, recall: 0.8072916666666666, precision: 0.796875, f_beta: 0.8008540372670808\n",
      "train: step: 2390, loss: 0.006910013500601053, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2391, loss: 0.0076949140056967735, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2392, loss: 0.02917269989848137, acc: 0.984375, recall: 0.7916666666666666, precision: 0.796875, f_beta: 0.7910714285714285\n",
      "train: step: 2393, loss: 0.02815864235162735, acc: 0.96875, recall: 0.6666666666666667, precision: 0.6822916666666667, f_beta: 0.6722826086956522\n",
      "train: step: 2394, loss: 0.011078553274273872, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2395, loss: 0.005870562046766281, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2396, loss: 0.04691411182284355, acc: 0.984375, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2397, loss: 0.016808316111564636, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2398, loss: 0.022350965067744255, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2399, loss: 0.032911330461502075, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 2400, loss: 0.00877583958208561, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:11:16.066366, step: 2400, loss: 7.626016987694634, acc: 0.15104166666666666,precision: 0.07394821467399511, recall: 0.08344059489892823, f_beta: 0.06985148297655308\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2400\n",
      "\n",
      "train: step: 2401, loss: 0.008004365488886833, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2402, loss: 0.017527805641293526, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2403, loss: 0.009152868762612343, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2404, loss: 0.010418208315968513, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2405, loss: 0.008033743128180504, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2406, loss: 0.005074948072433472, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2407, loss: 0.026066429913043976, acc: 0.984375, recall: 0.8125, precision: 0.78125, f_beta: 0.7916666666666666\n",
      "train: step: 2408, loss: 0.006744958460330963, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2409, loss: 0.10893170535564423, acc: 0.96875, recall: 0.7890625, precision: 0.8026515151515151, f_beta: 0.7942733990147783\n",
      "train: step: 2410, loss: 0.009452711790800095, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2411, loss: 0.05261186137795448, acc: 0.984375, recall: 0.7291666666666666, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 2412, loss: 0.1252354234457016, acc: 0.984375, recall: 0.6805555555555556, precision: 0.6818181818181819, f_beta: 0.6808473389355743\n",
      "train: step: 2413, loss: 0.516152560710907, acc: 0.875, recall: 0.6216911764705882, precision: 0.6262019230769231, f_beta: 0.6084152864044168\n",
      "train: step: 2414, loss: 0.09711907804012299, acc: 0.953125, recall: 0.85625, precision: 0.8616071428571429, f_beta: 0.8564705882352942\n",
      "train: step: 2415, loss: 0.11851572245359421, acc: 0.96875, recall: 0.7416666666666667, precision: 0.7395833333333334, f_beta: 0.7398538961038961\n",
      "train: step: 2416, loss: 0.012026377022266388, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2417, loss: 0.034257352352142334, acc: 0.984375, recall: 0.80625, precision: 0.8035714285714286, f_beta: 0.8044028340080972\n",
      "train: step: 2418, loss: 0.09329965710639954, acc: 0.96875, recall: 0.78125, precision: 0.75, f_beta: 0.7604166666666667\n",
      "train: step: 2419, loss: 0.012692245654761791, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2420, loss: 0.08913121372461319, acc: 0.96875, recall: 0.7109375, precision: 0.7139423076923077, f_beta: 0.7016666666666667\n",
      "train: step: 2421, loss: 0.08803299069404602, acc: 0.953125, recall: 0.7697916666666667, precision: 0.8080357142857143, f_beta: 0.7833449868632936\n",
      "train: step: 2422, loss: 0.10188566148281097, acc: 0.984375, recall: 0.7421875, precision: 0.74609375, f_beta: 0.7438172043010753\n",
      "train: step: 2423, loss: 0.09698018431663513, acc: 0.984375, recall: 0.87109375, precision: 0.8701923076923077, f_beta: 0.870483870967742\n",
      "train: step: 2424, loss: 0.07256770133972168, acc: 0.984375, recall: 0.7410714285714286, precision: 0.74609375, f_beta: 0.7431761786600497\n",
      "train: step: 2425, loss: 0.04110574722290039, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2426, loss: 0.12195024639368057, acc: 0.9375, recall: 0.6748737373737375, precision: 0.671875, f_beta: 0.6719187675070029\n",
      "train: step: 2427, loss: 0.0243180301040411, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7421875, f_beta: 0.7333333333333334\n",
      "train: step: 2428, loss: 0.01573551446199417, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2429, loss: 0.04372856020927429, acc: 0.984375, recall: 0.71875, precision: 0.734375, f_beta: 0.7202380952380952\n",
      "train: step: 2430, loss: 0.011004706844687462, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2431, loss: 0.010505815967917442, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2432, loss: 0.06655827164649963, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 2433, loss: 0.015656564384698868, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2434, loss: 0.09795013070106506, acc: 0.953125, recall: 0.8443181818181819, precision: 0.8364583333333334, f_beta: 0.8358138030551823\n",
      "train: step: 2435, loss: 0.08076958358287811, acc: 0.984375, recall: 0.74375, precision: 0.7291666666666666, f_beta: 0.7342105263157894\n",
      "train: step: 2436, loss: 0.10760096460580826, acc: 0.96875, recall: 0.7395833333333334, precision: 0.7386363636363636, f_beta: 0.7380681818181818\n",
      "start training model\n",
      "train: step: 2437, loss: 0.015696192160248756, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2438, loss: 0.014985380694270134, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2439, loss: 0.13454924523830414, acc: 0.9375, recall: 0.6871527777777777, precision: 0.6903769841269842, f_beta: 0.6870515513897868\n",
      "train: step: 2440, loss: 0.007680907845497131, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2441, loss: 0.03428235650062561, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2442, loss: 0.025068843737244606, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2443, loss: 0.03533892333507538, acc: 0.984375, recall: 0.5520833333333333, precision: 0.5625, f_beta: 0.5568181818181819\n",
      "train: step: 2444, loss: 0.05408213660120964, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380951\n",
      "train: step: 2445, loss: 0.007167557254433632, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2446, loss: 0.0037774061784148216, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2447, loss: 0.07020103186368942, acc: 0.96875, recall: 0.59375, precision: 0.6205357142857143, f_beta: 0.6018518518518519\n",
      "train: step: 2448, loss: 0.015012521296739578, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2449, loss: 0.013416936621069908, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2450, loss: 0.08768995106220245, acc: 0.984375, recall: 0.8055555555555556, precision: 0.8080357142857143, f_beta: 0.80650871459695\n",
      "train: step: 2451, loss: 0.016053523868322372, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2452, loss: 0.027456311509013176, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 2453, loss: 0.018730558454990387, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2454, loss: 0.012722358107566833, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2455, loss: 0.056464698165655136, acc: 0.984375, recall: 0.7458333333333333, precision: 0.7291666666666667, f_beta: 0.7353448275862069\n",
      "train: step: 2456, loss: 0.026637772098183632, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6666666666666667, f_beta: 0.6625\n",
      "train: step: 2457, loss: 0.017469312995672226, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2458, loss: 0.013437069021165371, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2459, loss: 0.05128569155931473, acc: 0.984375, recall: 0.62109375, precision: 0.6193181818181819, f_beta: 0.6200076804915515\n",
      "train: step: 2460, loss: 0.06882656365633011, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 2461, loss: 0.10593543946743011, acc: 0.953125, recall: 0.7371651785714286, precision: 0.7339015151515152, f_beta: 0.734518170002041\n",
      "train: step: 2462, loss: 0.006403252482414246, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2463, loss: 0.009108813479542732, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2464, loss: 0.034703705459833145, acc: 0.984375, recall: 0.65625, precision: 0.65625, f_beta: 0.6458333333333333\n",
      "train: step: 2465, loss: 0.08460332453250885, acc: 0.96875, recall: 0.7285714285714286, precision: 0.7410714285714286, f_beta: 0.733440170940171\n",
      "train: step: 2466, loss: 0.05193445086479187, acc: 0.984375, recall: 0.75, precision: 0.7410714285714286, f_beta: 0.7451923076923077\n",
      "train: step: 2467, loss: 0.04408913105726242, acc: 0.984375, recall: 0.59375, precision: 0.6193181818181818, f_beta: 0.6011904761904763\n",
      "train: step: 2468, loss: 0.06705798208713531, acc: 0.96875, recall: 0.7410714285714286, precision: 0.7098214285714286, f_beta: 0.7195512820512822\n",
      "train: step: 2469, loss: 0.04561009258031845, acc: 0.984375, recall: 0.9375, precision: 0.9166666666666666, f_beta: 0.925\n",
      "train: step: 2470, loss: 0.04283542186021805, acc: 0.984375, recall: 0.7375, precision: 0.7447916666666666, f_beta: 0.7403381642512078\n",
      "train: step: 2471, loss: 0.01973332092165947, acc: 0.984375, recall: 0.7421875, precision: 0.7421875, f_beta: 0.7416666666666667\n",
      "train: step: 2472, loss: 0.015333850868046284, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2473, loss: 0.025798911228775978, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2474, loss: 0.035600777715444565, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2475, loss: 0.006304764188826084, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2476, loss: 0.037200335413217545, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2477, loss: 0.15282940864562988, acc: 0.96875, recall: 0.6796875, precision: 0.6830357142857143, f_beta: 0.6810185185185185\n",
      "train: step: 2478, loss: 0.018892155960202217, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2479, loss: 0.006279382389038801, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2480, loss: 0.016009673476219177, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2481, loss: 0.03264173865318298, acc: 0.984375, recall: 0.8660714285714286, precision: 0.84375, f_beta: 0.8493589743589745\n",
      "train: step: 2482, loss: 0.05828540772199631, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 2483, loss: 0.011143818497657776, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2484, loss: 0.024285949766635895, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2485, loss: 0.008277753368020058, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2486, loss: 0.11676346510648727, acc: 0.9375, recall: 0.8333333333333333, precision: 0.76875, f_beta: 0.7743055555555555\n",
      "train: step: 2487, loss: 0.01469458919018507, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2488, loss: 0.04728524759411812, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 2489, loss: 0.014589530415832996, acc: 0.984375, recall: 0.8090277777777778, precision: 0.78125, f_beta: 0.7898809523809524\n",
      "train: step: 2490, loss: 0.022829096764326096, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2491, loss: 0.005962123163044453, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2492, loss: 0.06970778107643127, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666667\n",
      "train: step: 2493, loss: 0.018974564969539642, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2494, loss: 0.008205042220652103, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2495, loss: 0.030825350433588028, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2496, loss: 0.01733054593205452, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2497, loss: 0.0076188985258340836, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2498, loss: 0.029981844127178192, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2499, loss: 0.017313839867711067, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2500, loss: 0.04980599135160446, acc: 0.984375, recall: 0.8072916666666666, precision: 0.80859375, f_beta: 0.8077664796633942\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:13:09.426031, step: 2500, loss: 7.258235719468859, acc: 0.1545138888888889,precision: 0.07536565479273812, recall: 0.07947415239081906, f_beta: 0.07077488390938425\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2500\n",
      "\n",
      "train: step: 2501, loss: 0.034174900501966476, acc: 0.96875, recall: 0.855654761904762, precision: 0.8588235294117648, f_beta: 0.8556721056721057\n",
      "train: step: 2502, loss: 0.022583071142435074, acc: 0.984375, recall: 0.80625, precision: 0.8020833333333334, f_beta: 0.8035287081339714\n",
      "train: step: 2503, loss: 0.08361275494098663, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666666, f_beta: 0.7791666666666667\n",
      "train: step: 2504, loss: 0.009776131249964237, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2505, loss: 0.006774593610316515, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2506, loss: 0.01450318843126297, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2507, loss: 0.008562693372368813, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2508, loss: 0.04043097794055939, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6830357142857143, f_beta: 0.6726851851851852\n",
      "train: step: 2509, loss: 0.10698716342449188, acc: 0.953125, recall: 0.730654761904762, precision: 0.7171875, f_beta: 0.7206886504300297\n",
      "train: step: 2510, loss: 0.049502722918987274, acc: 0.984375, recall: 0.796875, precision: 0.8, f_beta: 0.7966269841269842\n",
      "train: step: 2511, loss: 0.017007015645503998, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2512, loss: 0.006618056446313858, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2513, loss: 0.004358699079602957, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2514, loss: 0.045672133564949036, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8125, f_beta: 0.8068181818181819\n",
      "train: step: 2515, loss: 0.039256125688552856, acc: 0.984375, recall: 0.8713235294117647, precision: 0.84375, f_beta: 0.8522727272727273\n",
      "train: step: 2516, loss: 0.0278659425675869, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2517, loss: 0.010216192342340946, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2518, loss: 0.06312944740056992, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 2519, loss: 0.007399510592222214, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2520, loss: 0.013706139288842678, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 2521, loss: 0.06517815589904785, acc: 0.984375, recall: 0.8, precision: 0.8035714285714286, f_beta: 0.8007478632478633\n",
      "train: step: 2522, loss: 0.014606446027755737, acc: 0.984375, recall: 0.8541666666666666, precision: 0.84375, f_beta: 0.8416666666666667\n",
      "train: step: 2523, loss: 0.019335784018039703, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2524, loss: 0.015761911869049072, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2525, loss: 0.056531064212322235, acc: 0.96875, recall: 0.7098214285714286, precision: 0.7239583333333334, f_beta: 0.7097485847485848\n",
      "train: step: 2526, loss: 0.011234673671424389, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2527, loss: 0.031809002161026, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2528, loss: 0.046450044959783554, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2529, loss: 0.006825692020356655, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2530, loss: 0.008063577115535736, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2531, loss: 0.01376824826002121, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2532, loss: 0.03746660426259041, acc: 0.984375, recall: 0.68125, precision: 0.6770833333333334, f_beta: 0.6785287081339713\n",
      "train: step: 2533, loss: 0.04513591527938843, acc: 0.96875, recall: 0.78125, precision: 0.7723214285714286, f_beta: 0.766025641025641\n",
      "train: step: 2534, loss: 0.031120888888835907, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2535, loss: 0.05206993222236633, acc: 0.984375, recall: 0.6826923076923077, precision: 0.6822916666666667, f_beta: 0.6822826086956522\n",
      "train: step: 2536, loss: 0.015619581565260887, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2537, loss: 0.03251856192946434, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2538, loss: 0.006989038083702326, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2539, loss: 0.026641152799129486, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 2540, loss: 0.01632104068994522, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2541, loss: 0.12067632377147675, acc: 0.96875, recall: 0.6791666666666667, precision: 0.6801470588235294, f_beta: 0.6791294642857143\n",
      "train: step: 2542, loss: 0.06553171575069427, acc: 0.984375, recall: 0.6875, precision: 0.6818181818181819, f_beta: 0.6845238095238095\n",
      "train: step: 2543, loss: 0.02954648993909359, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2544, loss: 0.011519304476678371, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2545, loss: 0.047171108424663544, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "train: step: 2546, loss: 0.08984582126140594, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 2547, loss: 0.07382424920797348, acc: 0.984375, recall: 0.71875, precision: 0.7395833333333334, f_beta: 0.7234848484848484\n",
      "train: step: 2548, loss: 0.016355112195014954, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2549, loss: 0.022401656955480576, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2550, loss: 0.10902809351682663, acc: 0.984375, recall: 0.796875, precision: 0.8083333333333333, f_beta: 0.8014162561576355\n",
      "train: step: 2551, loss: 0.004792193416506052, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2552, loss: 0.007657553534954786, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2553, loss: 0.026202166453003883, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2554, loss: 0.15111204981803894, acc: 0.96875, recall: 0.7467105263157895, precision: 0.7395833333333334, f_beta: 0.7426289926289926\n",
      "train: step: 2555, loss: 0.0008654688717797399, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2556, loss: 0.0021493472158908844, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2557, loss: 0.05825654789805412, acc: 0.984375, recall: 0.8660714285714286, precision: 0.8625, f_beta: 0.8632478632478633\n",
      "train: step: 2558, loss: 0.1872158646583557, acc: 0.96875, recall: 0.8035714285714286, precision: 0.7604166666666666, f_beta: 0.7743589743589745\n",
      "train: step: 2559, loss: 0.007984512485563755, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2560, loss: 0.06252558529376984, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666667\n",
      "train: step: 2561, loss: 0.052609995007514954, acc: 0.984375, recall: 0.6666666666666667, precision: 0.6666666666666666, f_beta: 0.6625000000000001\n",
      "train: step: 2562, loss: 0.10127778351306915, acc: 0.984375, recall: 0.859375, precision: 0.8671875, f_beta: 0.861904761904762\n",
      "train: step: 2563, loss: 0.0025194634217768908, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2564, loss: 0.027758607640862465, acc: 0.984375, recall: 0.84375, precision: 0.84375, f_beta: 0.8333333333333333\n",
      "train: step: 2565, loss: 0.0346904993057251, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8076923076923077, f_beta: 0.8043181818181819\n",
      "train: step: 2566, loss: 0.012022187933325768, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2567, loss: 0.036836184561252594, acc: 0.984375, recall: 0.8020833333333334, precision: 0.80625, f_beta: 0.8035287081339714\n",
      "train: step: 2568, loss: 0.021225646138191223, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2569, loss: 0.004532855935394764, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2570, loss: 0.015232665464282036, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2571, loss: 0.006065630353987217, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2572, loss: 0.007682648487389088, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2573, loss: 0.048700738698244095, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666666, f_beta: 0.8\n",
      "train: step: 2574, loss: 0.003076275810599327, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2575, loss: 0.02464677020907402, acc: 0.984375, recall: 0.7291666666666667, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 2576, loss: 0.01607581600546837, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2577, loss: 0.004095130600035191, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2578, loss: 0.04301575943827629, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 2579, loss: 0.017469260841608047, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2580, loss: 0.003786284476518631, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2581, loss: 0.006034873891621828, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2582, loss: 0.0018736945930868387, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2583, loss: 0.011165746487677097, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2584, loss: 0.04693273454904556, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2585, loss: 0.011962479911744595, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2586, loss: 0.011286422610282898, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2587, loss: 0.005679385736584663, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2588, loss: 0.006232158280909061, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2589, loss: 0.009876538999378681, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2590, loss: 0.008048007264733315, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2591, loss: 0.004123319406062365, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2592, loss: 0.010668943636119366, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2593, loss: 0.018355069682002068, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2594, loss: 0.08018870651721954, acc: 0.96875, recall: 0.703125, precision: 0.703125, f_beta: 0.6904761904761905\n",
      "train: step: 2595, loss: 0.0019267193274572492, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2596, loss: 0.018068140372633934, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2597, loss: 0.00935582909733057, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2598, loss: 0.113935187458992, acc: 0.96875, recall: 0.5368589743589743, precision: 0.5555555555555556, f_beta: 0.5438235294117647\n",
      "train: step: 2599, loss: 0.11399484425783157, acc: 0.96875, recall: 0.8541666666666666, precision: 0.85, f_beta: 0.846875\n",
      "train: step: 2600, loss: 0.07519160956144333, acc: 0.984375, recall: 0.8, precision: 0.7916666666666666, f_beta: 0.7930555555555556\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:15:01.027766, step: 2600, loss: 7.760875225067139, acc: 0.1423611111111111,precision: 0.06559286116980906, recall: 0.09254073472823472, f_beta: 0.07103632732049335\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2600\n",
      "\n",
      "train: step: 2601, loss: 0.0195010919123888, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2602, loss: 0.006111728027462959, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2603, loss: 0.00793618056923151, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2604, loss: 0.008126100525259972, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 2605, loss: 0.01611948572099209, acc: 0.984375, recall: 0.8020833333333334, precision: 0.796875, f_beta: 0.7978896103896104\n",
      "train: step: 2606, loss: 0.08153751492500305, acc: 0.984375, recall: 0.734375, precision: 0.71875, f_beta: 0.7202380952380952\n",
      "train: step: 2607, loss: 0.009132062084972858, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2608, loss: 0.03538922220468521, acc: 0.984375, recall: 0.7421875, precision: 0.7410714285714286, f_beta: 0.7410256410256411\n",
      "train: step: 2609, loss: 0.016747253015637398, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2610, loss: 0.019349582493305206, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2611, loss: 0.008756142109632492, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2612, loss: 0.08109775185585022, acc: 0.96875, recall: 0.6458333333333334, precision: 0.65625, f_beta: 0.6416666666666667\n",
      "train: step: 2613, loss: 0.010044366121292114, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2614, loss: 0.022108403965830803, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2615, loss: 0.00860205665230751, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2616, loss: 0.006363764870911837, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2617, loss: 0.0034698087256401777, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2618, loss: 0.006462035235017538, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2619, loss: 0.007009530905634165, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2620, loss: 0.06468899548053741, acc: 0.96875, recall: 0.7604166666666667, precision: 0.8076923076923077, f_beta: 0.7766666666666666\n",
      "train: step: 2621, loss: 0.10380242019891739, acc: 0.984375, recall: 0.8645833333333334, precision: 0.8697916666666666, f_beta: 0.866600790513834\n",
      "train: step: 2622, loss: 0.013505701906979084, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2623, loss: 0.1981600821018219, acc: 0.96875, recall: 0.725, precision: 0.71875, f_beta: 0.7135416666666667\n",
      "train: step: 2624, loss: 0.014812169596552849, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2625, loss: 0.018792446702718735, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2626, loss: 0.00867116916924715, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2627, loss: 0.01554700918495655, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2628, loss: 0.0024702316150069237, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2629, loss: 0.003521325998008251, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2630, loss: 0.10364962369203568, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "train: step: 2631, loss: 0.07178337872028351, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 2632, loss: 0.007086216937750578, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2633, loss: 0.05336800217628479, acc: 0.984375, recall: 0.8068181818181818, precision: 0.8076923076923077, f_beta: 0.8070238095238096\n",
      "train: step: 2634, loss: 0.00665881484746933, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2635, loss: 0.060462191700935364, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666667, f_beta: 0.7791666666666667\n",
      "train: step: 2636, loss: 0.006454515736550093, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2637, loss: 0.020374542102217674, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2638, loss: 0.020721767097711563, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2639, loss: 0.007401438429951668, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2640, loss: 0.023977695032954216, acc: 0.984375, recall: 0.6145833333333334, precision: 0.6208333333333333, f_beta: 0.6171630094043887\n",
      "train: step: 2641, loss: 0.006146661471575499, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2642, loss: 0.006720525212585926, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2643, loss: 0.010373919270932674, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2644, loss: 0.007326195947825909, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2645, loss: 0.005546035245060921, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2646, loss: 0.12074369937181473, acc: 0.984375, recall: 0.8090277777777778, precision: 0.8072916666666666, f_beta: 0.8079968944099379\n",
      "train: step: 2647, loss: 0.0033123274333775043, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2648, loss: 0.04454760625958443, acc: 0.984375, recall: 0.7410714285714286, precision: 0.74375, f_beta: 0.7419028340080972\n",
      "train: step: 2649, loss: 0.008453336544334888, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2650, loss: 0.00923691876232624, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2651, loss: 0.005473147612065077, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2652, loss: 0.027139680460095406, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 2653, loss: 0.014590786769986153, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2654, loss: 0.009872201830148697, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2655, loss: 0.024292930960655212, acc: 0.984375, recall: 0.625, precision: 0.6041666666666666, f_beta: 0.6125\n",
      "train: step: 2656, loss: 0.003584695979952812, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2657, loss: 0.0025388123467564583, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2658, loss: 0.006325392052531242, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2659, loss: 0.024159757420420647, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2660, loss: 0.007169582415372133, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2661, loss: 0.01773061417043209, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2662, loss: 0.034886907786130905, acc: 0.984375, recall: 0.6785714285714286, precision: 0.6805555555555556, f_beta: 0.6790158371040724\n",
      "train: step: 2663, loss: 0.016202954575419426, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2664, loss: 0.029336683452129364, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 2665, loss: 0.005665511824190617, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2666, loss: 0.013847608119249344, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2667, loss: 0.020280029624700546, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2668, loss: 0.006178268697112799, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2669, loss: 0.010024134069681168, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2670, loss: 0.11307607591152191, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 2671, loss: 0.005345968529582024, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2672, loss: 0.029718250036239624, acc: 0.984375, recall: 0.59375, precision: 0.6160714285714286, f_beta: 0.5993589743589743\n",
      "train: step: 2673, loss: 0.04973272234201431, acc: 0.984375, recall: 0.7447916666666666, precision: 0.734375, f_beta: 0.7383540372670807\n",
      "train: step: 2674, loss: 0.012519503943622112, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2675, loss: 0.02067948877811432, acc: 0.984375, recall: 0.8660714285714286, precision: 0.859375, f_beta: 0.8612637362637363\n",
      "train: step: 2676, loss: 0.0036531765945255756, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2677, loss: 0.01581098884344101, acc: 0.984375, recall: 0.6193181818181819, precision: 0.6160714285714286, f_beta: 0.6172161172161172\n",
      "train: step: 2678, loss: 0.022759199142456055, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2679, loss: 0.06684494763612747, acc: 0.984375, recall: 0.8068181818181818, precision: 0.80625, f_beta: 0.806234335839599\n",
      "train: step: 2680, loss: 0.017760613933205605, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2681, loss: 0.138742595911026, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 2682, loss: 0.11081432551145554, acc: 0.984375, recall: 0.6875, precision: 0.6818181818181819, f_beta: 0.6845238095238095\n",
      "train: step: 2683, loss: 0.0253242626786232, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2684, loss: 0.008015946485102177, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2685, loss: 0.03489227592945099, acc: 0.984375, recall: 0.75, precision: 0.74375, f_beta: 0.7467105263157895\n",
      "train: step: 2686, loss: 0.10136999934911728, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 2687, loss: 0.00899609923362732, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2688, loss: 0.04315164312720299, acc: 0.984375, recall: 0.75, precision: 0.7443181818181819, f_beta: 0.7470238095238095\n",
      "start training model\n",
      "train: step: 2689, loss: 0.006527985446155071, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2690, loss: 0.0032786079682409763, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2691, loss: 0.033311985433101654, acc: 0.984375, recall: 0.6822916666666666, precision: 0.6818181818181819, f_beta: 0.6818064182194616\n",
      "train: step: 2692, loss: 0.03770825266838074, acc: 0.984375, recall: 0.8098958333333334, precision: 0.7916666666666666, f_beta: 0.7986702127659575\n",
      "train: step: 2693, loss: 0.016753356903791428, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2694, loss: 0.1425475776195526, acc: 0.96875, recall: 0.6458333333333333, precision: 0.671875, f_beta: 0.6473214285714286\n",
      "train: step: 2695, loss: 0.004034786485135555, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2696, loss: 0.004133396781980991, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2697, loss: 0.024200037121772766, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2698, loss: 0.010065536946058273, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2699, loss: 0.0031048182863742113, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2700, loss: 0.08086912333965302, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6785714285714286, f_beta: 0.6770104895104896\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:16:53.706928, step: 2700, loss: 7.287367502848308, acc: 0.15625,precision: 0.07264234381268696, recall: 0.089024671316338, f_beta: 0.07071257883176346\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2700\n",
      "\n",
      "train: step: 2701, loss: 0.009735561907291412, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2702, loss: 0.022278957068920135, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6796875, f_beta: 0.6776515151515151\n",
      "train: step: 2703, loss: 0.011019951663911343, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2704, loss: 0.06431514769792557, acc: 0.984375, recall: 0.6796875, precision: 0.6875, f_beta: 0.6833333333333333\n",
      "train: step: 2705, loss: 0.022545253857970238, acc: 0.984375, recall: 0.8701923076923077, precision: 0.8660714285714286, f_beta: 0.8676923076923078\n",
      "train: step: 2706, loss: 0.011465809307992458, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2707, loss: 0.049919161945581436, acc: 0.96875, recall: 0.7361111111111112, precision: 0.7254464285714286, f_beta: 0.7284512362637363\n",
      "train: step: 2708, loss: 0.010264800861477852, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2709, loss: 0.01231356430798769, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2710, loss: 0.054491348564624786, acc: 0.984375, recall: 0.7421875, precision: 0.7395833333333334, f_beta: 0.7401515151515152\n",
      "train: step: 2711, loss: 0.006878027692437172, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2712, loss: 0.008060195483267307, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2713, loss: 0.009155090898275375, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2714, loss: 0.050107624381780624, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2715, loss: 0.0035229541826993227, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2716, loss: 0.00812259130179882, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2717, loss: 0.006300443783402443, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2718, loss: 0.006913541816174984, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2719, loss: 0.11965630203485489, acc: 0.984375, recall: 0.859375, precision: 0.8541666666666666, f_beta: 0.8535714285714285\n",
      "train: step: 2720, loss: 0.002163502387702465, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2721, loss: 0.07106299698352814, acc: 0.984375, recall: 0.75, precision: 0.7447916666666666, f_beta: 0.7472826086956522\n",
      "train: step: 2722, loss: 0.1660679429769516, acc: 0.953125, recall: 0.640625, precision: 0.6661706349206349, f_beta: 0.6455357142857143\n",
      "train: step: 2723, loss: 0.01010989397764206, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2724, loss: 0.008244473487138748, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2725, loss: 0.018133632838726044, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2726, loss: 0.002798034343868494, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2727, loss: 0.01953461766242981, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2728, loss: 0.004401282873004675, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2729, loss: 0.0162391047924757, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2730, loss: 0.08283917605876923, acc: 0.96875, recall: 0.6625, precision: 0.65625, f_beta: 0.6510416666666667\n",
      "train: step: 2731, loss: 0.00902345310896635, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2732, loss: 0.028459399938583374, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2733, loss: 0.05213379114866257, acc: 0.984375, recall: 0.625, precision: 0.6041666666666666, f_beta: 0.6125\n",
      "train: step: 2734, loss: 0.008799932897090912, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2735, loss: 0.02720286138355732, acc: 0.984375, recall: 0.925, precision: 0.90625, f_beta: 0.9097222222222222\n",
      "train: step: 2736, loss: 0.014005068689584732, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2737, loss: 0.014676199294626713, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2738, loss: 0.09599900245666504, acc: 0.96875, recall: 0.7421875, precision: 0.6875, f_beta: 0.7041666666666667\n",
      "train: step: 2739, loss: 0.013894867151975632, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2740, loss: 0.01447947509586811, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2741, loss: 0.03804455325007439, acc: 0.984375, recall: 0.859375, precision: 0.859375, f_beta: 0.8571428571428572\n",
      "train: step: 2742, loss: 0.009046804159879684, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2743, loss: 0.0071512130089104176, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2744, loss: 0.0026041539385914803, acc: 1.0, recall: 0.4375, precision: 0.4375, f_beta: 0.4375\n",
      "train: step: 2745, loss: 0.008853290230035782, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2746, loss: 0.007118349429219961, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2747, loss: 0.05098116025328636, acc: 0.984375, recall: 0.859375, precision: 0.8625, f_beta: 0.8591269841269842\n",
      "train: step: 2748, loss: 0.003126424504444003, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2749, loss: 0.005760060623288155, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2750, loss: 0.06905806809663773, acc: 0.984375, recall: 0.6875, precision: 0.68125, f_beta: 0.6842105263157895\n",
      "train: step: 2751, loss: 0.023296527564525604, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2752, loss: 0.0266571044921875, acc: 0.984375, recall: 0.8, precision: 0.8020833333333334, f_beta: 0.7998737373737373\n",
      "train: step: 2753, loss: 0.045953765511512756, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6666666666666666, f_beta: 0.6625000000000001\n",
      "train: step: 2754, loss: 0.01005362905561924, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2755, loss: 0.0023621791042387486, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2756, loss: 0.009999644011259079, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2757, loss: 0.002635058481246233, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2758, loss: 0.04479549452662468, acc: 0.984375, recall: 0.6125, precision: 0.59375, f_beta: 0.5972222222222222\n",
      "train: step: 2759, loss: 0.010956893675029278, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2760, loss: 0.04142395779490471, acc: 0.984375, recall: 0.8645833333333334, precision: 0.875, f_beta: 0.8693181818181819\n",
      "train: step: 2761, loss: 0.007149931974709034, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2762, loss: 0.03947300463914871, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2763, loss: 0.0012773445341736078, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2764, loss: 0.046049099415540695, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666667, f_beta: 0.7791666666666666\n",
      "train: step: 2765, loss: 0.0016459625912830234, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2766, loss: 0.0031662145629525185, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2767, loss: 0.03029605560004711, acc: 0.984375, recall: 0.71875, precision: 0.7430555555555556, f_beta: 0.7254901960784315\n",
      "train: step: 2768, loss: 0.0288766548037529, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 2769, loss: 0.01396973431110382, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2770, loss: 0.004025369416922331, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2771, loss: 0.0030510909855365753, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2772, loss: 0.032240115106105804, acc: 0.984375, recall: 0.7451923076923077, precision: 0.7395833333333334, f_beta: 0.7418181818181818\n",
      "start training model\n",
      "train: step: 2773, loss: 0.001635153777897358, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2774, loss: 0.0041725048795342445, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2775, loss: 0.039983946830034256, acc: 0.984375, recall: 0.8090277777777778, precision: 0.78125, f_beta: 0.7898809523809524\n",
      "train: step: 2776, loss: 0.0024828114546835423, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2777, loss: 0.0023520567920058966, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2778, loss: 0.03287985548377037, acc: 0.984375, recall: 0.8671875, precision: 0.8697916666666666, f_beta: 0.8681159420289856\n",
      "train: step: 2779, loss: 0.003192189149558544, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2780, loss: 0.12183645367622375, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 2781, loss: 0.011472668498754501, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2782, loss: 0.007256424054503441, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2783, loss: 0.015354511328041553, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2784, loss: 0.041566021740436554, acc: 0.984375, recall: 0.65625, precision: 0.6796875, f_beta: 0.6625\n",
      "train: step: 2785, loss: 0.004776894114911556, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2786, loss: 0.006104312837123871, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2787, loss: 0.0029775022994726896, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2788, loss: 0.013605589047074318, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2789, loss: 0.005819189827889204, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2790, loss: 0.014756240881979465, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2791, loss: 0.020294293761253357, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6785714285714286, f_beta: 0.6770104895104896\n",
      "train: step: 2792, loss: 0.004175687208771706, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2793, loss: 0.02435862272977829, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8125, f_beta: 0.8068181818181819\n",
      "train: step: 2794, loss: 0.025592373684048653, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2795, loss: 0.14567843079566956, acc: 0.96875, recall: 0.7723214285714286, precision: 0.8080357142857143, f_beta: 0.7845441595441596\n",
      "train: step: 2796, loss: 0.1653725802898407, acc: 0.96875, recall: 0.74375, precision: 0.7338235294117647, f_beta: 0.7378721424774056\n",
      "train: step: 2797, loss: 0.006118583492934704, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2798, loss: 0.04148167744278908, acc: 0.984375, recall: 0.8020833333333334, precision: 0.7916666666666667, f_beta: 0.7943181818181818\n",
      "train: step: 2799, loss: 0.051631052047014236, acc: 0.96875, recall: 0.8333333333333334, precision: 0.828125, f_beta: 0.8291396103896104\n",
      "train: step: 2800, loss: 0.002560130786150694, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:18:45.472708, step: 2800, loss: 7.809181372324626, acc: 0.15625,precision: 0.07984685673588537, recall: 0.09298546746463414, f_beta: 0.07971671169732025\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2800\n",
      "\n",
      "train: step: 2801, loss: 0.04443511739373207, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2802, loss: 0.014524407684803009, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2803, loss: 0.02473468706011772, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2804, loss: 0.0034419947769492865, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2805, loss: 0.018878072500228882, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2806, loss: 0.00244769174605608, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2807, loss: 0.012701194733381271, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2808, loss: 0.06344874948263168, acc: 0.984375, recall: 0.796875, precision: 0.7916666666666666, f_beta: 0.7910714285714285\n",
      "train: step: 2809, loss: 0.02160155028104782, acc: 0.984375, recall: 0.7465277777777778, precision: 0.7291666666666666, f_beta: 0.7357142857142857\n",
      "train: step: 2810, loss: 0.003540975274518132, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2811, loss: 0.03173467144370079, acc: 0.984375, recall: 0.8083333333333333, precision: 0.80625, f_beta: 0.8070553539019963\n",
      "train: step: 2812, loss: 0.09793125092983246, acc: 0.984375, recall: 0.625, precision: 0.6041666666666666, f_beta: 0.6125\n",
      "train: step: 2813, loss: 0.007598321884870529, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2814, loss: 0.006939258426427841, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2815, loss: 0.005258032586425543, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2816, loss: 0.004638264421373606, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2817, loss: 0.005433531478047371, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2818, loss: 0.004941243678331375, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2819, loss: 0.0615646131336689, acc: 0.984375, recall: 0.625, precision: 0.6041666666666667, f_beta: 0.6125\n",
      "train: step: 2820, loss: 0.006454057525843382, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2821, loss: 0.007755002938210964, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2822, loss: 0.004747414030134678, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2823, loss: 0.012943359091877937, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2824, loss: 0.05911475419998169, acc: 0.96875, recall: 0.7291666666666667, precision: 0.703125, f_beta: 0.7077380952380952\n",
      "train: step: 2825, loss: 0.028781257569789886, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2826, loss: 0.014237248338758945, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2827, loss: 0.007060446310788393, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2828, loss: 0.0029114577919244766, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2829, loss: 0.027246898040175438, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2830, loss: 0.003367223311215639, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2831, loss: 0.015904918313026428, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7451923076923077, f_beta: 0.7418181818181818\n",
      "train: step: 2832, loss: 0.01820504292845726, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2833, loss: 0.013487482443451881, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2834, loss: 0.04821845889091492, acc: 0.984375, recall: 0.7430555555555556, precision: 0.7455357142857143, f_beta: 0.7440087145969498\n",
      "train: step: 2835, loss: 0.04077192768454552, acc: 0.96875, recall: 0.7604166666666667, precision: 0.796875, f_beta: 0.7707674571805007\n",
      "train: step: 2836, loss: 0.012694410979747772, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2837, loss: 0.025936748832464218, acc: 0.984375, recall: 0.80625, precision: 0.78125, f_beta: 0.7883771929824561\n",
      "train: step: 2838, loss: 0.01181462500244379, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2839, loss: 0.0032453902531415224, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2840, loss: 0.004558597691357136, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2841, loss: 0.02282429113984108, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2842, loss: 0.012474020943045616, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2843, loss: 0.08832211792469025, acc: 0.96875, recall: 0.8029605263157895, precision: 0.76875, f_beta: 0.7797435593488226\n",
      "train: step: 2844, loss: 0.025267040356993675, acc: 0.984375, recall: 0.6160714285714286, precision: 0.625, f_beta: 0.6201923076923077\n",
      "train: step: 2845, loss: 0.0016474624862894416, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2846, loss: 0.0027288354467600584, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2847, loss: 0.01492183655500412, acc: 0.984375, recall: 0.61875, precision: 0.6193181818181819, f_beta: 0.618734335839599\n",
      "train: step: 2848, loss: 0.0007589671295136213, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2849, loss: 0.006799308583140373, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2850, loss: 0.020574649795889854, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2851, loss: 0.0031949037220329046, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2852, loss: 0.012454885989427567, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2853, loss: 0.01563015766441822, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2854, loss: 0.009624665603041649, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2855, loss: 0.014769854955375195, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 2856, loss: 0.03327216953039169, acc: 0.984375, recall: 0.8541666666666666, precision: 0.86875, f_beta: 0.8592105263157895\n",
      "start training model\n",
      "train: step: 2857, loss: 0.02556038275361061, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2858, loss: 0.007442132569849491, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2859, loss: 0.013389374129474163, acc: 0.984375, recall: 0.8035714285714286, precision: 0.78125, f_beta: 0.7868589743589743\n",
      "train: step: 2860, loss: 0.004282745532691479, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2861, loss: 0.014520673081278801, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2862, loss: 0.0033846255391836166, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2863, loss: 0.005836194846779108, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2864, loss: 0.0056727733463048935, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2865, loss: 0.02042471058666706, acc: 0.984375, recall: 0.734375, precision: 0.71875, f_beta: 0.7202380952380951\n",
      "train: step: 2866, loss: 0.06080425903201103, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2867, loss: 0.07648107409477234, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666667, f_beta: 0.8\n",
      "train: step: 2868, loss: 0.002854966791346669, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2869, loss: 0.0019959432538598776, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2870, loss: 0.004832162521779537, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2871, loss: 0.13138839602470398, acc: 0.96875, recall: 0.65625, precision: 0.675, f_beta: 0.6623737373737374\n",
      "train: step: 2872, loss: 0.006518542300909758, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2873, loss: 0.0036808110307902098, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2874, loss: 0.0013540999498218298, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2875, loss: 0.031944796442985535, acc: 0.96875, recall: 0.6785714285714286, precision: 0.6716269841269842, f_beta: 0.6742081447963801\n",
      "train: step: 2876, loss: 0.0020724614150822163, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2877, loss: 0.007054823916405439, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2878, loss: 0.002952692098915577, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2879, loss: 0.0034315783996134996, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2880, loss: 0.015876423567533493, acc: 0.984375, recall: 0.4930555555555556, precision: 0.49107142857142855, f_beta: 0.49151583710407243\n",
      "train: step: 2881, loss: 0.0011858256766572595, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2882, loss: 0.0012284694239497185, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2883, loss: 0.043754853308200836, acc: 0.984375, recall: 0.78125, precision: 0.796875, f_beta: 0.7827380952380952\n",
      "train: step: 2884, loss: 0.004023940768092871, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2885, loss: 0.0030194909777492285, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2886, loss: 0.06090087816119194, acc: 0.984375, recall: 0.75, precision: 0.7447916666666666, f_beta: 0.7472826086956521\n",
      "train: step: 2887, loss: 0.00463784858584404, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2888, loss: 0.04701383039355278, acc: 0.984375, recall: 0.65625, precision: 0.6770833333333334, f_beta: 0.6609848484848485\n",
      "train: step: 2889, loss: 0.04344600811600685, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 2890, loss: 0.01348155178129673, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2891, loss: 0.012985450215637684, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2892, loss: 0.009737038984894753, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2893, loss: 0.19020040333271027, acc: 0.96875, recall: 0.8392857142857143, precision: 0.83125, f_beta: 0.8240740740740741\n",
      "train: step: 2894, loss: 0.04301942512392998, acc: 0.984375, recall: 0.80625, precision: 0.7916666666666667, f_beta: 0.7967105263157894\n",
      "train: step: 2895, loss: 0.04908302426338196, acc: 0.96875, recall: 0.7361111111111112, precision: 0.7083333333333333, f_beta: 0.7109375\n",
      "train: step: 2896, loss: 0.08764824271202087, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 2897, loss: 0.007036215625703335, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2898, loss: 0.007663124240934849, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2899, loss: 0.01541897002607584, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2900, loss: 0.011004205793142319, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:20:38.252043, step: 2900, loss: 7.628222306569417, acc: 0.16145833333333334,precision: 0.08102723813185629, recall: 0.09223863010627716, f_beta: 0.07794893251763371\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-2900\n",
      "\n",
      "train: step: 2901, loss: 0.004626970738172531, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2902, loss: 0.002840298693627119, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2903, loss: 0.04437677934765816, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7430555555555556, f_beta: 0.7338235294117648\n",
      "train: step: 2904, loss: 0.008510444313287735, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2905, loss: 0.008357351645827293, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2906, loss: 0.17761357128620148, acc: 0.96875, recall: 0.8958333333333334, precision: 0.9227430555555556, f_beta: 0.9031417112299465\n",
      "train: step: 2907, loss: 0.0021414398215711117, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2908, loss: 0.0037743858993053436, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2909, loss: 0.035095807164907455, acc: 0.96875, recall: 0.7410714285714286, precision: 0.7118055555555556, f_beta: 0.7206825037707392\n",
      "train: step: 2910, loss: 0.008716696873307228, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2911, loss: 0.0742679089307785, acc: 0.96875, recall: 0.7386363636363636, precision: 0.7125, f_beta: 0.7196271929824561\n",
      "train: step: 2912, loss: 0.0961214005947113, acc: 0.96875, recall: 0.6766098484848485, precision: 0.6577380952380952, f_beta: 0.6644987259117694\n",
      "train: step: 2913, loss: 0.10252533853054047, acc: 0.96875, recall: 0.7993055555555556, precision: 0.7838541666666667, f_beta: 0.7888673890608875\n",
      "train: step: 2914, loss: 0.046767689287662506, acc: 0.984375, recall: 0.71875, precision: 0.7375, f_beta: 0.7222222222222223\n",
      "train: step: 2915, loss: 0.04470893740653992, acc: 0.984375, recall: 0.7916666666666666, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 2916, loss: 0.09971791505813599, acc: 0.96875, recall: 0.68359375, precision: 0.6629464285714286, f_beta: 0.6717476072314782\n",
      "train: step: 2917, loss: 0.04307759553194046, acc: 0.984375, recall: 0.9338235294117647, precision: 0.9270833333333334, f_beta: 0.9299242424242424\n",
      "train: step: 2918, loss: 0.08273512125015259, acc: 0.984375, recall: 0.7421875, precision: 0.71875, f_beta: 0.7250000000000001\n",
      "train: step: 2919, loss: 0.02097591571509838, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2920, loss: 0.08358249813318253, acc: 0.984375, recall: 0.6875, precision: 0.6830357142857143, f_beta: 0.6851851851851851\n",
      "train: step: 2921, loss: 0.009505581110715866, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2922, loss: 0.01711113378405571, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2923, loss: 0.011321291327476501, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2924, loss: 0.03195399045944214, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7410714285714286, f_beta: 0.7326923076923078\n",
      "train: step: 2925, loss: 0.057328835129737854, acc: 0.984375, recall: 0.71875, precision: 0.7451923076923077, f_beta: 0.7266666666666667\n",
      "train: step: 2926, loss: 0.029028698801994324, acc: 0.984375, recall: 0.68125, precision: 0.675, f_beta: 0.6772660818713451\n",
      "train: step: 2927, loss: 0.04606659710407257, acc: 0.984375, recall: 0.8046875, precision: 0.78125, f_beta: 0.7875000000000001\n",
      "train: step: 2928, loss: 0.06410413980484009, acc: 0.984375, recall: 0.7916666666666667, precision: 0.8088235294117647, f_beta: 0.7981060606060606\n",
      "train: step: 2929, loss: 0.05107448622584343, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 2930, loss: 0.004592293407768011, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2931, loss: 0.05711785703897476, acc: 0.96875, recall: 0.7291666666666667, precision: 0.734375, f_beta: 0.7285714285714285\n",
      "train: step: 2932, loss: 0.007873183116316795, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2933, loss: 0.012259695678949356, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2934, loss: 0.008802643045783043, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2935, loss: 0.0371246337890625, acc: 0.984375, recall: 0.7291666666666667, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 2936, loss: 0.014911659061908722, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2937, loss: 0.012502565048635006, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2938, loss: 0.028211548924446106, acc: 0.984375, recall: 0.8125, precision: 0.80859375, f_beta: 0.810483870967742\n",
      "train: step: 2939, loss: 0.009164618328213692, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2940, loss: 0.02132803201675415, acc: 0.984375, recall: 0.59375, precision: 0.625, f_beta: 0.6041666666666667\n",
      "start training model\n",
      "train: step: 2941, loss: 0.021715078502893448, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2942, loss: 0.03506940230727196, acc: 0.984375, recall: 0.8020833333333334, precision: 0.78125, f_beta: 0.7859848484848485\n",
      "train: step: 2943, loss: 0.019084973260760307, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2944, loss: 0.0276343896985054, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 2945, loss: 0.006097296252846718, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2946, loss: 0.0197449941188097, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2947, loss: 0.030980955809354782, acc: 0.96875, recall: 0.7391493055555556, precision: 0.7430555555555556, f_beta: 0.7410394265232976\n",
      "train: step: 2948, loss: 0.006963349413126707, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2949, loss: 0.006459706928580999, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2950, loss: 0.01601204089820385, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2951, loss: 0.035071633756160736, acc: 0.984375, recall: 0.7916666666666667, precision: 0.78125, f_beta: 0.7791666666666666\n",
      "train: step: 2952, loss: 0.005912770051509142, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2953, loss: 0.01905094087123871, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2954, loss: 0.004632726311683655, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2955, loss: 0.03322227671742439, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666667\n",
      "train: step: 2956, loss: 0.020155373960733414, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2957, loss: 0.0024196975864470005, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2958, loss: 0.02894754707813263, acc: 0.984375, recall: 0.6785714285714286, precision: 0.6826923076923077, f_beta: 0.6801923076923078\n",
      "train: step: 2959, loss: 0.00508306547999382, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2960, loss: 0.04098961129784584, acc: 0.984375, recall: 0.8, precision: 0.8020833333333334, f_beta: 0.7998737373737375\n",
      "train: step: 2961, loss: 0.00219591218046844, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2962, loss: 0.10304555296897888, acc: 0.984375, recall: 0.96875, precision: 0.96875, f_beta: 0.9583333333333333\n",
      "train: step: 2963, loss: 0.010134277865290642, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2964, loss: 0.03431475907564163, acc: 0.984375, recall: 0.625, precision: 0.61875, f_beta: 0.6217105263157895\n",
      "train: step: 2965, loss: 0.025419972836971283, acc: 0.984375, recall: 0.65625, precision: 0.6796875, f_beta: 0.6625\n",
      "train: step: 2966, loss: 0.005851465277373791, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2967, loss: 0.05489867553114891, acc: 0.984375, recall: 0.8072916666666666, precision: 0.7916666666666666, f_beta: 0.7972826086956523\n",
      "train: step: 2968, loss: 0.0014442030806094408, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2969, loss: 0.08046510815620422, acc: 0.984375, recall: 0.8055555555555556, precision: 0.8020833333333334, f_beta: 0.8031417112299465\n",
      "train: step: 2970, loss: 0.010997005738317966, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2971, loss: 0.024955933913588524, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 2972, loss: 0.03536222130060196, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8125, f_beta: 0.8068181818181818\n",
      "train: step: 2973, loss: 0.006895141210407019, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2974, loss: 0.02232990972697735, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7395833333333334, f_beta: 0.7395104895104895\n",
      "train: step: 2975, loss: 0.008451639674603939, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2976, loss: 0.023554418236017227, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2977, loss: 0.03269859775900841, acc: 0.984375, recall: 0.93125, precision: 0.90625, f_beta: 0.9133771929824561\n",
      "train: step: 2978, loss: 0.004319072235375643, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 2979, loss: 0.004072131589055061, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2980, loss: 0.08652228116989136, acc: 0.96875, recall: 0.78125, precision: 0.765625, f_beta: 0.7619047619047619\n",
      "train: step: 2981, loss: 0.053275950253009796, acc: 0.96875, recall: 0.6666666666666666, precision: 0.6785714285714286, f_beta: 0.6701923076923078\n",
      "train: step: 2982, loss: 0.07555456459522247, acc: 0.984375, recall: 0.6875, precision: 0.6805555555555556, f_beta: 0.6838235294117647\n",
      "train: step: 2983, loss: 0.039891064167022705, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 2984, loss: 0.039292074739933014, acc: 0.984375, recall: 0.6785714285714286, precision: 0.65625, f_beta: 0.6618589743589743\n",
      "train: step: 2985, loss: 0.015184509567916393, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2986, loss: 0.010808552615344524, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2987, loss: 0.007728778291493654, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2988, loss: 0.03423032537102699, acc: 0.984375, recall: 0.609375, precision: 0.625, f_beta: 0.6160714285714286\n",
      "train: step: 2989, loss: 0.031077321618795395, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666667\n",
      "train: step: 2990, loss: 0.012823192402720451, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2991, loss: 0.008172936737537384, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2992, loss: 0.0032231512013822794, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2993, loss: 0.006290719378739595, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2994, loss: 0.013114886358380318, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 2995, loss: 0.06549082696437836, acc: 0.984375, recall: 0.609375, precision: 0.6145833333333333, f_beta: 0.6103896103896105\n",
      "train: step: 2996, loss: 0.015504525043070316, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 2997, loss: 0.013529731892049313, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 2998, loss: 0.065242700278759, acc: 0.984375, recall: 0.7291666666666667, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 2999, loss: 0.022229235619306564, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3000, loss: 0.027212003245949745, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:22:30.388290, step: 3000, loss: 7.565095848507351, acc: 0.16666666666666666,precision: 0.07266380241418942, recall: 0.09697885119147373, f_beta: 0.07672573799029718\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3000\n",
      "\n",
      "train: step: 3001, loss: 0.04177122190594673, acc: 0.984375, recall: 0.734375, precision: 0.71875, f_beta: 0.7202380952380952\n",
      "train: step: 3002, loss: 0.012132687494158745, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3003, loss: 0.0033517174888402224, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3004, loss: 0.005997750908136368, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3005, loss: 0.018128450959920883, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3006, loss: 0.007077089045196772, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3007, loss: 0.004449507221579552, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3008, loss: 0.0062330616638064384, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3009, loss: 0.027082771062850952, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3010, loss: 0.004262447357177734, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3011, loss: 0.07726289331912994, acc: 0.984375, recall: 0.625, precision: 0.6125, f_beta: 0.6180555555555556\n",
      "train: step: 3012, loss: 0.0061350418254733086, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3013, loss: 0.0035332299303263426, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3014, loss: 0.015285671688616276, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3015, loss: 0.038148149847984314, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666667\n",
      "train: step: 3016, loss: 0.07867783308029175, acc: 0.96875, recall: 0.675, precision: 0.6770833333333334, f_beta: 0.6748737373737373\n",
      "train: step: 3017, loss: 0.00480770505964756, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3018, loss: 0.0023970899637788534, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3019, loss: 0.007586818188428879, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3020, loss: 0.005160645581781864, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3021, loss: 0.002874447498470545, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3022, loss: 0.005996714811772108, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3023, loss: 0.0050040725618600845, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3024, loss: 0.01646297238767147, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 3025, loss: 0.0054195839911699295, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3026, loss: 0.022769592702388763, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666667, f_beta: 0.675\n",
      "train: step: 3027, loss: 0.0014166785404086113, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3028, loss: 0.017346102744340897, acc: 0.984375, recall: 0.6193181818181819, precision: 0.6197916666666667, f_beta: 0.6193064182194616\n",
      "train: step: 3029, loss: 0.0016349740326404572, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3030, loss: 0.017617331817746162, acc: 0.984375, recall: 0.6666666666666667, precision: 0.65625, f_beta: 0.6541666666666667\n",
      "train: step: 3031, loss: 0.05987901613116264, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 3032, loss: 0.008916486985981464, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3033, loss: 0.006500774063169956, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3034, loss: 0.004280897788703442, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3035, loss: 0.002136798109859228, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3036, loss: 0.0024198628962039948, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3037, loss: 0.05439227819442749, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 3038, loss: 0.03588247299194336, acc: 0.984375, recall: 0.7447916666666666, precision: 0.74609375, f_beta: 0.7452664796633941\n",
      "train: step: 3039, loss: 0.01159337256103754, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3040, loss: 0.005620506592094898, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3041, loss: 0.0021206485107541084, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3042, loss: 0.09707029163837433, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 3043, loss: 0.0032000504434108734, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3044, loss: 0.004921208135783672, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3045, loss: 0.016414515674114227, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3046, loss: 0.012322694063186646, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3047, loss: 0.006431653164327145, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3048, loss: 0.00202641892246902, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3049, loss: 0.017992733046412468, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3050, loss: 0.016960494220256805, acc: 1.0, recall: 1.0, precision: 1.0, f_beta: 1.0\n",
      "train: step: 3051, loss: 0.014627494849264622, acc: 0.984375, recall: 0.8046875, precision: 0.8068181818181819, f_beta: 0.8053571428571429\n",
      "train: step: 3052, loss: 0.005141482222825289, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3053, loss: 0.011400539427995682, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3054, loss: 0.033020809292793274, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7291666666666667, f_beta: 0.725\n",
      "train: step: 3055, loss: 0.0034050587564706802, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3056, loss: 0.007970493286848068, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3057, loss: 0.00910660345107317, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3058, loss: 0.004021402448415756, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3059, loss: 0.009695122018456459, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3060, loss: 0.0020793264266103506, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3061, loss: 0.057647496461868286, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 3062, loss: 0.02764262817800045, acc: 0.984375, recall: 0.7291666666666667, precision: 0.71875, f_beta: 0.7166666666666667\n",
      "train: step: 3063, loss: 0.0038591891061514616, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3064, loss: 0.012185857631266117, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3065, loss: 0.032587967813014984, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 3066, loss: 0.03240404278039932, acc: 0.984375, recall: 0.80625, precision: 0.8125, f_beta: 0.8092105263157895\n",
      "train: step: 3067, loss: 0.005498094484210014, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3068, loss: 0.004542679525911808, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3069, loss: 0.0026979423128068447, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3070, loss: 0.003118992317467928, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3071, loss: 0.013501588255167007, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3072, loss: 0.0036279899068176746, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3073, loss: 0.03246661275625229, acc: 0.96875, recall: 0.6875, precision: 0.7139423076923077, f_beta: 0.6954166666666666\n",
      "train: step: 3074, loss: 0.06441818922758102, acc: 0.984375, recall: 0.796875, precision: 0.796875, f_beta: 0.7946428571428572\n",
      "train: step: 3075, loss: 0.006148010957986116, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3076, loss: 0.0019108981359750032, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3077, loss: 0.005058137699961662, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3078, loss: 0.006969667039811611, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3079, loss: 0.011056439019739628, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3080, loss: 0.03950442746281624, acc: 0.984375, recall: 0.7291666666666667, precision: 0.71875, f_beta: 0.7166666666666666\n",
      "train: step: 3081, loss: 0.012202941812574863, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3082, loss: 0.004982964135706425, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3083, loss: 0.061351072043180466, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3084, loss: 0.001656794804148376, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3085, loss: 0.02208709344267845, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3086, loss: 0.03308575227856636, acc: 0.984375, recall: 0.5535714285714286, precision: 0.5555555555555556, f_beta: 0.5540158371040724\n",
      "train: step: 3087, loss: 0.008032472804188728, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3088, loss: 0.01061246357858181, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3089, loss: 0.006985001731663942, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3090, loss: 0.0036877053789794445, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3091, loss: 0.004076298326253891, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3092, loss: 0.11837252974510193, acc: 0.984375, recall: 0.6833333333333333, precision: 0.6830357142857143, f_beta: 0.6830300127713921\n",
      "train: step: 3093, loss: 0.04413878917694092, acc: 0.984375, recall: 0.6822916666666667, precision: 0.68125, f_beta: 0.6814931350114417\n",
      "train: step: 3094, loss: 0.00961587205529213, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3095, loss: 0.016261344775557518, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3096, loss: 0.003174322657287121, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3097, loss: 0.006870412267744541, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3098, loss: 0.009970409795641899, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3099, loss: 0.08919018507003784, acc: 0.984375, recall: 0.8625, precision: 0.8660714285714286, f_beta: 0.8632478632478633\n",
      "train: step: 3100, loss: 0.1183168888092041, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:24:22.122603, step: 3100, loss: 7.759406036800808, acc: 0.1545138888888889,precision: 0.08250987053070387, recall: 0.0841767618728403, f_beta: 0.07128857405139542\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3100\n",
      "\n",
      "train: step: 3101, loss: 0.07866781949996948, acc: 0.96875, recall: 0.8671875, precision: 0.8671875, f_beta: 0.8666666666666667\n",
      "train: step: 3102, loss: 0.01737942360341549, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3103, loss: 0.01584503799676895, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3104, loss: 0.022275572642683983, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7375, f_beta: 0.7305555555555556\n",
      "train: step: 3105, loss: 0.044258132576942444, acc: 0.96875, recall: 0.7243589743589743, precision: 0.7222222222222222, f_beta: 0.7188235294117648\n",
      "train: step: 3106, loss: 0.013886033557355404, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3107, loss: 0.0050801499746739864, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3108, loss: 0.00857853889465332, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 3109, loss: 0.0011058519594371319, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3110, loss: 0.0013104657409712672, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3111, loss: 0.004405240993946791, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3112, loss: 0.004355994984507561, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3113, loss: 0.0014304437208920717, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3114, loss: 0.011172473430633545, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3115, loss: 0.0017509934259578586, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3116, loss: 0.06669570505619049, acc: 0.984375, recall: 0.8645833333333334, precision: 0.8541666666666667, f_beta: 0.8568181818181818\n",
      "train: step: 3117, loss: 0.003853520844131708, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3118, loss: 0.0025964220985770226, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3119, loss: 0.003591010347008705, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3120, loss: 0.00471064168959856, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3121, loss: 0.014497635886073112, acc: 0.984375, recall: 0.6041666666666666, precision: 0.6160714285714286, f_beta: 0.6076923076923078\n",
      "train: step: 3122, loss: 0.02215725928544998, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7291666666666666, f_beta: 0.7250000000000001\n",
      "train: step: 3123, loss: 0.01680576801300049, acc: 0.984375, recall: 0.71875, precision: 0.7375, f_beta: 0.7222222222222222\n",
      "train: step: 3124, loss: 0.007757240440696478, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3125, loss: 0.005152229685336351, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3126, loss: 0.008302136324346066, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3127, loss: 0.018753578886389732, acc: 0.984375, recall: 0.7430555555555556, precision: 0.7447916666666667, f_beta: 0.7436061381074168\n",
      "train: step: 3128, loss: 0.08398588746786118, acc: 0.953125, recall: 0.70625, precision: 0.7135416666666666, f_beta: 0.7034451659451659\n",
      "train: step: 3129, loss: 0.0033691274002194405, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3130, loss: 0.02226381003856659, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666666, f_beta: 0.675\n",
      "train: step: 3131, loss: 0.0061586638912558556, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3132, loss: 0.004582379478961229, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3133, loss: 0.0030744527466595173, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3134, loss: 0.005572636611759663, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3135, loss: 0.004440075717866421, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3136, loss: 0.01163474190980196, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3137, loss: 0.005435239523649216, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3138, loss: 0.001955244457349181, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3139, loss: 0.005634804256260395, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3140, loss: 0.0022883161436766386, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3141, loss: 0.012425716035068035, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3142, loss: 0.005666687153279781, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3143, loss: 0.013823929242789745, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3144, loss: 0.016563566401600838, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3145, loss: 0.05675813555717468, acc: 0.984375, recall: 0.7291666666666666, precision: 0.71875, f_beta: 0.7166666666666667\n",
      "train: step: 3146, loss: 0.0013116791378706694, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3147, loss: 0.006591493263840675, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3148, loss: 0.0015797583619132638, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3149, loss: 0.012186681851744652, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3150, loss: 0.002840059343725443, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3151, loss: 0.021292252466082573, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3152, loss: 0.018387509509921074, acc: 0.984375, recall: 0.8068181818181818, precision: 0.8046875, f_beta: 0.8053571428571429\n",
      "train: step: 3153, loss: 0.005957468878477812, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3154, loss: 0.03304330259561539, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848484\n",
      "train: step: 3155, loss: 0.004196318332105875, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3156, loss: 0.03274131566286087, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3157, loss: 0.006617808248847723, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3158, loss: 0.0343465730547905, acc: 0.984375, recall: 0.675, precision: 0.6785714285714286, f_beta: 0.6757478632478633\n",
      "train: step: 3159, loss: 0.04051264375448227, acc: 0.96875, recall: 0.855654761904762, precision: 0.8504464285714286, f_beta: 0.8507742257742258\n",
      "train: step: 3160, loss: 0.03712562844157219, acc: 0.984375, recall: 0.796875, precision: 0.8072916666666666, f_beta: 0.8008540372670808\n",
      "train: step: 3161, loss: 0.016687598079442978, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3162, loss: 0.009155834093689919, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3163, loss: 0.013619862496852875, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3164, loss: 0.002824928145855665, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3165, loss: 0.00213240017183125, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3166, loss: 0.0026177801191806793, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3167, loss: 0.007329167798161507, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3168, loss: 0.009922761470079422, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3169, loss: 0.01818334311246872, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3170, loss: 0.036184366792440414, acc: 0.984375, recall: 0.734375, precision: 0.71875, f_beta: 0.7202380952380952\n",
      "train: step: 3171, loss: 0.020123975351452827, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3172, loss: 0.0044990722090005875, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3173, loss: 0.004121092613786459, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3174, loss: 0.002546298550441861, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3175, loss: 0.030680745840072632, acc: 0.984375, recall: 0.8, precision: 0.7916666666666666, f_beta: 0.7930555555555556\n",
      "train: step: 3176, loss: 0.01102144829928875, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3177, loss: 0.007235652767121792, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3178, loss: 0.003476243931800127, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3179, loss: 0.0064857229590415955, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3180, loss: 0.0073246583342552185, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3181, loss: 0.0011292840354144573, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3182, loss: 0.0018519244622439146, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3183, loss: 0.002496212488040328, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3184, loss: 0.0017263820627704263, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3185, loss: 0.029514852911233902, acc: 0.984375, recall: 0.75, precision: 0.7375, f_beta: 0.7430555555555556\n",
      "train: step: 3186, loss: 0.005323916207998991, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3187, loss: 0.0047454917803406715, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3188, loss: 0.01276711281388998, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3189, loss: 0.019012248143553734, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 3190, loss: 0.0017215660773217678, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3191, loss: 0.003988388925790787, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3192, loss: 0.002611432457342744, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 3193, loss: 0.03251662477850914, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3194, loss: 0.0023605432361364365, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3195, loss: 0.007696837652474642, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3196, loss: 0.0019146951381117105, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3197, loss: 0.0028465515933930874, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3198, loss: 0.007378763984888792, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3199, loss: 0.0020474714692682028, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3200, loss: 0.053865790367126465, acc: 0.984375, recall: 0.7410714285714286, precision: 0.75, f_beta: 0.7451923076923077\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:26:14.150353, step: 3200, loss: 7.823930581410726, acc: 0.16319444444444445,precision: 0.07848119316208196, recall: 0.09940823235860002, f_beta: 0.07829900787589125\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3200\n",
      "\n",
      "train: step: 3201, loss: 0.017817210406064987, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3202, loss: 0.0041509345173835754, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3203, loss: 0.001026662765070796, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3204, loss: 0.009992513805627823, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3205, loss: 0.003115239553153515, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3206, loss: 0.0012397374957799911, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3207, loss: 0.002165147103369236, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3208, loss: 0.0016694400692358613, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3209, loss: 0.00759735656902194, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3210, loss: 0.0026396627072244883, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3211, loss: 0.08063709735870361, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 3212, loss: 0.00292020826600492, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3213, loss: 0.0018736214842647314, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3214, loss: 0.004628460388630629, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3215, loss: 0.017585301771759987, acc: 0.984375, recall: 0.78125, precision: 0.80625, f_beta: 0.7883771929824562\n",
      "train: step: 3216, loss: 0.0027839764952659607, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3217, loss: 0.0047261882573366165, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3218, loss: 0.004687855485826731, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3219, loss: 0.0008551198989152908, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3220, loss: 0.010301443748176098, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3221, loss: 0.002494590589776635, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3222, loss: 0.003340229857712984, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3223, loss: 0.0038809762336313725, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3224, loss: 0.053351227194070816, acc: 0.984375, recall: 0.7410714285714286, precision: 0.71875, f_beta: 0.7243589743589745\n",
      "train: step: 3225, loss: 0.007247963920235634, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3226, loss: 0.016635265201330185, acc: 0.984375, recall: 0.8055555555555556, precision: 0.7916666666666666, f_beta: 0.7963235294117648\n",
      "train: step: 3227, loss: 0.06448633968830109, acc: 0.984375, recall: 0.7451923076923077, precision: 0.7291666666666667, f_beta: 0.7350000000000001\n",
      "train: step: 3228, loss: 0.001865855185315013, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3229, loss: 0.03377576917409897, acc: 0.984375, recall: 0.8, precision: 0.8, f_beta: 0.7986111111111112\n",
      "train: step: 3230, loss: 0.11565173417329788, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8095238095238095, f_beta: 0.7984756097560977\n",
      "train: step: 3231, loss: 0.1064593717455864, acc: 0.984375, recall: 0.675, precision: 0.6796875, f_beta: 0.6763888888888889\n",
      "train: step: 3232, loss: 0.002341373125091195, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3233, loss: 0.005993576720356941, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3234, loss: 0.0036985434126108885, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3235, loss: 0.005074298940598965, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3236, loss: 0.012556690722703934, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3237, loss: 0.0034492341801524162, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3238, loss: 0.025169283151626587, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3239, loss: 0.06596572697162628, acc: 0.96875, recall: 0.76875, precision: 0.765625, f_beta: 0.7549603174603176\n",
      "train: step: 3240, loss: 0.003658727277070284, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3241, loss: 0.004418801516294479, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3242, loss: 0.009032145142555237, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3243, loss: 0.00870220921933651, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3244, loss: 0.01601189747452736, acc: 0.984375, recall: 0.796875, precision: 0.8076923076923077, f_beta: 0.8010714285714287\n",
      "train: step: 3245, loss: 0.0014648078940808773, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3246, loss: 0.005844395607709885, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3247, loss: 0.006514317821711302, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3248, loss: 0.007918927818536758, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3249, loss: 0.047929465770721436, acc: 0.984375, recall: 0.7443181818181819, precision: 0.7291666666666667, f_beta: 0.7345238095238096\n",
      "train: step: 3250, loss: 0.004241421353071928, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3251, loss: 0.0025908565148711205, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3252, loss: 0.007313847076147795, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3253, loss: 0.004662022925913334, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3254, loss: 0.004892564378678799, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3255, loss: 0.018847906962037086, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3256, loss: 0.011374770663678646, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3257, loss: 0.0029472345486283302, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3258, loss: 0.2399117648601532, acc: 0.953125, recall: 0.6597222222222223, precision: 0.6510416666666666, f_beta: 0.6477728047740836\n",
      "train: step: 3259, loss: 0.007012068293988705, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3260, loss: 0.004964010789990425, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3261, loss: 0.02244117483496666, acc: 0.984375, recall: 0.8035714285714286, precision: 0.78125, f_beta: 0.7868589743589743\n",
      "train: step: 3262, loss: 0.00601459015160799, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3263, loss: 0.0023337635211646557, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3264, loss: 0.019083833321928978, acc: 0.984375, recall: 0.7291666666666667, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 3265, loss: 0.013101226650178432, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3266, loss: 0.0018992217956110835, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3267, loss: 0.025200041010975838, acc: 0.984375, recall: 0.74375, precision: 0.7458333333333333, f_beta: 0.7445553539019963\n",
      "train: step: 3268, loss: 0.002677530748769641, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3269, loss: 0.0007484218222089112, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3270, loss: 0.0348065122961998, acc: 0.984375, recall: 0.74609375, precision: 0.7291666666666667, f_beta: 0.7354838709677419\n",
      "train: step: 3271, loss: 0.0019124713726341724, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3272, loss: 0.00461603794246912, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3273, loss: 0.0078033944591879845, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3274, loss: 0.008045953698456287, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3275, loss: 0.021372370421886444, acc: 0.984375, recall: 0.7916666666666667, precision: 0.8068181818181818, f_beta: 0.7970238095238096\n",
      "train: step: 3276, loss: 0.037113770842552185, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7421875, f_beta: 0.7333333333333334\n",
      "start training model\n",
      "train: step: 3277, loss: 0.10078287869691849, acc: 0.984375, recall: 0.734375, precision: 0.7451923076923077, f_beta: 0.7385714285714287\n",
      "train: step: 3278, loss: 0.003208532929420471, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3279, loss: 0.001639618189074099, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3280, loss: 0.005232914350926876, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3281, loss: 0.005827378947287798, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3282, loss: 0.0015518581494688988, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3283, loss: 0.014669004827737808, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3284, loss: 0.0104104308411479, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3285, loss: 0.002104018349200487, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3286, loss: 0.0026118820533156395, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3287, loss: 0.0031495133880525827, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3288, loss: 0.002992709632962942, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3289, loss: 0.0015131745021790266, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3290, loss: 0.012024767696857452, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3291, loss: 0.007966406643390656, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3292, loss: 0.005143376067280769, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3293, loss: 0.09571900963783264, acc: 0.984375, recall: 0.71875, precision: 0.7291666666666667, f_beta: 0.7166666666666667\n",
      "train: step: 3294, loss: 0.0007386093493551016, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3295, loss: 0.00817885622382164, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3296, loss: 0.0026439798530191183, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3297, loss: 0.0036974193062633276, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3298, loss: 0.0019463743083178997, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3299, loss: 0.0015015117824077606, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3300, loss: 0.002609614748507738, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:28:06.567809, step: 3300, loss: 8.061954922146267, acc: 0.16319444444444445,precision: 0.07783484229240163, recall: 0.09611529481321147, f_beta: 0.07713455060219478\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3300\n",
      "\n",
      "train: step: 3301, loss: 0.0012948040384799242, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3302, loss: 0.0014843204990029335, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3303, loss: 0.002158678835257888, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3304, loss: 0.0063193244859576225, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3305, loss: 0.001492033596150577, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3306, loss: 0.004023069050163031, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3307, loss: 0.001592237502336502, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3308, loss: 0.013061724603176117, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3309, loss: 0.003808614332228899, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3310, loss: 0.0021499295253306627, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3311, loss: 0.0018048956990242004, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3312, loss: 0.0009531425894238055, acc: 1.0, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 3313, loss: 0.0030403463169932365, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3314, loss: 0.00160555774345994, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3315, loss: 0.00725907739251852, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3316, loss: 0.002054080367088318, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3317, loss: 0.010552058927714825, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3318, loss: 0.002374454168602824, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3319, loss: 0.000998951611109078, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3320, loss: 0.0018594684079289436, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3321, loss: 0.0022080205380916595, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3322, loss: 0.006261416710913181, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3323, loss: 0.0008021723479032516, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3324, loss: 0.010337235406041145, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3325, loss: 0.0025014947168529034, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3326, loss: 0.0015688501298427582, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3327, loss: 0.0008446433930657804, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3328, loss: 0.0009072984685190022, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3329, loss: 0.0042346809059381485, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3330, loss: 0.002325762063264847, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3331, loss: 0.0010827197693288326, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3332, loss: 0.0007490003481507301, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3333, loss: 0.004008586518466473, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3334, loss: 0.0012369952164590359, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3335, loss: 0.002045415574684739, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3336, loss: 0.0030452033970505, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3337, loss: 0.0007230594055727124, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3338, loss: 0.0018641471397131681, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3339, loss: 0.004297517240047455, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3340, loss: 0.011338964104652405, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3341, loss: 0.001062316820025444, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3342, loss: 0.001298680086620152, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3343, loss: 0.002100201090797782, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3344, loss: 0.0013902198988944292, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3345, loss: 0.0013651151675730944, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3346, loss: 0.0017980907578021288, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3347, loss: 0.0015936759300529957, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3348, loss: 0.009480410255491734, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3349, loss: 0.004360141232609749, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3350, loss: 0.007211520802229643, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3351, loss: 0.0018462789012119174, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3352, loss: 0.010142235085368156, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3353, loss: 0.009215702302753925, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3354, loss: 0.004627932794392109, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3355, loss: 0.0017540109110996127, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3356, loss: 0.0023312699049711227, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3357, loss: 0.05989053100347519, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666666\n",
      "train: step: 3358, loss: 0.008034934289753437, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3359, loss: 0.005844277795404196, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3360, loss: 0.0007161828689277172, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 3361, loss: 0.0016661934787407517, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3362, loss: 0.0006510911625809968, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3363, loss: 0.0013918699696660042, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3364, loss: 0.0010438980534672737, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3365, loss: 0.0070231216959655285, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3366, loss: 0.0010454796720296144, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3367, loss: 0.0008651625830680132, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3368, loss: 0.003311603795737028, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3369, loss: 0.016197403892874718, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3370, loss: 0.001939130132086575, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3371, loss: 0.0008864318951964378, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3372, loss: 0.002268550917506218, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3373, loss: 0.004633332137018442, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3374, loss: 0.004366833716630936, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3375, loss: 0.002743644407019019, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3376, loss: 0.0014631063677370548, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3377, loss: 0.013442615047097206, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3378, loss: 0.0006863464368507266, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3379, loss: 0.10887283831834793, acc: 0.984375, recall: 0.875, precision: 0.84375, f_beta: 0.8541666666666666\n",
      "train: step: 3380, loss: 0.0005477574886754155, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3381, loss: 0.0017487858422100544, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3382, loss: 0.0025006169453263283, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3383, loss: 0.0011093418579548597, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3384, loss: 0.002114551141858101, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3385, loss: 0.0005598538555204868, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3386, loss: 0.0018334068590775132, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3387, loss: 0.0081246979534626, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3388, loss: 0.0005498556420207024, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3389, loss: 0.00042498618131503463, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3390, loss: 0.016551608219742775, acc: 0.984375, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3391, loss: 0.002483722986653447, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3392, loss: 0.0011932720663025975, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3393, loss: 0.0007979946676641703, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3394, loss: 0.004164647776633501, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3395, loss: 0.002544737420976162, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3396, loss: 0.003226227592676878, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3397, loss: 0.012881286442279816, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3398, loss: 0.0014097322709858418, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3399, loss: 0.0009649700950831175, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3400, loss: 0.001492973417043686, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:29:58.648382, step: 3400, loss: 7.997735076480442, acc: 0.16666666666666666,precision: 0.07473213514880182, recall: 0.09404547998297998, f_beta: 0.07841358440866493\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3400\n",
      "\n",
      "train: step: 3401, loss: 0.0016774714458733797, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3402, loss: 0.0015307196881622076, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3403, loss: 0.002243336057290435, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3404, loss: 0.0016986280679702759, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3405, loss: 0.0018437585094943643, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3406, loss: 0.0009503088076598942, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3407, loss: 0.0148016307502985, acc: 0.984375, recall: 0.7291666666666666, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 3408, loss: 0.012732252478599548, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3409, loss: 0.004038069862872362, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3410, loss: 0.0007708761841058731, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3411, loss: 0.004950239323079586, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3412, loss: 0.008830364793539047, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3413, loss: 0.0022137477062642574, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3414, loss: 0.0020624627359211445, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3415, loss: 0.02057592198252678, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 3416, loss: 0.0016663356218487024, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3417, loss: 0.003426202107220888, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3418, loss: 0.0015748203732073307, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3419, loss: 0.0010089084971696138, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3420, loss: 0.0011719216126948595, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3421, loss: 0.0014279611641541123, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3422, loss: 0.002147793071344495, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3423, loss: 0.00417843833565712, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3424, loss: 0.004030405543744564, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3425, loss: 0.005428649485111237, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3426, loss: 0.0011949683539569378, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3427, loss: 0.0024224971421062946, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3428, loss: 0.001068934565410018, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3429, loss: 0.0006600678898394108, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3430, loss: 0.0008506604935973883, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3431, loss: 0.0008464730344712734, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3432, loss: 0.0011755037121474743, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3433, loss: 0.000663247425109148, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3434, loss: 0.0035989154130220413, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3435, loss: 0.003021554322913289, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3436, loss: 0.0009788405150175095, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3437, loss: 0.002983581507578492, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3438, loss: 0.0016127950511872768, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3439, loss: 0.005373549647629261, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3440, loss: 0.0010015735169872642, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3441, loss: 0.002091101836413145, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3442, loss: 0.0018556914292275906, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3443, loss: 0.0029310104437172413, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3444, loss: 0.004100893624126911, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 3445, loss: 0.0027954059187322855, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3446, loss: 0.01824336312711239, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848485\n",
      "train: step: 3447, loss: 0.0037555499002337456, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3448, loss: 0.0010380616877228022, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3449, loss: 0.0014950709883123636, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3450, loss: 0.0014105429872870445, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3451, loss: 0.0016253533540293574, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3452, loss: 0.0009555693250149488, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3453, loss: 0.000528599601238966, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3454, loss: 0.0008661969332024455, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3455, loss: 0.00413614371791482, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3456, loss: 0.0022232988849282265, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3457, loss: 0.0020158428233116865, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3458, loss: 0.059849776327610016, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666666, f_beta: 0.8\n",
      "train: step: 3459, loss: 0.0007927660481072962, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3460, loss: 0.0010039517655968666, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3461, loss: 0.0005920196417719126, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3462, loss: 0.0017409505089744925, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3463, loss: 0.0021019906271249056, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3464, loss: 0.0005400516092777252, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3465, loss: 0.0012366257142275572, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3466, loss: 0.00039641244802623987, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3467, loss: 0.0009398519177921116, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3468, loss: 0.0004642919811885804, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3469, loss: 0.002028306946158409, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3470, loss: 0.0008990921778604388, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3471, loss: 0.0008680532337166369, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3472, loss: 0.001036808593198657, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3473, loss: 0.000685434672050178, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3474, loss: 0.001425036578439176, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3475, loss: 0.004108247347176075, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3476, loss: 0.00039532699156552553, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3477, loss: 0.00029924194677732885, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3478, loss: 0.0007572696777060628, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3479, loss: 0.0019348671194165945, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3480, loss: 0.0006489045917987823, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3481, loss: 0.0020224801264703274, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3482, loss: 0.013156174682080746, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3483, loss: 0.0006819025729782879, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3484, loss: 0.002727244747802615, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3485, loss: 0.0008793874876573682, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3486, loss: 0.0016807024367153645, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3487, loss: 0.0013561391970142722, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3488, loss: 0.001938436646014452, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3489, loss: 0.0004402306512929499, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3490, loss: 0.001196639845147729, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3491, loss: 0.001338288770057261, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3492, loss: 0.0015535822603851557, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3493, loss: 0.0006410940550267696, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3494, loss: 0.0009642625227570534, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3495, loss: 0.0021067289635539055, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3496, loss: 0.0003205345419701189, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3497, loss: 0.0010356565471738577, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3498, loss: 0.004417660646140575, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3499, loss: 0.0007231488125398755, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3500, loss: 0.0007186989532783628, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:31:51.132045, step: 3500, loss: 8.40686066945394, acc: 0.1597222222222222,precision: 0.07669678252269842, recall: 0.09124078082411415, f_beta: 0.07730947939979728\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3500\n",
      "\n",
      "train: step: 3501, loss: 0.0006358597311191261, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3502, loss: 0.0006800487171858549, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3503, loss: 0.0010517854243516922, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3504, loss: 0.0004566706484183669, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3505, loss: 0.0014017674839124084, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3506, loss: 0.0005798075580969453, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3507, loss: 0.0011466273572295904, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3508, loss: 0.0008688679081387818, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3509, loss: 0.0009935892885550857, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3510, loss: 0.0006282912800088525, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3511, loss: 0.0013519865460693836, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3512, loss: 0.0025064628571271896, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3513, loss: 0.0005903026321902871, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3514, loss: 0.000643974170088768, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3515, loss: 0.0016480047488585114, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3516, loss: 0.002973728347569704, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3517, loss: 0.0014242008328437805, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3518, loss: 0.00231461925432086, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3519, loss: 0.0004906851099804044, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3520, loss: 0.0006403109873645008, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3521, loss: 0.0009863540763035417, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3522, loss: 0.0006925549823790789, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3523, loss: 0.0007318295538425446, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3524, loss: 0.0006535501452162862, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3525, loss: 0.0022619788069278, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3526, loss: 0.0003442239249125123, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3527, loss: 0.0011908247834071517, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3528, loss: 0.0013525511603802443, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "start training model\n",
      "train: step: 3529, loss: 0.0014507611049339175, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3530, loss: 0.0003748491872102022, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3531, loss: 0.0005079428083263338, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3532, loss: 0.0012045191833749413, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3533, loss: 0.0006759444368071854, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3534, loss: 0.00047095699119381607, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3535, loss: 0.0006377364043146372, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3536, loss: 0.0009144472423940897, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3537, loss: 0.0014882105169817805, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3538, loss: 0.0009942352771759033, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3539, loss: 0.0010684659937396646, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3540, loss: 0.0005350448191165924, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3541, loss: 0.002124026184901595, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3542, loss: 0.0004862954665441066, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3543, loss: 0.0007876880699768662, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3544, loss: 0.0008632073295302689, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3545, loss: 0.00033495467505417764, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3546, loss: 0.0007337309652939439, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3547, loss: 0.007486278191208839, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3548, loss: 0.0006351525662466884, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3549, loss: 0.0006029658252373338, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3550, loss: 0.0004817982262466103, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3551, loss: 0.000452039617812261, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3552, loss: 0.0005337528418749571, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3553, loss: 0.0010389977833256125, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3554, loss: 0.0029245824553072453, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3555, loss: 0.0003443991590756923, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3556, loss: 0.00052595668239519, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3557, loss: 0.00033277651527896523, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3558, loss: 0.0032049112487584352, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3559, loss: 0.0007892745779827237, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3560, loss: 0.00026771274860948324, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3561, loss: 0.0009627142571844161, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3562, loss: 0.0193199310451746, acc: 0.984375, recall: 0.7916666666666667, precision: 0.7916666666666666, f_beta: 0.7875000000000001\n",
      "train: step: 3563, loss: 0.0005158154526725411, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3564, loss: 0.0010436302982270718, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3565, loss: 0.0007577867363579571, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3566, loss: 0.001819785451516509, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3567, loss: 0.008660092949867249, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3568, loss: 0.00034212495665997267, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3569, loss: 0.0005290369736030698, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3570, loss: 0.0005172985838726163, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3571, loss: 0.0009807450696825981, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3572, loss: 0.001193310716189444, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3573, loss: 0.0011289697140455246, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3574, loss: 0.0027371556498110294, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3575, loss: 0.00046956760343164206, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3576, loss: 0.0008910284377634525, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3577, loss: 0.000341524719260633, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3578, loss: 0.0022439388558268547, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3579, loss: 0.0022151980083435774, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3580, loss: 0.0008472728659398854, acc: 1.0, recall: 1.0, precision: 1.0, f_beta: 1.0\n",
      "train: step: 3581, loss: 0.001900779316201806, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3582, loss: 0.0047803036868572235, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3583, loss: 0.0009328699088655412, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3584, loss: 0.0009413203224539757, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3585, loss: 0.0013499879278242588, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3586, loss: 0.0004452083958312869, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3587, loss: 0.001536285737529397, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3588, loss: 0.00041313565452583134, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3589, loss: 0.0002932109055109322, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3590, loss: 0.000546158233191818, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3591, loss: 0.0022381567396223545, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3592, loss: 0.0010690789204090834, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3593, loss: 0.0008972491486929357, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3594, loss: 0.017666645348072052, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3595, loss: 0.001697536907158792, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3596, loss: 0.0004719523130916059, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3597, loss: 0.000986265018582344, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3598, loss: 0.0005843624239787459, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3599, loss: 0.0015964459162205458, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3600, loss: 0.0005616253474727273, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:33:42.776565, step: 3600, loss: 8.697241995069716, acc: 0.15625,precision: 0.07376823839300561, recall: 0.09610345287428622, f_beta: 0.07824686015428751\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3600\n",
      "\n",
      "train: step: 3601, loss: 0.00027502933517098427, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3602, loss: 0.00041969161247834563, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3603, loss: 0.001702378853224218, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3604, loss: 0.00033668812830001116, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3605, loss: 0.0008242605836130679, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3606, loss: 0.0008991408394649625, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3607, loss: 0.0010444894433021545, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3608, loss: 0.00025284275761805475, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3609, loss: 0.0004639840335585177, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3610, loss: 0.004540521185845137, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3611, loss: 0.0010714353993535042, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3612, loss: 0.0002804200048558414, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "start training model\n",
      "train: step: 3613, loss: 0.000983645673841238, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3614, loss: 0.0002769540878944099, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3615, loss: 0.0003309799649287015, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3616, loss: 0.0006962387124076486, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3617, loss: 0.0005805193213745952, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3618, loss: 0.0005665712524205446, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3619, loss: 0.0008034749189391732, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3620, loss: 0.0009554887074045837, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3621, loss: 0.00020913836488034576, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3622, loss: 0.0008437441429123282, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3623, loss: 0.0021062709856778383, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3624, loss: 0.0011499208630993962, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3625, loss: 0.001369287259876728, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3626, loss: 0.00045290403068065643, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3627, loss: 0.00043055956484749913, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3628, loss: 0.00039088749326765537, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3629, loss: 0.00035381363704800606, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3630, loss: 0.0002977775293402374, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3631, loss: 0.0012718456564471126, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3632, loss: 0.000497075729072094, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3633, loss: 0.0016740456921979785, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3634, loss: 0.0011814350727945566, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3635, loss: 0.003899236209690571, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3636, loss: 0.00209797197021544, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3637, loss: 0.00070788903394714, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3638, loss: 0.0005712773418053985, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3639, loss: 0.005175983998924494, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3640, loss: 0.000477511843200773, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3641, loss: 0.00034090576809830964, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3642, loss: 0.0003326315199956298, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3643, loss: 0.0002878839732147753, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3644, loss: 0.012096716091036797, acc: 0.984375, recall: 0.5416666666666667, precision: 0.5555555555555556, f_beta: 0.5463235294117648\n",
      "train: step: 3645, loss: 0.001903295866213739, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3646, loss: 0.0004879835178144276, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3647, loss: 0.0003527916851453483, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3648, loss: 0.0007718945853412151, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3649, loss: 0.00024272850714623928, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3650, loss: 0.0016575597692281008, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3651, loss: 0.001850189408287406, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3652, loss: 0.0005430664168670774, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3653, loss: 0.001501892926171422, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3654, loss: 0.0004545520059764385, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3655, loss: 0.008070510812103748, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3656, loss: 0.0023431447334587574, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3657, loss: 0.0010037301108241081, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3658, loss: 0.000581381085794419, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3659, loss: 0.0003354672808200121, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3660, loss: 0.0005212423857301474, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3661, loss: 0.00130563136190176, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3662, loss: 0.0005869910237379372, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3663, loss: 0.0003068158694077283, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3664, loss: 0.0011359697673469782, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3665, loss: 0.0009406449971720576, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3666, loss: 0.0012310019228607416, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3667, loss: 0.003223641775548458, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3668, loss: 0.0004623022105079144, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3669, loss: 0.0003642863593995571, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3670, loss: 0.0007121021044440567, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3671, loss: 0.0007306126062758267, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3672, loss: 0.0013782610185444355, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3673, loss: 0.0005231905961409211, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3674, loss: 0.00022373045794665813, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3675, loss: 0.002791142789646983, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3676, loss: 0.0002474653592798859, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3677, loss: 0.0006256020860746503, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3678, loss: 0.0010409760288894176, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3679, loss: 0.0002453777124173939, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3680, loss: 0.0006325616268441081, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3681, loss: 0.0005187487695366144, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3682, loss: 0.0013271421194076538, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3683, loss: 0.0009116760338656604, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3684, loss: 0.000414616777561605, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3685, loss: 0.00043887022184208035, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3686, loss: 0.0003240289515815675, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3687, loss: 0.0013740547001361847, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3688, loss: 0.0008204284822568297, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3689, loss: 0.0004143363330513239, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3690, loss: 0.00026430876459926367, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3691, loss: 0.002156516769900918, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3692, loss: 0.0005514450022019446, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3693, loss: 0.0012964715715497732, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3694, loss: 0.00031418888829648495, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3695, loss: 0.0017504313727840781, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3696, loss: 0.0057920245453715324, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "start training model\n",
      "train: step: 3697, loss: 0.00033800501842051744, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3698, loss: 0.00051414396148175, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3699, loss: 0.0003805045271292329, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3700, loss: 0.001906706253066659, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:35:34.627651, step: 3700, loss: 8.670252111223009, acc: 0.16493055555555555,precision: 0.07474623712502015, recall: 0.09099104984521651, f_beta: 0.07595941290145497\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3700\n",
      "\n",
      "train: step: 3701, loss: 0.0003188824630342424, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3702, loss: 0.0008335489546880126, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3703, loss: 0.0012360033579170704, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3704, loss: 0.001291009015403688, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3705, loss: 0.0009442546288482845, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3706, loss: 0.0006308666197583079, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3707, loss: 0.0027283530216664076, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3708, loss: 0.0007334628608077765, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3709, loss: 0.0004897945327684283, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3710, loss: 0.00032291049137711525, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3711, loss: 0.0003224698593840003, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3712, loss: 0.000685491890180856, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3713, loss: 0.0005983852315694094, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3714, loss: 0.0005528926849365234, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3715, loss: 0.0008714370778761804, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3716, loss: 0.00045437325024977326, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3717, loss: 0.0002232424885733053, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3718, loss: 0.0006416480173356831, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3719, loss: 0.00040383602026849985, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3720, loss: 0.0011382392840459943, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3721, loss: 0.000360454258043319, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3722, loss: 0.000703360594343394, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3723, loss: 0.004257794003933668, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3724, loss: 0.0016270908527076244, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3725, loss: 0.00047205114969983697, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3726, loss: 0.0028129310812801123, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3727, loss: 0.000901014544069767, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3728, loss: 0.0005164906615391374, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3729, loss: 0.0004415733565110713, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3730, loss: 0.000638226221781224, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3731, loss: 0.001217662007547915, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3732, loss: 0.0004036501341033727, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3733, loss: 0.0006550920661538839, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3734, loss: 0.0007327995845116675, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3735, loss: 0.0002143204037565738, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3736, loss: 0.0006877720588818192, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3737, loss: 0.000789725047070533, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3738, loss: 0.000948965665884316, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3739, loss: 0.0005238783196546137, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3740, loss: 0.0003164124209433794, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3741, loss: 0.0012159026227891445, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3742, loss: 0.0008101511048153043, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3743, loss: 0.0005531986244022846, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3744, loss: 0.00045514668454416096, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3745, loss: 0.000497469212859869, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3746, loss: 0.0008211493259295821, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3747, loss: 0.0020319775212556124, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3748, loss: 0.0006548372330144048, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3749, loss: 0.0013853727141395211, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3750, loss: 0.00035584100987762213, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3751, loss: 0.002258680062368512, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3752, loss: 0.001415116130374372, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3753, loss: 0.0013960701180621982, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3754, loss: 0.0005744410445913672, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3755, loss: 0.0014165438478812575, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3756, loss: 0.000274903402896598, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3757, loss: 0.0015256491024047136, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3758, loss: 0.0006932170945219696, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3759, loss: 0.00017850936274044216, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3760, loss: 0.00028145062969997525, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3761, loss: 0.00024620257318019867, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3762, loss: 0.0010016093729063869, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3763, loss: 0.00037197867641225457, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3764, loss: 0.0006790829938836396, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3765, loss: 0.0004995217313989997, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3766, loss: 0.0006961487233638763, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3767, loss: 0.0001700442226137966, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3768, loss: 0.000360626436304301, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3769, loss: 0.0007048595580272377, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3770, loss: 0.00032867243862710893, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3771, loss: 0.0004944271640852094, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3772, loss: 0.0003996443992946297, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3773, loss: 0.0005314135923981667, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3774, loss: 0.00513613922521472, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3775, loss: 0.00031555595342069864, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3776, loss: 0.00022654366330243647, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3777, loss: 0.004692360758781433, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3778, loss: 0.0005900588585063815, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3779, loss: 0.0004121625970583409, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3780, loss: 0.0010466482490301132, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 3781, loss: 0.0007405458018183708, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3782, loss: 0.0008426225977018476, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3783, loss: 0.0011071315966546535, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3784, loss: 0.002494232030585408, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3785, loss: 0.00016893932479433715, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3786, loss: 0.0006541095208376646, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3787, loss: 0.00033208716195076704, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3788, loss: 0.0011792259756475687, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3789, loss: 0.00022006833751220256, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3790, loss: 0.0005128397606313229, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3791, loss: 0.006499618291854858, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3792, loss: 0.000356549397110939, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3793, loss: 0.0003618264745455235, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3794, loss: 0.0003752170887310058, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3795, loss: 0.0008606985793448985, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3796, loss: 0.0013060502242296934, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3797, loss: 0.00036167321377433836, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3798, loss: 0.00021403172286227345, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3799, loss: 0.0005680654430761933, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3800, loss: 0.000406006263801828, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:37:26.340172, step: 3800, loss: 8.876836034986708, acc: 0.171875,precision: 0.09347309509041964, recall: 0.09465389689525397, f_beta: 0.08455303832600487\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3800\n",
      "\n",
      "train: step: 3801, loss: 9.687389683676884e-05, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3802, loss: 0.0007847921224310994, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3803, loss: 0.0013556908816099167, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3804, loss: 0.0003589152474887669, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3805, loss: 0.0006144676590338349, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3806, loss: 0.00028254740755073726, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3807, loss: 0.00036119509604759514, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3808, loss: 0.0003536990552674979, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3809, loss: 0.0026805209927260876, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3810, loss: 0.001062201103195548, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3811, loss: 0.0003842572041321546, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3812, loss: 0.000428415194619447, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3813, loss: 0.0005302964709699154, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3814, loss: 0.00048342044465243816, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3815, loss: 0.0009358695242553949, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3816, loss: 0.0002459358365740627, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3817, loss: 0.00037160757347010076, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3818, loss: 0.0007088190177455544, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3819, loss: 0.0004108311259187758, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3820, loss: 0.00028223483241163194, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3821, loss: 0.0006981766200624406, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3822, loss: 0.0003245808184146881, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3823, loss: 0.00030017615063115954, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3824, loss: 0.00029122739215381444, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3825, loss: 0.00028602968086488545, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3826, loss: 0.0003536979202181101, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3827, loss: 0.0005865053390152752, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3828, loss: 0.00047454226296395063, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3829, loss: 0.00015690304280724376, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3830, loss: 0.0002463468408677727, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3831, loss: 0.0009399905684404075, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3832, loss: 0.0009949684608727694, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3833, loss: 0.0006046102498658001, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3834, loss: 0.0002063065767288208, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3835, loss: 0.0003267877618782222, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3836, loss: 0.0003548869863152504, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3837, loss: 0.0006646454567089677, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3838, loss: 0.0014376037288457155, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3839, loss: 0.000867906550411135, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3840, loss: 0.00042960839346051216, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3841, loss: 0.00016059934569057077, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3842, loss: 0.0005488399183377624, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3843, loss: 0.0005942797288298607, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3844, loss: 0.0002983148442581296, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3845, loss: 0.0001396682346239686, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3846, loss: 0.0004112953320145607, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3847, loss: 0.00017890523304231465, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3848, loss: 0.04927536100149155, acc: 0.984375, recall: 0.7421875, precision: 0.74375, f_beta: 0.7425438596491228\n",
      "train: step: 3849, loss: 0.0002207633515354246, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3850, loss: 0.00019251476624049246, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3851, loss: 0.0028943486977368593, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3852, loss: 0.0005624396144412458, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3853, loss: 0.0015882350271567702, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3854, loss: 0.0012489153305068612, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3855, loss: 0.028217008337378502, acc: 0.984375, recall: 0.984375, precision: 0.9943181818181818, f_beta: 0.9880952380952381\n",
      "train: step: 3856, loss: 0.0009109391830861568, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3857, loss: 0.007097656838595867, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3858, loss: 0.0009428608464077115, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3859, loss: 0.0010374633129686117, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3860, loss: 0.07228312641382217, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7455357142857143, f_beta: 0.742003367003367\n",
      "train: step: 3861, loss: 0.0014481778489425778, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3862, loss: 0.00044060382060706615, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3863, loss: 0.00047044188249856234, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3864, loss: 0.000547699281014502, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 3865, loss: 0.0024990595411509275, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3866, loss: 0.007733295205980539, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3867, loss: 0.001273368252441287, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3868, loss: 0.06131569296121597, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666666\n",
      "train: step: 3869, loss: 0.0014049024321138859, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3870, loss: 0.0009218263439834118, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3871, loss: 0.004829256795346737, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3872, loss: 0.021517524495720863, acc: 0.984375, recall: 0.6197916666666666, precision: 0.6125, f_beta: 0.6153381642512078\n",
      "train: step: 3873, loss: 0.0020879926159977913, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3874, loss: 0.0035015936009585857, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 3875, loss: 0.005530013702809811, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3876, loss: 0.003144234651699662, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3877, loss: 0.004076385870575905, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3878, loss: 0.0006659331847913563, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3879, loss: 0.0010018819011747837, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3880, loss: 0.016759619116783142, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3881, loss: 0.0015735302586108446, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3882, loss: 0.0014415665064007044, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3883, loss: 0.0011955603258684278, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3884, loss: 0.0009648768464103341, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3885, loss: 0.01214467454701662, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3886, loss: 0.014096190221607685, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7443181818181818, f_beta: 0.7413419913419913\n",
      "train: step: 3887, loss: 0.0034232991747558117, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3888, loss: 0.0009985893266275525, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3889, loss: 0.00019305458408780396, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3890, loss: 0.002629972528666258, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3891, loss: 0.0011005483102053404, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3892, loss: 0.0006487950449809432, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3893, loss: 0.0025876560248434544, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3894, loss: 0.003882137592881918, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3895, loss: 0.0008625883492641151, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3896, loss: 0.0021432945504784584, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3897, loss: 0.015133247710764408, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3898, loss: 0.002501009963452816, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3899, loss: 0.0016735299723222852, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3900, loss: 0.0011493874480947852, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:39:19.713758, step: 3900, loss: 8.581835005018446, acc: 0.16666666666666666,precision: 0.08965719749710978, recall: 0.09580904242362576, f_beta: 0.08144847885968456\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-3900\n",
      "\n",
      "train: step: 3901, loss: 0.0011113747023046017, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3902, loss: 0.00030794815393164754, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3903, loss: 0.00047921083751134574, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3904, loss: 0.0008566138567402959, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3905, loss: 0.0005890073371119797, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3906, loss: 0.0003717030631378293, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3907, loss: 0.0003608018159866333, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3908, loss: 0.0004149950691498816, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3909, loss: 0.000958161661401391, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3910, loss: 0.0005051695043221116, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3911, loss: 0.0009617120958864689, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3912, loss: 0.00031222455436363816, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3913, loss: 0.0006384382722899318, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3914, loss: 0.0008884502458386123, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3915, loss: 0.001943723764270544, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3916, loss: 0.0005892479093745351, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3917, loss: 0.0007645695586688817, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3918, loss: 0.0005267503438517451, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3919, loss: 0.0017054134514182806, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3920, loss: 0.0021882792934775352, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3921, loss: 0.00042999297147616744, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3922, loss: 0.0013506847899407148, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3923, loss: 0.0005701628979295492, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3924, loss: 0.0008882735855877399, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3925, loss: 0.0015443717129528522, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3926, loss: 0.002969822147861123, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3927, loss: 0.0038929693400859833, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3928, loss: 0.000890080351382494, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3929, loss: 0.0005166549235582352, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3930, loss: 0.00040922733023762703, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3931, loss: 0.003972387872636318, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3932, loss: 0.00038121658144518733, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3933, loss: 0.00041879137279465795, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3934, loss: 0.0018583332421258092, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3935, loss: 0.00025997404009103775, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3936, loss: 0.0004140459932386875, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3937, loss: 0.00033415324287489057, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3938, loss: 0.0004783781769219786, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3939, loss: 0.00030777286156080663, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3940, loss: 0.0002571846707724035, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3941, loss: 0.0004912064177915454, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3942, loss: 0.01662261039018631, acc: 0.984375, recall: 0.6826923076923077, precision: 0.671875, f_beta: 0.6760714285714287\n",
      "train: step: 3943, loss: 0.0004919447237625718, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3944, loss: 0.0010543838143348694, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3945, loss: 0.002783000934869051, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3946, loss: 0.0003517170262057334, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3947, loss: 0.0014116645324975252, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3948, loss: 0.0007635750807821751, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "start training model\n",
      "train: step: 3949, loss: 0.0006050568772479892, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3950, loss: 0.00019917670579161495, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3951, loss: 0.0010145660489797592, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3952, loss: 0.0005914965877309442, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3953, loss: 0.004120256751775742, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3954, loss: 0.005770414602011442, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3955, loss: 0.0028250988107174635, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3956, loss: 0.00033797870855778456, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3957, loss: 0.00023293844424188137, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3958, loss: 0.0006128604291006923, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3959, loss: 0.004797712899744511, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3960, loss: 0.0010251831263303757, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3961, loss: 0.0004354947595857084, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3962, loss: 0.0009557752637192607, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3963, loss: 0.000756032532081008, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3964, loss: 0.046161506325006485, acc: 0.984375, recall: 0.5576923076923077, precision: 0.55625, f_beta: 0.5567105263157894\n",
      "train: step: 3965, loss: 0.0018981320317834616, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3966, loss: 0.000834092905279249, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3967, loss: 0.00045513216173276305, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3968, loss: 0.0008927715243771672, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3969, loss: 0.0008093756623566151, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3970, loss: 0.0007750029326416552, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3971, loss: 0.0012295731576159596, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 3972, loss: 0.0005534991505555809, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3973, loss: 0.0007230262272059917, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3974, loss: 0.0202114786952734, acc: 0.984375, recall: 0.921875, precision: 0.9285714285714286, f_beta: 0.9237637362637363\n",
      "train: step: 3975, loss: 0.0007470925338566303, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3976, loss: 0.007059445604681969, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3977, loss: 0.0007715118117630482, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3978, loss: 0.0008295404259115458, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3979, loss: 0.0009284474654123187, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3980, loss: 0.013611188158392906, acc: 0.984375, recall: 0.7455357142857143, precision: 0.7395833333333334, f_beta: 0.7420033670033671\n",
      "train: step: 3981, loss: 0.028803398832678795, acc: 0.984375, recall: 0.7443181818181818, precision: 0.7375, f_beta: 0.7400793650793651\n",
      "train: step: 3982, loss: 0.0010576999047771096, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3983, loss: 0.0010008011013269424, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3984, loss: 0.0009802202694118023, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3985, loss: 0.0014205938205122948, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3986, loss: 0.0006219852366484702, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3987, loss: 0.007857481017708778, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 3988, loss: 0.0012072096578776836, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3989, loss: 0.0011385709512978792, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 3990, loss: 0.005293990019708872, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3991, loss: 0.006750148255378008, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3992, loss: 0.03860130533576012, acc: 0.984375, recall: 0.6796875, precision: 0.65625, f_beta: 0.6625\n",
      "train: step: 3993, loss: 0.015973184257745743, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3994, loss: 0.10520460456609726, acc: 0.984375, recall: 0.8, precision: 0.8046875, f_beta: 0.8013888888888889\n",
      "train: step: 3995, loss: 0.0006406677421182394, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 3996, loss: 0.04070259630680084, acc: 0.984375, recall: 0.734375, precision: 0.7421875, f_beta: 0.736904761904762\n",
      "train: step: 3997, loss: 0.0006969422101974487, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 3998, loss: 0.0011934146750718355, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 3999, loss: 0.0010236401576548815, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4000, loss: 0.0011352284345775843, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:41:11.756511, step: 4000, loss: 8.625220404730904, acc: 0.1892361111111111,precision: 0.10243253943911838, recall: 0.09622448403085658, f_beta: 0.0870053408178913\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4000\n",
      "\n",
      "train: step: 4001, loss: 0.007742980495095253, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4002, loss: 0.011373855173587799, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4003, loss: 0.0012732396135106683, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4004, loss: 0.03608263283967972, acc: 0.96875, recall: 0.8, precision: 0.8046875, f_beta: 0.8013888888888889\n",
      "train: step: 4005, loss: 0.24167877435684204, acc: 0.953125, recall: 0.8033854166666666, precision: 0.778125, f_beta: 0.7886039901061678\n",
      "train: step: 4006, loss: 0.0005169514915905893, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4007, loss: 0.04910573363304138, acc: 0.984375, recall: 0.734375, precision: 0.7291666666666666, f_beta: 0.7285714285714286\n",
      "train: step: 4008, loss: 0.005983184557408094, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4009, loss: 0.001083633629605174, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4010, loss: 0.0002992881927639246, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4011, loss: 0.0013450501719489694, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4012, loss: 0.00166931317653507, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4013, loss: 0.00665474496781826, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4014, loss: 0.0013352921232581139, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4015, loss: 0.009583023376762867, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4016, loss: 0.0021862389985471964, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4017, loss: 0.011578400619328022, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4018, loss: 0.0014955217484384775, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4019, loss: 0.0006588056567125022, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4020, loss: 0.0006868620403110981, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4021, loss: 0.0009837429970502853, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4022, loss: 0.0008227828657254577, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4023, loss: 0.01912510395050049, acc: 0.984375, recall: 0.71875, precision: 0.7421875, f_beta: 0.725\n",
      "train: step: 4024, loss: 0.009011618793010712, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4025, loss: 0.10466865450143814, acc: 0.953125, recall: 0.7604166666666667, precision: 0.75625, f_beta: 0.7427083333333333\n",
      "train: step: 4026, loss: 0.0025986158289015293, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4027, loss: 0.038168489933013916, acc: 0.984375, recall: 0.6180555555555556, precision: 0.6125, f_beta: 0.6143790849673203\n",
      "train: step: 4028, loss: 0.1093129813671112, acc: 0.984375, recall: 0.8125, precision: 0.8046875, f_beta: 0.8083333333333333\n",
      "train: step: 4029, loss: 0.0037046652287244797, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4030, loss: 0.0003556028241291642, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4031, loss: 0.005187176167964935, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4032, loss: 0.002105893101543188, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 4033, loss: 0.0015215855091810226, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4034, loss: 0.008918333798646927, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4035, loss: 0.0010284787276759744, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4036, loss: 0.001540232333354652, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4037, loss: 0.001146906055510044, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4038, loss: 0.020590120926499367, acc: 0.984375, recall: 0.6193181818181819, precision: 0.625, f_beta: 0.6220238095238095\n",
      "train: step: 4039, loss: 0.23698240518569946, acc: 0.953125, recall: 0.733440170940171, precision: 0.721875, f_beta: 0.7259946741854636\n",
      "train: step: 4040, loss: 0.0021511195227503777, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4041, loss: 0.0037529119290411472, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4042, loss: 0.009636018425226212, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4043, loss: 0.010075625032186508, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4044, loss: 0.024855073541402817, acc: 0.984375, recall: 0.8125, precision: 0.8068181818181818, f_beta: 0.8095238095238095\n",
      "train: step: 4045, loss: 0.0034253131598234177, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4046, loss: 0.005984863732010126, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4047, loss: 0.0013244880829006433, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4048, loss: 0.04979536309838295, acc: 0.96875, recall: 0.71875, precision: 0.6979166666666666, f_beta: 0.6958333333333333\n",
      "train: step: 4049, loss: 0.03152880817651749, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666667\n",
      "train: step: 4050, loss: 0.03667297586798668, acc: 0.984375, recall: 0.7443181818181818, precision: 0.71875, f_beta: 0.7261904761904762\n",
      "train: step: 4051, loss: 0.0005303056095726788, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4052, loss: 0.004757415968924761, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4053, loss: 0.01987474039196968, acc: 0.984375, recall: 0.80625, precision: 0.8068181818181818, f_beta: 0.806234335839599\n",
      "train: step: 4054, loss: 0.04840422421693802, acc: 0.984375, recall: 0.875, precision: 0.859375, f_beta: 0.8660714285714286\n",
      "train: step: 4055, loss: 0.014476705342531204, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4056, loss: 0.022177862003445625, acc: 0.984375, recall: 0.6785714285714286, precision: 0.6822916666666666, f_beta: 0.6799749163879599\n",
      "train: step: 4057, loss: 0.005744383670389652, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4058, loss: 0.016349101439118385, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4059, loss: 0.03813573718070984, acc: 0.984375, recall: 0.8125, precision: 0.8020833333333333, f_beta: 0.8068181818181819\n",
      "train: step: 4060, loss: 0.002086014486849308, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4061, loss: 0.002115351613610983, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4062, loss: 0.0161568745970726, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6875, f_beta: 0.675\n",
      "train: step: 4063, loss: 0.03795865550637245, acc: 0.96875, recall: 0.7365056818181819, precision: 0.7395104895104895, f_beta: 0.7373809523809525\n",
      "train: step: 4064, loss: 0.02782556228339672, acc: 0.984375, recall: 0.7447916666666666, precision: 0.7443181818181819, f_beta: 0.7443064182194616\n",
      "train: step: 4065, loss: 0.01234554685652256, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4066, loss: 0.016452856361865997, acc: 0.984375, recall: 0.65625, precision: 0.6840277777777778, f_beta: 0.6648809523809525\n",
      "train: step: 4067, loss: 0.060690827667713165, acc: 0.984375, recall: 0.5, precision: 0.4947916666666667, f_beta: 0.49728260869565216\n",
      "train: step: 4068, loss: 0.16027668118476868, acc: 0.984375, recall: 0.6875, precision: 0.671875, f_beta: 0.6785714285714286\n",
      "train: step: 4069, loss: 0.01307444367557764, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4070, loss: 0.007885332219302654, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4071, loss: 0.0022574281319975853, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4072, loss: 0.017953837290406227, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 4073, loss: 0.18674635887145996, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8125, f_beta: 0.8068181818181818\n",
      "train: step: 4074, loss: 0.020812515169382095, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4075, loss: 0.011630572378635406, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4076, loss: 0.031797025352716446, acc: 0.984375, recall: 0.5590277777777778, precision: 0.546875, f_beta: 0.5517857142857143\n",
      "train: step: 4077, loss: 0.008860341273248196, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4078, loss: 0.044704701751470566, acc: 0.984375, recall: 0.8068181818181818, precision: 0.796875, f_beta: 0.8005952380952381\n",
      "train: step: 4079, loss: 0.03916092589497566, acc: 0.984375, recall: 0.8083333333333333, precision: 0.8020833333333334, f_beta: 0.8046630094043887\n",
      "train: step: 4080, loss: 0.023365262895822525, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4081, loss: 0.004921364597976208, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4082, loss: 0.016542505472898483, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4083, loss: 0.17016325891017914, acc: 0.96875, recall: 0.625, precision: 0.6004464285714286, f_beta: 0.6112637362637363\n",
      "train: step: 4084, loss: 0.022723140195012093, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666666, f_beta: 0.675\n",
      "train: step: 4085, loss: 0.027235226705670357, acc: 0.984375, recall: 0.625, precision: 0.6041666666666666, f_beta: 0.6125\n",
      "train: step: 4086, loss: 0.04368618130683899, acc: 0.984375, recall: 0.78125, precision: 0.8035714285714286, f_beta: 0.7868589743589745\n",
      "train: step: 4087, loss: 0.10010810941457748, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6826923076923077, f_beta: 0.6725000000000001\n",
      "train: step: 4088, loss: 0.012294966727495193, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4089, loss: 0.0039022094570100307, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4090, loss: 0.06819715350866318, acc: 0.984375, recall: 0.68359375, precision: 0.6805555555555556, f_beta: 0.6818074003795067\n",
      "train: step: 4091, loss: 0.01679588109254837, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4092, loss: 0.051019757986068726, acc: 0.984375, recall: 0.796875, precision: 0.7916666666666666, f_beta: 0.7910714285714286\n",
      "train: step: 4093, loss: 0.011676150374114513, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4094, loss: 0.050256770104169846, acc: 0.984375, recall: 0.7455357142857143, precision: 0.7410714285714286, f_beta: 0.7428774928774928\n",
      "train: step: 4095, loss: 0.030534444376826286, acc: 0.984375, recall: 0.7447916666666666, precision: 0.7467105263157895, f_beta: 0.745593419506463\n",
      "train: step: 4096, loss: 0.01745999976992607, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4097, loss: 0.01203697919845581, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4098, loss: 0.10822126269340515, acc: 0.96875, recall: 0.74375, precision: 0.7463235294117647, f_beta: 0.7448165869218502\n",
      "train: step: 4099, loss: 0.005503223277628422, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4100, loss: 0.04571784287691116, acc: 0.96875, recall: 0.7859848484848484, precision: 0.77734375, f_beta: 0.7741743471582181\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:43:03.147424, step: 4100, loss: 7.537907865312365, acc: 0.14930555555555555,precision: 0.07546171414608593, recall: 0.10760616698116698, f_beta: 0.07974261965372431\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4100\n",
      "\n",
      "train: step: 4101, loss: 0.07633323222398758, acc: 0.984375, recall: 0.6818181818181819, precision: 0.6830357142857143, f_beta: 0.6822089947089947\n",
      "train: step: 4102, loss: 0.14098034799098969, acc: 0.984375, recall: 0.7451923076923077, precision: 0.7291666666666666, f_beta: 0.735\n",
      "train: step: 4103, loss: 0.10996782779693604, acc: 0.953125, recall: 0.7104166666666667, precision: 0.7321428571428572, f_beta: 0.7142857142857143\n",
      "train: step: 4104, loss: 0.015671515837311745, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4105, loss: 0.02277812547981739, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4106, loss: 0.2511686682701111, acc: 0.9375, recall: 0.7284512362637363, precision: 0.6858173076923078, f_beta: 0.6995115995115996\n",
      "train: step: 4107, loss: 0.12070165574550629, acc: 0.96875, recall: 0.7916666666666666, precision: 0.8046875, f_beta: 0.7958333333333333\n",
      "train: step: 4108, loss: 0.008166559040546417, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4109, loss: 0.016778308898210526, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4110, loss: 0.0905364453792572, acc: 0.96875, recall: 0.8125, precision: 0.7791666666666667, f_beta: 0.7930555555555556\n",
      "train: step: 4111, loss: 0.02042897790670395, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 4112, loss: 0.021185901015996933, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4113, loss: 0.20932725071907043, acc: 0.9375, recall: 0.75, precision: 0.6934523809523809, f_beta: 0.7143518518518519\n",
      "train: step: 4114, loss: 0.14393149316310883, acc: 0.9375, recall: 0.71875, precision: 0.775, f_beta: 0.7232142857142857\n",
      "train: step: 4115, loss: 0.11683394014835358, acc: 0.953125, recall: 0.734375, precision: 0.7395833333333334, f_beta: 0.7353896103896104\n",
      "train: step: 4116, loss: 0.016058137640357018, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 4117, loss: 0.17958548665046692, acc: 0.96875, recall: 0.6840277777777778, precision: 0.6687500000000001, f_beta: 0.6754803675856308\n",
      "train: step: 4118, loss: 0.22253549098968506, acc: 0.9375, recall: 0.6180555555555556, precision: 0.6326923076923077, f_beta: 0.6085896112831098\n",
      "train: step: 4119, loss: 0.2389807254076004, acc: 0.953125, recall: 0.6576923076923077, precision: 0.6631944444444444, f_beta: 0.6568505094043887\n",
      "train: step: 4120, loss: 0.07380829006433487, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666666, f_beta: 0.7791666666666667\n",
      "train: step: 4121, loss: 0.05132053792476654, acc: 0.984375, recall: 0.80859375, precision: 0.80625, f_beta: 0.8071943972835314\n",
      "train: step: 4122, loss: 0.004813693463802338, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4123, loss: 0.02487258054316044, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4124, loss: 0.23795735836029053, acc: 0.953125, recall: 0.7202380952380953, precision: 0.6875, f_beta: 0.6889423076923078\n",
      "train: step: 4125, loss: 0.08464144915342331, acc: 0.96875, recall: 0.7916666666666666, precision: 0.75, f_beta: 0.7583333333333333\n",
      "train: step: 4126, loss: 0.059597838670015335, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666667\n",
      "train: step: 4127, loss: 0.039239563047885895, acc: 0.984375, recall: 0.671875, precision: 0.6666666666666667, f_beta: 0.6660714285714286\n",
      "train: step: 4128, loss: 0.04195674881339073, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 4129, loss: 0.027411947026848793, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8080357142857143, f_beta: 0.8045033670033671\n",
      "train: step: 4130, loss: 0.16172334551811218, acc: 0.953125, recall: 0.7604166666666666, precision: 0.7395833333333333, f_beta: 0.7270833333333333\n",
      "train: step: 4131, loss: 0.08146625012159348, acc: 0.96875, recall: 0.6111111111111112, precision: 0.6041666666666667, f_beta: 0.6046875\n",
      "train: step: 4132, loss: 0.08779068291187286, acc: 0.96875, recall: 0.7743055555555556, precision: 0.7708333333333333, f_beta: 0.7567401960784315\n",
      "train: step: 4133, loss: 0.0368824303150177, acc: 0.984375, recall: 0.8020833333333334, precision: 0.796875, f_beta: 0.7978896103896105\n",
      "train: step: 4134, loss: 0.02229948341846466, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4135, loss: 0.013959423638880253, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4136, loss: 0.0034334000665694475, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4137, loss: 0.01075548492372036, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4138, loss: 0.11826437711715698, acc: 0.96875, recall: 0.6979166666666667, precision: 0.75, f_beta: 0.7166666666666667\n",
      "train: step: 4139, loss: 0.013995099812746048, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4140, loss: 0.03938516229391098, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 4141, loss: 0.08749067038297653, acc: 0.953125, recall: 0.5372023809523809, precision: 0.5625, f_beta: 0.5476851851851852\n",
      "train: step: 4142, loss: 0.026976436376571655, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4143, loss: 0.02273242175579071, acc: 0.984375, recall: 0.7458333333333333, precision: 0.7451923076923077, f_beta: 0.7453448275862069\n",
      "train: step: 4144, loss: 0.1846233308315277, acc: 0.953125, recall: 0.5535714285714286, precision: 0.546875, f_beta: 0.5487637362637363\n",
      "train: step: 4145, loss: 0.08567018061876297, acc: 0.96875, recall: 0.8385416666666667, precision: 0.8333333333333334, f_beta: 0.8223214285714285\n",
      "train: step: 4146, loss: 0.05794743448495865, acc: 0.984375, recall: 0.8, precision: 0.796875, f_beta: 0.7966269841269842\n",
      "train: step: 4147, loss: 0.022398576140403748, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4148, loss: 0.004622979089617729, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4149, loss: 0.07976538687944412, acc: 0.96875, recall: 0.7465277777777778, precision: 0.7443181818181819, f_beta: 0.7452380952380953\n",
      "train: step: 4150, loss: 0.030990824103355408, acc: 0.984375, recall: 0.4930555555555556, precision: 0.4951923076923077, f_beta: 0.4938235294117647\n",
      "train: step: 4151, loss: 0.07322106510400772, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 4152, loss: 0.060375913977622986, acc: 0.984375, recall: 0.5546875, precision: 0.55859375, f_beta: 0.5563172043010753\n",
      "train: step: 4153, loss: 0.03730214387178421, acc: 0.984375, recall: 0.6125, precision: 0.61875, f_beta: 0.6147660818713451\n",
      "train: step: 4154, loss: 0.11170350760221481, acc: 0.953125, recall: 0.6011904761904763, precision: 0.6059027777777778, f_beta: 0.6014813889813889\n",
      "train: step: 4155, loss: 0.025825662538409233, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4156, loss: 0.07101835310459137, acc: 0.984375, recall: 0.8125, precision: 0.796875, f_beta: 0.8035714285714286\n",
      "train: step: 4157, loss: 0.12015212327241898, acc: 0.96875, recall: 0.68125, precision: 0.6734375, f_beta: 0.6770833333333334\n",
      "train: step: 4158, loss: 0.05048680305480957, acc: 0.984375, recall: 0.8125, precision: 0.8076923076923077, f_beta: 0.81\n",
      "train: step: 4159, loss: 0.03251629322767258, acc: 0.984375, recall: 0.6160714285714286, precision: 0.6220238095238095, f_beta: 0.6186679174484053\n",
      "train: step: 4160, loss: 0.044602975249290466, acc: 0.984375, recall: 0.8090277777777778, precision: 0.8035714285714286, f_beta: 0.8059065934065934\n",
      "train: step: 4181, loss: 0.23113927245140076, acc: 0.984375, recall: 0.7443181818181819, precision: 0.7421875, f_beta: 0.7428571428571429\n",
      "train: step: 4182, loss: 0.04265943542122841, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666666, f_beta: 0.7791666666666667\n",
      "train: step: 4183, loss: 0.0530882328748703, acc: 0.984375, recall: 0.65625, precision: 0.6785714285714286, f_beta: 0.6618589743589743\n",
      "train: step: 4184, loss: 0.056859202682971954, acc: 0.984375, recall: 0.7916666666666667, precision: 0.78125, f_beta: 0.7791666666666666\n",
      "train: step: 4185, loss: 0.03649628907442093, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8125, f_beta: 0.8\n",
      "train: step: 4186, loss: 0.11267650872468948, acc: 0.96875, recall: 0.7964015151515151, precision: 0.7743055555555556, f_beta: 0.7793321874204228\n",
      "train: step: 4187, loss: 0.014321736060082912, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4188, loss: 0.14417791366577148, acc: 0.96875, recall: 0.9841269841269842, precision: 0.9774305555555556, f_beta: 0.9793192918192919\n",
      "train: step: 4189, loss: 0.02770010568201542, acc: 0.984375, recall: 0.5580357142857143, precision: 0.5583333333333333, f_beta: 0.5580300127713921\n",
      "train: step: 4190, loss: 0.010262718424201012, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4191, loss: 0.03599555045366287, acc: 0.984375, recall: 0.7291666666666666, precision: 0.71875, f_beta: 0.7166666666666667\n",
      "train: step: 4192, loss: 0.03754313662648201, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666667, f_beta: 0.7791666666666667\n",
      "train: step: 4193, loss: 0.1847582310438156, acc: 0.953125, recall: 0.8022660818713451, precision: 0.7857142857142857, f_beta: 0.7919099812482165\n",
      "train: step: 4194, loss: 0.03260422870516777, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4195, loss: 0.25108927488327026, acc: 0.953125, recall: 0.8068181818181818, precision: 0.7843749999999999, f_beta: 0.7922962454212454\n",
      "train: step: 4196, loss: 0.23127421736717224, acc: 0.953125, recall: 0.78125, precision: 0.7723214285714286, f_beta: 0.766025641025641\n",
      "train: step: 4197, loss: 0.035283517092466354, acc: 0.984375, recall: 0.75, precision: 0.7291666666666666, f_beta: 0.7375\n",
      "train: step: 4198, loss: 0.010327412746846676, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4199, loss: 0.09583248943090439, acc: 0.96875, recall: 0.6761363636363636, precision: 0.6801470588235294, f_beta: 0.67734375\n",
      "train: step: 4200, loss: 0.0077484906651079655, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:44:54.686215, step: 4200, loss: 6.975189897749159, acc: 0.2013888888888889,precision: 0.08807284536451204, recall: 0.09096024538732872, f_beta: 0.0838588685561982\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4200\n",
      "\n",
      "start training model\n",
      "train: step: 4201, loss: 0.004325205460190773, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4202, loss: 0.02102605812251568, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4203, loss: 0.059465017169713974, acc: 0.96875, recall: 0.6822916666666667, precision: 0.6786151960784315, f_beta: 0.6803977272727273\n",
      "train: step: 4204, loss: 0.12345059216022491, acc: 0.984375, recall: 0.625, precision: 0.6213235294117647, f_beta: 0.6231060606060606\n",
      "train: step: 4205, loss: 0.029367052018642426, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7451923076923077, f_beta: 0.7426923076923078\n",
      "train: step: 4206, loss: 0.02612147107720375, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4207, loss: 0.0631670355796814, acc: 0.96875, recall: 0.7458333333333333, precision: 0.7139423076923077, f_beta: 0.7245114942528735\n",
      "train: step: 4208, loss: 0.012897019274532795, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4209, loss: 0.049530863761901855, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 4210, loss: 0.12162350118160248, acc: 0.953125, recall: 0.8395833333333333, precision: 0.8541666666666667, f_beta: 0.8423295454545454\n",
      "train: step: 4211, loss: 0.019564324989914894, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4212, loss: 0.02960481122136116, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 4213, loss: 0.01685950718820095, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4214, loss: 0.011307256296277046, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4215, loss: 0.06431499868631363, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 4216, loss: 0.1251663863658905, acc: 0.96875, recall: 0.6796875, precision: 0.6510416666666667, f_beta: 0.6619047619047619\n",
      "train: step: 4217, loss: 0.08882157504558563, acc: 0.96875, recall: 0.9041666666666667, precision: 0.921875, f_beta: 0.9091269841269842\n",
      "train: step: 4218, loss: 0.006762070115655661, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4219, loss: 0.121493399143219, acc: 0.984375, recall: 0.7421875, precision: 0.7430555555555556, f_beta: 0.7421568627450981\n",
      "train: step: 4220, loss: 0.012892893515527248, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4221, loss: 0.02015017159283161, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4222, loss: 0.036086056381464005, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4223, loss: 0.008594878017902374, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4224, loss: 0.0939190536737442, acc: 0.984375, recall: 0.75, precision: 0.74375, f_beta: 0.7467105263157895\n",
      "train: step: 4225, loss: 0.05806265398859978, acc: 0.984375, recall: 0.7421875, precision: 0.7395833333333334, f_beta: 0.7401515151515151\n",
      "train: step: 4226, loss: 0.0486765056848526, acc: 0.984375, recall: 0.7916666666666666, precision: 0.7916666666666667, f_beta: 0.7875000000000001\n",
      "train: step: 4227, loss: 0.03305971622467041, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4228, loss: 0.044122371822595596, acc: 0.984375, recall: 0.684375, precision: 0.6785714285714286, f_beta: 0.6810897435897436\n",
      "train: step: 4229, loss: 0.07445017993450165, acc: 0.984375, recall: 0.8046875, precision: 0.8055555555555556, f_beta: 0.8046568627450981\n",
      "train: step: 4230, loss: 0.0206458680331707, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4231, loss: 0.03168746829032898, acc: 0.984375, recall: 0.6818181818181819, precision: 0.65625, f_beta: 0.6636904761904763\n",
      "train: step: 4232, loss: 0.016271397471427917, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4233, loss: 0.04135905206203461, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666666, f_beta: 0.7791666666666667\n",
      "train: step: 4234, loss: 0.006046531721949577, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4235, loss: 0.045888762921094894, acc: 0.96875, recall: 0.53125, precision: 0.5625, f_beta: 0.5416666666666667\n",
      "train: step: 4236, loss: 0.009117832407355309, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4237, loss: 0.036195166409015656, acc: 0.984375, recall: 0.6826923076923077, precision: 0.6875, f_beta: 0.685\n",
      "train: step: 4238, loss: 0.037513721734285355, acc: 0.984375, recall: 0.7291666666666666, precision: 0.734375, f_beta: 0.7285714285714285\n",
      "train: step: 4239, loss: 0.013865330256521702, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4240, loss: 0.057562559843063354, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 4241, loss: 0.17278264462947845, acc: 0.953125, recall: 0.5989583333333334, precision: 0.59375, f_beta: 0.5897934491400917\n",
      "train: step: 4242, loss: 0.11132604628801346, acc: 0.984375, recall: 0.6770833333333334, precision: 0.65625, f_beta: 0.6609848484848484\n",
      "train: step: 4243, loss: 0.1611936390399933, acc: 0.953125, recall: 0.6875, precision: 0.7118055555555556, f_beta: 0.6838235294117646\n",
      "train: step: 4244, loss: 0.02453252673149109, acc: 0.984375, recall: 0.75, precision: 0.7291666666666666, f_beta: 0.7375\n",
      "train: step: 4245, loss: 0.03511596843600273, acc: 0.984375, recall: 0.8541666666666667, precision: 0.8645833333333333, f_beta: 0.8568181818181818\n",
      "train: step: 4246, loss: 0.02209678292274475, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4247, loss: 0.008106974884867668, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4248, loss: 0.03573472797870636, acc: 0.96875, recall: 0.6766098484848485, precision: 0.6505681818181819, f_beta: 0.6582674571805007\n",
      "train: step: 4249, loss: 0.008270693011581898, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4250, loss: 0.04080694168806076, acc: 0.984375, recall: 0.74375, precision: 0.7395833333333334, f_beta: 0.7410287081339713\n",
      "train: step: 4251, loss: 0.004139984026551247, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4252, loss: 0.0027256901375949383, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4253, loss: 0.0295167975127697, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666666\n",
      "train: step: 4254, loss: 0.004307494033128023, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4255, loss: 0.05751441791653633, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 4256, loss: 0.05870243161916733, acc: 0.984375, recall: 0.7916666666666666, precision: 0.7916666666666666, f_beta: 0.7875\n",
      "train: step: 4257, loss: 0.0053690774366259575, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4258, loss: 0.0075427470728755, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4259, loss: 0.18565452098846436, acc: 0.9375, recall: 0.649702380952381, precision: 0.6255208333333333, f_beta: 0.6337962962962963\n",
      "train: step: 4260, loss: 0.006847241893410683, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4261, loss: 0.005112683400511742, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4262, loss: 0.08444127440452576, acc: 0.96875, recall: 0.7838541666666666, precision: 0.7864583333333333, f_beta: 0.7806159420289857\n",
      "train: step: 4263, loss: 0.011705531738698483, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4264, loss: 0.04799332842230797, acc: 0.96875, recall: 0.65625, precision: 0.65625, f_beta: 0.6458333333333333\n",
      "train: step: 4265, loss: 0.005803617183119059, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4266, loss: 0.09069788455963135, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 4267, loss: 0.035638775676488876, acc: 0.984375, recall: 0.7916666666666666, precision: 0.80625, f_beta: 0.7967105263157895\n",
      "train: step: 4268, loss: 0.030951477587223053, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 4269, loss: 0.02684113010764122, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4270, loss: 0.018179090693593025, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4271, loss: 0.004936167038977146, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4272, loss: 0.014668918214738369, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4273, loss: 0.0787515640258789, acc: 0.984375, recall: 0.6197916666666667, precision: 0.6193181818181819, f_beta: 0.6193064182194616\n",
      "train: step: 4274, loss: 0.045263051986694336, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4275, loss: 0.1083124577999115, acc: 0.96875, recall: 0.6505681818181819, precision: 0.68125, f_beta: 0.6604010025062657\n",
      "train: step: 4276, loss: 0.03718649595975876, acc: 0.984375, recall: 0.7447916666666667, precision: 0.7455357142857143, f_beta: 0.7449677938808373\n",
      "train: step: 4277, loss: 0.039859555661678314, acc: 0.984375, recall: 0.71875, precision: 0.7410714285714286, f_beta: 0.7243589743589745\n",
      "train: step: 4278, loss: 0.03488679975271225, acc: 0.984375, recall: 0.7455357142857143, precision: 0.75, f_beta: 0.7476851851851852\n",
      "train: step: 4279, loss: 0.07273077964782715, acc: 0.984375, recall: 0.6818181818181819, precision: 0.6875, f_beta: 0.6845238095238095\n",
      "train: step: 4280, loss: 0.03797171637415886, acc: 0.984375, recall: 0.8125, precision: 0.8020833333333334, f_beta: 0.8068181818181819\n",
      "train: step: 4281, loss: 0.04035413637757301, acc: 0.984375, recall: 0.6875, precision: 0.6785714285714286, f_beta: 0.6826923076923077\n",
      "train: step: 4282, loss: 0.006757121533155441, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4283, loss: 0.03799035772681236, acc: 0.96875, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333334\n",
      "train: step: 4284, loss: 0.12753628194332123, acc: 0.984375, recall: 0.8625, precision: 0.859375, f_beta: 0.8591269841269841\n",
      "start training model\n",
      "train: step: 4285, loss: 0.19139748811721802, acc: 0.96875, recall: 0.6785714285714286, precision: 0.6748798076923077, f_beta: 0.6760256410256411\n",
      "train: step: 4286, loss: 0.012372201308608055, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4287, loss: 0.011363133788108826, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4288, loss: 0.00965055450797081, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4289, loss: 0.006345444358885288, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4290, loss: 0.0017172035295516253, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4291, loss: 0.00833725556731224, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4292, loss: 0.004412086680531502, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4293, loss: 0.057380035519599915, acc: 0.984375, recall: 0.921875, precision: 0.9305555555555556, f_beta: 0.9248949579831933\n",
      "train: step: 4294, loss: 0.0030162311159074306, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4295, loss: 0.021162014454603195, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4296, loss: 0.028819961473345757, acc: 0.984375, recall: 0.55, precision: 0.5625, f_beta: 0.5555555555555556\n",
      "train: step: 4297, loss: 0.022248417139053345, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4298, loss: 0.011031403206288815, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4299, loss: 0.012314846739172935, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4300, loss: 0.03590826690196991, acc: 0.984375, recall: 0.7443181818181818, precision: 0.75, f_beta: 0.7470238095238095\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:46:46.320784, step: 4300, loss: 7.274563047620985, acc: 0.16145833333333334,precision: 0.07610985657860657, recall: 0.09149191857525191, f_beta: 0.0771036312401514\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4300\n",
      "\n",
      "train: step: 4301, loss: 0.03038201481103897, acc: 0.984375, recall: 0.8125, precision: 0.8020833333333334, f_beta: 0.8068181818181819\n",
      "train: step: 4302, loss: 0.0019742778968065977, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4303, loss: 0.012572266161441803, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4304, loss: 0.03206959366798401, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7421875, f_beta: 0.7410256410256411\n",
      "train: step: 4305, loss: 0.0028131469152867794, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4306, loss: 0.01411758828908205, acc: 0.984375, recall: 0.7375, precision: 0.7447916666666666, f_beta: 0.7403381642512078\n",
      "train: step: 4307, loss: 0.0059967334382236, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4308, loss: 0.0025199097581207752, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4309, loss: 0.003633867483586073, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4310, loss: 0.047752633690834045, acc: 0.984375, recall: 0.90625, precision: 0.921875, f_beta: 0.9077380952380952\n",
      "train: step: 4311, loss: 0.03469589352607727, acc: 0.984375, recall: 0.90625, precision: 0.9270833333333334, f_beta: 0.9109848484848484\n",
      "train: step: 4312, loss: 0.006652188953012228, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4313, loss: 0.03507073596119881, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7291666666666667, f_beta: 0.725\n",
      "train: step: 4314, loss: 0.02918214350938797, acc: 0.984375, recall: 0.9375, precision: 0.90625, f_beta: 0.9166666666666666\n",
      "train: step: 4315, loss: 0.01133333332836628, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4316, loss: 0.009420281276106834, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4317, loss: 0.020927220582962036, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4318, loss: 0.01733270101249218, acc: 0.984375, recall: 0.8020833333333334, precision: 0.78125, f_beta: 0.7859848484848485\n",
      "train: step: 4319, loss: 0.010218226350843906, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4320, loss: 0.05413064360618591, acc: 0.984375, recall: 0.78125, precision: 0.8, f_beta: 0.7847222222222222\n",
      "train: step: 4321, loss: 0.04920196905732155, acc: 0.984375, recall: 0.6666666666666666, precision: 0.65625, f_beta: 0.6541666666666667\n",
      "train: step: 4322, loss: 0.005676619708538055, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4323, loss: 0.004613373428583145, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4324, loss: 0.0022244066931307316, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4325, loss: 0.003652836661785841, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4326, loss: 0.06096494197845459, acc: 0.96875, recall: 0.7139423076923077, precision: 0.74609375, f_beta: 0.7246505376344086\n",
      "train: step: 4327, loss: 0.0025472682900726795, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4328, loss: 0.017969302833080292, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4329, loss: 0.0030484467279165983, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4330, loss: 0.04564275965094566, acc: 0.984375, recall: 0.8035714285714286, precision: 0.8046875, f_beta: 0.8035256410256411\n",
      "train: step: 4331, loss: 0.009859609417617321, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4332, loss: 0.006004186347126961, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4333, loss: 0.03193555027246475, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4334, loss: 0.0190881434828043, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4335, loss: 0.057433582842350006, acc: 0.96875, recall: 0.7291666666666666, precision: 0.7252604166666667, f_beta: 0.7238379082348226\n",
      "train: step: 4336, loss: 0.054893989115953445, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 4337, loss: 0.0028932224959135056, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4338, loss: 0.016645018011331558, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4339, loss: 0.003534761955961585, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4340, loss: 0.012506227940320969, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4341, loss: 0.006916441023349762, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4342, loss: 0.005948713980615139, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4343, loss: 0.003668087301775813, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4344, loss: 0.005483281798660755, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4345, loss: 0.03682175278663635, acc: 0.984375, recall: 0.71875, precision: 0.7447916666666666, f_beta: 0.7264492753623187\n",
      "train: step: 4346, loss: 0.0809364765882492, acc: 0.96875, recall: 0.85, precision: 0.8612637362637363, f_beta: 0.8520673076923078\n",
      "train: step: 4347, loss: 0.005627675913274288, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4348, loss: 0.010483530350029469, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4349, loss: 0.001398114487528801, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4350, loss: 0.04979006201028824, acc: 0.96875, recall: 0.7291666666666667, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 4351, loss: 0.002947472268715501, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4352, loss: 0.004047946538776159, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4353, loss: 0.0031882822513580322, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4354, loss: 0.006633030250668526, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4355, loss: 0.02965335175395012, acc: 0.984375, recall: 0.8125, precision: 0.8020833333333334, f_beta: 0.8068181818181819\n",
      "train: step: 4356, loss: 0.07338060438632965, acc: 0.984375, recall: 0.8125, precision: 0.8035714285714286, f_beta: 0.8076923076923077\n",
      "train: step: 4357, loss: 0.006088683381676674, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4358, loss: 0.003961439244449139, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4359, loss: 0.0069298893213272095, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4360, loss: 0.030231934040784836, acc: 0.984375, recall: 0.7430555555555556, precision: 0.734375, f_beta: 0.7373949579831933\n",
      "train: step: 4361, loss: 0.14614471793174744, acc: 0.953125, recall: 0.6692708333333334, precision: 0.671875, f_beta: 0.6687229437229437\n",
      "train: step: 4362, loss: 0.0807669386267662, acc: 0.96875, recall: 0.7380681818181819, precision: 0.7202380952380953, f_beta: 0.7264266435319068\n",
      "train: step: 4363, loss: 0.03228725492954254, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 4364, loss: 0.019292179495096207, acc: 0.984375, recall: 0.71875, precision: 0.734375, f_beta: 0.7202380952380952\n",
      "train: step: 4365, loss: 0.002731290413066745, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4366, loss: 0.029908934608101845, acc: 0.984375, recall: 0.80625, precision: 0.8068181818181818, f_beta: 0.806234335839599\n",
      "train: step: 4367, loss: 0.05015432834625244, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 4368, loss: 0.05888371542096138, acc: 0.984375, recall: 0.671875, precision: 0.65625, f_beta: 0.6577380952380952\n",
      "start training model\n",
      "train: step: 4369, loss: 0.049984753131866455, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8020833333333334, f_beta: 0.7943181818181818\n",
      "train: step: 4370, loss: 0.06680964678525925, acc: 0.96875, recall: 0.6125, precision: 0.6123949579831933, f_beta: 0.6113539238539238\n",
      "train: step: 4371, loss: 0.032528262585401535, acc: 0.984375, recall: 0.6875, precision: 0.6826923076923077, f_beta: 0.685\n",
      "train: step: 4372, loss: 0.009005038067698479, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4373, loss: 0.13574087619781494, acc: 0.96875, recall: 0.5989583333333333, precision: 0.6118055555555556, f_beta: 0.6028166644232064\n",
      "train: step: 4374, loss: 0.1053275465965271, acc: 0.96875, recall: 0.7135416666666666, precision: 0.7430555555555556, f_beta: 0.7248949579831934\n",
      "train: step: 4375, loss: 0.014706771820783615, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4376, loss: 0.06547398120164871, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666667\n",
      "train: step: 4377, loss: 0.1873246133327484, acc: 0.9375, recall: 0.7, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 4378, loss: 0.05383112281560898, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4379, loss: 0.009618369862437248, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4380, loss: 0.026131028309464455, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4381, loss: 0.09988963603973389, acc: 0.96875, recall: 0.7916666666666666, precision: 0.765625, f_beta: 0.7702380952380952\n",
      "train: step: 4382, loss: 0.1919795274734497, acc: 0.96875, recall: 0.7234848484848484, precision: 0.75, f_beta: 0.7345238095238096\n",
      "train: step: 4383, loss: 0.030994173139333725, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4384, loss: 0.11804787069559097, acc: 0.953125, recall: 0.8363095238095237, precision: 0.84375, f_beta: 0.83125\n",
      "train: step: 4385, loss: 0.05937608331441879, acc: 0.96875, recall: 0.7979166666666667, precision: 0.7942708333333333, f_beta: 0.7948145245559037\n",
      "train: step: 4386, loss: 0.014412506483495235, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4387, loss: 0.037035487592220306, acc: 0.96875, recall: 0.58125, precision: 0.6004901960784313, f_beta: 0.5828282828282829\n",
      "train: step: 4388, loss: 0.019855214282870293, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666666\n",
      "train: step: 4389, loss: 0.0634797066450119, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4390, loss: 0.05112919583916664, acc: 0.96875, recall: 0.6875, precision: 0.6493055555555556, f_beta: 0.6629901960784313\n",
      "train: step: 4391, loss: 0.031399525701999664, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4392, loss: 0.08691056817770004, acc: 0.953125, recall: 0.6666666666666667, precision: 0.6618303571428571, f_beta: 0.6604166666666668\n",
      "train: step: 4393, loss: 0.05002614110708237, acc: 0.96875, recall: 0.78125, precision: 0.796875, f_beta: 0.7827380952380953\n",
      "train: step: 4394, loss: 0.07783149927854538, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848485\n",
      "train: step: 4395, loss: 0.09642671793699265, acc: 0.953125, recall: 0.7430555555555556, precision: 0.7840277777777778, f_beta: 0.7507159760455906\n",
      "train: step: 4396, loss: 0.05018305778503418, acc: 0.984375, recall: 0.75, precision: 0.74375, f_beta: 0.7467105263157895\n",
      "train: step: 4397, loss: 0.026893209666013718, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848485\n",
      "train: step: 4398, loss: 0.043767184019088745, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6666666666666666, f_beta: 0.6625\n",
      "train: step: 4399, loss: 0.0218118354678154, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4400, loss: 0.08384649455547333, acc: 0.953125, recall: 0.6160714285714286, precision: 0.665625, f_beta: 0.6288075959128591\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:48:37.561248, step: 4400, loss: 7.3434296713935, acc: 0.16319444444444445,precision: 0.08147768115599, recall: 0.09122180309132062, f_beta: 0.0737533859299347\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4400\n",
      "\n",
      "train: step: 4401, loss: 0.0456983745098114, acc: 0.984375, recall: 0.7458333333333333, precision: 0.7291666666666667, f_beta: 0.7353448275862069\n",
      "train: step: 4402, loss: 0.06561347842216492, acc: 0.984375, recall: 0.8125, precision: 0.8035714285714286, f_beta: 0.8076923076923077\n",
      "train: step: 4403, loss: 0.03635019063949585, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7443181818181818, f_beta: 0.7345238095238096\n",
      "train: step: 4404, loss: 0.007458741310983896, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4405, loss: 0.014803767204284668, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4406, loss: 0.057005107402801514, acc: 0.984375, recall: 0.7458333333333333, precision: 0.71875, f_beta: 0.7270114942528735\n",
      "train: step: 4407, loss: 0.06772982329130173, acc: 0.984375, recall: 0.625, precision: 0.6125, f_beta: 0.6180555555555556\n",
      "train: step: 4408, loss: 0.021081626415252686, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4409, loss: 0.16427582502365112, acc: 0.953125, recall: 0.6404605263157894, precision: 0.6041666666666666, f_beta: 0.6142830330330331\n",
      "train: step: 4410, loss: 0.03508811444044113, acc: 0.984375, recall: 0.7395833333333334, precision: 0.71875, f_beta: 0.7234848484848485\n",
      "train: step: 4411, loss: 0.017355363816022873, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4412, loss: 0.035627417266368866, acc: 0.984375, recall: 0.68125, precision: 0.6796875, f_beta: 0.6800438596491228\n",
      "train: step: 4413, loss: 0.00773241650313139, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4414, loss: 0.05426202341914177, acc: 0.984375, recall: 0.71875, precision: 0.7395833333333334, f_beta: 0.7234848484848485\n",
      "train: step: 4415, loss: 0.02432141825556755, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4416, loss: 0.09572522342205048, acc: 0.96875, recall: 0.8676470588235294, precision: 0.8602430555555556, f_beta: 0.8632506127450981\n",
      "train: step: 4417, loss: 0.008228017948567867, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4418, loss: 0.11009593307971954, acc: 0.96875, recall: 0.7443181818181819, precision: 0.7375, f_beta: 0.7400793650793651\n",
      "train: step: 4419, loss: 0.01378498412668705, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4420, loss: 0.139016255736351, acc: 0.96875, recall: 0.9214015151515151, precision: 0.9227430555555556, f_beta: 0.9209988540870894\n",
      "train: step: 4421, loss: 0.009120330214500427, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4422, loss: 0.005064645316451788, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4423, loss: 0.008245532400906086, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4424, loss: 0.04849373549222946, acc: 0.96875, recall: 0.7338235294117647, precision: 0.7130681818181818, f_beta: 0.7173520923520924\n",
      "train: step: 4425, loss: 0.008326014503836632, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4426, loss: 0.01788533478975296, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4427, loss: 0.013269071467220783, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4428, loss: 0.01685028336942196, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4429, loss: 0.027152983471751213, acc: 0.96875, recall: 0.59375, precision: 0.609375, f_beta: 0.5952380952380951\n",
      "train: step: 4430, loss: 0.025621958076953888, acc: 0.984375, recall: 0.78125, precision: 0.80859375, f_beta: 0.7896505376344085\n",
      "train: step: 4431, loss: 0.032981567084789276, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4432, loss: 0.05472971498966217, acc: 0.96875, recall: 0.7955357142857143, precision: 0.78125, f_beta: 0.7824074074074074\n",
      "train: step: 4433, loss: 0.04250276833772659, acc: 0.984375, recall: 0.6796875, precision: 0.6666666666666666, f_beta: 0.6708333333333334\n",
      "train: step: 4434, loss: 0.023135460913181305, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4435, loss: 0.014905627816915512, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4436, loss: 0.012296808883547783, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4437, loss: 0.032267335802316666, acc: 0.984375, recall: 0.6770833333333333, precision: 0.6666666666666666, f_beta: 0.6693181818181819\n",
      "train: step: 4438, loss: 0.010816228576004505, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4439, loss: 0.07218167185783386, acc: 0.953125, recall: 0.7073863636363636, precision: 0.7273065476190477, f_beta: 0.710753367003367\n",
      "train: step: 4440, loss: 0.007144835777580738, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4441, loss: 0.015273592434823513, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4442, loss: 0.12634384632110596, acc: 0.96875, recall: 0.7375, precision: 0.7447916666666666, f_beta: 0.7403381642512078\n",
      "train: step: 4443, loss: 0.003923271782696247, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4444, loss: 0.054565008729696274, acc: 0.984375, recall: 0.78125, precision: 0.796875, f_beta: 0.7827380952380953\n",
      "train: step: 4445, loss: 0.007732110098004341, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4446, loss: 0.001622226438485086, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4447, loss: 0.10981900990009308, acc: 0.984375, recall: 0.796875, precision: 0.8083333333333333, f_beta: 0.8014162561576355\n",
      "train: step: 4448, loss: 0.007160888519138098, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4449, loss: 0.0104568125680089, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4450, loss: 0.04383391886949539, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4451, loss: 0.017730876803398132, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4452, loss: 0.1428380310535431, acc: 0.96875, recall: 0.8611111111111112, precision: 0.875, f_beta: 0.8671875\n",
      "start training model\n",
      "train: step: 4453, loss: 0.00611899234354496, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4454, loss: 0.08465094864368439, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666667\n",
      "train: step: 4455, loss: 0.014360730536282063, acc: 0.984375, recall: 0.6875, precision: 0.6770833333333334, f_beta: 0.6818181818181819\n",
      "train: step: 4456, loss: 0.006935588084161282, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4457, loss: 0.0037431474775075912, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4458, loss: 0.007531607057899237, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4459, loss: 0.03362215310335159, acc: 0.984375, recall: 0.8660714285714286, precision: 0.875, f_beta: 0.8701923076923077\n",
      "train: step: 4460, loss: 0.00609658844769001, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4461, loss: 0.06194658577442169, acc: 0.984375, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4462, loss: 0.0014733861899003386, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4463, loss: 0.016545988619327545, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4464, loss: 0.06301035732030869, acc: 0.953125, recall: 0.6729166666666667, precision: 0.6657366071428572, f_beta: 0.668905621630872\n",
      "train: step: 4465, loss: 0.054525647312402725, acc: 0.984375, recall: 0.8125, precision: 0.796875, f_beta: 0.8035714285714286\n",
      "train: step: 4466, loss: 0.04112403467297554, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 4467, loss: 0.0434550903737545, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7430555555555556, f_beta: 0.7338235294117648\n",
      "train: step: 4468, loss: 0.0016855141147971153, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4469, loss: 0.009080765768885612, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4470, loss: 0.09629681706428528, acc: 0.984375, recall: 0.7291666666666666, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 4471, loss: 0.05365496501326561, acc: 0.984375, recall: 0.8080357142857143, precision: 0.78125, f_beta: 0.789351851851852\n",
      "train: step: 4472, loss: 0.0013485932722687721, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4473, loss: 0.0048741125501692295, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4474, loss: 0.07051946967840195, acc: 0.984375, recall: 0.80625, precision: 0.8020833333333334, f_beta: 0.8035287081339714\n",
      "train: step: 4475, loss: 0.009768649935722351, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4476, loss: 0.009150158613920212, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4477, loss: 0.07985574752092361, acc: 0.984375, recall: 0.6785714285714286, precision: 0.6805555555555556, f_beta: 0.6790158371040724\n",
      "train: step: 4478, loss: 0.00531566608697176, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4479, loss: 0.05732647702097893, acc: 0.984375, recall: 0.75, precision: 0.7395833333333334, f_beta: 0.7443181818181819\n",
      "train: step: 4480, loss: 0.002163889352232218, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4481, loss: 0.028299013152718544, acc: 0.984375, recall: 0.8055555555555556, precision: 0.8035714285714286, f_beta: 0.8040158371040724\n",
      "train: step: 4482, loss: 0.01786382496356964, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4483, loss: 0.0015194799052551389, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4484, loss: 0.049458347260951996, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "train: step: 4485, loss: 0.009296094998717308, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4486, loss: 0.012564850971102715, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4487, loss: 0.051354728639125824, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4488, loss: 0.052173029631376266, acc: 0.96875, recall: 0.765625, precision: 0.7920673076923077, f_beta: 0.7713095238095238\n",
      "train: step: 4489, loss: 0.004698025528341532, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4490, loss: 0.005906048230826855, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4491, loss: 0.0006278129294514656, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4492, loss: 0.001524425228126347, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4493, loss: 0.0341353602707386, acc: 0.984375, recall: 0.7916666666666667, precision: 0.8125, f_beta: 0.8\n",
      "train: step: 4494, loss: 0.041827280074357986, acc: 0.984375, recall: 0.6171875, precision: 0.6180555555555556, f_beta: 0.6171568627450981\n",
      "train: step: 4495, loss: 0.009159011766314507, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4496, loss: 0.00900895893573761, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4497, loss: 0.011755384504795074, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4498, loss: 0.0062357173301279545, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4499, loss: 0.009845901280641556, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4500, loss: 0.08500752598047256, acc: 0.96875, recall: 0.734375, precision: 0.7375, f_beta: 0.7341269841269842\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:50:29.438733, step: 4500, loss: 7.546418401930067, acc: 0.1701388888888889,precision: 0.08358261705543053, recall: 0.08336662271695167, f_beta: 0.07342030274308765\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4500\n",
      "\n",
      "train: step: 4501, loss: 0.01994841918349266, acc: 0.984375, recall: 0.7421875, precision: 0.7455357142857143, f_beta: 0.7435185185185185\n",
      "train: step: 4502, loss: 0.04152864217758179, acc: 0.96875, recall: 0.703125, precision: 0.74609375, f_beta: 0.7182219662058371\n",
      "train: step: 4503, loss: 0.011267013847827911, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4504, loss: 0.003909631632268429, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4505, loss: 0.008983057923614979, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4506, loss: 0.001182999461889267, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4507, loss: 0.015094796195626259, acc: 0.984375, recall: 0.8705357142857143, precision: 0.859375, f_beta: 0.8637566137566138\n",
      "train: step: 4508, loss: 0.0509205237030983, acc: 0.96875, recall: 0.6785714285714286, precision: 0.6696428571428572, f_beta: 0.672275641025641\n",
      "train: step: 4509, loss: 0.0321512371301651, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4510, loss: 0.0206094142049551, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4511, loss: 0.00333992438390851, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4512, loss: 0.03185639530420303, acc: 0.984375, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4513, loss: 0.02337777242064476, acc: 0.984375, recall: 0.8625, precision: 0.8680555555555556, f_beta: 0.8643790849673203\n",
      "train: step: 4514, loss: 0.006240644492208958, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4515, loss: 0.0037467104848474264, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4516, loss: 0.038149185478687286, acc: 0.984375, recall: 0.8035714285714286, precision: 0.8080357142857143, f_beta: 0.8053774928774929\n",
      "train: step: 4517, loss: 0.009982669726014137, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4518, loss: 0.0033029394689947367, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4519, loss: 0.0012549504172056913, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4520, loss: 0.022617541253566742, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4521, loss: 0.1030973345041275, acc: 0.984375, recall: 0.8020833333333334, precision: 0.796875, f_beta: 0.7978896103896104\n",
      "train: step: 4522, loss: 0.005463194102048874, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4523, loss: 0.018135618418455124, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4524, loss: 0.02591753751039505, acc: 0.984375, recall: 0.5520833333333334, precision: 0.5520833333333333, f_beta: 0.5511363636363636\n",
      "train: step: 4525, loss: 0.009334591217339039, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4526, loss: 0.09574147313833237, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7410714285714286, f_beta: 0.7326923076923078\n",
      "train: step: 4527, loss: 0.024642758071422577, acc: 0.984375, recall: 0.6041666666666666, precision: 0.621875, f_beta: 0.610897435897436\n",
      "train: step: 4528, loss: 0.0072691491805016994, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4529, loss: 0.07696114480495453, acc: 0.984375, recall: 0.71875, precision: 0.7291666666666666, f_beta: 0.7166666666666667\n",
      "train: step: 4530, loss: 0.11435293406248093, acc: 0.96875, recall: 0.875, precision: 0.8854166666666667, f_beta: 0.8624999999999999\n",
      "train: step: 4531, loss: 0.018073279410600662, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 4532, loss: 0.03686610236763954, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6796875, f_beta: 0.6708333333333334\n",
      "train: step: 4533, loss: 0.006975051946938038, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4534, loss: 0.018597284331917763, acc: 0.984375, recall: 0.859375, precision: 0.8625, f_beta: 0.8591269841269842\n",
      "train: step: 4535, loss: 0.029428785666823387, acc: 0.984375, recall: 0.6875, precision: 0.65625, f_beta: 0.6666666666666666\n",
      "train: step: 4536, loss: 0.01759498566389084, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 4537, loss: 0.01972251757979393, acc: 0.984375, recall: 0.8541666666666667, precision: 0.8705357142857143, f_beta: 0.8601851851851853\n",
      "train: step: 4538, loss: 0.004944288171827793, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4539, loss: 0.0048440746031701565, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4540, loss: 0.0008330472628585994, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4541, loss: 0.0018767057918012142, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4542, loss: 0.013833952136337757, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4543, loss: 0.005293753929436207, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4544, loss: 0.06786864250898361, acc: 0.984375, recall: 0.75, precision: 0.7291666666666667, f_beta: 0.7375\n",
      "train: step: 4545, loss: 0.08314981311559677, acc: 0.984375, recall: 0.71875, precision: 0.7447916666666666, f_beta: 0.7264492753623188\n",
      "train: step: 4546, loss: 0.037239182740449905, acc: 0.984375, recall: 0.7467105263157895, precision: 0.734375, f_beta: 0.7393822393822395\n",
      "train: step: 4547, loss: 0.0022624973207712173, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4548, loss: 0.01817496493458748, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4549, loss: 0.014424214139580727, acc: 0.984375, recall: 0.8, precision: 0.78125, f_beta: 0.7847222222222222\n",
      "train: step: 4550, loss: 0.003972282633185387, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4551, loss: 0.03446841612458229, acc: 0.984375, recall: 0.6785714285714286, precision: 0.65625, f_beta: 0.6618589743589743\n",
      "train: step: 4552, loss: 0.02914632484316826, acc: 0.984375, recall: 0.5572916666666667, precision: 0.5625, f_beta: 0.5597826086956521\n",
      "train: step: 4553, loss: 0.05605702847242355, acc: 0.96875, recall: 0.765625, precision: 0.784375, f_beta: 0.7668650793650793\n",
      "train: step: 4554, loss: 0.0030295460019260645, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4555, loss: 0.013193602673709393, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4556, loss: 0.004839438945055008, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4557, loss: 0.0032053773757070303, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4558, loss: 0.017439447343349457, acc: 0.984375, recall: 0.625, precision: 0.6220238095238095, f_beta: 0.6234756097560976\n",
      "train: step: 4559, loss: 0.0020814246963709593, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4560, loss: 0.017828620970249176, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4561, loss: 0.007935738191008568, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4562, loss: 0.03419756889343262, acc: 0.984375, recall: 0.71875, precision: 0.74609375, f_beta: 0.7271505376344085\n",
      "train: step: 4563, loss: 0.03592916950583458, acc: 0.984375, recall: 0.625, precision: 0.6215277777777778, f_beta: 0.6232142857142857\n",
      "train: step: 4564, loss: 0.027624987065792084, acc: 0.984375, recall: 0.80625, precision: 0.7916666666666667, f_beta: 0.7967105263157894\n",
      "train: step: 4565, loss: 0.00361022911965847, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4566, loss: 0.0032809977419674397, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4567, loss: 0.02964332327246666, acc: 0.984375, recall: 0.75, precision: 0.7375, f_beta: 0.7430555555555556\n",
      "train: step: 4568, loss: 0.0020280058961361647, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4569, loss: 0.0031094534788280725, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4570, loss: 0.0020264864433556795, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4571, loss: 0.0013313204981386662, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4572, loss: 0.0019195161294192076, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4573, loss: 0.015525998547673225, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 4574, loss: 0.011901838704943657, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4575, loss: 0.04943026974797249, acc: 0.984375, recall: 0.84375, precision: 0.8660714285714286, f_beta: 0.8493589743589743\n",
      "train: step: 4576, loss: 0.008281257003545761, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4577, loss: 0.009415635839104652, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4578, loss: 0.022833608090877533, acc: 0.984375, recall: 0.6875, precision: 0.6796875, f_beta: 0.6833333333333333\n",
      "train: step: 4579, loss: 0.007650736253708601, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4580, loss: 0.004172831773757935, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4581, loss: 0.03685620054602623, acc: 0.984375, recall: 0.925, precision: 0.921875, f_beta: 0.9216269841269842\n",
      "train: step: 4582, loss: 0.011559034697711468, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4583, loss: 0.004912877921015024, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4584, loss: 0.009894322603940964, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4585, loss: 0.0036494035739451647, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4586, loss: 0.006712537258863449, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4587, loss: 0.010527740232646465, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4588, loss: 0.002732174936681986, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4589, loss: 0.01681097410619259, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4590, loss: 0.06823248416185379, acc: 0.984375, recall: 0.7458333333333333, precision: 0.7447916666666667, f_beta: 0.7451274362818591\n",
      "train: step: 4591, loss: 0.019926736131310463, acc: 0.984375, recall: 0.6041666666666666, precision: 0.6160714285714286, f_beta: 0.6076923076923078\n",
      "train: step: 4592, loss: 0.0037118038162589073, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4593, loss: 0.06935557723045349, acc: 0.984375, recall: 0.7465277777777778, precision: 0.7421875, f_beta: 0.7440476190476191\n",
      "train: step: 4594, loss: 0.004081043414771557, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4595, loss: 0.022240756079554558, acc: 0.984375, recall: 0.75, precision: 0.74375, f_beta: 0.7467105263157895\n",
      "train: step: 4596, loss: 0.010704058222472668, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4597, loss: 0.0033257368486374617, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4598, loss: 0.01175185851752758, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4599, loss: 0.007510586641728878, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4600, loss: 0.0777587741613388, acc: 0.984375, recall: 0.6875, precision: 0.68125, f_beta: 0.6842105263157895\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:52:20.908283, step: 4600, loss: 7.420351134406196, acc: 0.18055555555555555,precision: 0.08265400129435217, recall: 0.08666559200937425, f_beta: 0.07947879356627603\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4600\n",
      "\n",
      "train: step: 4601, loss: 0.027186643332242966, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4602, loss: 0.047473303973674774, acc: 0.984375, recall: 0.8541666666666667, precision: 0.8697916666666666, f_beta: 0.8597826086956523\n",
      "train: step: 4603, loss: 0.16020040214061737, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 4604, loss: 0.00782863050699234, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4605, loss: 0.03514440730214119, acc: 0.984375, recall: 0.90625, precision: 0.90625, f_beta: 0.8958333333333333\n",
      "train: step: 4606, loss: 0.0020467559807002544, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4607, loss: 0.004385063890367746, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4608, loss: 0.0030378028750419617, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4609, loss: 0.0010677501559257507, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4610, loss: 0.0037443405017256737, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4611, loss: 0.01439973060041666, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4612, loss: 0.0024266561958938837, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4613, loss: 0.004024513065814972, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4614, loss: 0.05052313953638077, acc: 0.984375, recall: 0.75, precision: 0.734375, f_beta: 0.7410714285714286\n",
      "train: step: 4615, loss: 0.004142304882407188, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4616, loss: 0.007613562047481537, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4617, loss: 0.03382974490523338, acc: 0.984375, recall: 0.59375, precision: 0.625, f_beta: 0.6041666666666666\n",
      "train: step: 4618, loss: 0.004584303125739098, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4619, loss: 0.003151463344693184, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4620, loss: 0.005036282353103161, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 4621, loss: 0.0015691127628087997, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4622, loss: 0.0023799510672688484, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4623, loss: 0.005425176117569208, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4624, loss: 0.032032232731580734, acc: 0.984375, recall: 0.9791666666666666, precision: 0.96875, f_beta: 0.9666666666666667\n",
      "train: step: 4625, loss: 0.06295537948608398, acc: 0.984375, recall: 0.65625, precision: 0.65625, f_beta: 0.6458333333333333\n",
      "train: step: 4626, loss: 0.002415468916296959, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4627, loss: 0.03201078623533249, acc: 0.984375, recall: 0.8541666666666667, precision: 0.859375, f_beta: 0.8535714285714286\n",
      "train: step: 4628, loss: 0.014956575818359852, acc: 0.984375, recall: 0.5625, precision: 0.53125, f_beta: 0.5416666666666666\n",
      "train: step: 4629, loss: 0.010082220658659935, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4630, loss: 0.07989276200532913, acc: 0.984375, recall: 0.8035714285714286, precision: 0.796875, f_beta: 0.7987637362637362\n",
      "train: step: 4631, loss: 0.012111995369195938, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4632, loss: 0.0027070259675383568, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4633, loss: 0.06900586187839508, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 4634, loss: 0.0207278523594141, acc: 0.984375, recall: 0.78125, precision: 0.8072916666666666, f_beta: 0.7889492753623188\n",
      "train: step: 4635, loss: 0.014435905031859875, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4636, loss: 0.0011864292901009321, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4637, loss: 0.006507491692900658, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4638, loss: 0.019410721957683563, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4639, loss: 0.004502265248447657, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4640, loss: 0.008167974650859833, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4641, loss: 0.027322549372911453, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7465277777777778, f_beta: 0.7434065934065934\n",
      "train: step: 4642, loss: 0.06592082232236862, acc: 0.984375, recall: 0.7421875, precision: 0.7430555555555556, f_beta: 0.7421568627450981\n",
      "train: step: 4643, loss: 0.037796273827552795, acc: 0.96875, recall: 0.7395833333333334, precision: 0.7375, f_beta: 0.7373737373737373\n",
      "train: step: 4644, loss: 0.0033667406532913446, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4645, loss: 0.04961870610713959, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666667, f_beta: 0.7791666666666667\n",
      "train: step: 4646, loss: 0.0015543237095698714, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4647, loss: 0.001024753786623478, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4648, loss: 0.0022660833783447742, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4649, loss: 0.003981881774961948, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4650, loss: 0.0028259726241230965, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4651, loss: 0.020955149084329605, acc: 0.984375, recall: 0.78125, precision: 0.796875, f_beta: 0.7827380952380952\n",
      "train: step: 4652, loss: 0.022946065291762352, acc: 0.984375, recall: 0.7430555555555556, precision: 0.74609375, f_beta: 0.7443074003795067\n",
      "train: step: 4653, loss: 0.003318402450531721, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4654, loss: 0.0046555050648748875, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4655, loss: 0.0396985225379467, acc: 0.984375, recall: 0.80625, precision: 0.796875, f_beta: 0.8002819548872181\n",
      "train: step: 4656, loss: 0.018291091546416283, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4657, loss: 0.004326466470956802, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4658, loss: 0.007189818657934666, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4659, loss: 0.0030503892339766026, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4660, loss: 0.0014228725340217352, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4661, loss: 0.015879768878221512, acc: 0.984375, recall: 0.734375, precision: 0.7291666666666667, f_beta: 0.7285714285714286\n",
      "train: step: 4662, loss: 0.002889767987653613, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4663, loss: 0.033954866230487823, acc: 0.984375, recall: 0.796875, precision: 0.8125, f_beta: 0.8035714285714286\n",
      "train: step: 4664, loss: 0.021406514570116997, acc: 0.984375, recall: 0.734375, precision: 0.7451923076923077, f_beta: 0.7385714285714287\n",
      "train: step: 4665, loss: 0.002256574109196663, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4666, loss: 0.0029746592044830322, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4667, loss: 0.01232224702835083, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4668, loss: 0.015258396044373512, acc: 0.984375, recall: 0.8035714285714286, precision: 0.80859375, f_beta: 0.8056761786600497\n",
      "train: step: 4669, loss: 0.0019139207433909178, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4670, loss: 0.00579568836838007, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4671, loss: 0.006185480393469334, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4672, loss: 0.0007584533304907382, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4673, loss: 0.06829440593719482, acc: 0.984375, recall: 0.8693181818181818, precision: 0.87109375, f_beta: 0.8700076804915515\n",
      "train: step: 4674, loss: 0.032025307416915894, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 4675, loss: 0.00702922698110342, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4676, loss: 0.002023551380261779, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4677, loss: 0.0008078102255240083, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4678, loss: 0.004733687732368708, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4679, loss: 0.00259906193241477, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4680, loss: 0.015397333540022373, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 4681, loss: 0.0641455128788948, acc: 0.984375, recall: 0.5590277777777778, precision: 0.5625, f_beta: 0.5607142857142857\n",
      "train: step: 4682, loss: 0.03207328915596008, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4683, loss: 0.005849120672792196, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4684, loss: 0.002561497502028942, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4685, loss: 0.0006933142431080341, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4686, loss: 0.0013734637759625912, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4687, loss: 0.0035094632767140865, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4688, loss: 0.001541067729704082, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4689, loss: 0.001665762159973383, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4690, loss: 0.04911206290125847, acc: 0.984375, recall: 0.7916666666666666, precision: 0.7916666666666667, f_beta: 0.7875\n",
      "train: step: 4691, loss: 0.001213832525536418, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4692, loss: 0.0026662726886570454, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4693, loss: 0.0022233512718230486, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4694, loss: 0.010918204672634602, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4695, loss: 0.002501521725207567, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4696, loss: 0.0012608462711796165, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4697, loss: 0.011072874069213867, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4698, loss: 0.0006878736894577742, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4699, loss: 0.0031067896634340286, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4700, loss: 0.00425580283626914, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:54:13.295645, step: 4700, loss: 7.767429828643799, acc: 0.1909722222222222,precision: 0.08779676886294532, recall: 0.09905148093841334, f_beta: 0.0866396239587805\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4700\n",
      "\n",
      "train: step: 4701, loss: 0.0024589612148702145, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4702, loss: 0.012460029684007168, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4703, loss: 0.018799500539898872, acc: 0.984375, recall: 0.7916666666666667, precision: 0.78125, f_beta: 0.7791666666666666\n",
      "train: step: 4704, loss: 0.003003764431923628, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 4705, loss: 0.0012791779590770602, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4706, loss: 0.001787481945939362, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4707, loss: 0.0008477492374368012, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4708, loss: 0.0013031999114900827, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4709, loss: 0.0015580921899527311, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4710, loss: 0.0034326943568885326, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4711, loss: 0.0186172965914011, acc: 0.984375, recall: 0.75, precision: 0.7291666666666666, f_beta: 0.7375\n",
      "train: step: 4712, loss: 0.040425341576337814, acc: 0.984375, recall: 0.625, precision: 0.6125, f_beta: 0.6180555555555556\n",
      "train: step: 4713, loss: 0.0008971187053248286, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4714, loss: 0.0018049766076728702, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4715, loss: 0.0011246406938880682, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4716, loss: 0.0036795628257095814, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4717, loss: 0.0014083776623010635, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4718, loss: 0.002769774291664362, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4719, loss: 0.0018529384396970272, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4720, loss: 0.0012169801630079746, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4721, loss: 0.01861080899834633, acc: 0.984375, recall: 0.7916666666666666, precision: 0.8125, f_beta: 0.8\n",
      "train: step: 4722, loss: 0.0013258950784802437, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4723, loss: 0.03210796043276787, acc: 0.984375, recall: 0.90625, precision: 0.9305555555555556, f_beta: 0.9129901960784313\n",
      "train: step: 4724, loss: 0.001198985381051898, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4725, loss: 0.0016496296739205718, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4726, loss: 0.005911609157919884, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4727, loss: 0.002301593078300357, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4728, loss: 0.0007499008206650615, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4729, loss: 0.0015051717637106776, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4730, loss: 0.01742728427052498, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4731, loss: 0.01670524850487709, acc: 0.984375, recall: 0.75, precision: 0.7291666666666666, f_beta: 0.7375\n",
      "train: step: 4732, loss: 0.0037233156617730856, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4733, loss: 0.01168347429484129, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4734, loss: 0.0014429580187425017, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4735, loss: 0.0005410458543337882, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4736, loss: 0.0032750293612480164, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4737, loss: 0.01099334191530943, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4738, loss: 0.002244015224277973, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4739, loss: 0.003956412896513939, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4740, loss: 0.0023634519893676043, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4741, loss: 0.014459881000220776, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4742, loss: 0.0019470418337732553, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4743, loss: 0.013977901078760624, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4744, loss: 0.001040200935676694, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4745, loss: 0.0015846407040953636, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4746, loss: 0.01950463280081749, acc: 0.984375, recall: 0.6041666666666667, precision: 0.6160714285714286, f_beta: 0.6076923076923078\n",
      "train: step: 4747, loss: 0.0008592833764851093, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4748, loss: 0.004024603869765997, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4749, loss: 0.0067026251927018166, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4750, loss: 0.005269388202577829, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4751, loss: 0.0029986503068357706, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4752, loss: 0.02256890945136547, acc: 0.984375, recall: 0.6830357142857143, precision: 0.6666666666666666, f_beta: 0.6726851851851852\n",
      "train: step: 4753, loss: 0.000980486162006855, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4754, loss: 0.0009269795846194029, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4755, loss: 0.0019043131032958627, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4756, loss: 0.001590345986187458, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4757, loss: 0.006941110827028751, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4758, loss: 0.01694061979651451, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4759, loss: 0.0026298186276108027, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4760, loss: 0.006236109416931868, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4761, loss: 0.03302856534719467, acc: 0.984375, recall: 0.7447916666666667, precision: 0.7430555555555556, f_beta: 0.7436061381074168\n",
      "train: step: 4762, loss: 0.014366162940859795, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4763, loss: 0.0013513395097106695, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4764, loss: 0.0025807213969528675, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4765, loss: 0.013089794665575027, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4766, loss: 0.0026572663336992264, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4767, loss: 0.008417193777859211, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4768, loss: 0.035810813307762146, acc: 0.984375, recall: 0.734375, precision: 0.7463235294117647, f_beta: 0.7391774891774892\n",
      "train: step: 4769, loss: 0.013907959684729576, acc: 0.984375, recall: 0.8068181818181818, precision: 0.8035714285714286, f_beta: 0.8047161172161172\n",
      "train: step: 4770, loss: 0.0013023169012740254, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4771, loss: 0.009816830977797508, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4772, loss: 0.006353611126542091, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4773, loss: 0.023724712431430817, acc: 0.984375, recall: 0.675, precision: 0.6666666666666666, f_beta: 0.6680555555555556\n",
      "train: step: 4774, loss: 0.004050441551953554, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4775, loss: 0.004751075059175491, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4776, loss: 0.044591691344976425, acc: 0.984375, recall: 0.7443181818181818, precision: 0.734375, f_beta: 0.7380952380952381\n",
      "train: step: 4777, loss: 0.038247160613536835, acc: 0.96875, recall: 0.6541666666666667, precision: 0.671875, f_beta: 0.6591269841269842\n",
      "train: step: 4778, loss: 0.003533594775944948, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4779, loss: 0.020936086773872375, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7395833333333334, f_beta: 0.7386363636363635\n",
      "train: step: 4780, loss: 0.0218396857380867, acc: 0.984375, recall: 0.80625, precision: 0.8083333333333333, f_beta: 0.8070553539019963\n",
      "train: step: 4781, loss: 0.007979318499565125, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4782, loss: 0.1471971571445465, acc: 0.984375, recall: 0.68125, precision: 0.6875, f_beta: 0.6842105263157895\n",
      "train: step: 4783, loss: 0.05021177604794502, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 4784, loss: 0.0031137100886553526, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4785, loss: 0.002055593067780137, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4786, loss: 0.019589805975556374, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4787, loss: 0.06310266256332397, acc: 0.984375, recall: 0.6842105263157895, precision: 0.6822916666666667, f_beta: 0.683093419506463\n",
      "train: step: 4788, loss: 0.00970709789544344, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 4789, loss: 0.004758047871291637, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4790, loss: 0.0028905037324875593, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4791, loss: 0.008236231282353401, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4792, loss: 0.003373595653101802, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4793, loss: 0.006827216595411301, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4794, loss: 0.0017015562625601888, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4795, loss: 0.005641763098537922, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4796, loss: 0.00479495944455266, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4797, loss: 0.0674150288105011, acc: 0.984375, recall: 0.7430555555555556, precision: 0.7465277777777778, f_beta: 0.7445378151260504\n",
      "train: step: 4798, loss: 0.022969359531998634, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4799, loss: 0.02837360091507435, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 4800, loss: 0.04662363603711128, acc: 0.96875, recall: 0.7930555555555555, precision: 0.7760416666666667, f_beta: 0.7804505135387488\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:56:05.957507, step: 4800, loss: 7.671110047234429, acc: 0.1684027777777778,precision: 0.08236055996472663, recall: 0.08403374947492595, f_beta: 0.0747756287793859\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4800\n",
      "\n",
      "train: step: 4801, loss: 0.0037631047889590263, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4802, loss: 0.0076818992383778095, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4803, loss: 0.006465166341513395, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4804, loss: 0.0012189627159386873, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4805, loss: 0.0032689126674085855, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4806, loss: 0.0007497190963476896, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4807, loss: 0.005166006274521351, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4808, loss: 0.03370660915970802, acc: 0.984375, recall: 0.6830357142857143, precision: 0.6818181818181819, f_beta: 0.6822089947089947\n",
      "train: step: 4809, loss: 0.002778882160782814, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4810, loss: 0.0028663671109825373, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4811, loss: 0.0023331549018621445, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4812, loss: 0.0007029883563518524, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4813, loss: 0.004001131281256676, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4814, loss: 0.0010066626127809286, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4815, loss: 0.0012369259493425488, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4816, loss: 0.0019590251613408327, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4817, loss: 0.003967872355133295, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4818, loss: 0.0021283691748976707, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4819, loss: 0.0017022080719470978, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4820, loss: 0.0009062390308827162, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4821, loss: 0.0038890554569661617, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4822, loss: 0.010675230994820595, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4823, loss: 0.0038459422066807747, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4824, loss: 0.005852890200912952, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4825, loss: 0.008114243857562542, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4826, loss: 0.0012665928807109594, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4827, loss: 0.009471050463616848, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4828, loss: 0.003911642357707024, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4829, loss: 0.0008648502989672124, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4830, loss: 0.0036075322423130274, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4831, loss: 0.0064152199774980545, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4832, loss: 0.006766356527805328, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4833, loss: 0.000603711639996618, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4834, loss: 0.0023372794967144728, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4835, loss: 0.003994767088443041, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4836, loss: 0.005688793957233429, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4837, loss: 0.003461546963080764, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4838, loss: 0.00227774353697896, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4839, loss: 0.0014831775333732367, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4840, loss: 0.0010164149571210146, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4841, loss: 0.0025911484844982624, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4842, loss: 0.006645110435783863, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4843, loss: 0.0006448944332078099, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4844, loss: 0.002317662350833416, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4845, loss: 0.0005047242739237845, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4846, loss: 0.0009603967191651464, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4847, loss: 0.002490085316821933, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4848, loss: 0.0016475347802042961, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4849, loss: 0.0028930827975273132, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4850, loss: 0.002546280389651656, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4851, loss: 0.0032192354556173086, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4852, loss: 0.0011640102602541447, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4853, loss: 0.04087403416633606, acc: 0.984375, recall: 0.6785714285714286, precision: 0.65625, f_beta: 0.6618589743589743\n",
      "train: step: 4854, loss: 0.0012501401361078024, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4855, loss: 0.0015678494237363338, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4856, loss: 0.0015993047272786498, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4857, loss: 0.0022215908393263817, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4858, loss: 0.004928178153932095, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4859, loss: 0.0030044903978705406, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4860, loss: 0.029504654929041862, acc: 0.984375, recall: 0.6180555555555556, precision: 0.62109375, f_beta: 0.6193074003795067\n",
      "train: step: 4861, loss: 0.0018390427576377988, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4862, loss: 0.0018632616847753525, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4863, loss: 0.0023126474115997553, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4864, loss: 0.019362978637218475, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4865, loss: 0.0013151781167834997, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4866, loss: 0.006546128541231155, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4867, loss: 0.005134317558258772, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4868, loss: 0.004092683084309101, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4869, loss: 0.0008948121685534716, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4870, loss: 0.0013459206093102694, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4871, loss: 0.002787067787721753, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4872, loss: 0.0022928405087441206, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 4873, loss: 0.0006643355009146035, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4874, loss: 0.003338577225804329, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4875, loss: 0.0007197703816927969, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4876, loss: 0.0009651142754592001, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4877, loss: 0.0022374254185706377, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4878, loss: 0.025753643363714218, acc: 0.984375, recall: 0.65625, precision: 0.6770833333333334, f_beta: 0.6609848484848485\n",
      "train: step: 4879, loss: 0.007019638549536467, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4880, loss: 0.0018750019371509552, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4881, loss: 0.001355503685772419, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4882, loss: 0.0030036778189241886, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4883, loss: 0.001953540602698922, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4884, loss: 0.0006229780265130103, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4885, loss: 0.0009846899192780256, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4886, loss: 0.0017601383151486516, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4887, loss: 0.0019640065729618073, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4888, loss: 0.0016496112802997231, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4889, loss: 0.014505532570183277, acc: 0.984375, recall: 0.871875, precision: 0.859375, f_beta: 0.8644688644688645\n",
      "train: step: 4890, loss: 0.0030038845725357533, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4891, loss: 0.0011901042889803648, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4892, loss: 0.00048455933574587107, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4893, loss: 0.0005294676520861685, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4894, loss: 0.05316438525915146, acc: 0.984375, recall: 0.8072916666666666, precision: 0.8080357142857143, f_beta: 0.8074677938808374\n",
      "train: step: 4895, loss: 0.0003216543700546026, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4896, loss: 0.0015758465742692351, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4897, loss: 0.009424993768334389, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4898, loss: 0.00043900281889364123, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4899, loss: 0.0015758471563458443, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4900, loss: 0.022026710212230682, acc: 0.984375, recall: 0.859375, precision: 0.8541666666666667, f_beta: 0.8535714285714285\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:57:57.689721, step: 4900, loss: 8.328066243065727, acc: 0.1684027777777778,precision: 0.08121375719414936, recall: 0.0913767945017945, f_beta: 0.07847670889764669\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-4900\n",
      "\n",
      "train: step: 4901, loss: 0.0024526105262339115, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4902, loss: 0.0008750497363507748, acc: 1.0, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 4903, loss: 0.000741759839002043, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4904, loss: 0.0017206885386258364, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4905, loss: 0.00032671180088073015, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4906, loss: 0.0009580322075635195, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4907, loss: 0.0007201744592748582, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4908, loss: 0.002187954029068351, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4909, loss: 0.0005535007221624255, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4910, loss: 0.000391095585655421, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4911, loss: 0.005026696249842644, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4912, loss: 0.010667840950191021, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4913, loss: 0.0032227507326751947, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4914, loss: 0.00154851283878088, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4915, loss: 0.00023393567244056612, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4916, loss: 0.0006303278496488929, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4917, loss: 0.0008777015609666705, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4918, loss: 0.04252186417579651, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7467105263157895, f_beta: 0.7358108108108109\n",
      "train: step: 4919, loss: 0.0007110254373401403, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4920, loss: 0.0008657026337459683, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4921, loss: 0.004864696878939867, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4922, loss: 0.0011836810735985637, acc: 1.0, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 4923, loss: 0.001240163459442556, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4924, loss: 0.003158641280606389, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4925, loss: 0.004410566296428442, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4926, loss: 0.0015074864495545626, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4927, loss: 0.0017937410157173872, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4928, loss: 0.00035896318149752915, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4929, loss: 0.005498313345015049, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4930, loss: 0.0009013926610350609, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4931, loss: 0.00041843490907922387, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4932, loss: 0.0019312829244881868, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4933, loss: 0.002993083791807294, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4934, loss: 0.003313099965453148, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4935, loss: 0.0007947604754008353, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4936, loss: 0.0018965989584103227, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4937, loss: 0.0006131964037194848, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4938, loss: 0.0021211199928075075, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4939, loss: 0.0009503820911049843, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4940, loss: 0.0024990278761833906, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4941, loss: 0.0014064559945836663, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4942, loss: 0.000906243221834302, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4943, loss: 0.0017815926112234592, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4944, loss: 0.00025936568272300065, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4945, loss: 0.00101912347599864, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4946, loss: 0.007349558174610138, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4947, loss: 0.0011755222221836448, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4948, loss: 0.0003016195842064917, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4949, loss: 0.10119993984699249, acc: 0.984375, recall: 0.8080357142857143, precision: 0.7916666666666667, f_beta: 0.7976851851851853\n",
      "train: step: 4950, loss: 0.0037684901617467403, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4951, loss: 0.007238383404910564, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4952, loss: 0.00039557425770908594, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4953, loss: 0.002810359001159668, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4954, loss: 0.0006459073629230261, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4955, loss: 0.0009684873512014747, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4956, loss: 0.0011009973241016269, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 4957, loss: 0.002519104862585664, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4958, loss: 0.000438830116763711, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4959, loss: 0.00032973033376038074, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4960, loss: 0.0005350307328626513, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4961, loss: 0.0007030356209725142, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4962, loss: 0.04707924649119377, acc: 0.984375, recall: 0.6875, precision: 0.6666666666666667, f_beta: 0.675\n",
      "train: step: 4963, loss: 0.001065569929778576, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4964, loss: 0.00046778988325968385, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4965, loss: 0.0008544214651919901, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 4966, loss: 0.0005452766781672835, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4967, loss: 0.0005517019890248775, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4968, loss: 0.07398967444896698, acc: 0.984375, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4969, loss: 0.0017677664291113615, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4970, loss: 0.03366101533174515, acc: 0.984375, recall: 0.80859375, precision: 0.8072916666666666, f_beta: 0.8077664796633941\n",
      "train: step: 4971, loss: 0.0009331256151199341, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4972, loss: 0.0004572410834953189, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4973, loss: 0.0047414968721568584, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4974, loss: 0.00047196491505019367, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4975, loss: 0.0006027487106621265, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 4976, loss: 0.009897731244564056, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4977, loss: 0.0015326389111578465, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4978, loss: 0.002679410157725215, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4979, loss: 0.00035961682442575693, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4980, loss: 0.0007418090244755149, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4981, loss: 0.0017817624611780047, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4982, loss: 0.0004887523828074336, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4983, loss: 0.0015195291489362717, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 4984, loss: 0.002336755394935608, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4985, loss: 0.0033004723954945803, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4986, loss: 0.019290436059236526, acc: 0.984375, recall: 0.5576923076923077, precision: 0.5546875, f_beta: 0.5558333333333334\n",
      "train: step: 4987, loss: 0.013545204885303974, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4988, loss: 0.0007520458311773837, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4989, loss: 0.061980269849300385, acc: 0.984375, recall: 0.7447916666666666, precision: 0.7458333333333333, f_beta: 0.7451274362818591\n",
      "train: step: 4990, loss: 0.005703989416360855, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4991, loss: 0.0016335370019078255, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4992, loss: 0.00048308924306184053, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 4993, loss: 0.020528413355350494, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7467105263157895, f_beta: 0.7426289926289926\n",
      "train: step: 4994, loss: 0.001675342908129096, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4995, loss: 0.0017607919871807098, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 4996, loss: 0.0006112443516030908, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4997, loss: 0.000400656892452389, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 4998, loss: 0.0006096878205426037, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 4999, loss: 0.017686646431684494, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666667\n",
      "train: step: 5000, loss: 0.0004230808699503541, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T22:59:49.620815, step: 5000, loss: 8.419036971198189, acc: 0.1684027777777778,precision: 0.07903818789235456, recall: 0.08832667139958807, f_beta: 0.07806191702612542\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5000\n",
      "\n",
      "train: step: 5001, loss: 0.0048826951533555984, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5002, loss: 0.0015963423065841198, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5003, loss: 0.005122449714690447, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5004, loss: 0.0004316121921874583, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5005, loss: 0.0070308600552380085, acc: 1.0, recall: 1.0, precision: 1.0, f_beta: 1.0\n",
      "train: step: 5006, loss: 0.0003052641695830971, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5007, loss: 0.0010905800154432654, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5008, loss: 0.0022557443007826805, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5009, loss: 0.0060272919945418835, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5010, loss: 0.02519192360341549, acc: 0.984375, recall: 0.80625, precision: 0.8020833333333334, f_beta: 0.8035287081339713\n",
      "train: step: 5011, loss: 0.0003962330229114741, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5012, loss: 0.0014794341986998916, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5013, loss: 0.0008650660747662187, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5014, loss: 0.005106687545776367, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5015, loss: 0.0005836071213707328, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5016, loss: 0.00983292143791914, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5017, loss: 0.0001995659404201433, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5018, loss: 0.0035052865277975798, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5019, loss: 0.0008842077804729342, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5020, loss: 0.0005718569154851139, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5021, loss: 0.0027106902562081814, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5022, loss: 0.0016155893681570888, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5023, loss: 0.0012132534757256508, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5024, loss: 0.07668989151716232, acc: 0.984375, recall: 0.7916666666666666, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 5025, loss: 0.11240775883197784, acc: 0.984375, recall: 0.675, precision: 0.6805555555555556, f_beta: 0.6768790849673203\n",
      "train: step: 5026, loss: 0.02796921320259571, acc: 0.984375, recall: 0.8645833333333334, precision: 0.8660714285714286, f_beta: 0.8645104895104895\n",
      "train: step: 5027, loss: 0.00031923450296744704, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5028, loss: 0.0010289569618180394, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5029, loss: 0.0005451402976177633, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5030, loss: 0.0016288065817207098, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5031, loss: 0.0005311524728313088, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5032, loss: 0.041708070784807205, acc: 0.984375, recall: 0.6818181818181819, precision: 0.6838235294117647, f_beta: 0.6826298701298701\n",
      "train: step: 5033, loss: 0.00042983656749129295, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5034, loss: 0.0011063342681154609, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5035, loss: 0.028627628460526466, acc: 0.984375, recall: 0.8068181818181818, precision: 0.8020833333333334, f_beta: 0.8038419913419913\n",
      "train: step: 5036, loss: 0.15793079137802124, acc: 0.96875, recall: 0.8541666666666667, precision: 0.8484848484848484, f_beta: 0.8470238095238095\n",
      "train: step: 5037, loss: 0.04870525375008583, acc: 0.984375, recall: 0.6875, precision: 0.6785714285714286, f_beta: 0.6826923076923077\n",
      "train: step: 5038, loss: 0.002907073823735118, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5039, loss: 0.011017808690667152, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5040, loss: 0.02545335702598095, acc: 0.984375, recall: 0.734375, precision: 0.7421875, f_beta: 0.736904761904762\n",
      "start training model\n",
      "train: step: 5041, loss: 0.030565686523914337, acc: 0.984375, recall: 0.6171875, precision: 0.6201923076923077, f_beta: 0.6183333333333334\n",
      "train: step: 5042, loss: 0.03610095754265785, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666666, f_beta: 0.8\n",
      "train: step: 5043, loss: 0.0019219489768147469, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5044, loss: 0.01642368547618389, acc: 0.984375, recall: 0.8072916666666666, precision: 0.8083333333333333, f_beta: 0.8076274362818591\n",
      "train: step: 5045, loss: 0.04444670304656029, acc: 0.984375, recall: 0.80625, precision: 0.8055555555555556, f_beta: 0.8055340557275542\n",
      "train: step: 5046, loss: 0.010924452915787697, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5047, loss: 0.0011942270211875439, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5048, loss: 0.01368095725774765, acc: 0.984375, recall: 0.78125, precision: 0.8035714285714286, f_beta: 0.7868589743589745\n",
      "train: step: 5049, loss: 0.03195333853363991, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8, f_beta: 0.7998737373737373\n",
      "train: step: 5050, loss: 0.0009117018198594451, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5051, loss: 0.0015065582701936364, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5052, loss: 0.008345666341483593, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5053, loss: 0.004600397311151028, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5054, loss: 0.0061405124142766, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5055, loss: 0.013610856607556343, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5056, loss: 0.003074134700000286, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5057, loss: 0.007159342989325523, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5058, loss: 0.0011382702505216002, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5059, loss: 0.005185694899410009, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5060, loss: 0.0016379026928916574, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5061, loss: 0.0017499485984444618, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5062, loss: 0.08082956075668335, acc: 0.96875, recall: 0.7098214285714286, precision: 0.71875, f_beta: 0.703525641025641\n",
      "train: step: 5063, loss: 0.000898954807780683, acc: 1.0, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 5064, loss: 0.0007971674203872681, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5065, loss: 0.004871245473623276, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5066, loss: 0.013497474603354931, acc: 0.984375, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 5067, loss: 0.0044859349727630615, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5068, loss: 0.005742442794144154, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5069, loss: 0.13047954440116882, acc: 0.953125, recall: 0.59375, precision: 0.6171875, f_beta: 0.6\n",
      "train: step: 5070, loss: 0.0019223857671022415, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5071, loss: 0.0020727431401610374, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5072, loss: 0.001318825874477625, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5073, loss: 0.0023292142432183027, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5074, loss: 0.04265008121728897, acc: 0.984375, recall: 0.78125, precision: 0.8020833333333334, f_beta: 0.7859848484848484\n",
      "train: step: 5075, loss: 0.0031566256657242775, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5076, loss: 0.003725741058588028, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5077, loss: 0.016327667981386185, acc: 0.984375, recall: 0.8125, precision: 0.8, f_beta: 0.8055555555555556\n",
      "train: step: 5078, loss: 0.0023917334619909525, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5079, loss: 0.0010468736290931702, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5080, loss: 0.001218640012666583, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5081, loss: 0.003484311979264021, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5082, loss: 0.044231995940208435, acc: 0.984375, recall: 0.80625, precision: 0.8046875, f_beta: 0.8050438596491228\n",
      "train: step: 5083, loss: 0.002441082149744034, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5084, loss: 0.0017725296784192324, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5085, loss: 0.038285840302705765, acc: 0.984375, recall: 0.7451923076923077, precision: 0.74609375, f_beta: 0.7454838709677419\n",
      "train: step: 5086, loss: 0.11574748158454895, acc: 0.953125, recall: 0.6614583333333334, precision: 0.6536458333333333, f_beta: 0.6535055524185959\n",
      "train: step: 5087, loss: 0.000669690256472677, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5088, loss: 0.0019182015676051378, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5089, loss: 0.009985377080738544, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5090, loss: 0.004630661103874445, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5091, loss: 0.035428136587142944, acc: 0.984375, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 5092, loss: 0.0024592503905296326, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5093, loss: 0.05466843396425247, acc: 0.984375, recall: 0.6833333333333333, precision: 0.6822916666666667, f_beta: 0.6826274362818591\n",
      "train: step: 5094, loss: 0.003646885510534048, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5095, loss: 0.03534002602100372, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7410714285714286, f_beta: 0.7395104895104895\n",
      "train: step: 5096, loss: 0.0017403154633939266, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5097, loss: 0.005882066674530506, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5098, loss: 0.00232342048548162, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5099, loss: 0.007883107289671898, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5100, loss: 0.0367623008787632, acc: 0.984375, recall: 0.7375, precision: 0.7410714285714286, f_beta: 0.7382478632478633\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:01:41.641438, step: 5100, loss: 7.957030296325684, acc: 0.1701388888888889,precision: 0.08124357060518696, recall: 0.08853434374267707, f_beta: 0.07642675043151582\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5100\n",
      "\n",
      "train: step: 5101, loss: 0.0018943434115499258, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5102, loss: 0.0017703803023323417, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5103, loss: 0.01656412146985531, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5104, loss: 0.002653105417266488, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5105, loss: 0.002493699314072728, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5106, loss: 0.003660672577098012, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5107, loss: 0.0008544111624360085, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5108, loss: 0.0018255687318742275, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5109, loss: 0.001300490228459239, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5110, loss: 0.009386743418872356, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5111, loss: 0.004206841345876455, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5112, loss: 0.004477988928556442, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5113, loss: 0.00040643621468916535, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5114, loss: 0.0008398593636229634, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5115, loss: 0.0010402218904346228, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5116, loss: 0.004948209039866924, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5117, loss: 0.005805883556604385, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5118, loss: 0.0014481812249869108, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5119, loss: 0.0007187917944975197, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5120, loss: 0.008190984837710857, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5121, loss: 0.0017835842445492744, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5122, loss: 0.0009672441519796848, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5123, loss: 0.0007600843673571944, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5124, loss: 0.0077612996101379395, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "start training model\n",
      "train: step: 5125, loss: 0.022530755028128624, acc: 0.984375, recall: 0.78125, precision: 0.8090277777777778, f_beta: 0.7898809523809525\n",
      "train: step: 5126, loss: 0.006124554667621851, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5127, loss: 0.007764296606183052, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5128, loss: 0.0021479479037225246, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5129, loss: 0.0006183577934280038, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5130, loss: 0.0037120506167411804, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5131, loss: 0.005209996365010738, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5132, loss: 0.002585410373285413, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5133, loss: 0.0012777813244611025, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5134, loss: 0.0032405469100922346, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5135, loss: 0.001790340174920857, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5136, loss: 0.0026141589041799307, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5137, loss: 0.01394809503108263, acc: 0.984375, recall: 0.65625, precision: 0.671875, f_beta: 0.6577380952380952\n",
      "train: step: 5138, loss: 0.0003567588864825666, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5139, loss: 0.005341514945030212, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5140, loss: 0.0009306021966040134, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5141, loss: 0.004898207727819681, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5142, loss: 0.08433490991592407, acc: 0.984375, recall: 0.8072916666666666, precision: 0.8, f_beta: 0.8028381642512078\n",
      "train: step: 5143, loss: 0.00023758375027682632, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5144, loss: 0.029286200180649757, acc: 0.984375, recall: 0.609375, precision: 0.6193181818181818, f_beta: 0.6130952380952381\n",
      "train: step: 5145, loss: 0.0021733157336711884, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5146, loss: 0.0018262205412611365, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5147, loss: 0.0035288361832499504, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5148, loss: 0.0005431902827695012, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5149, loss: 0.011028250679373741, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5150, loss: 0.010697620920836926, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5151, loss: 0.000830102595500648, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5152, loss: 0.0014173754025250673, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5153, loss: 0.04864078387618065, acc: 0.984375, recall: 0.6833333333333333, precision: 0.6875, f_beta: 0.6853448275862069\n",
      "train: step: 5154, loss: 0.0016100655775517225, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5155, loss: 0.003395684761926532, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5156, loss: 0.01337550301104784, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5157, loss: 0.002156943315640092, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5158, loss: 0.0005655675195157528, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5159, loss: 0.07714971154928207, acc: 0.984375, recall: 0.78125, precision: 0.8035714285714286, f_beta: 0.7868589743589743\n",
      "train: step: 5160, loss: 0.0013142015086486936, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5161, loss: 0.0005326300160959363, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5162, loss: 0.0049216290935873985, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5163, loss: 0.026252320036292076, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5164, loss: 0.0040249209851026535, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5165, loss: 0.0005780171486549079, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5166, loss: 0.025452667847275734, acc: 0.984375, recall: 0.8020833333333334, precision: 0.8020833333333334, f_beta: 0.8011363636363636\n",
      "train: step: 5167, loss: 0.0029782431665807962, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5168, loss: 0.0018198428442701697, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5169, loss: 0.003807874396443367, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5170, loss: 0.0008241592440754175, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5171, loss: 0.0005352127482183278, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5172, loss: 0.0011845615226775408, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5173, loss: 0.031381674110889435, acc: 0.984375, recall: 0.8125, precision: 0.8035714285714286, f_beta: 0.8076923076923077\n",
      "train: step: 5174, loss: 0.0052425190806388855, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5175, loss: 0.0011536218225955963, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5176, loss: 0.0019515928579494357, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5177, loss: 0.0031760132405906916, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5178, loss: 0.017403746023774147, acc: 0.984375, recall: 0.7465277777777778, precision: 0.74375, f_beta: 0.7449248120300752\n",
      "train: step: 5179, loss: 0.0005972568178549409, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5180, loss: 0.06487050652503967, acc: 0.984375, recall: 0.7375, precision: 0.75, f_beta: 0.7430555555555556\n",
      "train: step: 5181, loss: 0.0009625653037801385, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5182, loss: 0.021961772814393044, acc: 0.984375, recall: 0.8035714285714286, precision: 0.78125, f_beta: 0.7868589743589743\n",
      "train: step: 5183, loss: 0.000805521965958178, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5184, loss: 0.0013953305315226316, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5185, loss: 0.013035131618380547, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5186, loss: 0.002412115689367056, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5187, loss: 0.0014677157159894705, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5188, loss: 0.002717489842325449, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5189, loss: 0.007459654938429594, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5190, loss: 0.019315483048558235, acc: 0.984375, recall: 0.6193181818181818, precision: 0.6160714285714286, f_beta: 0.6172161172161172\n",
      "train: step: 5191, loss: 0.0010973780881613493, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5192, loss: 0.0016539355274289846, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5193, loss: 0.0225408673286438, acc: 0.984375, recall: 0.78125, precision: 0.796875, f_beta: 0.7827380952380952\n",
      "train: step: 5194, loss: 0.009877455420792103, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5195, loss: 0.007206879556179047, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5196, loss: 0.023171961307525635, acc: 0.984375, recall: 0.78125, precision: 0.8046875, f_beta: 0.7875\n",
      "train: step: 5197, loss: 0.0041520362719893456, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5198, loss: 0.0005960861453786492, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5199, loss: 0.0003590871929191053, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5200, loss: 0.001609778730198741, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:03:33.462270, step: 5200, loss: 8.04815313551161, acc: 0.1736111111111111,precision: 0.06918468957942643, recall: 0.08775251051599092, f_beta: 0.07198955710806088\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5200\n",
      "\n",
      "train: step: 5201, loss: 0.004940743092447519, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5202, loss: 0.12191534042358398, acc: 0.96875, recall: 0.5902777777777778, precision: 0.6111111111111112, f_beta: 0.5945684523809524\n",
      "train: step: 5203, loss: 0.07338636368513107, acc: 0.96875, recall: 0.7916666666666667, precision: 0.7791666666666667, f_beta: 0.7805555555555556\n",
      "train: step: 5204, loss: 0.004198645241558552, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5205, loss: 0.0012016950640827417, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5206, loss: 0.0009473160607740283, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5207, loss: 0.001821249141357839, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5208, loss: 0.0021202333737164736, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 5209, loss: 0.22267046570777893, acc: 0.96875, recall: 0.7118055555555556, precision: 0.7404605263157895, f_beta: 0.7205115332050317\n",
      "train: step: 5210, loss: 0.07122854888439178, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7430555555555556, f_beta: 0.7415158371040724\n",
      "train: step: 5211, loss: 0.026049092411994934, acc: 0.984375, recall: 0.7375, precision: 0.7447916666666666, f_beta: 0.7403381642512078\n",
      "train: step: 5212, loss: 0.06012492999434471, acc: 0.984375, recall: 0.7410714285714286, precision: 0.734375, f_beta: 0.7362637362637363\n",
      "train: step: 5213, loss: 0.017420824617147446, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7447916666666667, f_beta: 0.7424749163879598\n",
      "train: step: 5214, loss: 0.03792274743318558, acc: 0.984375, recall: 0.6193181818181819, precision: 0.625, f_beta: 0.6220238095238095\n",
      "train: step: 5215, loss: 0.0025935815647244453, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5216, loss: 0.04345055669546127, acc: 0.984375, recall: 0.8097826086956522, precision: 0.8035714285714286, f_beta: 0.8063034188034188\n",
      "train: step: 5217, loss: 0.001550739980302751, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5218, loss: 0.01986168511211872, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5219, loss: 0.025048961862921715, acc: 0.984375, recall: 0.734375, precision: 0.75, f_beta: 0.7410714285714286\n",
      "train: step: 5220, loss: 0.0021937857381999493, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5221, loss: 0.009354233741760254, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5222, loss: 0.10014454275369644, acc: 0.984375, recall: 0.84375, precision: 0.8541666666666666, f_beta: 0.8416666666666668\n",
      "train: step: 5223, loss: 0.005851735360920429, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5224, loss: 0.0044404286891222, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5225, loss: 0.0018752688774839044, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5226, loss: 0.003913518041372299, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5227, loss: 0.06385810673236847, acc: 0.96875, recall: 0.725, precision: 0.7083333333333334, f_beta: 0.7093750000000001\n",
      "train: step: 5228, loss: 0.017680233344435692, acc: 0.984375, recall: 0.675, precision: 0.68359375, f_beta: 0.6785394265232976\n",
      "train: step: 5229, loss: 0.01383165456354618, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5230, loss: 0.05385391041636467, acc: 0.984375, recall: 0.7291666666666666, precision: 0.7443181818181818, f_beta: 0.7345238095238096\n",
      "train: step: 5231, loss: 0.016203269362449646, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5232, loss: 0.002212421502918005, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5233, loss: 0.007461831904947758, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5234, loss: 0.009024945087730885, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5235, loss: 0.001680601853877306, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5236, loss: 0.011667936109006405, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5237, loss: 0.009509289637207985, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5238, loss: 0.0045699323527514935, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5239, loss: 0.009809649549424648, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5240, loss: 0.008445543237030506, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5241, loss: 0.07996714860200882, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5242, loss: 0.020204631611704826, acc: 0.984375, recall: 0.74609375, precision: 0.7430555555555556, f_beta: 0.7443074003795067\n",
      "train: step: 5243, loss: 0.006524546071887016, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5244, loss: 0.013558024540543556, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5245, loss: 0.011964070610702038, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5246, loss: 0.08299174904823303, acc: 0.96875, recall: 0.6785714285714286, precision: 0.6458333333333334, f_beta: 0.6561771561771562\n",
      "train: step: 5247, loss: 0.0027655726298689842, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5248, loss: 0.0012232775334268808, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5249, loss: 0.0020190265495330095, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5250, loss: 0.0011349039850756526, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5251, loss: 0.004067879170179367, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5252, loss: 0.0044685546308755875, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5253, loss: 0.0009832658106461167, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5254, loss: 0.01225788239389658, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5255, loss: 0.0107148177921772, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5256, loss: 0.018310515210032463, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5257, loss: 0.06174057722091675, acc: 0.96875, recall: 0.6627604166666666, precision: 0.6833333333333333, f_beta: 0.6708286985539489\n",
      "train: step: 5258, loss: 0.012041005305945873, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5259, loss: 0.13693687319755554, acc: 0.984375, recall: 0.8671875, precision: 0.8697916666666666, f_beta: 0.8681159420289856\n",
      "train: step: 5260, loss: 0.004516107961535454, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5261, loss: 0.0085669020190835, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5262, loss: 0.056141745299100876, acc: 0.984375, recall: 0.78125, precision: 0.8, f_beta: 0.7847222222222223\n",
      "train: step: 5263, loss: 0.002938554622232914, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5264, loss: 0.013348166830837727, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5265, loss: 0.06922204047441483, acc: 0.96875, recall: 0.7361111111111112, precision: 0.7295673076923077, f_beta: 0.7307589285714287\n",
      "train: step: 5266, loss: 0.024890664964914322, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5267, loss: 0.05122480168938637, acc: 0.96875, recall: 0.6736111111111112, precision: 0.6875, f_beta: 0.6796875\n",
      "train: step: 5268, loss: 0.004405422136187553, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5269, loss: 0.008071563206613064, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5270, loss: 0.009478045627474785, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5271, loss: 0.001336005050688982, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5272, loss: 0.004195612855255604, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5273, loss: 0.004335326608270407, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5274, loss: 0.006005970761179924, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5275, loss: 0.011369310319423676, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5276, loss: 0.016365395858883858, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5277, loss: 0.004408262670040131, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5278, loss: 0.03185399994254112, acc: 0.984375, recall: 0.8125, precision: 0.78125, f_beta: 0.7916666666666666\n",
      "train: step: 5279, loss: 0.007565680891275406, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5280, loss: 0.001068436075001955, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5281, loss: 0.002462052972987294, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5282, loss: 0.05693162977695465, acc: 0.96875, recall: 0.6875, precision: 0.6625, f_beta: 0.671875\n",
      "train: step: 5283, loss: 0.0041201151907444, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5284, loss: 0.007944760844111443, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5285, loss: 0.019562087953090668, acc: 0.984375, recall: 0.8076923076923077, precision: 0.8020833333333334, f_beta: 0.8043181818181819\n",
      "train: step: 5286, loss: 0.029077598825097084, acc: 0.984375, recall: 0.93359375, precision: 0.9322916666666666, f_beta: 0.9327664796633941\n",
      "train: step: 5287, loss: 0.007383767515420914, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5288, loss: 0.0005833776667714119, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5289, loss: 0.005142144858837128, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5290, loss: 0.0016148088034242392, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5291, loss: 0.001813061535358429, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5292, loss: 0.001054228749126196, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 5293, loss: 0.013928795233368874, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5294, loss: 0.003690089099109173, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5295, loss: 0.0010343091562390327, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5296, loss: 0.011862870305776596, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5297, loss: 0.0014975022058933973, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5298, loss: 0.010954589582979679, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5299, loss: 0.002134837443009019, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5300, loss: 0.03895806893706322, acc: 0.984375, recall: 0.7421875, precision: 0.7421875, f_beta: 0.7416666666666667\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:05:25.679475, step: 5300, loss: 7.991564008924696, acc: 0.171875,precision: 0.08658888721453221, recall: 0.08767324553170142, f_beta: 0.07723060132926125\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5300\n",
      "\n",
      "train: step: 5301, loss: 0.002104461193084717, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5302, loss: 0.0011588716879487038, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5303, loss: 0.00854992214590311, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5304, loss: 0.004445458762347698, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5305, loss: 0.010163016617298126, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5306, loss: 0.0009596022428013384, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5307, loss: 0.0022576507180929184, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5308, loss: 0.0037136308383196592, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5309, loss: 0.0012249258579686284, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5310, loss: 0.0009075478883460164, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5311, loss: 0.0009160935296677053, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5312, loss: 0.0007310634246096015, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5313, loss: 0.03427896276116371, acc: 0.984375, recall: 0.80859375, precision: 0.80625, f_beta: 0.8071943972835315\n",
      "train: step: 5314, loss: 0.0007271085632964969, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5315, loss: 0.00027227087412029505, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5316, loss: 0.0016723294975236058, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5317, loss: 0.0105836670845747, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5318, loss: 0.0006398665718734264, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5319, loss: 0.0015803580172359943, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5320, loss: 0.01038079522550106, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5321, loss: 0.0013601157115772367, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5322, loss: 0.003152733203023672, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5323, loss: 0.007225098088383675, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5324, loss: 0.01843539997935295, acc: 0.984375, recall: 0.7447916666666666, precision: 0.7455357142857143, f_beta: 0.7449677938808373\n",
      "train: step: 5325, loss: 0.0009071789681911469, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5326, loss: 0.0007411616970784962, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5327, loss: 0.006838416680693626, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5328, loss: 0.001012957189232111, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5329, loss: 0.0007314459071494639, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5330, loss: 0.0006649129209108651, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5331, loss: 0.0022966014221310616, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5332, loss: 0.0004903208464384079, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5333, loss: 0.0015824631555005908, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5334, loss: 0.0019123059464618564, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5335, loss: 0.0002626900386530906, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5336, loss: 0.0002642788167577237, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5337, loss: 0.00044167047599330544, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5338, loss: 0.000781538721639663, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5339, loss: 0.0005064686993137002, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5340, loss: 0.001480543869547546, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5341, loss: 0.004633794538676739, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5342, loss: 0.0053211115300655365, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5343, loss: 0.0018682513618841767, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5344, loss: 0.028993016108870506, acc: 0.984375, recall: 0.8125, precision: 0.8035714285714286, f_beta: 0.8076923076923077\n",
      "train: step: 5345, loss: 0.002428187057375908, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5346, loss: 0.007454658392816782, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5347, loss: 0.00045699835754930973, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5348, loss: 0.00034357415279373527, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5349, loss: 0.0019078310579061508, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5350, loss: 0.0012007573386654258, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5351, loss: 0.0016980080399662256, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5352, loss: 0.0019942496437579393, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5353, loss: 0.0005271537229418755, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5354, loss: 0.001423054956831038, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5355, loss: 0.0038081021048128605, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5356, loss: 0.0166514553129673, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5357, loss: 0.0007920514326542616, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5358, loss: 0.0012058067368343472, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5359, loss: 0.001869404804892838, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5360, loss: 0.0010054957820102572, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5361, loss: 0.00019572727615013719, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5362, loss: 0.15471051633358002, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 5363, loss: 0.017809629440307617, acc: 0.984375, recall: 0.74375, precision: 0.734375, f_beta: 0.7377819548872181\n",
      "train: step: 5364, loss: 0.010405771434307098, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5365, loss: 0.007395013701170683, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5366, loss: 0.0016893672291189432, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5367, loss: 0.001742996391840279, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5368, loss: 0.011125920340418816, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5369, loss: 0.0025409383233636618, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5370, loss: 0.0011014295741915703, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5371, loss: 0.0032822745852172375, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5372, loss: 0.009669510647654533, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5373, loss: 0.000673624046612531, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5374, loss: 0.02734220214188099, acc: 0.984375, recall: 0.7467105263157895, precision: 0.7375, f_beta: 0.7413663663663663\n",
      "train: step: 5375, loss: 0.007742160465568304, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5376, loss: 0.014480780810117722, acc: 0.984375, recall: 0.7375, precision: 0.71875, f_beta: 0.7222222222222222\n",
      "start training model\n",
      "train: step: 5377, loss: 0.000727232254575938, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5378, loss: 0.03372467681765556, acc: 0.984375, recall: 0.9285714285714286, precision: 0.90625, f_beta: 0.9118589743589743\n",
      "train: step: 5379, loss: 0.0008989722700789571, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5380, loss: 0.0019186625722795725, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5381, loss: 0.0007334485999308527, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5382, loss: 0.0011199656873941422, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5383, loss: 0.002313156146556139, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5384, loss: 0.00262876832857728, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5385, loss: 0.0016269339248538017, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5386, loss: 0.0005373185267671943, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5387, loss: 0.0012669076677411795, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5388, loss: 0.0009350445470772684, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5389, loss: 0.0012942961184307933, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5390, loss: 0.001281258650124073, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5391, loss: 0.0030556500423699617, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5392, loss: 0.000643959385342896, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5393, loss: 0.0024340141098946333, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5394, loss: 0.0005927992751821876, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5395, loss: 0.0005845680134370923, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5396, loss: 0.0009049895452335477, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5397, loss: 0.0016627553850412369, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5398, loss: 0.002389481756836176, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5399, loss: 0.0003130943514406681, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5400, loss: 0.001451556570827961, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:07:17.187952, step: 5400, loss: 8.44472927517361, acc: 0.1684027777777778,precision: 0.07707682715342029, recall: 0.09698611979313734, f_beta: 0.07782195917620996\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5400\n",
      "\n",
      "train: step: 5401, loss: 0.005200328305363655, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5402, loss: 0.0011764224618673325, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5403, loss: 0.013140573166310787, acc: 0.984375, recall: 0.78125, precision: 0.8083333333333333, f_beta: 0.7895114942528735\n",
      "train: step: 5404, loss: 0.01767350360751152, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7458333333333333, f_beta: 0.7421630094043887\n",
      "train: step: 5405, loss: 0.07384762912988663, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6875, f_beta: 0.6818181818181819\n",
      "train: step: 5406, loss: 0.0006375106167979538, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5407, loss: 0.0021068290807306767, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5408, loss: 0.0005508586182259023, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5409, loss: 0.01371607556939125, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5410, loss: 0.0007459912449121475, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5411, loss: 0.005636535584926605, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5412, loss: 0.0013181280810385942, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5413, loss: 0.08018216490745544, acc: 0.984375, recall: 0.84375, precision: 0.87109375, f_beta: 0.8521505376344086\n",
      "train: step: 5414, loss: 0.0008073225617408752, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5415, loss: 0.0004326597263570875, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5416, loss: 0.004305255599319935, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5417, loss: 0.0040520173497498035, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5418, loss: 0.004509232006967068, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5419, loss: 0.001210058806464076, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5420, loss: 0.07999642193317413, acc: 0.984375, recall: 0.7916666666666666, precision: 0.7916666666666666, f_beta: 0.7875000000000001\n",
      "train: step: 5421, loss: 0.012341751717031002, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5422, loss: 0.0009117558365687728, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5423, loss: 0.0002606568159535527, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5424, loss: 0.0005737470928579569, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5425, loss: 0.0004238813417032361, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5426, loss: 0.002021855441853404, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5427, loss: 0.0014501921832561493, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5428, loss: 0.0037791139911860228, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5429, loss: 0.000746956910006702, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5430, loss: 0.01512668002396822, acc: 0.984375, recall: 0.8671875, precision: 0.8660714285714286, f_beta: 0.8660256410256411\n",
      "train: step: 5431, loss: 0.0042089782655239105, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5432, loss: 0.004679680801928043, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5433, loss: 0.0006450519431382418, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5434, loss: 0.0006839787820354104, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5435, loss: 0.0011576097458600998, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5436, loss: 0.07506252080202103, acc: 0.984375, recall: 0.8, precision: 0.78125, f_beta: 0.7847222222222223\n",
      "train: step: 5437, loss: 0.002505179261788726, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5438, loss: 0.0004551251186057925, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5439, loss: 0.000696044007781893, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5440, loss: 0.0006654951721429825, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5441, loss: 0.00543404882773757, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5442, loss: 0.0010824879864230752, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5443, loss: 0.0005169743089936674, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5444, loss: 0.0004930371651425958, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5445, loss: 0.0014733525458723307, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5446, loss: 0.0013982569798827171, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5447, loss: 0.0006897920393384993, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5448, loss: 0.012671228498220444, acc: 0.984375, recall: 0.6041666666666666, precision: 0.6205357142857143, f_beta: 0.6101851851851852\n",
      "train: step: 5449, loss: 0.0008070933981798589, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5450, loss: 0.002112356247380376, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5451, loss: 0.000499033194500953, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5452, loss: 0.03702777251601219, acc: 0.984375, recall: 0.8125, precision: 0.8, f_beta: 0.8055555555555556\n",
      "train: step: 5453, loss: 0.004343366716057062, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5454, loss: 0.0003663089300971478, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5455, loss: 0.0004891381249763072, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5456, loss: 0.0008941660635173321, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5457, loss: 0.001556220930069685, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5458, loss: 0.0007638315437361598, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5459, loss: 0.010148582980036736, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5460, loss: 0.001503538223914802, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 5461, loss: 0.0015703854151070118, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5462, loss: 0.00612166803330183, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5463, loss: 0.00023742993653286248, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5464, loss: 0.0022324908059090376, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5465, loss: 0.004213632550090551, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5466, loss: 0.0010581433307379484, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5467, loss: 0.0036475062370300293, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5468, loss: 0.001019368413835764, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5469, loss: 0.0009102764306589961, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5470, loss: 0.0028171648737043142, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5471, loss: 0.0001835544826462865, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5472, loss: 0.0010678729740902781, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5473, loss: 0.00043897907016798854, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5474, loss: 0.0013894682051613927, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5475, loss: 0.0003442490997258574, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5476, loss: 0.0006435869727283716, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5477, loss: 0.004318988416343927, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5478, loss: 0.001201858278363943, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5479, loss: 0.0016016610898077488, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5480, loss: 0.0025485085789114237, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5481, loss: 0.00029119057580828667, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5482, loss: 0.00022099167108535767, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5483, loss: 0.0007050288841128349, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5484, loss: 0.00034281681291759014, acc: 1.0, recall: 1.0, precision: 1.0, f_beta: 1.0\n",
      "train: step: 5485, loss: 0.0010820673778653145, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5486, loss: 0.0011574102099984884, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5487, loss: 0.007160228211432695, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5488, loss: 0.00198564724996686, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5489, loss: 0.004671882838010788, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5490, loss: 0.0013434062711894512, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5491, loss: 0.0003741678665392101, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5492, loss: 0.0014144154265522957, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5493, loss: 0.0006639798521064222, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5494, loss: 0.0007046123500913382, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5495, loss: 0.0005436474457383156, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5496, loss: 0.0006999352481216192, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5497, loss: 0.0027201815973967314, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5498, loss: 0.00018033001106232405, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5499, loss: 0.00037132296711206436, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5500, loss: 0.0024878757540136576, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:09:08.937970, step: 5500, loss: 8.592959456973606, acc: 0.15625,precision: 0.07977745633995634, recall: 0.08684760455593789, f_beta: 0.07525635910734002\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5500\n",
      "\n",
      "train: step: 5501, loss: 0.022935256361961365, acc: 0.984375, recall: 0.7375, precision: 0.71875, f_beta: 0.7222222222222222\n",
      "train: step: 5502, loss: 0.0010063262889161706, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5503, loss: 0.00038115354254841805, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5504, loss: 0.0005069953040219843, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5505, loss: 0.0010104180546477437, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5506, loss: 0.014645776711404324, acc: 0.984375, recall: 0.6785714285714286, precision: 0.6805555555555556, f_beta: 0.6790158371040724\n",
      "train: step: 5507, loss: 0.0007511019939556718, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5508, loss: 0.002242087619379163, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5509, loss: 0.0010795159032568336, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5510, loss: 0.047874826937913895, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7443181818181818, f_beta: 0.7422161172161172\n",
      "train: step: 5511, loss: 0.0011421272065490484, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5512, loss: 0.0007680488051846623, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5513, loss: 0.0006025974871590734, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5514, loss: 0.06762818247079849, acc: 0.96875, recall: 0.7946428571428571, precision: 0.7708333333333333, f_beta: 0.7708333333333334\n",
      "train: step: 5515, loss: 0.003213852643966675, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5516, loss: 0.05708297714591026, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7291666666666667, f_beta: 0.7326923076923078\n",
      "train: step: 5517, loss: 0.0960446298122406, acc: 0.96875, recall: 0.8671875, precision: 0.8333333333333334, f_beta: 0.8395833333333333\n",
      "train: step: 5518, loss: 0.0011061179684475064, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5519, loss: 0.003436356084421277, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5520, loss: 0.012249909341335297, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5521, loss: 0.0009342159028165042, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5522, loss: 0.004104004241526127, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5523, loss: 0.001511946553364396, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5524, loss: 0.025374745950102806, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666667\n",
      "train: step: 5525, loss: 0.00981071311980486, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5526, loss: 0.018577486276626587, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5527, loss: 0.005929810926318169, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5528, loss: 0.005917836911976337, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5529, loss: 0.016729231923818588, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5530, loss: 0.04823305830359459, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7443181818181818, f_beta: 0.7345238095238096\n",
      "train: step: 5531, loss: 0.04729956015944481, acc: 0.984375, recall: 0.6125, precision: 0.6180555555555556, f_beta: 0.6143790849673203\n",
      "train: step: 5532, loss: 0.0028525348752737045, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5533, loss: 0.010424740612506866, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5534, loss: 0.0024758579675108194, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5535, loss: 0.001289903186261654, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5536, loss: 0.0024667682591825724, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5537, loss: 0.007882369682192802, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5538, loss: 0.0029111397452652454, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5539, loss: 0.005250740330666304, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5540, loss: 0.0006926250644028187, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5541, loss: 0.003672488499432802, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5542, loss: 0.0013632726622745395, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5543, loss: 0.0027624918147921562, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5544, loss: 0.0011504945578053594, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "start training model\n",
      "train: step: 5545, loss: 0.04465189576148987, acc: 0.984375, recall: 0.796875, precision: 0.78125, f_beta: 0.7827380952380952\n",
      "train: step: 5546, loss: 0.00839328020811081, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5547, loss: 0.0033208008389919996, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5548, loss: 0.0016001493204385042, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5549, loss: 0.0015987171791493893, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5550, loss: 0.001327246311120689, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5551, loss: 0.005924292840063572, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5552, loss: 0.0007167084841057658, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5553, loss: 0.06166956201195717, acc: 0.984375, recall: 0.6818181818181819, precision: 0.671875, f_beta: 0.6755952380952381\n",
      "train: step: 5554, loss: 0.0020825446117669344, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5555, loss: 0.01949097216129303, acc: 0.984375, recall: 0.84375, precision: 0.875, f_beta: 0.8541666666666667\n",
      "train: step: 5556, loss: 0.001998323481529951, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5557, loss: 0.0036594332195818424, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5558, loss: 0.001817889278754592, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5559, loss: 0.0049532875418663025, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5560, loss: 0.023070814087986946, acc: 0.984375, recall: 0.7291666666666666, precision: 0.734375, f_beta: 0.7285714285714285\n",
      "train: step: 5561, loss: 0.02604694478213787, acc: 0.984375, recall: 0.78125, precision: 0.8, f_beta: 0.7847222222222223\n",
      "train: step: 5562, loss: 0.009691338986158371, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5563, loss: 0.0028508109971880913, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5564, loss: 0.008813985623419285, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5565, loss: 0.0013307678746059537, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5566, loss: 0.004217839799821377, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5567, loss: 0.0034095365554094315, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5568, loss: 0.00430684071034193, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5569, loss: 0.0025753737427294254, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5570, loss: 0.021201442927122116, acc: 0.984375, recall: 0.75, precision: 0.7375, f_beta: 0.7430555555555556\n",
      "train: step: 5571, loss: 0.1143111065030098, acc: 0.984375, recall: 0.6666666666666667, precision: 0.671875, f_beta: 0.6660714285714285\n",
      "train: step: 5572, loss: 0.07184963673353195, acc: 0.96875, recall: 0.625, precision: 0.5833333333333334, f_beta: 0.59375\n",
      "train: step: 5573, loss: 0.03192443400621414, acc: 0.984375, recall: 0.78125, precision: 0.8046875, f_beta: 0.7875000000000001\n",
      "train: step: 5574, loss: 0.0009644626406952739, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5575, loss: 0.005078180693089962, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5576, loss: 0.00034224457340314984, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5577, loss: 0.0010037412866950035, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5578, loss: 0.0020828647539019585, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5579, loss: 0.007352005690336227, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5580, loss: 0.0015489503275603056, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5581, loss: 0.0011919961543753743, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5582, loss: 0.008506369777023792, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5583, loss: 0.000989121850579977, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5584, loss: 0.09943082183599472, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6875, f_beta: 0.675\n",
      "train: step: 5585, loss: 0.0015971655957400799, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5586, loss: 0.0019497061148285866, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5587, loss: 0.003759304527193308, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5588, loss: 0.03433593735098839, acc: 0.984375, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5589, loss: 0.011015588417649269, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5590, loss: 0.0019818544387817383, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5591, loss: 0.0013452711282297969, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5592, loss: 0.0014128056354820728, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5593, loss: 0.0025935098528862, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5594, loss: 0.0011504371650516987, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5595, loss: 0.02898571267724037, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666667, f_beta: 0.7791666666666667\n",
      "train: step: 5596, loss: 0.0036993701942265034, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5597, loss: 0.025254327803850174, acc: 0.984375, recall: 0.7291666666666667, precision: 0.71875, f_beta: 0.7166666666666667\n",
      "train: step: 5598, loss: 0.0014092826750129461, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5599, loss: 0.014416083693504333, acc: 0.984375, recall: 0.7430555555555556, precision: 0.7291666666666667, f_beta: 0.7338235294117648\n",
      "train: step: 5600, loss: 0.24432893097400665, acc: 0.96875, recall: 0.6629464285714286, precision: 0.6734068627450981, f_beta: 0.6661879786879786\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:11:01.716203, step: 5600, loss: 8.172274960411919, acc: 0.1684027777777778,precision: 0.07530010952192324, recall: 0.10069569704986371, f_beta: 0.07990415985203018\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5600\n",
      "\n",
      "train: step: 5601, loss: 0.001717553474009037, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5602, loss: 0.0038499818183481693, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5603, loss: 0.0004599879030138254, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5604, loss: 0.000480126851471141, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5605, loss: 0.005446986295282841, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5606, loss: 0.0030715777538716793, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5607, loss: 0.0017562658758834004, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5608, loss: 0.028995364904403687, acc: 0.984375, recall: 0.7430555555555556, precision: 0.7291666666666666, f_beta: 0.7338235294117648\n",
      "train: step: 5609, loss: 0.0007201133412308991, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5610, loss: 0.0007962717209011316, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5611, loss: 0.052076566964387894, acc: 0.984375, recall: 0.78125, precision: 0.7916666666666667, f_beta: 0.7791666666666667\n",
      "train: step: 5612, loss: 0.054198622703552246, acc: 0.953125, recall: 0.8451923076923077, precision: 0.8480113636363636, f_beta: 0.8416964285714287\n",
      "train: step: 5613, loss: 0.018063170835375786, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5614, loss: 0.0007211779593490064, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5615, loss: 0.05359932780265808, acc: 0.984375, recall: 0.7291666666666667, precision: 0.75, f_beta: 0.7375\n",
      "train: step: 5616, loss: 0.004108934197574854, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5617, loss: 0.0019782432354986668, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5618, loss: 0.0008598322747275233, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5619, loss: 0.002724461257457733, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5620, loss: 0.008870198391377926, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5621, loss: 0.0006766616716049612, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5622, loss: 0.001813685055822134, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5623, loss: 0.007492606528103352, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5624, loss: 0.0014082181733101606, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5625, loss: 0.006207478232681751, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5626, loss: 0.0036731185391545296, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5627, loss: 0.011059775948524475, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5628, loss: 0.002404644852504134, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 5629, loss: 0.001829066895879805, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5630, loss: 0.004371851682662964, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5631, loss: 0.0008455089409835637, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5632, loss: 0.0027795112691819668, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5633, loss: 0.002161589218303561, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5634, loss: 0.007275511510670185, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5635, loss: 0.05558266490697861, acc: 0.96875, recall: 0.6666666666666667, precision: 0.6666666666666666, f_beta: 0.6633540372670809\n",
      "train: step: 5636, loss: 0.00684007816016674, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5637, loss: 0.0008464520797133446, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5638, loss: 0.020561497658491135, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 5639, loss: 0.004441477358341217, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5640, loss: 0.002071782248094678, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5641, loss: 0.0003170963900629431, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5642, loss: 0.0035615498200058937, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5643, loss: 0.018938308581709862, acc: 0.984375, recall: 0.8020833333333334, precision: 0.78125, f_beta: 0.7859848484848485\n",
      "train: step: 5644, loss: 0.0930345356464386, acc: 0.984375, recall: 0.7916666666666667, precision: 0.7916666666666667, f_beta: 0.7875\n",
      "train: step: 5645, loss: 0.0008750345441512764, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5646, loss: 0.0010171850444748998, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5647, loss: 0.0012183001963421702, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5648, loss: 0.0008163467282429338, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5649, loss: 0.0017426194390282035, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5650, loss: 0.03926615044474602, acc: 0.984375, recall: 0.796875, precision: 0.8, f_beta: 0.7966269841269842\n",
      "train: step: 5651, loss: 0.007620220072567463, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5652, loss: 0.013110948726534843, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5653, loss: 0.0023708005901426077, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5654, loss: 0.0003798417455982417, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5655, loss: 0.015662306919693947, acc: 0.984375, recall: 0.9166666666666667, precision: 0.90625, f_beta: 0.9041666666666667\n",
      "train: step: 5656, loss: 0.000547860749065876, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5657, loss: 0.0008940208936110139, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5658, loss: 0.0011739006731659174, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5659, loss: 0.00044166797306388617, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5660, loss: 0.007307339459657669, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5661, loss: 0.005310595501214266, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5662, loss: 0.0025812494568526745, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5663, loss: 0.0006554743158631027, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5664, loss: 0.0004035765887238085, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5665, loss: 0.002968407701700926, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5666, loss: 0.0019775298424065113, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5667, loss: 0.0012523222249001265, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5668, loss: 0.004233929328620434, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5669, loss: 0.001775188371539116, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5670, loss: 0.001225680229254067, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5671, loss: 0.0036374423652887344, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5672, loss: 0.0002700574113987386, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5673, loss: 0.05127457156777382, acc: 0.984375, recall: 0.6875, precision: 0.6785714285714286, f_beta: 0.6826923076923077\n",
      "train: step: 5674, loss: 0.0009796529775485396, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5675, loss: 0.004137538839131594, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5676, loss: 0.0005241887993179262, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5677, loss: 0.0003205113171134144, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5678, loss: 0.0007221885025501251, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5679, loss: 0.003918418660759926, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5680, loss: 0.07294832170009613, acc: 0.984375, recall: 0.8541666666666667, precision: 0.859375, f_beta: 0.8535714285714286\n",
      "train: step: 5681, loss: 0.0008329740958288312, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5682, loss: 0.003960100468248129, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5683, loss: 0.006015119142830372, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5684, loss: 0.002500015776604414, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5685, loss: 0.00038609857438132167, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5686, loss: 0.0012834513327106833, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5687, loss: 0.0006135056610219181, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5688, loss: 0.0016487096436321735, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5689, loss: 0.001767994137480855, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5690, loss: 0.005717905703932047, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5691, loss: 0.0009935032576322556, acc: 1.0, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 5692, loss: 0.018868442624807358, acc: 0.984375, recall: 0.675, precision: 0.65625, f_beta: 0.6597222222222222\n",
      "train: step: 5693, loss: 0.0012453296221792698, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5694, loss: 0.006443144753575325, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5695, loss: 0.0011066150618717074, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5696, loss: 0.003469733288511634, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5697, loss: 0.006188621744513512, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5698, loss: 0.0036111860536038876, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5699, loss: 0.0007982971146702766, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5700, loss: 0.0005309841362759471, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:12:53.373361, step: 5700, loss: 8.419918643103706, acc: 0.1597222222222222,precision: 0.07627397930839959, recall: 0.09401032768067082, f_beta: 0.07206007881551012\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5700\n",
      "\n",
      "train: step: 5701, loss: 0.0005337718175724149, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5702, loss: 0.0013110899599269032, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5703, loss: 0.0074026500806212425, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5704, loss: 0.011150339618325233, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5705, loss: 0.011408801190555096, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5706, loss: 0.002216791268438101, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5707, loss: 0.0010849484242498875, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5708, loss: 0.0007632814231328666, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5709, loss: 0.0008108158363029361, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5710, loss: 0.0005692280828952789, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5711, loss: 0.00047291023656725883, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5712, loss: 0.0003118433814961463, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 5713, loss: 0.00048125910689122975, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5714, loss: 0.019843965768814087, acc: 0.984375, recall: 0.8541666666666667, precision: 0.84375, f_beta: 0.8416666666666667\n",
      "train: step: 5715, loss: 0.015068544074892998, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666667\n",
      "train: step: 5716, loss: 0.01089886948466301, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5717, loss: 0.03547067195177078, acc: 0.984375, recall: 0.68359375, precision: 0.6796875, f_beta: 0.6813172043010753\n",
      "train: step: 5718, loss: 0.0034026268403977156, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5719, loss: 0.08044895529747009, acc: 0.984375, recall: 0.8055555555555556, precision: 0.8035714285714286, f_beta: 0.8040158371040724\n",
      "train: step: 5720, loss: 0.0010648518800735474, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5721, loss: 0.00022698401880916208, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5722, loss: 0.0004998173681087792, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5723, loss: 0.0010546519188210368, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5724, loss: 0.001073864521458745, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5725, loss: 0.015768198296427727, acc: 0.984375, recall: 0.8541666666666666, precision: 0.8660714285714286, f_beta: 0.8576923076923078\n",
      "train: step: 5726, loss: 0.002765200799331069, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5727, loss: 0.000539528438821435, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5728, loss: 0.00033285515382885933, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5729, loss: 0.0020969004835933447, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5730, loss: 0.0005336656467989087, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5731, loss: 0.0012533717090263963, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5732, loss: 0.000806715339422226, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5733, loss: 0.0022442652843892574, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5734, loss: 0.05368422344326973, acc: 0.984375, recall: 0.734375, precision: 0.7291666666666667, f_beta: 0.7285714285714286\n",
      "train: step: 5735, loss: 0.0004131841124035418, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5736, loss: 0.013779060915112495, acc: 0.984375, recall: 0.71875, precision: 0.7395833333333334, f_beta: 0.7234848484848485\n",
      "train: step: 5737, loss: 0.006704045459628105, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5738, loss: 0.0012516623828560114, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5739, loss: 0.00041784433415159583, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5740, loss: 0.0017527826130390167, acc: 1.0, recall: 1.0, precision: 1.0, f_beta: 1.0\n",
      "train: step: 5741, loss: 0.00042522704461589456, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5742, loss: 0.0030025795567780733, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5743, loss: 0.004062158055603504, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5744, loss: 0.0006080379243940115, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5745, loss: 0.002458242466673255, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5746, loss: 0.0008833179017528892, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5747, loss: 0.0012724457774311304, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5748, loss: 0.0011115805245935917, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5749, loss: 0.0062136282213032246, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5750, loss: 0.00041726656490936875, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5751, loss: 0.0017615542747080326, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5752, loss: 0.0010303673334419727, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5753, loss: 0.005827867891639471, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5754, loss: 0.0004046162066515535, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5755, loss: 0.015792468562722206, acc: 0.984375, recall: 0.7916666666666667, precision: 0.8076923076923077, f_beta: 0.7975000000000001\n",
      "train: step: 5756, loss: 0.0018798199016600847, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5757, loss: 0.0009970046812668443, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5758, loss: 0.0006759631214663386, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5759, loss: 0.012315788306295872, acc: 0.984375, recall: 0.8068181818181819, precision: 0.8076923076923077, f_beta: 0.8070238095238096\n",
      "train: step: 5760, loss: 0.0006729320739395916, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5761, loss: 0.012299695052206516, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5762, loss: 0.00116346450522542, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5763, loss: 0.0007331011584028602, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5764, loss: 0.0022972028236836195, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5765, loss: 0.00242178188636899, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5766, loss: 0.002022025641053915, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5767, loss: 0.007932616397738457, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5768, loss: 0.001571224071085453, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5769, loss: 0.0034301714040338993, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5770, loss: 0.004209517501294613, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5771, loss: 0.00772762531414628, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5772, loss: 0.04146364703774452, acc: 0.984375, recall: 0.7447916666666666, precision: 0.71875, f_beta: 0.7264492753623188\n",
      "train: step: 5773, loss: 0.03170594200491905, acc: 0.984375, recall: 0.8, precision: 0.8035714285714286, f_beta: 0.8007478632478633\n",
      "train: step: 5774, loss: 0.0006129289977252483, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5775, loss: 0.0023419875651597977, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5776, loss: 0.0019333132077008486, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5777, loss: 0.000509181059896946, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5778, loss: 0.005030149128288031, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5779, loss: 0.0768541768193245, acc: 0.96875, recall: 0.7135416666666666, precision: 0.71875, f_beta: 0.7056159420289856\n",
      "train: step: 5780, loss: 0.0011216592974960804, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5781, loss: 0.0007692859508097172, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5782, loss: 0.004494096152484417, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5783, loss: 0.0004518541682045907, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5784, loss: 0.0010311678051948547, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5785, loss: 0.06368130445480347, acc: 0.984375, recall: 0.796875, precision: 0.8046875, f_beta: 0.799404761904762\n",
      "train: step: 5786, loss: 0.0002983160666190088, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5787, loss: 0.0015164067735895514, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5788, loss: 0.015772037208080292, acc: 0.984375, recall: 0.796875, precision: 0.8125, f_beta: 0.8035714285714286\n",
      "train: step: 5789, loss: 0.0019329801434651017, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5790, loss: 0.0024550349917262793, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5791, loss: 0.028927668929100037, acc: 0.984375, recall: 0.796875, precision: 0.8055555555555556, f_beta: 0.7998949579831933\n",
      "train: step: 5792, loss: 0.0004922837833873928, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5793, loss: 0.0040181172080338, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5794, loss: 0.003655747277662158, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5795, loss: 0.04045715928077698, acc: 0.984375, recall: 0.8125, precision: 0.8, f_beta: 0.8055555555555556\n",
      "train: step: 5796, loss: 0.0028853558469563723, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 5797, loss: 0.0021983282640576363, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5798, loss: 0.0028393142856657505, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5799, loss: 0.1642359346151352, acc: 0.984375, recall: 0.71875, precision: 0.75, f_beta: 0.7291666666666666\n",
      "train: step: 5800, loss: 0.002746742917224765, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:14:44.725564, step: 5800, loss: 8.208564493391249, acc: 0.1597222222222222,precision: 0.07088313885188885, recall: 0.08694322855507067, f_beta: 0.06712947788946119\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5800\n",
      "\n",
      "train: step: 5801, loss: 0.010517927818000317, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5802, loss: 0.004208210855722427, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5803, loss: 0.0006990302354097366, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5804, loss: 0.002487714635208249, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5805, loss: 0.009074822068214417, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5806, loss: 0.015691237524151802, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5807, loss: 0.001864663790911436, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5808, loss: 0.001621732604689896, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5809, loss: 0.005571901798248291, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5810, loss: 0.0008623623289167881, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5811, loss: 0.00045114802196621895, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5812, loss: 0.006320101208984852, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5813, loss: 0.001271469285711646, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5814, loss: 0.06133900582790375, acc: 0.984375, recall: 0.71875, precision: 0.7291666666666667, f_beta: 0.7166666666666666\n",
      "train: step: 5815, loss: 0.003035223577171564, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5816, loss: 0.001592449378222227, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5817, loss: 0.0004494385211728513, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5818, loss: 0.005915425717830658, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5819, loss: 0.025312820449471474, acc: 0.984375, recall: 0.796875, precision: 0.80625, f_beta: 0.8002819548872181\n",
      "train: step: 5820, loss: 0.0010973510798066854, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5821, loss: 0.003157929051667452, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5822, loss: 0.0023233210667967796, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5823, loss: 0.0017085745930671692, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5824, loss: 0.000750322244130075, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5825, loss: 0.0010736522963270545, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5826, loss: 0.0007445528754033148, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5827, loss: 0.02136249467730522, acc: 0.984375, recall: 0.84375, precision: 0.8625, f_beta: 0.8472222222222223\n",
      "train: step: 5828, loss: 0.0013271099887788296, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5829, loss: 0.015001033432781696, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5830, loss: 0.0023991847410798073, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5831, loss: 0.000814802129752934, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5832, loss: 0.0006727976142428815, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5833, loss: 0.001450980082154274, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5834, loss: 0.009591002017259598, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5835, loss: 0.0006398817058652639, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5836, loss: 0.001353345694951713, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5837, loss: 0.014458127319812775, acc: 0.984375, recall: 0.78125, precision: 0.78125, f_beta: 0.7708333333333333\n",
      "train: step: 5838, loss: 0.009419484995305538, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5839, loss: 0.0021783290430903435, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5840, loss: 0.000782620394602418, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5841, loss: 0.005686604883521795, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5842, loss: 0.004559339489787817, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5843, loss: 0.0017704274505376816, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5844, loss: 0.01329817809164524, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5845, loss: 0.0006667199777439237, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5846, loss: 0.0005868814769200981, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5847, loss: 0.003199679311364889, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5848, loss: 0.004194172564893961, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5849, loss: 0.0033706710673868656, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5850, loss: 0.0004196679510641843, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5851, loss: 0.0008977780234999955, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5852, loss: 0.00031665380811318755, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5853, loss: 0.0017357394099235535, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5854, loss: 0.07583712786436081, acc: 0.984375, recall: 0.84375, precision: 0.8697916666666666, f_beta: 0.8514492753623188\n",
      "train: step: 5855, loss: 0.0374881885945797, acc: 0.96875, recall: 0.6666666666666666, precision: 0.65625, f_beta: 0.6541666666666667\n",
      "train: step: 5856, loss: 0.0004221889830660075, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5857, loss: 0.008601771667599678, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5858, loss: 0.05766407027840614, acc: 0.984375, recall: 0.9166666666666666, precision: 0.90625, f_beta: 0.9041666666666667\n",
      "train: step: 5859, loss: 0.009037944488227367, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5860, loss: 0.0015340547543019056, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5861, loss: 0.000885356217622757, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5862, loss: 0.0046437266282737255, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5863, loss: 0.00048397801583632827, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5864, loss: 0.00045566679909825325, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5865, loss: 0.0007157422369346023, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5866, loss: 0.0026192977093160152, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5867, loss: 0.0005750929703935981, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5868, loss: 0.0006840800633653998, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5869, loss: 0.0009821937419474125, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5870, loss: 0.0014144247397780418, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5871, loss: 0.0007334045367315412, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5872, loss: 0.0018282891251146793, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5873, loss: 0.0007598049705848098, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5874, loss: 0.005002086982131004, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5875, loss: 0.0026659586001187563, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5876, loss: 0.001029436243698001, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5877, loss: 0.0006742778932675719, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5878, loss: 0.0033954069949686527, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5879, loss: 0.0018681613728404045, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5880, loss: 0.00622376287356019, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 5881, loss: 0.0005468764575198293, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5882, loss: 0.0003232132876291871, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5883, loss: 0.002334244316443801, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5884, loss: 0.0014972616918385029, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5885, loss: 0.0003807864850386977, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5886, loss: 0.004596797749400139, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5887, loss: 0.011864621192216873, acc: 0.984375, recall: 0.75, precision: 0.71875, f_beta: 0.7291666666666666\n",
      "train: step: 5888, loss: 0.004318321589380503, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5889, loss: 0.002844844479113817, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5890, loss: 0.0022236339282244444, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5891, loss: 0.0003587427199818194, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5892, loss: 0.002370183588936925, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5893, loss: 0.0005036669317632914, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5894, loss: 0.0017283126944676042, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5895, loss: 0.0007317919516935945, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5896, loss: 0.0005471401382237673, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5897, loss: 0.0010507737752050161, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5898, loss: 0.0007683579460717738, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5899, loss: 0.001326915924437344, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5900, loss: 0.000620958162471652, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:16:36.967742, step: 5900, loss: 8.396620432535807, acc: 0.1684027777777778,precision: 0.07862845382840224, recall: 0.08916066572316572, f_beta: 0.07713312005089676\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-5900\n",
      "\n",
      "train: step: 5901, loss: 0.0014175984542816877, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5902, loss: 0.0010139468358829618, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5903, loss: 0.10094678401947021, acc: 0.96875, recall: 0.8973214285714286, precision: 0.9062500000000001, f_beta: 0.8936771561771562\n",
      "train: step: 5904, loss: 0.00021399020624812692, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5905, loss: 0.0011730187106877565, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5906, loss: 0.0007671142229810357, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5907, loss: 0.0007950930157676339, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5908, loss: 0.00028686830773949623, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5909, loss: 0.0003781281702686101, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5910, loss: 0.0033259792253375053, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5911, loss: 0.00025611312594264746, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5912, loss: 0.007005932740867138, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5913, loss: 0.0015580581966787577, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5914, loss: 0.0037293676286935806, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5915, loss: 0.0010224599391222, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5916, loss: 0.0003409499768167734, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5917, loss: 0.001242231111973524, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5918, loss: 0.007294061128050089, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5919, loss: 0.00051933090435341, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5920, loss: 0.0011981625575572252, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5921, loss: 0.0034862058237195015, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5922, loss: 0.000845789909362793, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5923, loss: 0.009212149307131767, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5924, loss: 0.0009911524830386043, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5925, loss: 0.0003581739729270339, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5926, loss: 0.001052144099958241, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5927, loss: 0.0006756718503311276, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5928, loss: 0.00028692212072201073, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5929, loss: 0.0005272618727758527, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5930, loss: 0.0007551473681814969, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5931, loss: 0.0005100569687783718, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5932, loss: 0.00023213730310089886, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5933, loss: 0.009634898044168949, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5934, loss: 0.011079761199653149, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5935, loss: 0.009342270903289318, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5936, loss: 0.00048046407755464315, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5937, loss: 0.0009478814899921417, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5938, loss: 0.00043787219328805804, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5939, loss: 0.00031093135476112366, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5940, loss: 0.0006848479388281703, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5941, loss: 0.0005996259860694408, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5942, loss: 0.00046909344382584095, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5943, loss: 0.000947360647842288, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5944, loss: 0.00037669221637770534, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5945, loss: 0.0019110218854621053, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5946, loss: 0.0007298787822946906, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5947, loss: 0.0007285786559805274, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5948, loss: 0.000524241360835731, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5949, loss: 0.0006009978242218494, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5950, loss: 0.0005209942464716733, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5951, loss: 0.0028592757880687714, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5952, loss: 0.0002605334739200771, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5953, loss: 0.00029352097772061825, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5954, loss: 0.0023894410114735365, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5955, loss: 0.0006544073112308979, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5956, loss: 0.0022622933611273766, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5957, loss: 0.0003185274836141616, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5958, loss: 0.0006547266966663301, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5959, loss: 0.0009778692619875073, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5960, loss: 0.001804121769964695, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5961, loss: 0.008354577235877514, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5962, loss: 0.0002824466209858656, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 5963, loss: 0.0005912065389566123, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5964, loss: 0.0006042838213033974, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "start training model\n",
      "train: step: 5965, loss: 0.0005180647713132203, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5966, loss: 0.001979220425710082, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5967, loss: 0.00043988984543830156, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5968, loss: 0.012003974989056587, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5969, loss: 0.0005975537933409214, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5970, loss: 0.11190687865018845, acc: 0.984375, recall: 0.7447916666666666, precision: 0.7447916666666667, f_beta: 0.7445652173913043\n",
      "train: step: 5971, loss: 0.00022302729485090822, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5972, loss: 0.00021816324442625046, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5973, loss: 0.0014713045675307512, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5974, loss: 0.0005074847722426057, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5975, loss: 0.0007424669456668198, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5976, loss: 0.003734464291483164, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 5977, loss: 0.006284922827035189, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5978, loss: 0.006262381095439196, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5979, loss: 0.0004684981540776789, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5980, loss: 0.07746680825948715, acc: 0.984375, recall: 0.7443181818181819, precision: 0.7463235294117647, f_beta: 0.7451298701298701\n",
      "train: step: 5981, loss: 0.0038004000671207905, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5982, loss: 0.012416965328156948, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5983, loss: 0.0012868208577856421, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5984, loss: 0.0007238595862872899, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5985, loss: 0.0006665380205959082, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5986, loss: 0.0010082925437018275, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5987, loss: 0.0011644420446828008, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5988, loss: 0.004457701928913593, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5989, loss: 0.004331690724939108, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 5990, loss: 0.0011110638733953238, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 5991, loss: 0.001610449398867786, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5992, loss: 0.0019735947716981173, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5993, loss: 0.00281604565680027, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5994, loss: 0.0021306751295924187, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5995, loss: 0.0003322301199659705, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5996, loss: 0.000533335143700242, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 5997, loss: 0.0005991647485643625, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 5998, loss: 0.001118829590268433, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 5999, loss: 0.02234496735036373, acc: 0.984375, recall: 0.6222826086956521, precision: 0.6145833333333333, f_beta: 0.617929292929293\n",
      "train: step: 6000, loss: 0.06028901785612106, acc: 0.984375, recall: 0.8068181818181818, precision: 0.8080357142857143, f_beta: 0.8072089947089948\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:18:28.711680, step: 6000, loss: 8.566284815470377, acc: 0.1579861111111111,precision: 0.08176841994243955, recall: 0.09254441432750256, f_beta: 0.07668224641130957\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6000\n",
      "\n",
      "train: step: 6001, loss: 0.001056871609762311, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6002, loss: 0.0010568061843514442, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6003, loss: 0.002066610846668482, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6004, loss: 0.0005448475712910295, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6005, loss: 0.0856781154870987, acc: 0.984375, recall: 0.6796875, precision: 0.6818181818181818, f_beta: 0.6803571428571429\n",
      "train: step: 6006, loss: 0.0003875716356560588, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6007, loss: 0.000536183244548738, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6008, loss: 0.018021799623966217, acc: 0.984375, recall: 0.675, precision: 0.6666666666666666, f_beta: 0.6680555555555556\n",
      "train: step: 6009, loss: 0.0009417107212357223, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6010, loss: 0.000622978201135993, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6011, loss: 0.003538812045007944, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6012, loss: 0.0012669319985434413, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6013, loss: 0.003092911560088396, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6014, loss: 0.001404674956575036, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6015, loss: 0.0005335150053724647, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6016, loss: 0.0003839056007564068, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6017, loss: 0.0012183610815554857, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6018, loss: 0.020304424688220024, acc: 0.984375, recall: 0.9296875, precision: 0.9333333333333333, f_beta: 0.9311781609195402\n",
      "train: step: 6019, loss: 0.000949172128457576, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6020, loss: 0.0014744040090590715, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6021, loss: 0.0010608157608658075, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6022, loss: 0.0012174081057310104, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6023, loss: 0.01488024927675724, acc: 0.984375, recall: 0.55625, precision: 0.5568181818181819, f_beta: 0.556234335839599\n",
      "train: step: 6024, loss: 0.0006696999771520495, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6025, loss: 0.0008311545243486762, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6026, loss: 0.0016345148906111717, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6027, loss: 0.0007469657575711608, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6028, loss: 0.002062941435724497, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6029, loss: 0.0004187943122815341, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6030, loss: 0.00041536259232088923, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6031, loss: 0.0018159556202590466, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6032, loss: 0.002113969763740897, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6033, loss: 0.0012568878009915352, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6034, loss: 0.0009177173487842083, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6035, loss: 0.008558930829167366, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6036, loss: 0.0014036098727956414, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6037, loss: 0.002076150383800268, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6038, loss: 0.00038047655834816396, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6039, loss: 0.0005905730067752302, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6040, loss: 0.0018719444051384926, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6041, loss: 0.0007416927255690098, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6042, loss: 0.002725789090618491, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6043, loss: 0.0004159155650995672, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6044, loss: 0.00033761761733330786, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6045, loss: 0.000754470587708056, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6046, loss: 0.0002533108345232904, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6047, loss: 0.00031311926431953907, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6048, loss: 0.001311725820414722, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 6049, loss: 0.0027579013258218765, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6050, loss: 0.0009486364433541894, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6051, loss: 0.0007762261666357517, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6052, loss: 0.00041819753823801875, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6053, loss: 0.000768467434681952, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6054, loss: 0.0008427267894148827, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6055, loss: 0.0004185014695394784, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6056, loss: 0.009713060222566128, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6057, loss: 0.015996936708688736, acc: 0.984375, recall: 0.8125, precision: 0.8, f_beta: 0.8055555555555556\n",
      "train: step: 6058, loss: 0.00042174727423116565, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6059, loss: 0.003721867222338915, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6060, loss: 0.00034983258228749037, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6061, loss: 0.0007801969768479466, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6062, loss: 0.000715347588993609, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6063, loss: 0.003490560920909047, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6064, loss: 0.00018594520224723965, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6065, loss: 0.00016459234757348895, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6066, loss: 0.0003429077041801065, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6067, loss: 0.00034388608764857054, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6068, loss: 0.00024576738360337913, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6069, loss: 0.00031058170134201646, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6070, loss: 0.0006571408594027162, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6071, loss: 0.00016986523405648768, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6072, loss: 0.0029795889277011156, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6073, loss: 0.00019436475122347474, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6074, loss: 0.0010799409355968237, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6075, loss: 0.006749759428203106, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6076, loss: 0.0005176234408281744, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6077, loss: 0.0016202724073082209, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6078, loss: 0.0014728512614965439, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6079, loss: 0.00023565420997329056, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6080, loss: 0.00019182129472028464, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6081, loss: 0.00032313447445631027, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6082, loss: 0.00031550691346637905, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6083, loss: 0.00018087108037434518, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6084, loss: 0.0019629441667348146, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6085, loss: 0.0006987676024436951, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6086, loss: 0.0009950059466063976, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6087, loss: 0.00034123245859518647, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6088, loss: 0.055498454719781876, acc: 0.984375, recall: 0.9375, precision: 0.921875, f_beta: 0.9285714285714286\n",
      "train: step: 6089, loss: 0.00017110948101617396, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6090, loss: 0.0005659231101162732, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6091, loss: 0.0002662966726347804, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6092, loss: 0.00041247939225286245, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6093, loss: 0.004766091238707304, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6094, loss: 0.0008993962546810508, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6095, loss: 0.0006561008049175143, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6096, loss: 0.041364386677742004, acc: 0.984375, recall: 0.6193181818181819, precision: 0.625, f_beta: 0.6220238095238095\n",
      "train: step: 6097, loss: 0.0018645926611497998, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6098, loss: 0.000898016442079097, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6099, loss: 0.002657681703567505, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6100, loss: 0.00039799572550691664, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:20:21.178726, step: 6100, loss: 8.494670126173231, acc: 0.14583333333333334,precision: 0.07397508027103615, recall: 0.08655416728333394, f_beta: 0.07216830147240184\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6100\n",
      "\n",
      "train: step: 6101, loss: 0.007770183030515909, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6102, loss: 0.0008236038847826421, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6103, loss: 0.0004857259918935597, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6104, loss: 0.002397426636889577, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6105, loss: 0.0031097112223505974, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6106, loss: 0.011759658344089985, acc: 0.984375, recall: 0.7410714285714286, precision: 0.7421875, f_beta: 0.7410256410256411\n",
      "train: step: 6107, loss: 0.0012161365011706948, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6108, loss: 0.0002909237227868289, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6109, loss: 0.0015570351388305426, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6110, loss: 0.0034493047278374434, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6111, loss: 0.0006559803150594234, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6112, loss: 0.0011383362580090761, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6113, loss: 0.0007445825031027198, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6114, loss: 0.006117312703281641, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6115, loss: 0.00026552414055913687, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6116, loss: 0.007640982046723366, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6117, loss: 0.00043023499893024564, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6118, loss: 0.0012132709380239248, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6119, loss: 0.0002714575966820121, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6120, loss: 0.01800697296857834, acc: 0.984375, recall: 0.74609375, precision: 0.71875, f_beta: 0.7271505376344086\n",
      "train: step: 6121, loss: 0.0007782895117998123, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6122, loss: 0.0011550283525139093, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6123, loss: 0.002841221634298563, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6124, loss: 0.003061118070036173, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6125, loss: 0.0018117825966328382, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6126, loss: 0.0033202236518263817, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6127, loss: 0.00024937797570601106, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6128, loss: 0.003445719601586461, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6129, loss: 0.0006189299747347832, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6130, loss: 0.000491598853841424, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6131, loss: 0.0016265840968117118, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6132, loss: 0.000773795647546649, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 6133, loss: 0.0009809352923184633, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6134, loss: 0.0008622665191069245, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6135, loss: 0.0010722305160015821, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6136, loss: 0.0003768088645301759, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6137, loss: 0.0005423900438472629, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6138, loss: 0.0005353811429813504, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6139, loss: 0.0008428115397691727, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6140, loss: 0.003949746023863554, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6141, loss: 0.001681937137618661, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6142, loss: 0.0006280625821091235, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6143, loss: 0.0004322461027186364, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6144, loss: 0.0007816717261448503, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6145, loss: 0.0005683884955942631, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6146, loss: 0.00046319657121784985, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6147, loss: 0.00030340682133100927, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6148, loss: 0.0011396849295124412, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6149, loss: 0.0004523274255916476, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6150, loss: 0.0019483384676277637, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6151, loss: 0.00036596704740077257, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6152, loss: 0.001379729830659926, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6153, loss: 0.001092886901460588, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6154, loss: 0.00037155294558033347, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6155, loss: 0.0005907794111408293, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6156, loss: 0.0008716356242075562, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6157, loss: 0.0004251645877957344, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6158, loss: 0.0001538308133604005, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6159, loss: 0.00029320974135771394, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6160, loss: 0.0014566151658073068, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6161, loss: 0.0014527655439451337, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6162, loss: 0.08843916654586792, acc: 0.984375, recall: 0.75, precision: 0.7443181818181819, f_beta: 0.7470238095238095\n",
      "train: step: 6163, loss: 0.0013732577208429575, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6164, loss: 0.00040219974471256137, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6165, loss: 0.0076270196586847305, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6166, loss: 0.00015812262427061796, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6167, loss: 0.00045274844160303473, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6168, loss: 0.0005838838405907154, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6169, loss: 0.0025022034533321857, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6170, loss: 0.01759154535830021, acc: 0.984375, recall: 0.68359375, precision: 0.6875, f_beta: 0.685483870967742\n",
      "train: step: 6171, loss: 0.0006404101150110364, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6172, loss: 0.008834454230964184, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6173, loss: 0.0007267338805831969, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6174, loss: 0.004429883323609829, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6175, loss: 0.001021752366796136, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6176, loss: 0.0009138032328337431, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6177, loss: 0.014459996484220028, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6178, loss: 0.0010675655212253332, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6179, loss: 0.0007038768962956965, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6180, loss: 0.0005185920745134354, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6181, loss: 0.0005429375451058149, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6182, loss: 0.0007180152460932732, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6183, loss: 0.0004105432890355587, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6184, loss: 0.0018562529003247619, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6185, loss: 0.0007126897107809782, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6186, loss: 0.0003664910327643156, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6187, loss: 0.009985550306737423, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6188, loss: 0.0004484782984945923, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6189, loss: 0.0003142266650684178, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6190, loss: 0.0008544783340767026, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6191, loss: 0.0005778253544121981, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6192, loss: 0.010736338794231415, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6193, loss: 0.005730945151299238, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6194, loss: 0.0003981255285907537, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6195, loss: 0.0004436018061824143, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6196, loss: 0.0003313059569336474, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6197, loss: 0.0008423575200140476, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6198, loss: 0.001133481739088893, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6199, loss: 0.015954039990901947, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6200, loss: 0.00042892206693068147, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:22:13.350367, step: 6200, loss: 8.583925353156197, acc: 0.17881944444444445,precision: 0.08545396692326518, recall: 0.09172062958827665, f_beta: 0.0796136352818339\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6200\n",
      "\n",
      "train: step: 6201, loss: 0.0003144645888824016, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6202, loss: 0.0013279516715556383, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6203, loss: 0.0002175710687879473, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6204, loss: 0.00036655727308243513, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6205, loss: 0.0006813876098021865, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6206, loss: 0.00025946259847842157, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6207, loss: 0.0006195002351887524, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6208, loss: 0.00010654898505890742, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6209, loss: 0.00018524291226640344, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6210, loss: 0.000665446394123137, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6211, loss: 0.00018812905182130635, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6212, loss: 0.0014116126112639904, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6213, loss: 0.005803273990750313, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6214, loss: 0.010237880982458591, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6215, loss: 0.0003464194305706769, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6216, loss: 0.00021434607333503664, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "start training model\n",
      "train: step: 6217, loss: 0.0001941968803294003, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6218, loss: 0.0008066649897955358, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6219, loss: 0.00012683232489507645, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6220, loss: 0.00031064398353919387, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6221, loss: 0.00011657451977953315, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6222, loss: 0.0006122809136286378, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6223, loss: 0.0008318632608279586, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6224, loss: 0.000379477278329432, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6225, loss: 0.0001906087709357962, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6226, loss: 0.0002221017930423841, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6227, loss: 0.00041965514537878335, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6228, loss: 0.0004263419541530311, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6229, loss: 0.001531699439510703, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6230, loss: 0.00031655034399591386, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6231, loss: 0.0013307095505297184, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6232, loss: 0.0010975160403177142, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6233, loss: 0.0677742287516594, acc: 0.984375, recall: 0.7455357142857143, precision: 0.7443181818181819, f_beta: 0.7447089947089948\n",
      "train: step: 6234, loss: 0.0055424487218260765, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6235, loss: 0.00042130271322093904, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6236, loss: 0.00024296225456055254, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6237, loss: 0.0017956201918423176, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6238, loss: 0.0004962224629707634, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6239, loss: 0.0006814252119511366, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6240, loss: 0.001983432797715068, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6241, loss: 0.0017733387649059296, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6242, loss: 0.0011194385588169098, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6243, loss: 0.003113438142463565, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6244, loss: 0.0158286914229393, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6245, loss: 0.001989864744246006, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6246, loss: 0.0005826110718771815, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6247, loss: 0.05361563339829445, acc: 0.984375, recall: 0.8072916666666666, precision: 0.80625, f_beta: 0.8064931350114417\n",
      "train: step: 6248, loss: 0.030552992597222328, acc: 0.984375, recall: 0.5625, precision: 0.546875, f_beta: 0.5535714285714286\n",
      "train: step: 6249, loss: 0.0003967700758948922, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6250, loss: 0.11902903020381927, acc: 0.984375, recall: 0.8035714285714286, precision: 0.8090277777777778, f_beta: 0.8059065934065934\n",
      "train: step: 6251, loss: 0.12023782730102539, acc: 0.984375, recall: 0.6770833333333334, precision: 0.6830357142857143, f_beta: 0.679503367003367\n",
      "train: step: 6252, loss: 0.0037627308629453182, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6253, loss: 0.002927617635577917, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6254, loss: 0.0031957169994711876, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6255, loss: 0.010303647257387638, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6256, loss: 0.0008654986741021276, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6257, loss: 0.0032072816975414753, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6258, loss: 0.06865426898002625, acc: 0.984375, recall: 0.7430555555555556, precision: 0.7291666666666666, f_beta: 0.7338235294117648\n",
      "train: step: 6259, loss: 0.0006705005653202534, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6260, loss: 0.0014979752013459802, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6261, loss: 0.015365677885711193, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6262, loss: 0.005735921673476696, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6263, loss: 0.002389236120507121, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6264, loss: 0.0013079915661364794, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6265, loss: 0.10741011053323746, acc: 0.984375, recall: 0.8645833333333334, precision: 0.86875, f_beta: 0.8660287081339714\n",
      "train: step: 6266, loss: 0.0021562855690717697, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6267, loss: 0.06370857357978821, acc: 0.953125, recall: 0.609375, precision: 0.6063034188034189, f_beta: 0.6057589285714285\n",
      "train: step: 6268, loss: 0.0030359020456671715, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6269, loss: 0.0012502619065344334, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6270, loss: 0.0032975985668599606, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6271, loss: 0.02720712311565876, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666667, f_beta: 0.8\n",
      "train: step: 6272, loss: 0.0015202229842543602, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6273, loss: 0.0009715787600725889, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6274, loss: 0.0015521285822615027, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6275, loss: 0.01033491175621748, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6276, loss: 0.0012274356558918953, acc: 1.0, recall: 1.0, precision: 1.0, f_beta: 1.0\n",
      "train: step: 6277, loss: 0.0007373030530288815, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6278, loss: 0.002186847385019064, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6279, loss: 0.0050805858336389065, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6280, loss: 0.10667884349822998, acc: 0.96875, recall: 0.71875, precision: 0.71875, f_beta: 0.7083333333333333\n",
      "train: step: 6281, loss: 0.0010930984281003475, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6282, loss: 0.0015900461003184319, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6283, loss: 0.006606814451515675, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6284, loss: 0.055022526532411575, acc: 0.984375, recall: 0.6666666666666667, precision: 0.6805555555555556, f_beta: 0.6713235294117648\n",
      "train: step: 6285, loss: 0.01324225589632988, acc: 0.984375, recall: 0.90625, precision: 0.9338235294117647, f_beta: 0.9147727272727273\n",
      "train: step: 6286, loss: 0.003187027759850025, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6287, loss: 0.001453356584534049, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6288, loss: 0.001986484508961439, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6289, loss: 0.0037986584939062595, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6290, loss: 0.0006554550491273403, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6291, loss: 0.0007917706971056759, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6292, loss: 0.0010317836422473192, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6293, loss: 0.025210630148649216, acc: 0.984375, recall: 0.78125, precision: 0.8, f_beta: 0.7847222222222223\n",
      "train: step: 6294, loss: 0.019217001274228096, acc: 0.984375, recall: 0.6213235294117647, precision: 0.625, f_beta: 0.6231060606060606\n",
      "train: step: 6295, loss: 0.013744780793786049, acc: 0.984375, recall: 0.68125, precision: 0.6822916666666666, f_beta: 0.6814931350114417\n",
      "train: step: 6296, loss: 0.006715745199471712, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6297, loss: 0.0024635139852762222, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6298, loss: 0.0022968470584601164, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6299, loss: 0.013696886599063873, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666666, f_beta: 0.8\n",
      "train: step: 6300, loss: 0.06333653628826141, acc: 0.96875, recall: 0.775, precision: 0.7875, f_beta: 0.773722020568663\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:24:04.622595, step: 6300, loss: 8.578112390306261, acc: 0.15625,precision: 0.07636478370724371, recall: 0.08751832658082657, f_beta: 0.07256589728677022\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6300\n",
      "\n",
      "start training model\n",
      "train: step: 6301, loss: 0.0010244623990729451, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6302, loss: 0.0004522841772995889, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6303, loss: 0.0020996255334466696, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6304, loss: 0.0003026761987712234, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6305, loss: 0.0012033040402457118, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6306, loss: 0.0014939975226297975, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6307, loss: 0.0002870493335649371, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6308, loss: 0.00031978642800822854, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6309, loss: 0.00043024649494327605, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6310, loss: 0.0009101683972403407, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6311, loss: 0.0038089891895651817, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6312, loss: 0.0007535728509537876, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6313, loss: 0.08838988095521927, acc: 0.984375, recall: 0.6041666666666666, precision: 0.6041666666666667, f_beta: 0.6\n",
      "train: step: 6314, loss: 0.0015126607613638043, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6315, loss: 0.0006626900867559016, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6316, loss: 0.0029646609909832478, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6317, loss: 0.0008347353432327509, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6318, loss: 0.004403383936733007, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6319, loss: 0.0037346137687563896, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6320, loss: 0.02118358388543129, acc: 0.984375, recall: 0.75, precision: 0.7410714285714286, f_beta: 0.7451923076923077\n",
      "train: step: 6321, loss: 0.000738507485948503, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6322, loss: 0.0007045353995636106, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6323, loss: 0.0010189360473304987, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6324, loss: 0.0023702685721218586, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6325, loss: 0.026410307735204697, acc: 0.984375, recall: 0.6830357142857143, precision: 0.6875, f_beta: 0.6851851851851851\n",
      "train: step: 6326, loss: 0.0013486533425748348, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6327, loss: 0.0007668114849366248, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6328, loss: 0.035309698432683945, acc: 0.984375, recall: 0.8046875, precision: 0.7916666666666666, f_beta: 0.7958333333333334\n",
      "train: step: 6329, loss: 0.0035211057402193546, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6330, loss: 0.0006391633069142699, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6331, loss: 0.01178400032222271, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6332, loss: 0.003383031114935875, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6333, loss: 0.0006606613751500845, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6334, loss: 0.03491286560893059, acc: 0.984375, recall: 0.75, precision: 0.7375, f_beta: 0.7430555555555556\n",
      "train: step: 6335, loss: 0.0896199494600296, acc: 0.984375, recall: 0.6770833333333333, precision: 0.6770833333333333, f_beta: 0.6761363636363636\n",
      "train: step: 6336, loss: 0.0011781969806179404, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6337, loss: 0.0005908927996642888, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6338, loss: 0.03848990052938461, acc: 0.96875, recall: 0.7254464285714286, precision: 0.75, f_beta: 0.7362637362637363\n",
      "train: step: 6339, loss: 0.0012176035670563579, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6340, loss: 0.03911621496081352, acc: 0.96875, recall: 0.671875, precision: 0.6833333333333333, f_beta: 0.6764162561576355\n",
      "train: step: 6341, loss: 0.0010665848385542631, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6342, loss: 0.00046418188139796257, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6343, loss: 0.030612807720899582, acc: 0.984375, recall: 0.6875, precision: 0.68359375, f_beta: 0.685483870967742\n",
      "train: step: 6344, loss: 0.046056635677814484, acc: 0.984375, recall: 0.75, precision: 0.74609375, f_beta: 0.747983870967742\n",
      "train: step: 6345, loss: 0.000929327099584043, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6346, loss: 0.01338442787528038, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6347, loss: 0.003957213833928108, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6348, loss: 0.010609354823827744, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6349, loss: 0.04816955700516701, acc: 0.984375, recall: 0.74375, precision: 0.7395833333333334, f_beta: 0.7410287081339713\n",
      "train: step: 6350, loss: 0.03981844708323479, acc: 0.984375, recall: 0.59375, precision: 0.625, f_beta: 0.6041666666666666\n",
      "train: step: 6351, loss: 0.00575864315032959, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6352, loss: 0.05434504523873329, acc: 0.984375, recall: 0.7447916666666666, precision: 0.7291666666666666, f_beta: 0.7347826086956523\n",
      "train: step: 6353, loss: 0.0016019429313018918, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6354, loss: 0.1422455608844757, acc: 0.984375, recall: 0.68125, precision: 0.6805555555555556, f_beta: 0.6805340557275542\n",
      "train: step: 6355, loss: 0.003267251653596759, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6356, loss: 0.0007168026641011238, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6357, loss: 0.03122054785490036, acc: 0.984375, recall: 0.625, precision: 0.61875, f_beta: 0.6217105263157895\n",
      "train: step: 6358, loss: 0.03323306515812874, acc: 0.984375, recall: 0.93125, precision: 0.925, f_beta: 0.9272660818713451\n",
      "train: step: 6359, loss: 0.0021391247864812613, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6360, loss: 0.019216440618038177, acc: 0.984375, recall: 0.8035714285714286, precision: 0.7916666666666666, f_beta: 0.7951923076923078\n",
      "train: step: 6361, loss: 0.03769218176603317, acc: 0.984375, recall: 0.65625, precision: 0.6818181818181818, f_beta: 0.6636904761904762\n",
      "train: step: 6362, loss: 0.00044931742013432086, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6363, loss: 0.0011994761880487204, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6364, loss: 0.023429838940501213, acc: 0.984375, recall: 0.7291666666666667, precision: 0.7430555555555556, f_beta: 0.7338235294117648\n",
      "train: step: 6365, loss: 0.002219663467258215, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6366, loss: 0.008546310476958752, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6367, loss: 0.018351050093770027, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6368, loss: 0.02412276156246662, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6369, loss: 0.031233541667461395, acc: 0.984375, recall: 0.859375, precision: 0.8541666666666667, f_beta: 0.8535714285714285\n",
      "train: step: 6370, loss: 0.029316158965229988, acc: 0.984375, recall: 0.8680555555555556, precision: 0.8671875, f_beta: 0.8671568627450981\n",
      "train: step: 6371, loss: 0.003149969968944788, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6372, loss: 0.06583502888679504, acc: 0.984375, recall: 0.8625, precision: 0.84375, f_beta: 0.8472222222222222\n",
      "train: step: 6373, loss: 0.006069740746170282, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6374, loss: 0.0007284565945155919, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6375, loss: 0.008149569854140282, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6376, loss: 0.00393351586535573, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6377, loss: 0.0011301639024168253, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6378, loss: 0.0011807084083557129, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6379, loss: 0.016662338748574257, acc: 0.984375, recall: 0.8645833333333334, precision: 0.8708333333333333, f_beta: 0.8671630094043887\n",
      "train: step: 6380, loss: 0.004214768297970295, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6381, loss: 0.0059830197133123875, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6382, loss: 0.001072637620382011, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6383, loss: 0.04129442945122719, acc: 0.984375, recall: 0.90625, precision: 0.90625, f_beta: 0.8958333333333334\n",
      "train: step: 6384, loss: 0.001247817650437355, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 6385, loss: 0.004414128139615059, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6386, loss: 0.09111974388360977, acc: 0.96875, recall: 0.8484848484848485, precision: 0.8536931818181818, f_beta: 0.8476190476190476\n",
      "train: step: 6387, loss: 0.1349967122077942, acc: 0.984375, recall: 0.78125, precision: 0.80625, f_beta: 0.7883771929824562\n",
      "train: step: 6388, loss: 0.0020538142416626215, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6389, loss: 0.0020418360363692045, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6390, loss: 0.0004884708323515952, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6391, loss: 0.004498316906392574, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6392, loss: 0.0007001449703238904, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6393, loss: 0.08966760337352753, acc: 0.984375, recall: 0.7916666666666667, precision: 0.8, f_beta: 0.7930555555555555\n",
      "train: step: 6394, loss: 0.0011128163896501064, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6395, loss: 0.06592068076133728, acc: 0.984375, recall: 0.7916666666666667, precision: 0.78125, f_beta: 0.7791666666666667\n",
      "train: step: 6396, loss: 0.004259991925209761, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6397, loss: 0.014445549808442593, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6398, loss: 0.01931188814342022, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6399, loss: 0.013678856194019318, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6400, loss: 0.008390983566641808, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:25:57.578271, step: 6400, loss: 7.5950972239176435, acc: 0.1701388888888889,precision: 0.08402024832052006, recall: 0.0960533486575153, f_beta: 0.08426181652866115\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6400\n",
      "\n",
      "train: step: 6401, loss: 0.0019673886708915234, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6402, loss: 0.004025929141789675, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6403, loss: 0.01626726984977722, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6404, loss: 0.1604122519493103, acc: 0.96875, recall: 0.8333333333333334, precision: 0.859375, f_beta: 0.8410326086956522\n",
      "train: step: 6405, loss: 0.00035425653913989663, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6406, loss: 0.006901834160089493, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6407, loss: 0.022288121283054352, acc: 0.984375, recall: 0.8671875, precision: 0.8671875, f_beta: 0.8666666666666667\n",
      "train: step: 6408, loss: 0.009793970733880997, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6409, loss: 0.001723762135952711, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6410, loss: 0.009757068008184433, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6411, loss: 0.007961111143231392, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6412, loss: 0.0031914329156279564, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6413, loss: 0.015107132494449615, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6414, loss: 0.01747998408973217, acc: 0.984375, recall: 0.7291666666666667, precision: 0.734375, f_beta: 0.7285714285714285\n",
      "train: step: 6415, loss: 0.010532218962907791, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6416, loss: 0.004130321554839611, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6417, loss: 0.0026038361247628927, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6418, loss: 0.0015601437771692872, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6419, loss: 0.003938020672649145, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6420, loss: 0.005627520848065615, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6421, loss: 0.014847731217741966, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6422, loss: 0.007881199941039085, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6423, loss: 0.003952407743781805, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6424, loss: 0.0015560871688649058, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6425, loss: 0.004013962112367153, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6426, loss: 0.0010546735720708966, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6427, loss: 0.009385495446622372, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6428, loss: 0.010319017805159092, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6429, loss: 0.0009433093946427107, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6430, loss: 0.010383239015936852, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6431, loss: 0.0024602848570793867, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6432, loss: 0.0014458387158811092, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6433, loss: 0.00686192512512207, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6434, loss: 0.0025520436465740204, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6435, loss: 0.0016462765634059906, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6436, loss: 0.027708521112799644, acc: 0.984375, recall: 0.7395833333333334, precision: 0.7421875, f_beta: 0.7401515151515152\n",
      "train: step: 6437, loss: 0.00821481179445982, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6438, loss: 0.0006320764659903944, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6439, loss: 0.000731829961296171, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6440, loss: 0.0020856335759162903, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6441, loss: 0.000804502225946635, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6442, loss: 0.0034566170070320368, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6443, loss: 0.0013495611492544413, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6444, loss: 0.0009751841425895691, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6445, loss: 0.0005296070012263954, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6446, loss: 0.15952849388122559, acc: 0.984375, recall: 0.71875, precision: 0.7410714285714286, f_beta: 0.7243589743589743\n",
      "train: step: 6447, loss: 0.0006252533057704568, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6448, loss: 0.0019047483801841736, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6449, loss: 0.0013917669421061873, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6450, loss: 0.001965872012078762, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6451, loss: 0.0007386785000562668, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6452, loss: 0.0023482171818614006, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6453, loss: 0.005445439368486404, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6454, loss: 0.013863991014659405, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6455, loss: 0.04720050096511841, acc: 0.984375, recall: 0.84375, precision: 0.8645833333333334, f_beta: 0.8484848484848484\n",
      "train: step: 6456, loss: 0.0008733975701034069, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6457, loss: 0.0016867185477167368, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6458, loss: 0.0005207925569266081, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6459, loss: 0.0005704406648874283, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6460, loss: 0.016056925058364868, acc: 0.984375, recall: 0.55, precision: 0.5625, f_beta: 0.5555555555555556\n",
      "train: step: 6461, loss: 0.000803471717517823, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6462, loss: 0.002217259258031845, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6463, loss: 0.16860443353652954, acc: 0.953125, recall: 0.7125, precision: 0.7291666666666666, f_beta: 0.7107142857142857\n",
      "train: step: 6464, loss: 0.0005971079226583242, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6465, loss: 0.002804873511195183, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6466, loss: 0.0011489619500935078, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6467, loss: 0.001916796318255365, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6468, loss: 0.0004156682698521763, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "start training model\n",
      "train: step: 6469, loss: 0.0007263403967954218, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6470, loss: 0.002932282630354166, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6471, loss: 0.06700919568538666, acc: 0.984375, recall: 0.6785714285714286, precision: 0.6796875, f_beta: 0.6785256410256411\n",
      "train: step: 6472, loss: 0.1457560956478119, acc: 0.984375, recall: 0.5520833333333334, precision: 0.5520833333333333, f_beta: 0.5511363636363636\n",
      "train: step: 6473, loss: 0.0017707634251564741, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6474, loss: 0.00092116225278005, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6475, loss: 0.00032128195744007826, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6476, loss: 0.004197283647954464, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6477, loss: 0.06108424812555313, acc: 0.984375, recall: 0.6875, precision: 0.675, f_beta: 0.6805555555555556\n",
      "train: step: 6478, loss: 0.00314338319003582, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6479, loss: 0.0011593354865908623, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6480, loss: 0.011860218830406666, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6481, loss: 0.00043668723083101213, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6482, loss: 0.004213760141283274, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6483, loss: 0.007459072396159172, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6484, loss: 0.0017350050620734692, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6485, loss: 0.0003017927519977093, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6486, loss: 0.00032225478207692504, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6487, loss: 0.002769782906398177, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6488, loss: 0.0015241201035678387, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6489, loss: 0.020231308415532112, acc: 0.984375, recall: 0.8645833333333334, precision: 0.8671875, f_beta: 0.8651515151515151\n",
      "train: step: 6490, loss: 0.008942662738263607, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6491, loss: 0.0012600114569067955, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6492, loss: 0.020610788837075233, acc: 0.984375, recall: 0.6805555555555556, precision: 0.675, f_beta: 0.6768790849673203\n",
      "train: step: 6493, loss: 0.002561559434980154, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6494, loss: 0.001039160299114883, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6495, loss: 0.0006954234559088945, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6496, loss: 0.001128127332776785, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6497, loss: 0.0015374480281025171, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6498, loss: 0.005905630998313427, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6499, loss: 0.003732681041583419, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6500, loss: 0.0005936091183684766, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:27:49.501383, step: 6500, loss: 8.077922927008736, acc: 0.1597222222222222,precision: 0.06933916336167367, recall: 0.08960302814469481, f_beta: 0.07349449063904473\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6500\n",
      "\n",
      "train: step: 6501, loss: 0.008016401901841164, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6502, loss: 0.0026214015670120716, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6503, loss: 0.000766389537602663, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6504, loss: 0.0004379187594167888, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6505, loss: 0.0012170602567493916, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6506, loss: 0.0007429125835187733, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6507, loss: 0.023605236783623695, acc: 0.984375, recall: 0.68125, precision: 0.6770833333333334, f_beta: 0.6785287081339713\n",
      "train: step: 6508, loss: 0.000395844312151894, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6509, loss: 0.0013609669404104352, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6510, loss: 0.00029516813810914755, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6511, loss: 0.0019132692832499743, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6512, loss: 0.0005040764226578176, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6513, loss: 0.0006481612799689174, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6514, loss: 0.00044749875087291, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6515, loss: 0.00040808855555951595, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6516, loss: 0.00757342716678977, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6517, loss: 0.001408835407346487, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6518, loss: 0.0005013635382056236, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6519, loss: 0.0008246091310866177, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6520, loss: 0.0004547038406599313, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6521, loss: 0.006135811097919941, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6522, loss: 0.006833107676357031, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6523, loss: 0.02586113102734089, acc: 0.984375, recall: 0.796875, precision: 0.8046875, f_beta: 0.799404761904762\n",
      "train: step: 6524, loss: 0.0005202001193538308, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6525, loss: 0.028646785765886307, acc: 0.984375, recall: 0.6822916666666667, precision: 0.6785714285714286, f_beta: 0.6799749163879598\n",
      "train: step: 6526, loss: 0.004298927262425423, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6527, loss: 0.0031072264537215233, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6528, loss: 0.019141245633363724, acc: 0.984375, recall: 0.78125, precision: 0.8125, f_beta: 0.7916666666666666\n",
      "train: step: 6529, loss: 0.07377884536981583, acc: 0.953125, recall: 0.846875, precision: 0.8375, f_beta: 0.8402125104427737\n",
      "train: step: 6530, loss: 0.0011275304714217782, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6531, loss: 0.014375027269124985, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6532, loss: 0.001015505287796259, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6533, loss: 0.0017995102098211646, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6534, loss: 0.0003422134614083916, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6535, loss: 0.0009789214236661792, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6536, loss: 0.010380672290921211, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6537, loss: 0.001602326869033277, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6538, loss: 0.0006423212471418083, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6539, loss: 0.00054381531663239, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6540, loss: 0.0004846354422625154, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6541, loss: 0.012565120123326778, acc: 0.984375, recall: 0.55, precision: 0.5568181818181819, f_beta: 0.5525793650793651\n",
      "train: step: 6542, loss: 0.00811512116342783, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6543, loss: 0.0064340573735535145, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6544, loss: 0.009591230191290379, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6545, loss: 0.002165315905585885, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6546, loss: 0.0010701705468818545, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6547, loss: 0.0007561659440398216, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6548, loss: 0.0010125687113031745, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6549, loss: 0.0012011975049972534, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6550, loss: 0.05587337538599968, acc: 0.984375, recall: 0.8020833333333334, precision: 0.80625, f_beta: 0.8035287081339713\n",
      "train: step: 6551, loss: 0.000833287718705833, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6552, loss: 0.028318488970398903, acc: 0.984375, recall: 0.734375, precision: 0.71875, f_beta: 0.7202380952380952\n",
      "start training model\n",
      "train: step: 6553, loss: 0.0059845177456736565, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6554, loss: 0.0003138344327453524, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6555, loss: 0.0007637552917003632, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6556, loss: 0.0037381614092737436, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6557, loss: 0.018723882734775543, acc: 0.984375, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6558, loss: 0.0015195305459201336, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6559, loss: 0.000763589225243777, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6560, loss: 0.000917597790248692, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6561, loss: 0.0008302369387820363, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6562, loss: 0.0012964957859367132, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6563, loss: 0.014173848554491997, acc: 0.984375, recall: 0.8055555555555556, precision: 0.8068181818181818, f_beta: 0.8058473389355743\n",
      "train: step: 6564, loss: 0.0011985576711595058, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6565, loss: 0.0006946347421035171, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6566, loss: 0.0017725327052175999, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6567, loss: 0.0009603381622582674, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6568, loss: 0.013496998697519302, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6569, loss: 0.0017820675857365131, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6570, loss: 0.047383714467287064, acc: 0.984375, recall: 0.8080357142857143, precision: 0.78125, f_beta: 0.7893518518518519\n",
      "train: step: 6571, loss: 0.00038198873517103493, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6572, loss: 0.005548169836401939, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6573, loss: 0.0010672903154045343, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6574, loss: 0.0023017735220491886, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6575, loss: 0.0021317375358194113, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6576, loss: 0.0025272842030972242, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6577, loss: 0.0017558372346684337, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6578, loss: 0.0031792037189006805, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6579, loss: 0.0007761797751300037, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6580, loss: 0.0008936273516155779, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6581, loss: 0.001564882812090218, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6582, loss: 0.00879412330687046, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6583, loss: 0.0024497241247445345, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6584, loss: 0.03195064887404442, acc: 0.984375, recall: 0.7455357142857143, precision: 0.7430555555555556, f_beta: 0.74400871459695\n",
      "train: step: 6585, loss: 0.0007621732074767351, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6586, loss: 0.0003337959060445428, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6587, loss: 0.0020498160738497972, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6588, loss: 0.03778999298810959, acc: 0.984375, recall: 0.7455357142857143, precision: 0.7410714285714286, f_beta: 0.7428774928774928\n",
      "train: step: 6589, loss: 0.0012417454272508621, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6590, loss: 0.0023510653991252184, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6591, loss: 0.0009533126140013337, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6592, loss: 0.002448570914566517, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6593, loss: 0.037861235439777374, acc: 0.96875, recall: 0.765625, precision: 0.8080357142857143, f_beta: 0.7804232804232805\n",
      "train: step: 6594, loss: 0.007734945043921471, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6595, loss: 0.0018687531119212508, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6596, loss: 0.0007250726921483874, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6597, loss: 0.0005478460807353258, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6598, loss: 0.002375970594584942, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6599, loss: 0.0005890672327950597, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6600, loss: 0.009908133186399937, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:29:41.186131, step: 6600, loss: 8.385949929555258, acc: 0.1736111111111111,precision: 0.07782077892533258, recall: 0.09098956906216321, f_beta: 0.07516887740043256\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6600\n",
      "\n",
      "train: step: 6601, loss: 0.0016727354377508163, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6602, loss: 0.010838530026376247, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6603, loss: 0.001155417412519455, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6604, loss: 0.001391461119055748, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6605, loss: 0.002984367311000824, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6606, loss: 0.0013681026175618172, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6607, loss: 0.0004981620004400611, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6608, loss: 0.013589469715952873, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6609, loss: 0.0007926167454570532, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6610, loss: 0.0009769232710823417, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6611, loss: 0.0006292485632002354, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6612, loss: 0.004429176449775696, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6613, loss: 0.028079358860850334, acc: 0.984375, recall: 0.65625, precision: 0.6875, f_beta: 0.6666666666666666\n",
      "train: step: 6614, loss: 0.06717420369386673, acc: 0.984375, recall: 0.8, precision: 0.8035714285714286, f_beta: 0.8007478632478633\n",
      "train: step: 6615, loss: 0.0018343308474868536, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6616, loss: 0.0019508055411279202, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6617, loss: 0.001337836030870676, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6618, loss: 0.0005358959315344691, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6619, loss: 0.0023609143681824207, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6620, loss: 0.004361777566373348, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6621, loss: 0.0005029398016631603, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6622, loss: 0.0014532621717080474, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6623, loss: 0.037868961691856384, acc: 0.984375, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6624, loss: 0.013213776051998138, acc: 0.984375, recall: 0.8125, precision: 0.7916666666666666, f_beta: 0.8\n",
      "train: step: 6625, loss: 0.000948893022723496, acc: 1.0, recall: 0.5, precision: 0.5, f_beta: 0.5\n",
      "train: step: 6626, loss: 0.0005232206895016134, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6627, loss: 0.004700484685599804, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6628, loss: 0.0003330649924464524, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6629, loss: 0.0007356556598097086, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6630, loss: 0.001130045740865171, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6631, loss: 0.0003335429646540433, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6632, loss: 0.00042273616418242455, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6633, loss: 0.0007330579683184624, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6634, loss: 0.04067761078476906, acc: 0.984375, recall: 0.6770833333333334, precision: 0.671875, f_beta: 0.6728896103896104\n",
      "train: step: 6635, loss: 0.002889364492148161, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6636, loss: 0.0013616940705105662, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "start training model\n",
      "train: step: 6637, loss: 0.000678431533742696, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6638, loss: 0.0011495532235130668, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6639, loss: 0.0017216650303453207, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6640, loss: 0.0005501864943653345, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6641, loss: 0.0006821158458478749, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6642, loss: 0.003296725684776902, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6643, loss: 0.0002755373134277761, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6644, loss: 0.0002475492365192622, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6645, loss: 0.0003705070121213794, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6646, loss: 0.00034307350870221853, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6647, loss: 0.06674560904502869, acc: 0.984375, recall: 0.8080357142857143, precision: 0.8055555555555556, f_beta: 0.80650871459695\n",
      "train: step: 6648, loss: 0.00025670917239040136, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6649, loss: 0.0006887206109240651, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6650, loss: 0.0006107860244810581, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6651, loss: 0.0002849106094799936, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6652, loss: 0.0003757894446607679, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6653, loss: 0.004571808036416769, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6654, loss: 0.00038469897117465734, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6655, loss: 0.0005018302472308278, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6656, loss: 0.0032677350100129843, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6657, loss: 0.05358457565307617, acc: 0.984375, recall: 0.75, precision: 0.7463235294117647, f_beta: 0.7481060606060606\n",
      "train: step: 6658, loss: 0.00018051854567602277, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6659, loss: 0.0008854478364810348, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6660, loss: 0.001279211137443781, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6661, loss: 0.0002473721688147634, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6662, loss: 0.00021318317158147693, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6663, loss: 0.00042550574289634824, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6664, loss: 0.0002753572480287403, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6665, loss: 0.0006207404076121747, acc: 1.0, recall: 0.5625, precision: 0.5625, f_beta: 0.5625\n",
      "train: step: 6666, loss: 0.14794275164604187, acc: 0.96875, recall: 0.6731770833333334, precision: 0.6796875, f_beta: 0.6756353861192571\n",
      "train: step: 6667, loss: 0.004894195590168238, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6668, loss: 0.044437579810619354, acc: 0.984375, recall: 0.625, precision: 0.609375, f_beta: 0.6160714285714286\n",
      "train: step: 6669, loss: 0.0011885357089340687, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6670, loss: 0.004525304306298494, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6671, loss: 0.0014297828311100602, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6672, loss: 0.00120936322491616, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6673, loss: 0.002579080406576395, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6674, loss: 0.00043306892621330917, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6675, loss: 0.0010554983746260405, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6676, loss: 0.002279857872053981, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6677, loss: 0.00470071192830801, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6678, loss: 0.002327247988432646, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6679, loss: 0.0005779809434898198, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6680, loss: 0.0012616843450814486, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6681, loss: 0.0013834517449140549, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6682, loss: 0.001676429994404316, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6683, loss: 0.000664681545458734, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6684, loss: 0.0008442613761872053, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6685, loss: 0.0011076303198933601, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6686, loss: 0.004972497932612896, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6687, loss: 0.04352114722132683, acc: 0.984375, recall: 0.6666666666666667, precision: 0.6833333333333333, f_beta: 0.6728448275862069\n",
      "train: step: 6688, loss: 0.029265165328979492, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6689, loss: 0.011257491074502468, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6690, loss: 0.0023809908889234066, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6691, loss: 0.003501717932522297, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6692, loss: 0.0004987913416698575, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6693, loss: 0.0005446746945381165, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6694, loss: 0.0008782553486526012, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6695, loss: 0.0021290085278451443, acc: 1.0, recall: 0.9375, precision: 0.9375, f_beta: 0.9375\n",
      "train: step: 6696, loss: 0.0028523022774606943, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6697, loss: 0.0008325442904606462, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6698, loss: 0.02584976516664028, acc: 0.984375, recall: 0.8, precision: 0.8020833333333334, f_beta: 0.7998737373737373\n",
      "train: step: 6699, loss: 0.0021802233532071114, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6700, loss: 0.001497361110523343, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2021-06-27T23:31:33.463919, step: 6700, loss: 8.317537943522135, acc: 0.16666666666666666,precision: 0.06991191059995884, recall: 0.08392173027589694, f_beta: 0.06984437369643894\n",
      "Saved model checkpoint to ./Bi-LSTM/model/my-model-6700\n",
      "\n",
      "train: step: 6701, loss: 0.00023381348000839353, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6702, loss: 0.00024810028844513, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6703, loss: 0.0005595551338046789, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6704, loss: 0.0016871560364961624, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6705, loss: 0.00044164323480799794, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6706, loss: 0.0008145314641296864, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6707, loss: 0.05444999411702156, acc: 0.984375, recall: 0.68125, precision: 0.65625, f_beta: 0.6633771929824562\n",
      "train: step: 6708, loss: 0.002018657047301531, acc: 1.0, recall: 0.875, precision: 0.875, f_beta: 0.875\n",
      "train: step: 6709, loss: 0.00014094656216911972, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6710, loss: 0.04859665408730507, acc: 0.984375, recall: 0.6666666666666666, precision: 0.6818181818181818, f_beta: 0.6720238095238095\n",
      "train: step: 6711, loss: 0.00031217580544762313, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6712, loss: 0.0002852070319931954, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6713, loss: 0.001238908269442618, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n",
      "train: step: 6714, loss: 0.004294598940759897, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6715, loss: 0.0008705086074769497, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6716, loss: 0.0010600235546007752, acc: 1.0, recall: 0.8125, precision: 0.8125, f_beta: 0.8125\n",
      "train: step: 6717, loss: 0.001449483330361545, acc: 1.0, recall: 0.625, precision: 0.625, f_beta: 0.625\n",
      "train: step: 6718, loss: 0.0002982856531161815, acc: 1.0, recall: 0.6875, precision: 0.6875, f_beta: 0.6875\n",
      "train: step: 6719, loss: 0.0006166441598907113, acc: 1.0, recall: 0.75, precision: 0.75, f_beta: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 23:31:54,893 : INFO : No assets to save.\n",
      "2021-06-27 23:31:54,894 : INFO : No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step: 6720, loss: 0.04987324774265289, acc: 0.96875, recall: 0.7139423076923077, precision: 0.7247023809523809, f_beta: 0.711851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 23:31:56,534 : INFO : SavedModel written to: ./Bi-LSTM/savedModel/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "\n",
    "# 生成训练集和验证集\n",
    "trainReviews = data.trainReviews\n",
    "trainLabels = data.trainLabels\n",
    "evalReviews = data.evalReviews\n",
    "evalLabels = data.evalLabels\n",
    "\n",
    "wordEmbedding = data.wordEmbedding\n",
    "labelList = data.labelList\n",
    "\n",
    "# 定义计算图\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    session_conf.gpu_options.allow_growth=True\n",
    "    session_conf.gpu_options.per_process_gpu_memory_fraction = 0.9  # 配置gpu占用率  \n",
    "\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    # 定义会话\n",
    "    with sess.as_default():\n",
    "        lstm = BiLSTM(config, wordEmbedding)\n",
    "        \n",
    "        globalStep = tf.Variable(0, name=\"globalStep\", trainable=False)\n",
    "        # 定义优化函数，传入学习速率参数\n",
    "        optimizer = tf.train.AdamOptimizer(config.training.learningRate)\n",
    "        # 计算梯度,得到梯度和变量\n",
    "        gradsAndVars = optimizer.compute_gradients(lstm.loss)\n",
    "        # 将梯度应用到变量下，生成训练器\n",
    "        trainOp = optimizer.apply_gradients(gradsAndVars, global_step=globalStep)\n",
    "        \n",
    "        # 用summary绘制tensorBoard\n",
    "        gradSummaries = []\n",
    "        for g, v in gradsAndVars:\n",
    "            if g is not None:\n",
    "                tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "        \n",
    "        outDir = os.path.abspath(os.path.join(os.path.curdir, \"summarys\"))\n",
    "        print(\"Writing to {}\\n\".format(outDir))\n",
    "        \n",
    "        lossSummary = tf.summary.scalar(\"loss\", lstm.loss)\n",
    "        summaryOp = tf.summary.merge_all()\n",
    "        \n",
    "        trainSummaryDir = os.path.join(outDir, \"train\")\n",
    "        trainSummaryWriter = tf.summary.FileWriter(trainSummaryDir, sess.graph)\n",
    "        \n",
    "        evalSummaryDir = os.path.join(outDir, \"eval\")\n",
    "        evalSummaryWriter = tf.summary.FileWriter(evalSummaryDir, sess.graph)\n",
    "        \n",
    "        \n",
    "        # 初始化所有变量\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=5)\n",
    "        \n",
    "        # 保存模型的一种方式，保存为pb文件\n",
    "        savedModelPath = \"./Bi-LSTM/savedModel\"\n",
    "        if os.path.exists(savedModelPath):\n",
    "            os.rmdir(savedModelPath)\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(savedModelPath)\n",
    "            \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def trainStep(batchX, batchY):\n",
    "            \"\"\"\n",
    "            训练函数\n",
    "            \"\"\"   \n",
    "            feed_dict = {\n",
    "              lstm.inputX: batchX,\n",
    "              lstm.inputY: batchY,\n",
    "              lstm.dropoutKeepProb: config.model.dropoutKeepProb\n",
    "            }\n",
    "            _, summary, step, loss, predictions = sess.run(\n",
    "                [trainOp, summaryOp, globalStep, lstm.loss, lstm.predictions],\n",
    "                feed_dict)\n",
    "            \n",
    "            timeStr = datetime.datetime.now().isoformat()\n",
    "            \n",
    "            if config.numClasses == 1:\n",
    "                acc, recall, prec, f_beta = get_binary_metrics(pred_y=predictions, true_y=batchY)\n",
    "                \n",
    "            elif config.numClasses > 1:\n",
    "                acc, recall, prec, f_beta = get_multi_metrics(pred_y=predictions, true_y=batchY,\n",
    "                                                              labels=labelList)\n",
    "                \n",
    "            trainSummaryWriter.add_summary(summary, step)\n",
    "            \n",
    "            return loss, acc, prec, recall, f_beta\n",
    "\n",
    "        def devStep(batchX, batchY):\n",
    "            \"\"\"\n",
    "            验证函数\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              lstm.inputX: batchX,\n",
    "              lstm.inputY: batchY,\n",
    "              lstm.dropoutKeepProb: 1.0\n",
    "            }\n",
    "            summary, step, loss, predictions = sess.run(\n",
    "                [summaryOp, globalStep, lstm.loss, lstm.predictions],\n",
    "                feed_dict)\n",
    "            \n",
    "            if config.numClasses == 1:\n",
    "            \n",
    "                acc, precision, recall, f_beta = get_binary_metrics(pred_y=predictions, true_y=batchY)\n",
    "            elif config.numClasses > 1:\n",
    "                acc, precision, recall, f_beta = get_multi_metrics(pred_y=predictions, true_y=batchY, labels=labelList)\n",
    "            \n",
    "            evalSummaryWriter.add_summary(summary, step)\n",
    "            \n",
    "            return loss, acc, precision, recall, f_beta\n",
    "        \n",
    "        for i in range(config.training.epoches):\n",
    "            # 训练模型\n",
    "            print(\"start training model\")\n",
    "            for batchTrain in nextBatch(trainReviews, trainLabels, config.batchSize):\n",
    "                loss, acc, prec, recall, f_beta = trainStep(batchTrain[0], batchTrain[1])\n",
    "                \n",
    "                currentStep = tf.train.global_step(sess, globalStep) \n",
    "                print(\"train: step: {}, loss: {}, acc: {}, recall: {}, precision: {}, f_beta: {}\".format(\n",
    "                    currentStep, loss, acc, recall, prec, f_beta))\n",
    "                if currentStep % config.training.evaluateEvery == 0:\n",
    "                    print(\"\\nEvaluation:\")\n",
    "                    \n",
    "                    losses = []\n",
    "                    accs = []\n",
    "                    f_betas = []\n",
    "                    precisions = []\n",
    "                    recalls = []\n",
    "                    \n",
    "                    for batchEval in nextBatch(evalReviews, evalLabels, config.batchSize):\n",
    "                        loss, acc, precision, recall, f_beta = devStep(batchEval[0], batchEval[1])\n",
    "                        losses.append(loss)\n",
    "                        accs.append(acc)\n",
    "                        f_betas.append(f_beta)\n",
    "                        precisions.append(precision)\n",
    "                        recalls.append(recall)\n",
    "                        \n",
    "                    time_str = datetime.datetime.now().isoformat()\n",
    "                    print(\"{}, step: {}, loss: {}, acc: {},precision: {}, recall: {}, f_beta: {}\".format(time_str, currentStep, mean(losses), \n",
    "                                                                                                       mean(accs), mean(precisions),\n",
    "                                                                                                       mean(recalls), mean(f_betas)))\n",
    "                    \n",
    "                if currentStep % config.training.checkpointEvery == 0:\n",
    "                    # 保存模型的另一种方法，保存checkpoint文件\n",
    "                    path = saver.save(sess, \"./Bi-LSTM/model/my-model\", global_step=currentStep)\n",
    "                    print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "                    \n",
    "        inputs = {\"inputX\": tf.saved_model.utils.build_tensor_info(lstm.inputX),\n",
    "                  \"keepProb\": tf.saved_model.utils.build_tensor_info(lstm.dropoutKeepProb)}\n",
    "\n",
    "        outputs = {\"predictions\": tf.saved_model.utils.build_tensor_info(lstm.predictions)}\n",
    "\n",
    "        prediction_signature = tf.saved_model.signature_def_utils.build_signature_def(inputs=inputs, outputs=outputs,\n",
    "                                                                                      method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "        legacy_init_op = tf.group(tf.tables_initializer(), name=\"legacy_init_op\")\n",
    "        builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING],\n",
    "                                            signature_def_map={\"predict\": prediction_signature}, legacy_init_op=legacy_init_op)\n",
    "\n",
    "        builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "feaa83df-2a87-4535-b020-9151d0604636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/data/workdata/summarys\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/data/workdata/summarys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d66254-a49a-442f-9961-39b34e2b9468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Removing leading `/' from member names\n",
      "/workdir/data/workdata/\n",
      "/workdir/data/workdata/summarys-old/\n",
      "/workdir/data/workdata/summarys-old/eval/\n",
      "/workdir/data/workdata/summarys-old/eval/events.out.tfevents.1624789878.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys-old/eval/events.out.tfevents.1624793818.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys-old/eval/events.out.tfevents.1624797243.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys-old/eval/events.out.tfevents.1624794409.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys-old/eval/events.out.tfevents.1624794312.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys-old/eval/events.out.tfevents.1624795602.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys-old/.ipynb_checkpoints/\n",
      "/workdir/data/workdata/summarys-old/train/\n",
      "/workdir/data/workdata/summarys-old/train/.ipynb_checkpoints/\n",
      "/workdir/data/workdata/summarys-old/train/events.out.tfevents.1624797241.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/mbti_test.csv\n",
      "/workdir/data/workdata/Bi-LSTM/\n",
      "/workdir/data/workdata/Bi-LSTM/model/\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6500.data-00000-of-00001\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6600.index\n",
      "/workdir/data/workdata/Bi-LSTM/model/checkpoint\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6700.index\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6500.meta\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6700.meta\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6400.data-00000-of-00001\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6500.index\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6700.data-00000-of-00001\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6300.index\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6300.data-00000-of-00001\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6600.data-00000-of-00001\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6400.index\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6400.meta\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6300.meta\n",
      "/workdir/data/workdata/Bi-LSTM/model/my-model-6600.meta\n",
      "/workdir/data/workdata/Bi-LSTM/savedModel/\n",
      "/workdir/data/workdata/Bi-LSTM/savedModel/saved_model.pb\n",
      "/workdir/data/workdata/Bi-LSTM/savedModel/variables/\n",
      "/workdir/data/workdata/Bi-LSTM/savedModel/variables/variables.data-00000-of-00001\n",
      "/workdir/data/workdata/Bi-LSTM/savedModel/variables/variables.index\n",
      "/workdir/data/workdata/mbti_train.csv\n",
      "/workdir/data/workdata/summarys/\n",
      "/workdir/data/workdata/summarys/eval/\n",
      "/workdir/data/workdata/summarys/eval/events.out.tfevents.1624800380.zw03-data-hdp-dn-gpu0363.mt\n",
      "/workdir/data/workdata/summarys/train/\n",
      "/workdir/data/workdata/summarys/train/events.out.tfevents.1624800378.zw03-data-hdp-dn-gpu0363.mt\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf /workdir/data/workdata.tar /workdir/data/workdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "07e09a65-07b5-4343-89b7-c0bb9c95ca8b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12347), started 2:19:00 ago. (Use '!kill 12347' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2c1079cbdef3f8d1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2c1079cbdef3f8d1\");\n",
       "          const url = new URL(\"/mtjupyter/user/liuminwen/proxy/absolute/6006/\", window.location);\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard_compat --logdir /workdir/data/workdata/summarys/train/ --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "efaf5be0-6fd7-419e-a314-5821cd1a1dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 23:47:11,460 : INFO : Restoring parameters from ./Bi-LSTM/model/my-model-6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISFP']\n"
     ]
    }
   ],
   "source": [
    "x = \"this movie is full of references like mad max ii the wild one and many others the ladybug´s face it´s a clear reference or tribute to peter lorre this movie is a masterpiece we´ll talk much more about in the future\"\n",
    "\n",
    "# 注：下面两个词典要保证和当前加载的模型对应的词典是一致的\n",
    "with open(\"./wordJson/word2idx.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    word2idx = json.load(f)\n",
    "        \n",
    "with open(\"./wordJson/label2idx.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    label2idx = json.load(f)\n",
    "idx2label = {value: key for key, value in label2idx.items()}\n",
    "    \n",
    "xIds = [word2idx.get(item, word2idx[\"UNK\"]) for item in x.split(\" \")]\n",
    "if len(xIds) >= config.sequenceLength:\n",
    "    xIds = xIds[:config.sequenceLength]\n",
    "else:\n",
    "    xIds = xIds + [word2idx[\"PAD\"]] * (config.sequenceLength - len(xIds))\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, gpu_options=gpu_options)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "\n",
    "    with sess.as_default():\n",
    "        checkpoint_file = tf.train.latest_checkpoint(\"./Bi-LSTM/model/\")\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "        saver.restore(sess, checkpoint_file)\n",
    "\n",
    "        # 获得需要喂给模型的参数，输出的结果依赖的输入值\n",
    "        inputX = graph.get_operation_by_name(\"inputX\").outputs[0]\n",
    "        dropoutKeepProb = graph.get_operation_by_name(\"dropoutKeepProb\").outputs[0]\n",
    "\n",
    "        # 获得输出的结果\n",
    "        predictions = graph.get_tensor_by_name(\"output/predictions:0\")\n",
    "\n",
    "        pred = sess.run(predictions, feed_dict={inputX: [xIds], dropoutKeepProb: 1.0})\n",
    "        \n",
    "pred = [idx2label[item] for item in pred]     \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fad7719e-28c2-42e2-bd84-64145a1da5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ISFJ',\n",
       " 1: 'INTJ',\n",
       " 2: 'ENFP',\n",
       " 3: 'ESFP',\n",
       " 4: 'ESTJ',\n",
       " 5: 'ESFJ',\n",
       " 6: 'ESTP',\n",
       " 7: 'ISFP',\n",
       " 8: 'ISTJ',\n",
       " 9: 'ENFJ',\n",
       " 10: 'ISTP',\n",
       " 11: 'INFJ',\n",
       " 12: 'INFP',\n",
       " 13: 'ENTP',\n",
       " 14: 'ENTJ',\n",
       " 15: 'INTP'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
